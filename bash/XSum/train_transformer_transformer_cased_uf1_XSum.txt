nohup: ignoring input
2022-10-19 17:04:17 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:12352
2022-10-19 17:04:17 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:12352
2022-10-19 17:04:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2022-10-19 17:04:17 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:12352
2022-10-19 17:04:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2022-10-19 17:04:17 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:12352
2022-10-19 17:04:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-19 17:04:17 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-19 17:04:17 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-10-19 17:04:17 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 0
2022-10-19 17:04:17 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-10-19 17:04:17 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 1
2022-10-19 17:04:17 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-10-19 17:04:17 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 2
2022-10-19 17:04:17 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-10-19 17:04:17 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 3
2022-10-19 17:04:20 | INFO | fairseq_cli.train | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir='', seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, criterion='nat_loss', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', task='translation_lev', num_workers=0, skip_invalid_size_inputs_valid_test=True, max_tokens=8000, max_sentences=None, required_batch_size_multiple=8, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, fixed_validation_seed=7, disable_validation=False, max_tokens_valid=8000, max_sentences_valid=None, curriculum=0, distributed_world_size=4, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:12352', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, arch='kpe_editor_transformer_with_adapter', max_epoch=0, max_update=300000, clip_norm=25, sentence_avg=False, update_freq=[1], lr=[0.0005], min_lr=1e-09, use_bmuf=False, save_dir='../checkpoints_transformer_transformer_cased_uf1_XSum', restore_file='checkpoint_last.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, no_token_positional_embeddings=False, no_cross_attention=False, cross_self_attention=False, encoder_layerdrop=0, decoder_layerdrop=0, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, early_exit='6,6,6', layers_num='6,6,6', finetune_embeddings=False, finetune_whole_encoder=False, decoder_adapter_dimention=2048, finetune_position_embeddings=False, use_adapter_bert=False, keywords_num=40, constraint=False, label_smoothing=0.1, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, warmup_updates=10000, warmup_init_lr=1e-07, data='../data-bin-bert-cased-XSum', source_lang=None, target_lang=None, load_alignments=False, left_pad_source='False', left_pad_target='False', max_source_positions=2048, max_target_positions=512, upsample_primary=1, truncate_source=False, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, noise='random_delete_shuffle', random_seed=1, cached_features_dir='../cached_examples_bert_cased_510_XSum', tokenizer_dir='/data/yukangliang/预训练模型/bert-base-cased', encoder_adapter_dimention=2048, decoder_input='target', kpe=False, share_all_embeddings=True, no_share_discriminator=True, dropout=0.3, decoder_learned_pos=True, encoder_learned_pos=True, apply_bert_init=True, cache_dir='/data/yukangliang/预训练模型/bert-base-cased', decoder_cache_dir='/data/yukangliang/预训练模型/bert-base-cased-decoder', share_decoder_input_output_embed=False, encoder='transformer', decoder='transformer', keywords_gran='token', encoder_embed_path=None, encoder_embed_dim=768, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_attention_heads=8, encoder_normalize_before=False, decoder_embed_path=None, decoder_embed_dim=768, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_input=False, decoder_output_dim=768, decoder_input_dim=768, no_share_maskpredictor=False, share_discriminator_maskpredictor=False, no_share_last_layer=False, cached_dir='/data/yukangliang/预训练模型/bert-base-cased')
2022-10-19 17:04:21 | INFO | fairseq.tasks.translation | [source] dictionary: 28996 types
2022-10-19 17:04:21 | INFO | fairseq.tasks.translation | [target] dictionary: 28996 types
2022-10-19 17:04:21 | INFO | fairseq.data.data_utils | loaded 11332 examples from: ../data-bin-bert-cased-XSum/valid.source-target.source
2022-10-19 17:04:21 | INFO | fairseq.data.data_utils | loaded 11332 examples from: ../data-bin-bert-cased-XSum/valid.source-target.target
2022-10-19 17:04:21 | INFO | fairseq.tasks.translation | ../data-bin-bert-cased-XSum valid source-target 11332 examples
2022-10-19 17:04:21 | INFO | transformer.configuration_utils | loading configuration file /data/yukangliang/预训练模型/bert-base-cased/config.json
2022-10-19 17:04:21 | INFO | transformer.configuration_utils | Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 2048,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "pruned_heads": {},
  "torchscript": false,
  "transformers_version": "4.6.0.dev0",
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "use_cache": true,
  "vocab_size": 28996
}

Trained parameters: len 412
Trained parameters: ['encoder.embed_tokens.weight', 'encoder.embed_positions.weight', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.layers.2.self_attn.k_proj.bias', 'encoder.layers.2.self_attn.v_proj.weight', 'encoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'encoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.3.fc1.bias', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.fc2.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.weight', 'encoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.4.self_attn.v_proj.weight', 'encoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.4.self_attn_layer_norm.bias', 'encoder.layers.4.fc1.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.4.fc2.weight', 'encoder.layers.4.fc2.bias', 'encoder.layers.4.final_layer_norm.weight', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.5.self_attn.k_proj.bias', 'encoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.5.fc1.weight', 'encoder.layers.5.fc1.bias', 'encoder.layers.5.fc2.weight', 'encoder.layers.5.fc2.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.final_layer_norm.bias', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.encoder_attn.k_proj.weight', 'decoder.layers_reposition.0.encoder_attn.k_proj.bias', 'decoder.layers_reposition.0.encoder_attn.v_proj.weight', 'decoder.layers_reposition.0.encoder_attn.v_proj.bias', 'decoder.layers_reposition.0.encoder_attn.q_proj.weight', 'decoder.layers_reposition.0.encoder_attn.q_proj.bias', 'decoder.layers_reposition.0.encoder_attn.out_proj.weight', 'decoder.layers_reposition.0.encoder_attn.out_proj.bias', 'decoder.layers_reposition.0.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.0.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.encoder_attn.k_proj.weight', 'decoder.layers_reposition.1.encoder_attn.k_proj.bias', 'decoder.layers_reposition.1.encoder_attn.v_proj.weight', 'decoder.layers_reposition.1.encoder_attn.v_proj.bias', 'decoder.layers_reposition.1.encoder_attn.q_proj.weight', 'decoder.layers_reposition.1.encoder_attn.q_proj.bias', 'decoder.layers_reposition.1.encoder_attn.out_proj.weight', 'decoder.layers_reposition.1.encoder_attn.out_proj.bias', 'decoder.layers_reposition.1.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.1.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.encoder_attn.k_proj.weight', 'decoder.layers_reposition.2.encoder_attn.k_proj.bias', 'decoder.layers_reposition.2.encoder_attn.v_proj.weight', 'decoder.layers_reposition.2.encoder_attn.v_proj.bias', 'decoder.layers_reposition.2.encoder_attn.q_proj.weight', 'decoder.layers_reposition.2.encoder_attn.q_proj.bias', 'decoder.layers_reposition.2.encoder_attn.out_proj.weight', 'decoder.layers_reposition.2.encoder_attn.out_proj.bias', 'decoder.layers_reposition.2.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.2.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.encoder_attn.k_proj.weight', 'decoder.layers_reposition.3.encoder_attn.k_proj.bias', 'decoder.layers_reposition.3.encoder_attn.v_proj.weight', 'decoder.layers_reposition.3.encoder_attn.v_proj.bias', 'decoder.layers_reposition.3.encoder_attn.q_proj.weight', 'decoder.layers_reposition.3.encoder_attn.q_proj.bias', 'decoder.layers_reposition.3.encoder_attn.out_proj.weight', 'decoder.layers_reposition.3.encoder_attn.out_proj.bias', 'decoder.layers_reposition.3.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.3.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.encoder_attn.k_proj.weight', 'decoder.layers_reposition.4.encoder_attn.k_proj.bias', 'decoder.layers_reposition.4.encoder_attn.v_proj.weight', 'decoder.layers_reposition.4.encoder_attn.v_proj.bias', 'decoder.layers_reposition.4.encoder_attn.q_proj.weight', 'decoder.layers_reposition.4.encoder_attn.q_proj.bias', 'decoder.layers_reposition.4.encoder_attn.out_proj.weight', 'decoder.layers_reposition.4.encoder_attn.out_proj.bias', 'decoder.layers_reposition.4.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.4.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.encoder_attn.k_proj.weight', 'decoder.layers_reposition.5.encoder_attn.k_proj.bias', 'decoder.layers_reposition.5.encoder_attn.v_proj.weight', 'decoder.layers_reposition.5.encoder_attn.v_proj.bias', 'decoder.layers_reposition.5.encoder_attn.q_proj.weight', 'decoder.layers_reposition.5.encoder_attn.q_proj.bias', 'decoder.layers_reposition.5.encoder_attn.out_proj.weight', 'decoder.layers_reposition.5.encoder_attn.out_proj.bias', 'decoder.layers_reposition.5.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.5.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
Trained parameters not adapter: len 292
Trained parameters not adapter: ['encoder.embed_tokens.weight', 'encoder.embed_positions.weight', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.layers.2.self_attn.k_proj.bias', 'encoder.layers.2.self_attn.v_proj.weight', 'encoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'encoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.3.fc1.bias', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.fc2.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.weight', 'encoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.4.self_attn.v_proj.weight', 'encoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.4.self_attn_layer_norm.bias', 'encoder.layers.4.fc1.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.4.fc2.weight', 'encoder.layers.4.fc2.bias', 'encoder.layers.4.final_layer_norm.weight', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.5.self_attn.k_proj.bias', 'encoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.5.fc1.weight', 'encoder.layers.5.fc1.bias', 'encoder.layers.5.fc2.weight', 'encoder.layers.5.fc2.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.final_layer_norm.bias', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
2022-10-19 17:04:23 | INFO | fairseq_cli.train | KPEEDITORTransformerModel(
  (encoder): EditorTransformerEncoder(
    (embed_tokens): Embedding(28996, 768, padding_idx=0)
    (embed_positions): LearnedPositionalEmbedding(2049, 768, padding_idx=0)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): EditorTransformerDecoder(
    (embed_tokens): Embedding(28996, 768, padding_idx=0)
    (embed_positions): LearnedPositionalEmbedding(513, 768, padding_idx=0)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=28996, bias=False)
    (embed_mask_ins): Embedding(256, 1536)
    (layers_reposition): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
2022-10-19 17:04:23 | INFO | fairseq_cli.train | model kpe_editor_transformer_with_adapter, criterion LabelSmoothedDualImitationCriterion
2022-10-19 17:04:23 | INFO | fairseq_cli.train | num. model params: 152248320 (num. trained: 152248320)
2022-10-19 17:04:23 | INFO | fairseq_cli.train | num. Encoder model params: 56926464 (Encoder num. trained: 56926464)
2022-10-19 17:04:23 | INFO | fairseq_cli.train | num. Decoder model params: 117590784 (Decoder num. trained: 117590784)
Trained parameters: len 412
Trained parameters: ['encoder.embed_tokens.weight', 'encoder.embed_positions.weight', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.layers.2.self_attn.k_proj.bias', 'encoder.layers.2.self_attn.v_proj.weight', 'encoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'encoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.3.fc1.bias', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.fc2.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.weight', 'encoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.4.self_attn.v_proj.weight', 'encoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.4.self_attn_layer_norm.bias', 'encoder.layers.4.fc1.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.4.fc2.weight', 'encoder.layers.4.fc2.bias', 'encoder.layers.4.final_layer_norm.weight', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.5.self_attn.k_proj.bias', 'encoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.5.fc1.weight', 'encoder.layers.5.fc1.bias', 'encoder.layers.5.fc2.weight', 'encoder.layers.5.fc2.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.final_layer_norm.bias', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.encoder_attn.k_proj.weight', 'decoder.layers_reposition.0.encoder_attn.k_proj.bias', 'decoder.layers_reposition.0.encoder_attn.v_proj.weight', 'decoder.layers_reposition.0.encoder_attn.v_proj.bias', 'decoder.layers_reposition.0.encoder_attn.q_proj.weight', 'decoder.layers_reposition.0.encoder_attn.q_proj.bias', 'decoder.layers_reposition.0.encoder_attn.out_proj.weight', 'decoder.layers_reposition.0.encoder_attn.out_proj.bias', 'decoder.layers_reposition.0.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.0.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.encoder_attn.k_proj.weight', 'decoder.layers_reposition.1.encoder_attn.k_proj.bias', 'decoder.layers_reposition.1.encoder_attn.v_proj.weight', 'decoder.layers_reposition.1.encoder_attn.v_proj.bias', 'decoder.layers_reposition.1.encoder_attn.q_proj.weight', 'decoder.layers_reposition.1.encoder_attn.q_proj.bias', 'decoder.layers_reposition.1.encoder_attn.out_proj.weight', 'decoder.layers_reposition.1.encoder_attn.out_proj.bias', 'decoder.layers_reposition.1.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.1.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.encoder_attn.k_proj.weight', 'decoder.layers_reposition.2.encoder_attn.k_proj.bias', 'decoder.layers_reposition.2.encoder_attn.v_proj.weight', 'decoder.layers_reposition.2.encoder_attn.v_proj.bias', 'decoder.layers_reposition.2.encoder_attn.q_proj.weight', 'decoder.layers_reposition.2.encoder_attn.q_proj.bias', 'decoder.layers_reposition.2.encoder_attn.out_proj.weight', 'decoder.layers_reposition.2.encoder_attn.out_proj.bias', 'decoder.layers_reposition.2.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.2.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.encoder_attn.k_proj.weight', 'decoder.layers_reposition.3.encoder_attn.k_proj.bias', 'decoder.layers_reposition.3.encoder_attn.v_proj.weight', 'decoder.layers_reposition.3.encoder_attn.v_proj.bias', 'decoder.layers_reposition.3.encoder_attn.q_proj.weight', 'decoder.layers_reposition.3.encoder_attn.q_proj.bias', 'decoder.layers_reposition.3.encoder_attn.out_proj.weight', 'decoder.layers_reposition.3.encoder_attn.out_proj.bias', 'decoder.layers_reposition.3.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.3.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.encoder_attn.k_proj.weight', 'decoder.layers_reposition.4.encoder_attn.k_proj.bias', 'decoder.layers_reposition.4.encoder_attn.v_proj.weight', 'decoder.layers_reposition.4.encoder_attn.v_proj.bias', 'decoder.layers_reposition.4.encoder_attn.q_proj.weight', 'decoder.layers_reposition.4.encoder_attn.q_proj.bias', 'decoder.layers_reposition.4.encoder_attn.out_proj.weight', 'decoder.layers_reposition.4.encoder_attn.out_proj.bias', 'decoder.layers_reposition.4.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.4.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.encoder_attn.k_proj.weight', 'decoder.layers_reposition.5.encoder_attn.k_proj.bias', 'decoder.layers_reposition.5.encoder_attn.v_proj.weight', 'decoder.layers_reposition.5.encoder_attn.v_proj.bias', 'decoder.layers_reposition.5.encoder_attn.q_proj.weight', 'decoder.layers_reposition.5.encoder_attn.q_proj.bias', 'decoder.layers_reposition.5.encoder_attn.out_proj.weight', 'decoder.layers_reposition.5.encoder_attn.out_proj.bias', 'decoder.layers_reposition.5.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.5.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
Trained parameters not adapter: len 292
Trained parameters not adapter: ['encoder.embed_tokens.weight', 'encoder.embed_positions.weight', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.layers.2.self_attn.k_proj.bias', 'encoder.layers.2.self_attn.v_proj.weight', 'encoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'encoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.3.fc1.bias', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.fc2.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.weight', 'encoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.4.self_attn.v_proj.weight', 'encoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.4.self_attn_layer_norm.bias', 'encoder.layers.4.fc1.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.4.fc2.weight', 'encoder.layers.4.fc2.bias', 'encoder.layers.4.final_layer_norm.weight', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.5.self_attn.k_proj.bias', 'encoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.5.fc1.weight', 'encoder.layers.5.fc1.bias', 'encoder.layers.5.fc2.weight', 'encoder.layers.5.fc2.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.final_layer_norm.bias', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']Trained parameters: len 412
Trained parameters: ['encoder.embed_tokens.weight', 'encoder.embed_positions.weight', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.layers.2.self_attn.k_proj.bias', 'encoder.layers.2.self_attn.v_proj.weight', 'encoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'encoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.3.fc1.bias', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.fc2.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.weight', 'encoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.4.self_attn.v_proj.weight', 'encoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.4.self_attn_layer_norm.bias', 'encoder.layers.4.fc1.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.4.fc2.weight', 'encoder.layers.4.fc2.bias', 'encoder.layers.4.final_layer_norm.weight', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.5.self_attn.k_proj.bias', 'encoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.5.fc1.weight', 'encoder.layers.5.fc1.bias', 'encoder.layers.5.fc2.weight', 'encoder.layers.5.fc2.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.final_layer_norm.bias', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.encoder_attn.k_proj.weight', 'decoder.layers_reposition.0.encoder_attn.k_proj.bias', 'decoder.layers_reposition.0.encoder_attn.v_proj.weight', 'decoder.layers_reposition.0.encoder_attn.v_proj.bias', 'decoder.layers_reposition.0.encoder_attn.q_proj.weight', 'decoder.layers_reposition.0.encoder_attn.q_proj.bias', 'decoder.layers_reposition.0.encoder_attn.out_proj.weight', 'decoder.layers_reposition.0.encoder_attn.out_proj.bias', 'decoder.layers_reposition.0.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.0.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.encoder_attn.k_proj.weight', 'decoder.layers_reposition.1.encoder_attn.k_proj.bias', 'decoder.layers_reposition.1.encoder_attn.v_proj.weight', 'decoder.layers_reposition.1.encoder_attn.v_proj.bias', 'decoder.layers_reposition.1.encoder_attn.q_proj.weight', 'decoder.layers_reposition.1.encoder_attn.q_proj.bias', 'decoder.layers_reposition.1.encoder_attn.out_proj.weight', 'decoder.layers_reposition.1.encoder_attn.out_proj.bias', 'decoder.layers_reposition.1.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.1.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.encoder_attn.k_proj.weight', 'decoder.layers_reposition.2.encoder_attn.k_proj.bias', 'decoder.layers_reposition.2.encoder_attn.v_proj.weight', 'decoder.layers_reposition.2.encoder_attn.v_proj.bias', 'decoder.layers_reposition.2.encoder_attn.q_proj.weight', 'decoder.layers_reposition.2.encoder_attn.q_proj.bias', 'decoder.layers_reposition.2.encoder_attn.out_proj.weight', 'decoder.layers_reposition.2.encoder_attn.out_proj.bias', 'decoder.layers_reposition.2.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.2.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.encoder_attn.k_proj.weight', 'decoder.layers_reposition.3.encoder_attn.k_proj.bias', 'decoder.layers_reposition.3.encoder_attn.v_proj.weight', 'decoder.layers_reposition.3.encoder_attn.v_proj.bias', 'decoder.layers_reposition.3.encoder_attn.q_proj.weight', 'decoder.layers_reposition.3.encoder_attn.q_proj.bias', 'decoder.layers_reposition.3.encoder_attn.out_proj.weight', 'decoder.layers_reposition.3.encoder_attn.out_proj.bias', 'decoder.layers_reposition.3.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.3.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.encoder_attn.k_proj.weight', 'decoder.layers_reposition.4.encoder_attn.k_proj.bias', 'decoder.layers_reposition.4.encoder_attn.v_proj.weight', 'decoder.layers_reposition.4.encoder_attn.v_proj.bias', 'decoder.layers_reposition.4.encoder_attn.q_proj.weight', 'decoder.layers_reposition.4.encoder_attn.q_proj.bias', 'decoder.layers_reposition.4.encoder_attn.out_proj.weight', 'decoder.layers_reposition.4.encoder_attn.out_proj.bias', 'decoder.layers_reposition.4.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.4.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.encoder_attn.k_proj.weight', 'decoder.layers_reposition.5.encoder_attn.k_proj.bias', 'decoder.layers_reposition.5.encoder_attn.v_proj.weight', 'decoder.layers_reposition.5.encoder_attn.v_proj.bias', 'decoder.layers_reposition.5.encoder_attn.q_proj.weight', 'decoder.layers_reposition.5.encoder_attn.q_proj.bias', 'decoder.layers_reposition.5.encoder_attn.out_proj.weight', 'decoder.layers_reposition.5.encoder_attn.out_proj.bias', 'decoder.layers_reposition.5.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.5.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
Trained parameters not adapter: len 292
Trained parameters not adapter: ['encoder.embed_tokens.weight', 'encoder.embed_positions.weight', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.layers.2.self_attn.k_proj.bias', 'encoder.layers.2.self_attn.v_proj.weight', 'encoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'encoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.3.fc1.bias', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.fc2.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.weight', 'encoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.4.self_attn.v_proj.weight', 'encoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.4.self_attn_layer_norm.bias', 'encoder.layers.4.fc1.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.4.fc2.weight', 'encoder.layers.4.fc2.bias', 'encoder.layers.4.final_layer_norm.weight', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.5.self_attn.k_proj.bias', 'encoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.5.fc1.weight', 'encoder.layers.5.fc1.bias', 'encoder.layers.5.fc2.weight', 'encoder.layers.5.fc2.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.final_layer_norm.bias', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']2022-10-19 17:04:23 | INFO | fairseq_cli.train | training on 4 GPUs
2022-10-19 17:04:23 | INFO | fairseq_cli.train | max tokens per GPU = 8000 and max sentences per GPU = None
2022-10-19 17:04:23 | INFO | fairseq.trainer | no existing checkpoint found ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt
2022-10-19 17:04:23 | INFO | fairseq.trainer | loading train data for epoch 1
2022-10-19 17:04:23 | INFO | fairseq.data.data_utils | loaded 204045 examples from: ../data-bin-bert-cased-XSum/train.source-target.source
2022-10-19 17:04:23 | INFO | fairseq.data.data_utils | loaded 204045 examples from: ../data-bin-bert-cased-XSum/train.source-target.target
2022-10-19 17:04:23 | INFO | fairseq.tasks.translation | ../data-bin-bert-cased-XSum train source-target 204045 examples
Trained parameters: len 412
Trained parameters: ['encoder.embed_tokens.weight', 'encoder.embed_positions.weight', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.layers.2.self_attn.k_proj.bias', 'encoder.layers.2.self_attn.v_proj.weight', 'encoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'encoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.3.fc1.bias', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.fc2.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.weight', 'encoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.4.self_attn.v_proj.weight', 'encoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.4.self_attn_layer_norm.bias', 'encoder.layers.4.fc1.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.4.fc2.weight', 'encoder.layers.4.fc2.bias', 'encoder.layers.4.final_layer_norm.weight', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.5.self_attn.k_proj.bias', 'encoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.5.fc1.weight', 'encoder.layers.5.fc1.bias', 'encoder.layers.5.fc2.weight', 'encoder.layers.5.fc2.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.final_layer_norm.bias', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.encoder_attn.k_proj.weight', 'decoder.layers_reposition.0.encoder_attn.k_proj.bias', 'decoder.layers_reposition.0.encoder_attn.v_proj.weight', 'decoder.layers_reposition.0.encoder_attn.v_proj.bias', 'decoder.layers_reposition.0.encoder_attn.q_proj.weight', 'decoder.layers_reposition.0.encoder_attn.q_proj.bias', 'decoder.layers_reposition.0.encoder_attn.out_proj.weight', 'decoder.layers_reposition.0.encoder_attn.out_proj.bias', 'decoder.layers_reposition.0.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.0.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.encoder_attn.k_proj.weight', 'decoder.layers_reposition.1.encoder_attn.k_proj.bias', 'decoder.layers_reposition.1.encoder_attn.v_proj.weight', 'decoder.layers_reposition.1.encoder_attn.v_proj.bias', 'decoder.layers_reposition.1.encoder_attn.q_proj.weight', 'decoder.layers_reposition.1.encoder_attn.q_proj.bias', 'decoder.layers_reposition.1.encoder_attn.out_proj.weight', 'decoder.layers_reposition.1.encoder_attn.out_proj.bias', 'decoder.layers_reposition.1.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.1.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.encoder_attn.k_proj.weight', 'decoder.layers_reposition.2.encoder_attn.k_proj.bias', 'decoder.layers_reposition.2.encoder_attn.v_proj.weight', 'decoder.layers_reposition.2.encoder_attn.v_proj.bias', 'decoder.layers_reposition.2.encoder_attn.q_proj.weight', 'decoder.layers_reposition.2.encoder_attn.q_proj.bias', 'decoder.layers_reposition.2.encoder_attn.out_proj.weight', 'decoder.layers_reposition.2.encoder_attn.out_proj.bias', 'decoder.layers_reposition.2.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.2.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.encoder_attn.k_proj.weight', 'decoder.layers_reposition.3.encoder_attn.k_proj.bias', 'decoder.layers_reposition.3.encoder_attn.v_proj.weight', 'decoder.layers_reposition.3.encoder_attn.v_proj.bias', 'decoder.layers_reposition.3.encoder_attn.q_proj.weight', 'decoder.layers_reposition.3.encoder_attn.q_proj.bias', 'decoder.layers_reposition.3.encoder_attn.out_proj.weight', 'decoder.layers_reposition.3.encoder_attn.out_proj.bias', 'decoder.layers_reposition.3.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.3.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.encoder_attn.k_proj.weight', 'decoder.layers_reposition.4.encoder_attn.k_proj.bias', 'decoder.layers_reposition.4.encoder_attn.v_proj.weight', 'decoder.layers_reposition.4.encoder_attn.v_proj.bias', 'decoder.layers_reposition.4.encoder_attn.q_proj.weight', 'decoder.layers_reposition.4.encoder_attn.q_proj.bias', 'decoder.layers_reposition.4.encoder_attn.out_proj.weight', 'decoder.layers_reposition.4.encoder_attn.out_proj.bias', 'decoder.layers_reposition.4.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.4.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.encoder_attn.k_proj.weight', 'decoder.layers_reposition.5.encoder_attn.k_proj.bias', 'decoder.layers_reposition.5.encoder_attn.v_proj.weight', 'decoder.layers_reposition.5.encoder_attn.v_proj.bias', 'decoder.layers_reposition.5.encoder_attn.q_proj.weight', 'decoder.layers_reposition.5.encoder_attn.q_proj.bias', 'decoder.layers_reposition.5.encoder_attn.out_proj.weight', 'decoder.layers_reposition.5.encoder_attn.out_proj.bias', 'decoder.layers_reposition.5.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.5.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
Trained parameters not adapter: len 292
Trained parameters not adapter: ['encoder.embed_tokens.weight', 'encoder.embed_positions.weight', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'encoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.0.self_attn_layer_norm.bias', 'encoder.layers.0.fc1.weight', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.fc2.weight', 'encoder.layers.0.fc2.bias', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.fc1.bias', 'encoder.layers.1.fc2.weight', 'encoder.layers.1.fc2.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.layers.2.self_attn.k_proj.bias', 'encoder.layers.2.self_attn.v_proj.weight', 'encoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.2.fc1.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'encoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.3.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'encoder.layers.3.fc1.weight', 'encoder.layers.3.fc1.bias', 'encoder.layers.3.fc2.weight', 'encoder.layers.3.fc2.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.3.final_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.weight', 'encoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.4.self_attn.v_proj.weight', 'encoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.4.self_attn_layer_norm.weight', 'encoder.layers.4.self_attn_layer_norm.bias', 'encoder.layers.4.fc1.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.4.fc2.weight', 'encoder.layers.4.fc2.bias', 'encoder.layers.4.final_layer_norm.weight', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.5.self_attn.k_proj.bias', 'encoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.5.fc1.weight', 'encoder.layers.5.fc1.bias', 'encoder.layers.5.fc2.weight', 'encoder.layers.5.fc2.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.final_layer_norm.bias', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']2022-10-19 17:04:25 | WARNING | fairseq.data.data_utils | 1291 samples have invalid sizes and will be skipped, max_positions=(2048, 512), first few sample ids=[81783, 99129, 95369, 73710, 164788, 126943, 22738, 203955, 180526, 180055]

2022-10-19 17:04:26 | WARNING | fairseq.data.data_utils | 1291 samples have invalid sizes and will be skipped, max_positions=(2048, 512), first few sample ids=[81783, 99129, 95369, 73710, 164788, 126943, 22738, 203955, 180526, 180055]

2022-10-19 17:04:26 | WARNING | fairseq.data.data_utils | 1291 samples have invalid sizes and will be skipped, max_positions=(2048, 512), first few sample ids=[81783, 99129, 95369, 73710, 164788, 126943, 22738, 203955, 180526, 180055]

2022-10-19 17:04:26 | WARNING | fairseq.data.data_utils | 1291 samples have invalid sizes and will be skipped, max_positions=(2048, 512), first few sample ids=[81783, 99129, 95369, 73710, 164788, 126943, 22738, 203955, 180526, 180055]
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
2022-10-19 17:04:56 | INFO | train_inner | epoch 001:    100 / 3937 loss=25.038, nll_loss=14.29, mask_ins=7.814, word_ins_ml=14.368, word_reposition=2.856, ppl=3.44446e+07, wps=5771.3, ups=3.42, wpb=1693.6, bsz=51.1, num_updates=100, lr=5.099e-06, gnorm=18.092, clip=3, loss_scale=128, train_wall=31, wall=33
2022-10-19 17:05:25 | INFO | train_inner | epoch 001:    200 / 3937 loss=20.701, nll_loss=12.987, mask_ins=6.197, word_ins_ml=13.199, word_reposition=1.305, ppl=1.70454e+06, wps=5300.5, ups=3.46, wpb=1533.8, bsz=46.2, num_updates=200, lr=1.0098e-05, gnorm=21.41, clip=1, loss_scale=128, train_wall=29, wall=62
2022-10-19 17:05:54 | INFO | train_inner | epoch 001:    300 / 3937 loss=16.851, nll_loss=12.094, mask_ins=3.398, word_ins_ml=12.405, word_reposition=1.049, ppl=118244, wps=5802.6, ups=3.47, wpb=1674, bsz=51, num_updates=300, lr=1.5097e-05, gnorm=16.506, clip=1, loss_scale=128, train_wall=29, wall=91
2022-10-19 17:06:23 | INFO | train_inner | epoch 001:    400 / 3937 loss=14.858, nll_loss=11.248, mask_ins=2.205, word_ins_ml=11.677, word_reposition=0.976, ppl=29692, wps=6244.3, ups=3.43, wpb=1818, bsz=54.9, num_updates=400, lr=2.0096e-05, gnorm=4.956, clip=0, loss_scale=128, train_wall=29, wall=120
2022-10-19 17:06:52 | INFO | train_inner | epoch 001:    500 / 3937 loss=14.185, nll_loss=10.629, mask_ins=2.034, word_ins_ml=11.173, word_reposition=0.979, ppl=18629.8, wps=6049.9, ups=3.38, wpb=1787.4, bsz=54.7, num_updates=500, lr=2.5095e-05, gnorm=3.896, clip=0, loss_scale=128, train_wall=29, wall=149
2022-10-19 17:07:21 | INFO | train_inner | epoch 001:    600 / 3937 loss=13.854, nll_loss=10.351, mask_ins=1.922, word_ins_ml=10.972, word_reposition=0.96, ppl=14810.7, wps=5986.9, ups=3.46, wpb=1730.4, bsz=53, num_updates=600, lr=3.0094e-05, gnorm=3.526, clip=0, loss_scale=128, train_wall=29, wall=178
2022-10-19 17:07:51 | INFO | train_inner | epoch 001:    700 / 3937 loss=13.718, nll_loss=10.259, mask_ins=1.856, word_ins_ml=10.916, word_reposition=0.947, ppl=13477.7, wps=5992.1, ups=3.41, wpb=1759.2, bsz=54.6, num_updates=700, lr=3.5093e-05, gnorm=3.274, clip=0, loss_scale=128, train_wall=29, wall=207
2022-10-19 17:08:20 | INFO | train_inner | epoch 001:    800 / 3937 loss=13.778, nll_loss=10.25, mask_ins=1.92, word_ins_ml=10.918, word_reposition=0.939, ppl=14046.9, wps=5742.4, ups=3.41, wpb=1683.8, bsz=51.9, num_updates=800, lr=4.0092e-05, gnorm=3.174, clip=0, loss_scale=128, train_wall=29, wall=237
2022-10-19 17:08:49 | INFO | train_inner | epoch 001:    900 / 3937 loss=13.726, nll_loss=10.208, mask_ins=1.887, word_ins_ml=10.885, word_reposition=0.954, ppl=13552.6, wps=5487.4, ups=3.43, wpb=1599.3, bsz=48.6, num_updates=900, lr=4.5091e-05, gnorm=3.622, clip=0, loss_scale=128, train_wall=29, wall=266
2022-10-19 17:09:18 | INFO | train_inner | epoch 001:   1000 / 3937 loss=13.675, nll_loss=10.191, mask_ins=1.876, word_ins_ml=10.872, word_reposition=0.928, ppl=13079.6, wps=6066.8, ups=3.44, wpb=1764.6, bsz=53.4, num_updates=1000, lr=5.009e-05, gnorm=3.193, clip=0, loss_scale=128, train_wall=29, wall=295
2022-10-19 17:09:47 | INFO | train_inner | epoch 001:   1100 / 3937 loss=13.708, nll_loss=10.164, mask_ins=1.911, word_ins_ml=10.848, word_reposition=0.949, ppl=13379.3, wps=5849.9, ups=3.43, wpb=1707.4, bsz=51.6, num_updates=1100, lr=5.5089e-05, gnorm=3.126, clip=0, loss_scale=128, train_wall=29, wall=324
2022-10-19 17:10:17 | INFO | train_inner | epoch 001:   1200 / 3937 loss=13.63, nll_loss=10.133, mask_ins=1.916, word_ins_ml=10.818, word_reposition=0.896, ppl=12675.9, wps=6110.2, ups=3.43, wpb=1781.6, bsz=54.6, num_updates=1200, lr=6.0088e-05, gnorm=3.199, clip=0, loss_scale=128, train_wall=29, wall=353
2022-10-19 17:10:46 | INFO | train_inner | epoch 001:   1300 / 3937 loss=13.579, nll_loss=10.078, mask_ins=1.882, word_ins_ml=10.769, word_reposition=0.928, ppl=12235.2, wps=5589.2, ups=3.43, wpb=1630.7, bsz=49.1, num_updates=1300, lr=6.5087e-05, gnorm=3.085, clip=0, loss_scale=128, train_wall=29, wall=383
2022-10-19 17:11:15 | INFO | train_inner | epoch 001:   1400 / 3937 loss=13.511, nll_loss=10.02, mask_ins=1.876, word_ins_ml=10.717, word_reposition=0.917, ppl=11670.4, wps=5841.3, ups=3.44, wpb=1696.9, bsz=51.4, num_updates=1400, lr=7.0086e-05, gnorm=3.138, clip=0, loss_scale=128, train_wall=29, wall=412
2022-10-19 17:11:44 | INFO | train_inner | epoch 001:   1500 / 3937 loss=13.427, nll_loss=9.956, mask_ins=1.887, word_ins_ml=10.661, word_reposition=0.879, ppl=11013.4, wps=6230.5, ups=3.4, wpb=1831.8, bsz=56.8, num_updates=1500, lr=7.5085e-05, gnorm=3.057, clip=0, loss_scale=128, train_wall=29, wall=441
2022-10-19 17:12:13 | INFO | train_inner | epoch 001:   1600 / 3937 loss=13.43, nll_loss=9.939, mask_ins=1.893, word_ins_ml=10.647, word_reposition=0.889, ppl=11035.4, wps=5488.2, ups=3.45, wpb=1593.1, bsz=48.1, num_updates=1600, lr=8.0084e-05, gnorm=3.096, clip=0, loss_scale=128, train_wall=29, wall=470
2022-10-19 17:12:42 | INFO | train_inner | epoch 001:   1700 / 3937 loss=13.354, nll_loss=9.911, mask_ins=1.841, word_ins_ml=10.624, word_reposition=0.888, ppl=10468, wps=5709.5, ups=3.47, wpb=1646.4, bsz=50, num_updates=1700, lr=8.5083e-05, gnorm=3.049, clip=0, loss_scale=128, train_wall=29, wall=499
2022-10-19 17:13:11 | INFO | train_inner | epoch 001:   1800 / 3937 loss=13.387, nll_loss=9.884, mask_ins=1.895, word_ins_ml=10.6, word_reposition=0.892, ppl=10714.5, wps=5968.9, ups=3.43, wpb=1741.9, bsz=53.2, num_updates=1800, lr=9.0082e-05, gnorm=3.086, clip=0, loss_scale=128, train_wall=29, wall=528
2022-10-19 17:13:40 | INFO | train_inner | epoch 001:   1900 / 3937 loss=13.307, nll_loss=9.851, mask_ins=1.827, word_ins_ml=10.572, word_reposition=0.908, ppl=10133.8, wps=5928.5, ups=3.44, wpb=1724.7, bsz=51.6, num_updates=1900, lr=9.5081e-05, gnorm=2.971, clip=0, loss_scale=128, train_wall=29, wall=557
2022-10-19 17:14:10 | INFO | train_inner | epoch 001:   2000 / 3937 loss=13.281, nll_loss=9.824, mask_ins=1.849, word_ins_ml=10.547, word_reposition=0.886, ppl=9954.51, wps=5970.9, ups=3.42, wpb=1745.3, bsz=53.3, num_updates=2000, lr=0.00010008, gnorm=2.92, clip=0, loss_scale=128, train_wall=29, wall=586
2022-10-19 17:14:39 | INFO | train_inner | epoch 001:   2100 / 3937 loss=13.198, nll_loss=9.779, mask_ins=1.815, word_ins_ml=10.508, word_reposition=0.874, ppl=9395.24, wps=6213.4, ups=3.42, wpb=1817.6, bsz=55.3, num_updates=2100, lr=0.000105079, gnorm=2.752, clip=0, loss_scale=128, train_wall=29, wall=616
2022-10-19 17:15:08 | INFO | train_inner | epoch 001:   2200 / 3937 loss=13.288, nll_loss=9.793, mask_ins=1.869, word_ins_ml=10.521, word_reposition=0.898, ppl=9999.53, wps=6314.3, ups=3.45, wpb=1829.2, bsz=54.7, num_updates=2200, lr=0.000110078, gnorm=2.752, clip=0, loss_scale=128, train_wall=29, wall=645
2022-10-19 17:15:37 | INFO | train_inner | epoch 001:   2300 / 3937 loss=13.222, nll_loss=9.72, mask_ins=1.885, word_ins_ml=10.456, word_reposition=0.881, ppl=9554.58, wps=5525.1, ups=3.46, wpb=1599.2, bsz=49.2, num_updates=2300, lr=0.000115077, gnorm=2.968, clip=0, loss_scale=128, train_wall=29, wall=674
2022-10-19 17:16:06 | INFO | train_inner | epoch 001:   2400 / 3937 loss=13.187, nll_loss=9.709, mask_ins=1.871, word_ins_ml=10.446, word_reposition=0.87, ppl=9324.77, wps=6149.1, ups=3.42, wpb=1798, bsz=54.5, num_updates=2400, lr=0.000120076, gnorm=2.641, clip=0, loss_scale=128, train_wall=29, wall=703
2022-10-19 17:16:35 | INFO | train_inner | epoch 001:   2500 / 3937 loss=13.146, nll_loss=9.695, mask_ins=1.824, word_ins_ml=10.434, word_reposition=0.888, ppl=9062.54, wps=6009.2, ups=3.47, wpb=1730.4, bsz=51.1, num_updates=2500, lr=0.000125075, gnorm=2.942, clip=0, loss_scale=128, train_wall=28, wall=732
2022-10-19 17:17:04 | INFO | train_inner | epoch 001:   2600 / 3937 loss=13.183, nll_loss=9.689, mask_ins=1.851, word_ins_ml=10.43, word_reposition=0.903, ppl=9301.12, wps=5475.8, ups=3.46, wpb=1581.6, bsz=47.6, num_updates=2600, lr=0.000130074, gnorm=2.879, clip=0, loss_scale=128, train_wall=29, wall=760
2022-10-19 17:17:33 | INFO | train_inner | epoch 001:   2700 / 3937 loss=13.122, nll_loss=9.681, mask_ins=1.823, word_ins_ml=10.422, word_reposition=0.877, ppl=8916.81, wps=5719.1, ups=3.44, wpb=1660.6, bsz=50.2, num_updates=2700, lr=0.000135073, gnorm=2.768, clip=0, loss_scale=128, train_wall=29, wall=790
2022-10-19 17:18:02 | INFO | train_inner | epoch 001:   2800 / 3937 loss=13.1, nll_loss=9.652, mask_ins=1.839, word_ins_ml=10.398, word_reposition=0.863, ppl=8777.45, wps=5782.8, ups=3.44, wpb=1679.9, bsz=51.5, num_updates=2800, lr=0.000140072, gnorm=2.972, clip=0, loss_scale=128, train_wall=29, wall=819
2022-10-19 17:18:31 | INFO | train_inner | epoch 001:   2900 / 3937 loss=13.089, nll_loss=9.636, mask_ins=1.854, word_ins_ml=10.383, word_reposition=0.851, ppl=8711.78, wps=5883.5, ups=3.43, wpb=1715.3, bsz=52.1, num_updates=2900, lr=0.000145071, gnorm=2.675, clip=0, loss_scale=128, train_wall=29, wall=848
2022-10-19 17:19:00 | INFO | train_inner | epoch 001:   3000 / 3937 loss=13.121, nll_loss=9.629, mask_ins=1.859, word_ins_ml=10.377, word_reposition=0.885, ppl=8911.15, wps=5811.8, ups=3.48, wpb=1669.5, bsz=49.5, num_updates=3000, lr=0.00015007, gnorm=2.757, clip=0, loss_scale=128, train_wall=28, wall=876
2022-10-19 17:19:29 | INFO | train_inner | epoch 001:   3100 / 3937 loss=13.052, nll_loss=9.605, mask_ins=1.831, word_ins_ml=10.358, word_reposition=0.863, ppl=8489.89, wps=5831.3, ups=3.46, wpb=1686.4, bsz=51.1, num_updates=3100, lr=0.000155069, gnorm=2.686, clip=0, loss_scale=128, train_wall=29, wall=905
2022-10-19 17:19:58 | INFO | train_inner | epoch 001:   3200 / 3937 loss=13.097, nll_loss=9.61, mask_ins=1.855, word_ins_ml=10.363, word_reposition=0.879, ppl=8764.09, wps=5600, ups=3.44, wpb=1626.9, bsz=49.3, num_updates=3200, lr=0.000160068, gnorm=3.046, clip=0, loss_scale=128, train_wall=29, wall=934
2022-10-19 17:20:26 | INFO | train_inner | epoch 001:   3300 / 3937 loss=13.059, nll_loss=9.591, mask_ins=1.843, word_ins_ml=10.345, word_reposition=0.871, ppl=8533.19, wps=5586.6, ups=3.46, wpb=1612.6, bsz=48.1, num_updates=3300, lr=0.000165067, gnorm=2.888, clip=0, loss_scale=128, train_wall=29, wall=963
2022-10-19 17:20:55 | INFO | train_inner | epoch 001:   3400 / 3937 loss=13.001, nll_loss=9.571, mask_ins=1.803, word_ins_ml=10.328, word_reposition=0.87, ppl=8200.36, wps=5683, ups=3.47, wpb=1640.1, bsz=49, num_updates=3400, lr=0.000170066, gnorm=2.691, clip=0, loss_scale=128, train_wall=29, wall=992
2022-10-19 17:21:24 | INFO | train_inner | epoch 001:   3500 / 3937 loss=13.018, nll_loss=9.518, mask_ins=1.868, word_ins_ml=10.282, word_reposition=0.868, ppl=8295.81, wps=6047.1, ups=3.5, wpb=1729.7, bsz=53, num_updates=3500, lr=0.000175065, gnorm=2.825, clip=0, loss_scale=128, train_wall=28, wall=1021
2022-10-19 17:21:53 | INFO | train_inner | epoch 001:   3600 / 3937 loss=13.018, nll_loss=9.543, mask_ins=1.832, word_ins_ml=10.303, word_reposition=0.883, ppl=8292.17, wps=5519.7, ups=3.47, wpb=1589.1, bsz=48.4, num_updates=3600, lr=0.000180064, gnorm=3.056, clip=0, loss_scale=128, train_wall=29, wall=1050
2022-10-19 17:22:22 | INFO | train_inner | epoch 001:   3700 / 3937 loss=13.049, nll_loss=9.517, mask_ins=1.883, word_ins_ml=10.281, word_reposition=0.885, ppl=8474.07, wps=5805.3, ups=3.46, wpb=1677.5, bsz=51, num_updates=3700, lr=0.000185063, gnorm=2.721, clip=0, loss_scale=128, train_wall=29, wall=1078
2022-10-19 17:22:51 | INFO | train_inner | epoch 001:   3800 / 3937 loss=12.996, nll_loss=9.49, mask_ins=1.884, word_ins_ml=10.258, word_reposition=0.854, ppl=8170.94, wps=5858.4, ups=3.44, wpb=1704.7, bsz=51.9, num_updates=3800, lr=0.000190062, gnorm=2.735, clip=0, loss_scale=128, train_wall=29, wall=1108
2022-10-19 17:23:20 | INFO | train_inner | epoch 001:   3900 / 3937 loss=12.969, nll_loss=9.479, mask_ins=1.857, word_ins_ml=10.248, word_reposition=0.864, ppl=8015.72, wps=5921.3, ups=3.44, wpb=1721, bsz=53.1, num_updates=3900, lr=0.000195061, gnorm=2.782, clip=0, loss_scale=128, train_wall=29, wall=1137
2022-10-19 17:23:31 | INFO | train | epoch 001 | loss 13.938 | nll_loss 10.126 | mask_ins 2.178 | word_ins_ml 10.798 | word_reposition 0.962 | ppl 15698.1 | wps 5837.6 | ups 3.44 | wpb 1696.2 | bsz 51.5 | num_updates 3937 | lr 0.000196911 | gnorm 4.243 | clip 0.1 | loss_scale 128 | train_wall 1135 | wall 1147
2022-10-19 17:23:31 | WARNING | fairseq.data.data_utils | 57 samples have invalid sizes and will be skipped, max_positions=(2048, 512), first few sample ids=[4035, 6763, 6786, 9418, 8487, 5896, 3904, 1150, 83, 4003]
2022-10-19 17:23:31 | WARNING | fairseq.data.data_utils | 57 samples have invalid sizes and will be skipped, max_positions=(2048, 512), first few sample ids=[4035, 6763, 6786, 9418, 8487, 5896, 3904, 1150, 83, 4003]
2022-10-19 17:23:31 | WARNING | fairseq.data.data_utils | 57 samples have invalid sizes and will be skipped, max_positions=(2048, 512), first few sample ids=[4035, 6763, 6786, 9418, 8487, 5896, 3904, 1150, 83, 4003]
2022-10-19 17:23:31 | WARNING | fairseq.data.data_utils | 57 samples have invalid sizes and will be skipped, max_positions=(2048, 512), first few sample ids=[4035, 6763, 6786, 9418, 8487, 5896, 3904, 1150, 83, 4003]
2022-10-19 17:23:42 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.467 | nll_loss 11.261 | mask_ins 1.895 | word_ins_ml 11.883 | word_reposition 0.689 | ppl 22649.5 | wps 27572.9 | wpb 1503.2 | bsz 51.5 | num_updates 3937
2022-10-19 17:23:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_best.pt (epoch 1 @ 3937 updates, score 14.467) (writing took 2.8393800550838932 seconds)
2022-10-19 17:24:04 | INFO | train_inner | epoch 002:     63 / 3937 loss=12.952, nll_loss=9.417, mask_ins=1.893, word_ins_ml=10.194, word_reposition=0.865, ppl=7921.2, wps=3956, ups=2.28, wpb=1732, bsz=53.3, num_updates=4000, lr=0.00020006, gnorm=2.797, clip=0, loss_scale=128, train_wall=29, wall=1180
2022-10-19 17:24:33 | INFO | train_inner | epoch 002:    163 / 3937 loss=12.917, nll_loss=9.439, mask_ins=1.821, word_ins_ml=10.215, word_reposition=0.882, ppl=7736.62, wps=6202.4, ups=3.45, wpb=1796.6, bsz=54.9, num_updates=4100, lr=0.000205059, gnorm=2.702, clip=0, loss_scale=134, train_wall=29, wall=1209
2022-10-19 17:25:01 | INFO | train_inner | epoch 002:    263 / 3937 loss=12.88, nll_loss=9.438, mask_ins=1.804, word_ins_ml=10.213, word_reposition=0.863, ppl=7540.01, wps=5451.3, ups=3.47, wpb=1570.2, bsz=47.1, num_updates=4200, lr=0.000210058, gnorm=2.655, clip=0, loss_scale=256, train_wall=29, wall=1238
2022-10-19 17:25:30 | INFO | train_inner | epoch 002:    363 / 3937 loss=12.938, nll_loss=9.449, mask_ins=1.856, word_ins_ml=10.222, word_reposition=0.86, ppl=7846.27, wps=5642.1, ups=3.49, wpb=1616.7, bsz=50, num_updates=4300, lr=0.000215057, gnorm=2.762, clip=0, loss_scale=256, train_wall=28, wall=1267
2022-10-19 17:25:59 | INFO | train_inner | epoch 002:    463 / 3937 loss=12.914, nll_loss=9.425, mask_ins=1.838, word_ins_ml=10.202, word_reposition=0.875, ppl=7718.21, wps=5591.9, ups=3.43, wpb=1630.1, bsz=49.6, num_updates=4400, lr=0.000220056, gnorm=2.72, clip=0, loss_scale=256, train_wall=29, wall=1296
2022-10-19 17:26:29 | INFO | train_inner | epoch 002:    563 / 3937 loss=12.84, nll_loss=9.398, mask_ins=1.797, word_ins_ml=10.179, word_reposition=0.864, ppl=7333.62, wps=5944.3, ups=3.4, wpb=1750.5, bsz=53.7, num_updates=4500, lr=0.000225055, gnorm=2.583, clip=0, loss_scale=256, train_wall=29, wall=1325
2022-10-19 17:26:57 | INFO | train_inner | epoch 002:    663 / 3937 loss=12.92, nll_loss=9.43, mask_ins=1.835, word_ins_ml=10.205, word_reposition=0.88, ppl=7749.63, wps=5528.1, ups=3.47, wpb=1591.2, bsz=47.4, num_updates=4600, lr=0.000230054, gnorm=2.831, clip=0, loss_scale=256, train_wall=29, wall=1354
2022-10-19 17:27:26 | INFO | train_inner | epoch 002:    763 / 3937 loss=12.85, nll_loss=9.386, mask_ins=1.809, word_ins_ml=10.168, word_reposition=0.873, ppl=7384, wps=6070.1, ups=3.46, wpb=1756.4, bsz=54.5, num_updates=4700, lr=0.000235053, gnorm=2.721, clip=0, loss_scale=256, train_wall=29, wall=1383
2022-10-19 17:27:56 | INFO | train_inner | epoch 002:    863 / 3937 loss=12.958, nll_loss=9.415, mask_ins=1.903, word_ins_ml=10.194, word_reposition=0.86, ppl=7955.05, wps=6051.4, ups=3.4, wpb=1778.4, bsz=54.5, num_updates=4800, lr=0.000240052, gnorm=3.046, clip=0, loss_scale=256, train_wall=29, wall=1413
2022-10-19 17:28:25 | INFO | train_inner | epoch 002:    963 / 3937 loss=12.918, nll_loss=9.422, mask_ins=1.835, word_ins_ml=10.2, word_reposition=0.883, ppl=7740.63, wps=5961.6, ups=3.42, wpb=1742.3, bsz=52.6, num_updates=4900, lr=0.000245051, gnorm=2.787, clip=0, loss_scale=256, train_wall=29, wall=1442
2022-10-19 17:28:54 | INFO | train_inner | epoch 002:   1063 / 3937 loss=12.912, nll_loss=9.36, mask_ins=1.887, word_ins_ml=10.145, word_reposition=0.88, ppl=7704.58, wps=5775.9, ups=3.44, wpb=1676.9, bsz=50.7, num_updates=5000, lr=0.00025005, gnorm=2.881, clip=0, loss_scale=256, train_wall=29, wall=1471
2022-10-19 17:29:23 | INFO | train_inner | epoch 002:   1163 / 3937 loss=12.847, nll_loss=9.393, mask_ins=1.792, word_ins_ml=10.176, word_reposition=0.879, ppl=7368.94, wps=6040.8, ups=3.43, wpb=1759.4, bsz=53.9, num_updates=5100, lr=0.000255049, gnorm=3.814, clip=1, loss_scale=256, train_wall=29, wall=1500
2022-10-19 17:29:52 | INFO | train_inner | epoch 002:   1263 / 3937 loss=12.907, nll_loss=9.334, mask_ins=1.907, word_ins_ml=10.124, word_reposition=0.876, ppl=7683.09, wps=5830.6, ups=3.46, wpb=1685.5, bsz=51.3, num_updates=5200, lr=0.000260048, gnorm=2.992, clip=0, loss_scale=256, train_wall=29, wall=1529
2022-10-19 17:30:21 | INFO | train_inner | epoch 002:   1363 / 3937 loss=12.868, nll_loss=9.378, mask_ins=1.819, word_ins_ml=10.163, word_reposition=0.886, ppl=7474.39, wps=5899, ups=3.4, wpb=1734.7, bsz=52.3, num_updates=5300, lr=0.000265047, gnorm=4.354, clip=1, loss_scale=256, train_wall=29, wall=1558
2022-10-19 17:30:50 | INFO | train_inner | epoch 002:   1463 / 3937 loss=12.923, nll_loss=9.402, mask_ins=1.878, word_ins_ml=10.183, word_reposition=0.862, ppl=7767.28, wps=5476.8, ups=3.48, wpb=1574.7, bsz=47.1, num_updates=5400, lr=0.000270046, gnorm=4.01, clip=0, loss_scale=256, train_wall=29, wall=1587
2022-10-19 17:31:19 | INFO | train_inner | epoch 002:   1563 / 3937 loss=12.757, nll_loss=9.318, mask_ins=1.785, word_ins_ml=10.11, word_reposition=0.862, ppl=6920.65, wps=5713.9, ups=3.44, wpb=1659.8, bsz=50.2, num_updates=5500, lr=0.000275045, gnorm=3.688, clip=1, loss_scale=256, train_wall=29, wall=1616
2022-10-19 17:31:48 | INFO | train_inner | epoch 002:   1663 / 3937 loss=12.996, nll_loss=9.403, mask_ins=1.917, word_ins_ml=10.186, word_reposition=0.894, ppl=8170.94, wps=5604.6, ups=3.47, wpb=1614.6, bsz=48.4, num_updates=5600, lr=0.000280044, gnorm=4.859, clip=0, loss_scale=256, train_wall=29, wall=1645
2022-10-19 17:32:17 | INFO | train_inner | epoch 002:   1763 / 3937 loss=13.009, nll_loss=9.437, mask_ins=1.937, word_ins_ml=10.216, word_reposition=0.857, ppl=8242.19, wps=6016.8, ups=3.42, wpb=1760.1, bsz=53.5, num_updates=5700, lr=0.000285043, gnorm=16.154, clip=6, loss_scale=256, train_wall=29, wall=1674
2022-10-19 17:32:46 | INFO | train_inner | epoch 002:   1863 / 3937 loss=12.9, nll_loss=9.441, mask_ins=1.823, word_ins_ml=10.22, word_reposition=0.858, ppl=7645.89, wps=5632.9, ups=3.46, wpb=1629.4, bsz=49.5, num_updates=5800, lr=0.000290042, gnorm=12.122, clip=10, loss_scale=256, train_wall=29, wall=1703
2022-10-19 17:33:15 | INFO | train_inner | epoch 002:   1963 / 3937 loss=13.003, nll_loss=9.421, mask_ins=1.919, word_ins_ml=10.201, word_reposition=0.883, ppl=8210.14, wps=6311.4, ups=3.46, wpb=1824.2, bsz=55, num_updates=5900, lr=0.000295041, gnorm=8.552, clip=6, loss_scale=256, train_wall=29, wall=1732
2022-10-19 17:33:44 | INFO | train_inner | epoch 002:   2063 / 3937 loss=12.866, nll_loss=9.388, mask_ins=1.85, word_ins_ml=10.173, word_reposition=0.843, ppl=7466.08, wps=5950.9, ups=3.44, wpb=1728.3, bsz=52.4, num_updates=6000, lr=0.00030004, gnorm=5.456, clip=2, loss_scale=256, train_wall=29, wall=1761
2022-10-19 17:34:13 | INFO | train_inner | epoch 002:   2163 / 3937 loss=12.964, nll_loss=9.412, mask_ins=1.904, word_ins_ml=10.194, word_reposition=0.867, ppl=7991.88, wps=5894.3, ups=3.45, wpb=1709.3, bsz=51.9, num_updates=6100, lr=0.000305039, gnorm=5.958, clip=2, loss_scale=256, train_wall=29, wall=1790
2022-10-19 17:34:42 | INFO | train_inner | epoch 002:   2263 / 3937 loss=12.943, nll_loss=9.371, mask_ins=1.886, word_ins_ml=10.157, word_reposition=0.9, ppl=7876.21, wps=5892.1, ups=3.45, wpb=1705.7, bsz=51.9, num_updates=6200, lr=0.000310038, gnorm=4.808, clip=2, loss_scale=256, train_wall=29, wall=1819
2022-10-19 17:35:11 | INFO | train_inner | epoch 002:   2363 / 3937 loss=12.957, nll_loss=9.372, mask_ins=1.892, word_ins_ml=10.16, word_reposition=0.905, ppl=7950.08, wps=5980.2, ups=3.41, wpb=1753.5, bsz=53.5, num_updates=6300, lr=0.000315037, gnorm=4.104, clip=2, loss_scale=256, train_wall=29, wall=1848
2022-10-19 17:35:40 | INFO | train_inner | epoch 002:   2463 / 3937 loss=13.102, nll_loss=9.441, mask_ins=2, word_ins_ml=10.22, word_reposition=0.882, ppl=8792.12, wps=5415.3, ups=3.46, wpb=1564.3, bsz=45.8, num_updates=6400, lr=0.000320036, gnorm=7.162, clip=3, loss_scale=256, train_wall=29, wall=1877
2022-10-19 17:36:09 | INFO | train_inner | epoch 002:   2563 / 3937 loss=13.145, nll_loss=9.423, mask_ins=2.048, word_ins_ml=10.205, word_reposition=0.891, ppl=9058.29, wps=5521.5, ups=3.5, wpb=1577.5, bsz=47.7, num_updates=6500, lr=0.000325035, gnorm=4.473, clip=0, loss_scale=256, train_wall=28, wall=1906
2022-10-19 17:36:38 | INFO | train_inner | epoch 002:   2663 / 3937 loss=13.051, nll_loss=9.383, mask_ins=2.031, word_ins_ml=10.169, word_reposition=0.851, ppl=8485.82, wps=5770.9, ups=3.4, wpb=1699.4, bsz=52.2, num_updates=6600, lr=0.000330034, gnorm=10.975, clip=2, loss_scale=256, train_wall=29, wall=1935
2022-10-19 17:37:07 | INFO | train_inner | epoch 002:   2763 / 3937 loss=13.207, nll_loss=9.426, mask_ins=2.137, word_ins_ml=10.208, word_reposition=0.862, ppl=9457.57, wps=5814.6, ups=3.49, wpb=1668.1, bsz=51.4, num_updates=6700, lr=0.000335033, gnorm=7.995, clip=4, loss_scale=256, train_wall=28, wall=1964
2022-10-19 17:37:36 | INFO | train_inner | epoch 002:   2863 / 3937 loss=13.208, nll_loss=9.417, mask_ins=2.115, word_ins_ml=10.202, word_reposition=0.891, ppl=9460.61, wps=6206, ups=3.42, wpb=1815.4, bsz=55.5, num_updates=6800, lr=0.000340032, gnorm=3.795, clip=0, loss_scale=256, train_wall=29, wall=1993
2022-10-19 17:38:05 | INFO | train_inner | epoch 002:   2963 / 3937 loss=13.275, nll_loss=9.437, mask_ins=2.175, word_ins_ml=10.218, word_reposition=0.882, ppl=9912.12, wps=5990.2, ups=3.45, wpb=1734.9, bsz=51.7, num_updates=6900, lr=0.000345031, gnorm=4.9, clip=2, loss_scale=256, train_wall=29, wall=2022
2022-10-19 17:38:34 | INFO | train_inner | epoch 002:   3063 / 3937 loss=13.229, nll_loss=9.449, mask_ins=2.126, word_ins_ml=10.229, word_reposition=0.874, ppl=9600.5, wps=5961.9, ups=3.43, wpb=1737.6, bsz=52.8, num_updates=7000, lr=0.00035003, gnorm=4.403, clip=0, loss_scale=256, train_wall=29, wall=2051
2022-10-19 17:39:04 | INFO | train_inner | epoch 002:   3163 / 3937 loss=13.131, nll_loss=9.406, mask_ins=2.088, word_ins_ml=10.193, word_reposition=0.85, ppl=8972.54, wps=5941.2, ups=3.42, wpb=1738.5, bsz=53.5, num_updates=7100, lr=0.000355029, gnorm=4.345, clip=1, loss_scale=256, train_wall=29, wall=2080
2022-10-19 17:39:33 | INFO | train_inner | epoch 002:   3263 / 3937 loss=13.173, nll_loss=9.435, mask_ins=2.097, word_ins_ml=10.217, word_reposition=0.859, ppl=9234.15, wps=6145.7, ups=3.42, wpb=1795.9, bsz=56.1, num_updates=7200, lr=0.000360028, gnorm=7.604, clip=5, loss_scale=256, train_wall=29, wall=2110
2022-10-19 17:40:02 | INFO | train_inner | epoch 002:   3363 / 3937 loss=13.903, nll_loss=10.293, mask_ins=2.114, word_ins_ml=10.968, word_reposition=0.821, ppl=15316.4, wps=5813.8, ups=3.45, wpb=1684.7, bsz=50.6, num_updates=7300, lr=0.000365027, gnorm=4.527, clip=2, loss_scale=256, train_wall=29, wall=2139
2022-10-19 17:40:31 | INFO | train_inner | epoch 002:   3463 / 3937 loss=13.914, nll_loss=10.333, mask_ins=2.125, word_ins_ml=11.006, word_reposition=0.783, ppl=15439.9, wps=5861.3, ups=3.47, wpb=1688.5, bsz=50.6, num_updates=7400, lr=0.000370026, gnorm=2.673, clip=0, loss_scale=256, train_wall=29, wall=2167
2022-10-19 17:40:59 | INFO | train_inner | epoch 002:   3563 / 3937 loss=13.958, nll_loss=10.319, mask_ins=2.174, word_ins_ml=10.995, word_reposition=0.789, ppl=15916.6, wps=5758.6, ups=3.5, wpb=1643.8, bsz=50.2, num_updates=7500, lr=0.000375025, gnorm=2.633, clip=0, loss_scale=256, train_wall=28, wall=2196
2022-10-19 17:41:28 | INFO | train_inner | epoch 002:   3663 / 3937 loss=13.864, nll_loss=10.33, mask_ins=2.085, word_ins_ml=11.008, word_reposition=0.772, ppl=14910.8, wps=5955.5, ups=3.46, wpb=1722.9, bsz=51.5, num_updates=7600, lr=0.000380024, gnorm=2.804, clip=0, loss_scale=256, train_wall=29, wall=2225
2022-10-19 17:41:57 | INFO | train_inner | epoch 002:   3763 / 3937 loss=13.905, nll_loss=10.32, mask_ins=2.15, word_ins_ml=10.998, word_reposition=0.757, ppl=15339.8, wps=5787.3, ups=3.42, wpb=1690.2, bsz=51.9, num_updates=7700, lr=0.000385023, gnorm=2.742, clip=0, loss_scale=256, train_wall=29, wall=2254
2022-10-19 17:42:26 | INFO | train_inner | epoch 002:   3863 / 3937 loss=13.972, nll_loss=10.309, mask_ins=2.128, word_ins_ml=10.994, word_reposition=0.851, ppl=16070, wps=5507.8, ups=3.44, wpb=1600.1, bsz=48.6, num_updates=7800, lr=0.000390022, gnorm=4.023, clip=1, loss_scale=256, train_wall=29, wall=2283
2022-10-19 17:42:48 | INFO | train | epoch 002 | loss 13.144 | nll_loss 9.563 | mask_ins 1.958 | word_ins_ml 10.327 | word_reposition 0.859 | ppl 9048.78 | wps 5771.9 | ups 3.4 | wpb 1696.2 | bsz 51.5 | num_updates 7874 | lr 0.000393721 | gnorm 4.754 | clip 1.3 | loss_scale 251 | train_wall 1132 | wall 2304
2022-10-19 17:42:59 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 14.267 | nll_loss 10.666 | mask_ins 2.184 | word_ins_ml 11.4 | word_reposition 0.682 | ppl 19708.2 | wps 27531.9 | wpb 1503.2 | bsz 51.5 | num_updates 7874 | best_loss 14.267
2022-10-19 17:43:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_best.pt (epoch 2 @ 7874 updates, score 14.267) (writing took 15.57823573902715 seconds)
2022-10-19 17:43:22 | INFO | train_inner | epoch 003:     26 / 3937 loss=13.917, nll_loss=10.293, mask_ins=2.189, word_ins_ml=10.972, word_reposition=0.755, ppl=15464.4, wps=3005.3, ups=1.79, wpb=1680.6, bsz=50.1, num_updates=7900, lr=0.000395021, gnorm=2.518, clip=0, loss_scale=256, train_wall=28, wall=2339
2022-10-19 17:43:51 | INFO | train_inner | epoch 003:    126 / 3937 loss=13.827, nll_loss=10.286, mask_ins=2.089, word_ins_ml=10.967, word_reposition=0.77, ppl=14529.6, wps=6102.4, ups=3.46, wpb=1764.1, bsz=52.4, num_updates=8000, lr=0.00040002, gnorm=2.348, clip=0, loss_scale=256, train_wall=29, wall=2368
2022-10-19 17:44:20 | INFO | train_inner | epoch 003:    226 / 3937 loss=13.758, nll_loss=10.27, mask_ins=2.045, word_ins_ml=10.954, word_reposition=0.759, ppl=13855.6, wps=5764.9, ups=3.46, wpb=1664.2, bsz=50.7, num_updates=8100, lr=0.000405019, gnorm=2.413, clip=0, loss_scale=256, train_wall=29, wall=2397
2022-10-19 17:44:49 | INFO | train_inner | epoch 003:    326 / 3937 loss=13.756, nll_loss=10.296, mask_ins=2.024, word_ins_ml=10.975, word_reposition=0.757, ppl=13836.7, wps=5769.6, ups=3.46, wpb=1665.2, bsz=49.9, num_updates=8200, lr=0.000410018, gnorm=2.506, clip=0, loss_scale=279, train_wall=29, wall=2426
2022-10-19 17:45:18 | INFO | train_inner | epoch 003:    426 / 3937 loss=13.676, nll_loss=10.285, mask_ins=1.961, word_ins_ml=10.965, word_reposition=0.75, ppl=13086, wps=5900.7, ups=3.42, wpb=1726.5, bsz=54.1, num_updates=8300, lr=0.000415017, gnorm=2.893, clip=1, loss_scale=512, train_wall=29, wall=2455
2022-10-19 17:45:47 | INFO | train_inner | epoch 003:    526 / 3937 loss=13.722, nll_loss=10.27, mask_ins=1.994, word_ins_ml=10.951, word_reposition=0.777, ppl=13508.2, wps=5942.2, ups=3.42, wpb=1737.9, bsz=52.4, num_updates=8400, lr=0.000420016, gnorm=2.388, clip=0, loss_scale=512, train_wall=29, wall=2484
2022-10-19 17:46:16 | INFO | train_inner | epoch 003:    626 / 3937 loss=13.725, nll_loss=10.273, mask_ins=2.005, word_ins_ml=10.953, word_reposition=0.767, ppl=13543, wps=5909.8, ups=3.44, wpb=1717.7, bsz=51.4, num_updates=8500, lr=0.000425015, gnorm=2.571, clip=0, loss_scale=512, train_wall=29, wall=2513
2022-10-19 17:46:45 | INFO | train_inner | epoch 003:    726 / 3937 loss=13.732, nll_loss=10.293, mask_ins=1.984, word_ins_ml=10.97, word_reposition=0.778, ppl=13606.2, wps=5752.3, ups=3.47, wpb=1658.1, bsz=50.6, num_updates=8600, lr=0.000430014, gnorm=2.079, clip=0, loss_scale=512, train_wall=29, wall=2542
2022-10-19 17:47:15 | INFO | train_inner | epoch 003:    826 / 3937 loss=13.716, nll_loss=10.274, mask_ins=1.989, word_ins_ml=10.955, word_reposition=0.772, ppl=13452.7, wps=5773.1, ups=3.42, wpb=1686.5, bsz=50.5, num_updates=8700, lr=0.000435013, gnorm=2.243, clip=0, loss_scale=512, train_wall=29, wall=2571
2022-10-19 17:47:44 | INFO | train_inner | epoch 003:    926 / 3937 loss=13.733, nll_loss=10.272, mask_ins=1.987, word_ins_ml=10.951, word_reposition=0.795, ppl=13611.3, wps=6174.2, ups=3.44, wpb=1795.2, bsz=54.6, num_updates=8800, lr=0.000440012, gnorm=2.07, clip=0, loss_scale=512, train_wall=29, wall=2600
2022-10-19 17:48:13 | INFO | train_inner | epoch 003:   1026 / 3937 loss=13.682, nll_loss=10.238, mask_ins=1.968, word_ins_ml=10.922, word_reposition=0.792, ppl=13142.3, wps=6060, ups=3.45, wpb=1754.5, bsz=53.6, num_updates=8900, lr=0.000445011, gnorm=2.143, clip=0, loss_scale=512, train_wall=29, wall=2629
2022-10-19 17:48:42 | INFO | train_inner | epoch 003:   1126 / 3937 loss=13.701, nll_loss=10.25, mask_ins=1.994, word_ins_ml=10.933, word_reposition=0.773, ppl=13312.6, wps=5937.8, ups=3.43, wpb=1728.8, bsz=53.3, num_updates=9000, lr=0.00045001, gnorm=2.35, clip=0, loss_scale=512, train_wall=29, wall=2659
2022-10-19 17:49:11 | INFO | train_inner | epoch 003:   1226 / 3937 loss=13.697, nll_loss=10.275, mask_ins=1.961, word_ins_ml=10.954, word_reposition=0.783, ppl=13283.2, wps=6110.3, ups=3.4, wpb=1798.4, bsz=54.2, num_updates=9100, lr=0.000455009, gnorm=2.042, clip=0, loss_scale=512, train_wall=29, wall=2688
2022-10-19 17:49:40 | INFO | train_inner | epoch 003:   1326 / 3937 loss=13.797, nll_loss=10.262, mask_ins=2.035, word_ins_ml=10.944, word_reposition=0.818, ppl=14233, wps=5858.5, ups=3.43, wpb=1707.2, bsz=52, num_updates=9200, lr=0.000460008, gnorm=2.062, clip=0, loss_scale=512, train_wall=29, wall=2717
2022-10-19 17:50:09 | INFO | train_inner | epoch 003:   1426 / 3937 loss=13.714, nll_loss=10.255, mask_ins=2.015, word_ins_ml=10.936, word_reposition=0.763, ppl=13440.6, wps=5848.8, ups=3.49, wpb=1678.1, bsz=51.2, num_updates=9300, lr=0.000465007, gnorm=1.837, clip=0, loss_scale=512, train_wall=28, wall=2746
2022-10-19 17:50:38 | INFO | train_inner | epoch 003:   1526 / 3937 loss=13.614, nll_loss=10.23, mask_ins=1.9, word_ins_ml=10.913, word_reposition=0.801, ppl=12537.6, wps=6234.7, ups=3.46, wpb=1804.1, bsz=54.7, num_updates=9400, lr=0.000470006, gnorm=1.805, clip=0, loss_scale=512, train_wall=29, wall=2775
2022-10-19 17:51:07 | INFO | train_inner | epoch 003:   1626 / 3937 loss=13.67, nll_loss=10.247, mask_ins=1.953, word_ins_ml=10.928, word_reposition=0.789, ppl=13035.7, wps=5721.1, ups=3.48, wpb=1646, bsz=49.3, num_updates=9500, lr=0.000475005, gnorm=2.402, clip=0, loss_scale=512, train_wall=29, wall=2803
2022-10-19 17:51:36 | INFO | train_inner | epoch 003:   1726 / 3937 loss=13.673, nll_loss=10.228, mask_ins=1.982, word_ins_ml=10.913, word_reposition=0.778, ppl=13065.3, wps=5948.8, ups=3.42, wpb=1738.4, bsz=52.9, num_updates=9600, lr=0.000480004, gnorm=1.761, clip=0, loss_scale=512, train_wall=29, wall=2833
2022-10-19 17:52:05 | INFO | train_inner | epoch 003:   1826 / 3937 loss=13.703, nll_loss=10.244, mask_ins=2.013, word_ins_ml=10.925, word_reposition=0.764, ppl=13332.4, wps=5819.7, ups=3.49, wpb=1669.8, bsz=51.4, num_updates=9700, lr=0.000485003, gnorm=1.712, clip=0, loss_scale=512, train_wall=28, wall=2861
2022-10-19 17:52:33 | INFO | train_inner | epoch 003:   1926 / 3937 loss=13.674, nll_loss=10.235, mask_ins=1.946, word_ins_ml=10.918, word_reposition=0.809, ppl=13067.1, wps=5653.4, ups=3.48, wpb=1623, bsz=49.8, num_updates=9800, lr=0.000490002, gnorm=1.901, clip=0, loss_scale=512, train_wall=28, wall=2890
2022-10-19 17:53:02 | INFO | train_inner | epoch 003:   2026 / 3937 loss=13.693, nll_loss=10.232, mask_ins=1.997, word_ins_ml=10.915, word_reposition=0.781, ppl=13239.5, wps=5821.8, ups=3.42, wpb=1700.7, bsz=51.9, num_updates=9900, lr=0.000495001, gnorm=1.869, clip=0, loss_scale=512, train_wall=29, wall=2919
2022-10-19 17:53:31 | INFO | train_inner | epoch 003:   2126 / 3937 loss=13.676, nll_loss=10.219, mask_ins=1.994, word_ins_ml=10.904, word_reposition=0.778, ppl=13091.1, wps=5964.5, ups=3.47, wpb=1719.9, bsz=52.2, num_updates=10000, lr=0.0005, gnorm=1.683, clip=0, loss_scale=512, train_wall=29, wall=2948
2022-10-19 17:54:01 | INFO | train_inner | epoch 003:   2226 / 3937 loss=13.722, nll_loss=10.25, mask_ins=1.988, word_ins_ml=10.93, word_reposition=0.804, ppl=13511.1, wps=6115.6, ups=3.39, wpb=1804.8, bsz=54.6, num_updates=10100, lr=0.000497519, gnorm=2.044, clip=0, loss_scale=512, train_wall=29, wall=2978
2022-10-19 17:54:30 | INFO | train_inner | epoch 003:   2326 / 3937 loss=13.692, nll_loss=10.259, mask_ins=1.966, word_ins_ml=10.939, word_reposition=0.787, ppl=13229.9, wps=5748.7, ups=3.48, wpb=1653.1, bsz=49.5, num_updates=10200, lr=0.000495074, gnorm=1.853, clip=0, loss_scale=512, train_wall=29, wall=3006
2022-10-19 17:54:58 | INFO | train_inner | epoch 003:   2426 / 3937 loss=13.652, nll_loss=10.249, mask_ins=1.965, word_ins_ml=10.93, word_reposition=0.758, ppl=12873.8, wps=5663.1, ups=3.5, wpb=1616.7, bsz=49.3, num_updates=10300, lr=0.000492665, gnorm=1.543, clip=0, loss_scale=512, train_wall=28, wall=3035
2022-10-19 17:55:27 | INFO | train_inner | epoch 003:   2526 / 3937 loss=13.726, nll_loss=10.24, mask_ins=1.998, word_ins_ml=10.922, word_reposition=0.806, ppl=13554, wps=5316.9, ups=3.5, wpb=1521.3, bsz=45.8, num_updates=10400, lr=0.00049029, gnorm=2.994, clip=1, loss_scale=512, train_wall=28, wall=3064
2022-10-19 17:55:56 | INFO | train_inner | epoch 003:   2626 / 3937 loss=13.649, nll_loss=10.232, mask_ins=1.991, word_ins_ml=10.915, word_reposition=0.744, ppl=12841.9, wps=5930.7, ups=3.46, wpb=1711.7, bsz=52.4, num_updates=10500, lr=0.00048795, gnorm=1.752, clip=0, loss_scale=512, train_wall=29, wall=3092
2022-10-19 17:56:25 | INFO | train_inner | epoch 003:   2726 / 3937 loss=13.658, nll_loss=10.218, mask_ins=1.978, word_ins_ml=10.902, word_reposition=0.778, ppl=12926.7, wps=5757.9, ups=3.45, wpb=1667.2, bsz=51, num_updates=10600, lr=0.000485643, gnorm=1.452, clip=0, loss_scale=512, train_wall=29, wall=3121
2022-10-19 17:56:53 | INFO | train_inner | epoch 003:   2826 / 3937 loss=13.705, nll_loss=10.211, mask_ins=2.033, word_ins_ml=10.896, word_reposition=0.777, ppl=13357.6, wps=5905.8, ups=3.47, wpb=1701.4, bsz=51.8, num_updates=10700, lr=0.000483368, gnorm=1.558, clip=0, loss_scale=512, train_wall=29, wall=3150
2022-10-19 17:57:22 | INFO | train_inner | epoch 003:   2926 / 3937 loss=13.69, nll_loss=10.238, mask_ins=1.971, word_ins_ml=10.919, word_reposition=0.8, ppl=13218.3, wps=5575.4, ups=3.5, wpb=1592.4, bsz=47.8, num_updates=10800, lr=0.000481125, gnorm=1.584, clip=0, loss_scale=512, train_wall=28, wall=3179
2022-10-19 17:57:51 | INFO | train_inner | epoch 003:   3026 / 3937 loss=13.606, nll_loss=10.221, mask_ins=1.93, word_ins_ml=10.904, word_reposition=0.772, ppl=12470.6, wps=5630, ups=3.49, wpb=1615, bsz=48.8, num_updates=10900, lr=0.000478913, gnorm=1.648, clip=0, loss_scale=512, train_wall=28, wall=3207
2022-10-19 17:58:19 | INFO | train_inner | epoch 003:   3126 / 3937 loss=13.663, nll_loss=10.193, mask_ins=1.976, word_ins_ml=10.88, word_reposition=0.806, ppl=12968.4, wps=6053.4, ups=3.51, wpb=1726.8, bsz=52.9, num_updates=11000, lr=0.000476731, gnorm=1.466, clip=0, loss_scale=512, train_wall=28, wall=3236
2022-10-19 17:58:48 | INFO | train_inner | epoch 003:   3226 / 3937 loss=13.695, nll_loss=10.218, mask_ins=1.987, word_ins_ml=10.901, word_reposition=0.807, ppl=13264.6, wps=5729.8, ups=3.5, wpb=1635, bsz=49.1, num_updates=11100, lr=0.000474579, gnorm=2.812, clip=2, loss_scale=512, train_wall=28, wall=3265
2022-10-19 17:59:17 | INFO | train_inner | epoch 003:   3326 / 3937 loss=13.64, nll_loss=10.216, mask_ins=1.932, word_ins_ml=10.9, word_reposition=0.808, ppl=12765.4, wps=5763.1, ups=3.45, wpb=1670.1, bsz=51.1, num_updates=11200, lr=0.000472456, gnorm=1.343, clip=0, loss_scale=512, train_wall=29, wall=3294
2022-10-19 17:59:46 | INFO | train_inner | epoch 003:   3426 / 3937 loss=13.557, nll_loss=10.203, mask_ins=1.906, word_ins_ml=10.888, word_reposition=0.762, ppl=12048.3, wps=5838, ups=3.42, wpb=1708.6, bsz=51.7, num_updates=11300, lr=0.00047036, gnorm=1.234, clip=0, loss_scale=512, train_wall=29, wall=3323
2022-10-19 18:00:15 | INFO | train_inner | epoch 003:   3526 / 3937 loss=13.627, nll_loss=10.22, mask_ins=1.94, word_ins_ml=10.901, word_reposition=0.786, ppl=12649.2, wps=5578.2, ups=3.46, wpb=1610.6, bsz=48.9, num_updates=11400, lr=0.000468293, gnorm=1.344, clip=0, loss_scale=512, train_wall=29, wall=3352
2022-10-19 18:00:44 | INFO | train_inner | epoch 003:   3626 / 3937 loss=13.648, nll_loss=10.225, mask_ins=1.968, word_ins_ml=10.907, word_reposition=0.773, ppl=12837.4, wps=5965.3, ups=3.45, wpb=1728.5, bsz=51.9, num_updates=11500, lr=0.000466252, gnorm=1.249, clip=0, loss_scale=512, train_wall=29, wall=3381
2022-10-19 18:01:13 | INFO | train_inner | epoch 003:   3726 / 3937 loss=13.617, nll_loss=10.216, mask_ins=1.953, word_ins_ml=10.9, word_reposition=0.764, ppl=12560.4, wps=6235.9, ups=3.45, wpb=1805.1, bsz=55.9, num_updates=11600, lr=0.000464238, gnorm=1.321, clip=0, loss_scale=512, train_wall=29, wall=3410
2022-10-19 18:01:42 | INFO | train_inner | epoch 003:   3826 / 3937 loss=13.604, nll_loss=10.22, mask_ins=1.928, word_ins_ml=10.902, word_reposition=0.774, ppl=12453.6, wps=5913.1, ups=3.44, wpb=1717.2, bsz=52.4, num_updates=11700, lr=0.00046225, gnorm=1.318, clip=0, loss_scale=512, train_wall=29, wall=3439
2022-10-19 18:02:11 | INFO | train_inner | epoch 003:   3926 / 3937 loss=13.567, nll_loss=10.213, mask_ins=1.909, word_ins_ml=10.896, word_reposition=0.763, ppl=12136.4, wps=5773.4, ups=3.47, wpb=1664.9, bsz=50.5, num_updates=11800, lr=0.000460287, gnorm=1.283, clip=0, loss_scale=512, train_wall=29, wall=3467
2022-10-19 18:02:14 | INFO | train | epoch 003 | loss 13.685 | nll_loss 10.243 | mask_ins 1.98 | word_ins_ml 10.925 | word_reposition 0.78 | ppl 13167.1 | wps 5726.3 | ups 3.38 | wpb 1696.2 | bsz 51.5 | num_updates 11811 | lr 0.000460073 | gnorm 1.922 | clip 0.1 | loss_scale 491 | train_wall 1129 | wall 3471
2022-10-19 18:02:25 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 16.746 | nll_loss 12.25 | mask_ins 3.554 | word_ins_ml 12.544 | word_reposition 0.648 | ppl 109926 | wps 27553.3 | wpb 1503.2 | bsz 51.5 | num_updates 11811 | best_loss 14.267
2022-10-19 18:02:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 3 @ 11811 updates, score 16.746) (writing took 8.346877202042378 seconds)
2022-10-19 18:03:00 | INFO | train_inner | epoch 004:     89 / 3937 loss=13.625, nll_loss=10.216, mask_ins=1.934, word_ins_ml=10.899, word_reposition=0.792, ppl=12633.9, wps=3445.7, ups=2.04, wpb=1685.5, bsz=50.9, num_updates=11900, lr=0.000458349, gnorm=2.639, clip=1, loss_scale=512, train_wall=29, wall=3516
2022-10-19 18:03:29 | INFO | train_inner | epoch 004:    189 / 3937 loss=13.604, nll_loss=10.203, mask_ins=1.916, word_ins_ml=10.889, word_reposition=0.801, ppl=12453.9, wps=5881.8, ups=3.43, wpb=1713.3, bsz=53.3, num_updates=12000, lr=0.000456435, gnorm=1.543, clip=0, loss_scale=512, train_wall=29, wall=3546
2022-10-19 18:03:58 | INFO | train_inner | epoch 004:    289 / 3937 loss=13.559, nll_loss=10.221, mask_ins=1.878, word_ins_ml=10.904, word_reposition=0.778, ppl=12070.5, wps=6114.8, ups=3.42, wpb=1790.1, bsz=55.6, num_updates=12100, lr=0.000454545, gnorm=1.549, clip=1, loss_scale=512, train_wall=29, wall=3575
2022-10-19 18:04:27 | INFO | train_inner | epoch 004:    389 / 3937 loss=13.615, nll_loss=10.191, mask_ins=1.954, word_ins_ml=10.877, word_reposition=0.783, ppl=12542.7, wps=6047.8, ups=3.44, wpb=1756.7, bsz=52.9, num_updates=12200, lr=0.000452679, gnorm=1.214, clip=0, loss_scale=512, train_wall=29, wall=3604
2022-10-19 18:04:56 | INFO | train_inner | epoch 004:    489 / 3937 loss=13.622, nll_loss=10.197, mask_ins=1.963, word_ins_ml=10.881, word_reposition=0.778, ppl=12605.8, wps=5724.6, ups=3.48, wpb=1647.3, bsz=49.8, num_updates=12300, lr=0.000450835, gnorm=1.546, clip=0, loss_scale=579, train_wall=29, wall=3633
2022-10-19 18:05:25 | INFO | train_inner | epoch 004:    589 / 3937 loss=13.581, nll_loss=10.181, mask_ins=1.934, word_ins_ml=10.868, word_reposition=0.779, ppl=12256, wps=5647.1, ups=3.46, wpb=1632.2, bsz=50.3, num_updates=12400, lr=0.000449013, gnorm=1.44, clip=0, loss_scale=1024, train_wall=29, wall=3662
2022-10-19 18:05:53 | INFO | train_inner | epoch 004:    689 / 3937 loss=13.537, nll_loss=10.175, mask_ins=1.875, word_ins_ml=10.863, word_reposition=0.8, ppl=11887.4, wps=5897.5, ups=3.5, wpb=1685.7, bsz=51.7, num_updates=12500, lr=0.000447214, gnorm=1.251, clip=0, loss_scale=1024, train_wall=28, wall=3690
2022-10-19 18:06:22 | INFO | train_inner | epoch 004:    789 / 3937 loss=13.58, nll_loss=10.22, mask_ins=1.933, word_ins_ml=10.901, word_reposition=0.746, ppl=12247.1, wps=6087.1, ups=3.42, wpb=1780.3, bsz=54.6, num_updates=12600, lr=0.000445435, gnorm=1.149, clip=0, loss_scale=1024, train_wall=29, wall=3719
2022-10-19 18:06:52 | INFO | train_inner | epoch 004:    889 / 3937 loss=13.581, nll_loss=10.219, mask_ins=1.91, word_ins_ml=10.9, word_reposition=0.77, ppl=12250.2, wps=5826.4, ups=3.44, wpb=1693.7, bsz=50.2, num_updates=12700, lr=0.000443678, gnorm=1.201, clip=0, loss_scale=1024, train_wall=29, wall=3748
2022-10-19 18:07:21 | INFO | train_inner | epoch 004:    989 / 3937 loss=13.559, nll_loss=10.188, mask_ins=1.917, word_ins_ml=10.874, word_reposition=0.768, ppl=12067.1, wps=6238.9, ups=3.43, wpb=1818.1, bsz=55.8, num_updates=12800, lr=0.000441942, gnorm=1.034, clip=0, loss_scale=1024, train_wall=29, wall=3778
2022-10-19 18:07:49 | INFO | train_inner | epoch 004:   1089 / 3937 loss=13.577, nll_loss=10.21, mask_ins=1.907, word_ins_ml=10.893, word_reposition=0.777, ppl=12218.7, wps=5898.9, ups=3.48, wpb=1692.7, bsz=50.9, num_updates=12900, lr=0.000440225, gnorm=1.159, clip=0, loss_scale=1024, train_wall=28, wall=3806
2022-10-19 18:08:18 | INFO | train_inner | epoch 004:   1189 / 3937 loss=13.555, nll_loss=10.209, mask_ins=1.911, word_ins_ml=10.891, word_reposition=0.753, ppl=12038.3, wps=5487.6, ups=3.46, wpb=1584.9, bsz=48.1, num_updates=13000, lr=0.000438529, gnorm=1.045, clip=0, loss_scale=1024, train_wall=29, wall=3835
2022-10-19 18:08:47 | INFO | train_inner | epoch 004:   1289 / 3937 loss=13.601, nll_loss=10.211, mask_ins=1.93, word_ins_ml=10.893, word_reposition=0.778, ppl=12428.3, wps=5718.3, ups=3.5, wpb=1634.1, bsz=49.2, num_updates=13100, lr=0.000436852, gnorm=1.145, clip=0, loss_scale=1024, train_wall=28, wall=3864
2022-10-19 18:09:16 | INFO | train_inner | epoch 004:   1389 / 3937 loss=13.564, nll_loss=10.184, mask_ins=1.898, word_ins_ml=10.871, word_reposition=0.795, ppl=12107.5, wps=6211.6, ups=3.44, wpb=1805, bsz=55.5, num_updates=13200, lr=0.000435194, gnorm=1.083, clip=0, loss_scale=1024, train_wall=29, wall=3893
2022-10-19 18:09:45 | INFO | train_inner | epoch 004:   1489 / 3937 loss=13.549, nll_loss=10.206, mask_ins=1.904, word_ins_ml=10.889, word_reposition=0.755, ppl=11982.1, wps=5737.2, ups=3.48, wpb=1646.5, bsz=49.7, num_updates=13300, lr=0.000433555, gnorm=1.307, clip=0, loss_scale=1024, train_wall=28, wall=3921
2022-10-19 18:10:14 | INFO | train_inner | epoch 004:   1589 / 3937 loss=13.565, nll_loss=10.212, mask_ins=1.895, word_ins_ml=10.894, word_reposition=0.776, ppl=12120.5, wps=5737.3, ups=3.46, wpb=1659.7, bsz=49.6, num_updates=13400, lr=0.000431934, gnorm=1.132, clip=0, loss_scale=1024, train_wall=29, wall=3950
2022-10-19 18:10:42 | INFO | train_inner | epoch 004:   1689 / 3937 loss=13.62, nll_loss=10.195, mask_ins=1.948, word_ins_ml=10.88, word_reposition=0.792, ppl=12586.6, wps=5923.2, ups=3.49, wpb=1697, bsz=51.2, num_updates=13500, lr=0.000430331, gnorm=1.29, clip=0, loss_scale=1024, train_wall=28, wall=3979
2022-10-19 18:11:11 | INFO | train_inner | epoch 004:   1789 / 3937 loss=13.6, nll_loss=10.21, mask_ins=1.953, word_ins_ml=10.892, word_reposition=0.754, ppl=12414, wps=5752.6, ups=3.46, wpb=1662.4, bsz=50.7, num_updates=13600, lr=0.000428746, gnorm=1.374, clip=0, loss_scale=1024, train_wall=29, wall=4008
2022-10-19 18:11:40 | INFO | train_inner | epoch 004:   1889 / 3937 loss=13.566, nll_loss=10.153, mask_ins=1.959, word_ins_ml=10.842, word_reposition=0.765, ppl=12130.5, wps=5923.9, ups=3.46, wpb=1713.9, bsz=53.6, num_updates=13700, lr=0.000427179, gnorm=0.992, clip=0, loss_scale=1024, train_wall=29, wall=4037
2022-10-19 18:12:09 | INFO | train_inner | epoch 004:   1989 / 3937 loss=13.496, nll_loss=10.221, mask_ins=1.841, word_ins_ml=10.902, word_reposition=0.753, ppl=11552.9, wps=6108.9, ups=3.43, wpb=1781.5, bsz=53.7, num_updates=13800, lr=0.000425628, gnorm=1.04, clip=0, loss_scale=1024, train_wall=29, wall=4066
2022-10-19 18:12:39 | INFO | train_inner | epoch 004:   2089 / 3937 loss=13.592, nll_loss=10.224, mask_ins=1.906, word_ins_ml=10.904, word_reposition=0.784, ppl=12352.1, wps=6028.8, ups=3.4, wpb=1774.7, bsz=53.3, num_updates=13900, lr=0.000424094, gnorm=1.182, clip=0, loss_scale=1024, train_wall=29, wall=4095
2022-10-19 18:13:08 | INFO | train_inner | epoch 004:   2189 / 3937 loss=13.511, nll_loss=10.189, mask_ins=1.889, word_ins_ml=10.874, word_reposition=0.748, ppl=11677.5, wps=5365.5, ups=3.46, wpb=1549.1, bsz=47.5, num_updates=14000, lr=0.000422577, gnorm=1.221, clip=0, loss_scale=1024, train_wall=29, wall=4124
2022-10-19 18:13:36 | INFO | train_inner | epoch 004:   2289 / 3937 loss=13.615, nll_loss=10.211, mask_ins=1.948, word_ins_ml=10.893, word_reposition=0.774, ppl=12547.6, wps=5994.3, ups=3.49, wpb=1716.7, bsz=51, num_updates=14100, lr=0.000421076, gnorm=1.298, clip=0, loss_scale=1024, train_wall=28, wall=4153
2022-10-19 18:14:05 | INFO | train_inner | epoch 004:   2389 / 3937 loss=13.496, nll_loss=10.186, mask_ins=1.869, word_ins_ml=10.872, word_reposition=0.755, ppl=11550.8, wps=5376.1, ups=3.48, wpb=1543.8, bsz=46.3, num_updates=14200, lr=0.000419591, gnorm=1.096, clip=0, loss_scale=1024, train_wall=28, wall=4182
2022-10-19 18:14:34 | INFO | train_inner | epoch 004:   2489 / 3937 loss=13.554, nll_loss=10.189, mask_ins=1.897, word_ins_ml=10.874, word_reposition=0.782, ppl=12027.4, wps=5862.3, ups=3.49, wpb=1681.4, bsz=50.9, num_updates=14300, lr=0.000418121, gnorm=1.147, clip=0, loss_scale=1024, train_wall=28, wall=4210
2022-10-19 18:15:03 | INFO | train_inner | epoch 004:   2589 / 3937 loss=13.57, nll_loss=10.19, mask_ins=1.923, word_ins_ml=10.874, word_reposition=0.772, ppl=12157, wps=5851.8, ups=3.45, wpb=1694.8, bsz=51.5, num_updates=14400, lr=0.000416667, gnorm=1.135, clip=0, loss_scale=1024, train_wall=29, wall=4239
2022-10-19 18:15:31 | INFO | train_inner | epoch 004:   2689 / 3937 loss=13.578, nll_loss=10.187, mask_ins=1.93, word_ins_ml=10.872, word_reposition=0.776, ppl=12225.5, wps=5639.4, ups=3.46, wpb=1632, bsz=49.6, num_updates=14500, lr=0.000415227, gnorm=1.314, clip=0, loss_scale=1024, train_wall=29, wall=4268
2022-10-19 18:16:00 | INFO | train_inner | epoch 004:   2789 / 3937 loss=13.525, nll_loss=10.215, mask_ins=1.888, word_ins_ml=10.897, word_reposition=0.74, ppl=11790.1, wps=5884.5, ups=3.49, wpb=1686, bsz=50.8, num_updates=14600, lr=0.000413803, gnorm=0.994, clip=0, loss_scale=1024, train_wall=28, wall=4297
2022-10-19 18:16:29 | INFO | train_inner | epoch 004:   2889 / 3937 loss=13.697, nll_loss=10.214, mask_ins=2.024, word_ins_ml=10.895, word_reposition=0.778, ppl=13280.6, wps=5376, ups=3.49, wpb=1542, bsz=46.5, num_updates=14700, lr=0.000412393, gnorm=1.085, clip=0, loss_scale=1024, train_wall=28, wall=4326
2022-10-19 18:16:58 | INFO | train_inner | epoch 004:   2989 / 3937 loss=13.613, nll_loss=10.206, mask_ins=1.96, word_ins_ml=10.887, word_reposition=0.766, ppl=12529, wps=6260.9, ups=3.42, wpb=1831.6, bsz=56, num_updates=14800, lr=0.000410997, gnorm=1.044, clip=0, loss_scale=1024, train_wall=29, wall=4355
2022-10-19 18:17:27 | INFO | train_inner | epoch 004:   3089 / 3937 loss=13.585, nll_loss=10.23, mask_ins=1.926, word_ins_ml=10.909, word_reposition=0.75, ppl=12292.2, wps=6267, ups=3.44, wpb=1822.9, bsz=55.1, num_updates=14900, lr=0.000409616, gnorm=1.078, clip=0, loss_scale=1024, train_wall=29, wall=4384
2022-10-19 18:17:56 | INFO | train_inner | epoch 004:   3189 / 3937 loss=13.574, nll_loss=10.198, mask_ins=1.905, word_ins_ml=10.881, word_reposition=0.788, ppl=12193, wps=5898.6, ups=3.43, wpb=1718.1, bsz=52.6, num_updates=15000, lr=0.000408248, gnorm=1.177, clip=0, loss_scale=1024, train_wall=29, wall=4413
2022-10-19 18:18:26 | INFO | train_inner | epoch 004:   3289 / 3937 loss=13.601, nll_loss=10.189, mask_ins=1.935, word_ins_ml=10.872, word_reposition=0.793, ppl=12421.1, wps=6269.1, ups=3.38, wpb=1853.7, bsz=56.5, num_updates=15100, lr=0.000406894, gnorm=1.76, clip=1, loss_scale=1024, train_wall=29, wall=4443
2022-10-19 18:18:55 | INFO | train_inner | epoch 004:   3389 / 3937 loss=13.529, nll_loss=10.154, mask_ins=1.934, word_ins_ml=10.843, word_reposition=0.751, ppl=11819, wps=5674.8, ups=3.45, wpb=1647.2, bsz=50.5, num_updates=15200, lr=0.000405554, gnorm=1.187, clip=0, loss_scale=1024, train_wall=29, wall=4472
2022-10-19 18:19:24 | INFO | train_inner | epoch 004:   3489 / 3937 loss=13.495, nll_loss=10.195, mask_ins=1.845, word_ins_ml=10.878, word_reposition=0.771, ppl=11542, wps=5618.4, ups=3.42, wpb=1641.7, bsz=49.8, num_updates=15300, lr=0.000404226, gnorm=1.08, clip=0, loss_scale=1024, train_wall=29, wall=4501
2022-10-19 18:19:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-10-19 18:19:53 | INFO | train_inner | epoch 004:   3590 / 3937 loss=13.616, nll_loss=10.219, mask_ins=1.93, word_ins_ml=10.898, word_reposition=0.788, ppl=12556.9, wps=5758.7, ups=3.46, wpb=1664.1, bsz=50, num_updates=15400, lr=0.000402911, gnorm=1.137, clip=0, loss_scale=710, train_wall=29, wall=4530
2022-10-19 18:20:22 | INFO | train_inner | epoch 004:   3690 / 3937 loss=13.586, nll_loss=10.189, mask_ins=1.936, word_ins_ml=10.873, word_reposition=0.778, ppl=12295.5, wps=5911.7, ups=3.48, wpb=1700.5, bsz=51.7, num_updates=15500, lr=0.00040161, gnorm=1.094, clip=0, loss_scale=512, train_wall=29, wall=4559
2022-10-19 18:20:51 | INFO | train_inner | epoch 004:   3790 / 3937 loss=13.603, nll_loss=10.192, mask_ins=1.965, word_ins_ml=10.876, word_reposition=0.762, ppl=12442.2, wps=5571.9, ups=3.47, wpb=1606.1, bsz=48, num_updates=15600, lr=0.00040032, gnorm=1.32, clip=0, loss_scale=512, train_wall=29, wall=4587
2022-10-19 18:21:19 | INFO | train_inner | epoch 004:   3890 / 3937 loss=13.543, nll_loss=10.179, mask_ins=1.9, word_ins_ml=10.865, word_reposition=0.778, ppl=11932.4, wps=6060.5, ups=3.46, wpb=1750.7, bsz=52.5, num_updates=15700, lr=0.000399043, gnorm=1.275, clip=0, loss_scale=512, train_wall=29, wall=4616
2022-10-19 18:21:33 | INFO | train | epoch 004 | loss 13.576 | nll_loss 10.2 | mask_ins 1.92 | word_ins_ml 10.883 | word_reposition 0.772 | ppl 12208.6 | wps 5760 | ups 3.4 | wpb 1696.4 | bsz 51.5 | num_updates 15747 | lr 0.000398447 | gnorm 1.248 | clip 0.1 | loss_scale 909 | train_wall 1129 | wall 4630
2022-10-19 18:21:45 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 20.637 | nll_loss 12.829 | mask_ins 4.827 | word_ins_ml 13.047 | word_reposition 2.763 | ppl 1.63039e+06 | wps 27629.5 | wpb 1503.2 | bsz 51.5 | num_updates 15747 | best_loss 14.267
2022-10-19 18:21:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 4 @ 15747 updates, score 20.637) (writing took 9.257513959892094 seconds)
2022-10-19 18:22:09 | INFO | train_inner | epoch 005:     53 / 3937 loss=13.577, nll_loss=10.172, mask_ins=1.961, word_ins_ml=10.858, word_reposition=0.758, ppl=12220.6, wps=3395.4, ups=2, wpb=1697, bsz=52.8, num_updates=15800, lr=0.000397779, gnorm=1.195, clip=0, loss_scale=512, train_wall=29, wall=4666
2022-10-19 18:22:38 | INFO | train_inner | epoch 005:    153 / 3937 loss=13.506, nll_loss=10.208, mask_ins=1.866, word_ins_ml=10.889, word_reposition=0.75, ppl=11630.7, wps=6051.7, ups=3.46, wpb=1751, bsz=54.3, num_updates=15900, lr=0.000396526, gnorm=1.011, clip=0, loss_scale=512, train_wall=29, wall=4695
2022-10-19 18:23:08 | INFO | train_inner | epoch 005:    253 / 3937 loss=13.569, nll_loss=10.166, mask_ins=1.937, word_ins_ml=10.853, word_reposition=0.779, ppl=12149.5, wps=6016.8, ups=3.43, wpb=1756, bsz=54.4, num_updates=16000, lr=0.000395285, gnorm=1.098, clip=0, loss_scale=512, train_wall=29, wall=4724
2022-10-19 18:23:36 | INFO | train_inner | epoch 005:    353 / 3937 loss=13.616, nll_loss=10.206, mask_ins=1.954, word_ins_ml=10.888, word_reposition=0.775, ppl=12555.5, wps=5957.1, ups=3.47, wpb=1718.2, bsz=52.1, num_updates=16100, lr=0.000394055, gnorm=1.081, clip=0, loss_scale=512, train_wall=29, wall=4753
2022-10-19 18:24:06 | INFO | train_inner | epoch 005:    453 / 3937 loss=13.607, nll_loss=10.214, mask_ins=1.94, word_ins_ml=10.894, word_reposition=0.772, ppl=12475.3, wps=6263.6, ups=3.42, wpb=1829.3, bsz=54.7, num_updates=16200, lr=0.000392837, gnorm=0.981, clip=0, loss_scale=512, train_wall=29, wall=4782
2022-10-19 18:24:34 | INFO | train_inner | epoch 005:    553 / 3937 loss=13.532, nll_loss=10.177, mask_ins=1.902, word_ins_ml=10.862, word_reposition=0.768, ppl=11846.5, wps=5745.1, ups=3.46, wpb=1660.1, bsz=50.6, num_updates=16300, lr=0.00039163, gnorm=1.05, clip=0, loss_scale=512, train_wall=29, wall=4811
2022-10-19 18:25:04 | INFO | train_inner | epoch 005:    653 / 3937 loss=13.571, nll_loss=10.176, mask_ins=1.946, word_ins_ml=10.861, word_reposition=0.764, ppl=12168.9, wps=6707.8, ups=3.43, wpb=1958, bsz=60.1, num_updates=16400, lr=0.000390434, gnorm=1.39, clip=1, loss_scale=512, train_wall=29, wall=4841
2022-10-19 18:25:33 | INFO | train_inner | epoch 005:    753 / 3937 loss=13.537, nll_loss=10.196, mask_ins=1.915, word_ins_ml=10.878, word_reposition=0.745, ppl=11885.9, wps=5591, ups=3.42, wpb=1633, bsz=50.4, num_updates=16500, lr=0.000389249, gnorm=1.047, clip=0, loss_scale=512, train_wall=29, wall=4870
2022-10-19 18:26:02 | INFO | train_inner | epoch 005:    853 / 3937 loss=13.546, nll_loss=10.186, mask_ins=1.922, word_ins_ml=10.87, word_reposition=0.754, ppl=11963.9, wps=5913.3, ups=3.44, wpb=1721.1, bsz=52.9, num_updates=16600, lr=0.000388075, gnorm=1.096, clip=0, loss_scale=512, train_wall=29, wall=4899
2022-10-19 18:26:31 | INFO | train_inner | epoch 005:    953 / 3937 loss=13.595, nll_loss=10.162, mask_ins=1.968, word_ins_ml=10.85, word_reposition=0.778, ppl=12376.1, wps=5900.1, ups=3.42, wpb=1725.2, bsz=52.4, num_updates=16700, lr=0.000386912, gnorm=1.162, clip=0, loss_scale=512, train_wall=29, wall=4928
2022-10-19 18:27:00 | INFO | train_inner | epoch 005:   1053 / 3937 loss=13.525, nll_loss=10.186, mask_ins=1.888, word_ins_ml=10.87, word_reposition=0.766, ppl=11783.7, wps=5753.6, ups=3.47, wpb=1659.6, bsz=49.5, num_updates=16800, lr=0.000385758, gnorm=1.116, clip=0, loss_scale=512, train_wall=29, wall=4957
2022-10-19 18:27:29 | INFO | train_inner | epoch 005:   1153 / 3937 loss=13.5, nll_loss=10.186, mask_ins=1.885, word_ins_ml=10.871, word_reposition=0.744, ppl=11588.6, wps=5687.1, ups=3.45, wpb=1650.2, bsz=50.2, num_updates=16900, lr=0.000384615, gnorm=1.129, clip=0, loss_scale=512, train_wall=29, wall=4986
2022-10-19 18:27:58 | INFO | train_inner | epoch 005:   1253 / 3937 loss=13.516, nll_loss=10.22, mask_ins=1.876, word_ins_ml=10.899, word_reposition=0.741, ppl=11716, wps=5724.3, ups=3.44, wpb=1664.6, bsz=51, num_updates=17000, lr=0.000383482, gnorm=1.083, clip=0, loss_scale=512, train_wall=29, wall=5015
2022-10-19 18:28:27 | INFO | train_inner | epoch 005:   1353 / 3937 loss=13.605, nll_loss=10.19, mask_ins=1.96, word_ins_ml=10.873, word_reposition=0.771, ppl=12459.5, wps=5556.7, ups=3.51, wpb=1581.3, bsz=46.9, num_updates=17100, lr=0.00038236, gnorm=1.041, clip=0, loss_scale=512, train_wall=28, wall=5043
2022-10-19 18:28:55 | INFO | train_inner | epoch 005:   1453 / 3937 loss=13.478, nll_loss=10.18, mask_ins=1.877, word_ins_ml=10.864, word_reposition=0.737, ppl=11413.4, wps=5649.3, ups=3.47, wpb=1626.6, bsz=49.8, num_updates=17200, lr=0.000381246, gnorm=1.13, clip=0, loss_scale=512, train_wall=29, wall=5072
2022-10-19 18:29:24 | INFO | train_inner | epoch 005:   1553 / 3937 loss=13.574, nll_loss=10.215, mask_ins=1.91, word_ins_ml=10.895, word_reposition=0.769, ppl=12191.3, wps=5673.5, ups=3.48, wpb=1630, bsz=48.5, num_updates=17300, lr=0.000380143, gnorm=1.401, clip=0, loss_scale=512, train_wall=28, wall=5101
2022-10-19 18:29:53 | INFO | train_inner | epoch 005:   1653 / 3937 loss=13.558, nll_loss=10.182, mask_ins=1.911, word_ins_ml=10.868, word_reposition=0.778, ppl=12062.9, wps=5791.4, ups=3.47, wpb=1668, bsz=50.7, num_updates=17400, lr=0.000379049, gnorm=1.107, clip=0, loss_scale=512, train_wall=29, wall=5130
2022-10-19 18:30:22 | INFO | train_inner | epoch 005:   1753 / 3937 loss=13.483, nll_loss=10.191, mask_ins=1.841, word_ins_ml=10.873, word_reposition=0.769, ppl=11448.6, wps=5564.3, ups=3.48, wpb=1596.7, bsz=48.3, num_updates=17500, lr=0.000377964, gnorm=0.999, clip=0, loss_scale=512, train_wall=28, wall=5159
2022-10-19 18:30:50 | INFO | train_inner | epoch 005:   1853 / 3937 loss=13.578, nll_loss=10.195, mask_ins=1.905, word_ins_ml=10.878, word_reposition=0.795, ppl=12227.5, wps=5428.2, ups=3.5, wpb=1549.1, bsz=46.4, num_updates=17600, lr=0.000376889, gnorm=1.226, clip=0, loss_scale=512, train_wall=28, wall=5187
2022-10-19 18:31:20 | INFO | train_inner | epoch 005:   1953 / 3937 loss=13.545, nll_loss=10.161, mask_ins=1.941, word_ins_ml=10.848, word_reposition=0.755, ppl=11952.5, wps=6350.3, ups=3.41, wpb=1862.5, bsz=58.1, num_updates=17700, lr=0.000375823, gnorm=1.203, clip=0, loss_scale=512, train_wall=29, wall=5216
2022-10-19 18:31:49 | INFO | train_inner | epoch 005:   2053 / 3937 loss=13.551, nll_loss=10.207, mask_ins=1.893, word_ins_ml=10.889, word_reposition=0.769, ppl=12001.8, wps=5601.2, ups=3.42, wpb=1636.8, bsz=50, num_updates=17800, lr=0.000374766, gnorm=1.111, clip=0, loss_scale=512, train_wall=29, wall=5246
2022-10-19 18:32:18 | INFO | train_inner | epoch 005:   2153 / 3937 loss=13.606, nll_loss=10.196, mask_ins=1.956, word_ins_ml=10.878, word_reposition=0.772, ppl=12464.3, wps=5723.5, ups=3.46, wpb=1656.6, bsz=49.1, num_updates=17900, lr=0.000373718, gnorm=1.202, clip=0, loss_scale=512, train_wall=29, wall=5275
2022-10-19 18:32:46 | INFO | train_inner | epoch 005:   2253 / 3937 loss=13.754, nll_loss=10.093, mask_ins=1.936, word_ins_ml=10.789, word_reposition=1.03, ppl=13816.4, wps=6159, ups=3.48, wpb=1768, bsz=54.3, num_updates=18000, lr=0.000372678, gnorm=3.193, clip=3, loss_scale=512, train_wall=28, wall=5303
2022-10-19 18:33:16 | INFO | train_inner | epoch 005:   2353 / 3937 loss=13.692, nll_loss=10.13, mask_ins=1.982, word_ins_ml=10.82, word_reposition=0.89, ppl=13235.1, wps=5826.7, ups=3.43, wpb=1697.6, bsz=51.4, num_updates=18100, lr=0.000371647, gnorm=1.933, clip=1, loss_scale=512, train_wall=29, wall=5332
2022-10-19 18:33:45 | INFO | train_inner | epoch 005:   2453 / 3937 loss=13.629, nll_loss=10.169, mask_ins=1.982, word_ins_ml=10.855, word_reposition=0.792, ppl=12665.3, wps=5750.8, ups=3.43, wpb=1676.9, bsz=50.7, num_updates=18200, lr=0.000370625, gnorm=2.037, clip=1, loss_scale=512, train_wall=29, wall=5362
2022-10-19 18:34:13 | INFO | train_inner | epoch 005:   2553 / 3937 loss=13.554, nll_loss=10.184, mask_ins=1.909, word_ins_ml=10.868, word_reposition=0.777, ppl=12024.6, wps=5775.5, ups=3.5, wpb=1649.1, bsz=49.6, num_updates=18300, lr=0.000369611, gnorm=2.352, clip=1, loss_scale=512, train_wall=28, wall=5390
2022-10-19 18:34:42 | INFO | train_inner | epoch 005:   2653 / 3937 loss=13.499, nll_loss=10.171, mask_ins=1.882, word_ins_ml=10.857, word_reposition=0.76, ppl=11577.9, wps=6045.2, ups=3.47, wpb=1740.7, bsz=53.4, num_updates=18400, lr=0.000368605, gnorm=1.378, clip=0, loss_scale=512, train_wall=29, wall=5419
2022-10-19 18:35:11 | INFO | train_inner | epoch 005:   2753 / 3937 loss=13.555, nll_loss=10.204, mask_ins=1.905, word_ins_ml=10.885, word_reposition=0.764, ppl=12031.4, wps=5896.9, ups=3.46, wpb=1705.4, bsz=51.4, num_updates=18500, lr=0.000367607, gnorm=1.038, clip=0, loss_scale=512, train_wall=29, wall=5448
2022-10-19 18:35:40 | INFO | train_inner | epoch 005:   2853 / 3937 loss=13.598, nll_loss=10.198, mask_ins=1.931, word_ins_ml=10.881, word_reposition=0.786, ppl=12396.3, wps=6026.7, ups=3.43, wpb=1754.8, bsz=53.2, num_updates=18600, lr=0.000366618, gnorm=1.044, clip=0, loss_scale=512, train_wall=29, wall=5477
2022-10-19 18:36:09 | INFO | train_inner | epoch 005:   2953 / 3937 loss=13.566, nll_loss=10.167, mask_ins=1.925, word_ins_ml=10.854, word_reposition=0.788, ppl=12128.4, wps=5673.7, ups=3.48, wpb=1632.2, bsz=49.6, num_updates=18700, lr=0.000365636, gnorm=1.402, clip=0, loss_scale=512, train_wall=29, wall=5506
2022-10-19 18:36:38 | INFO | train_inner | epoch 005:   3053 / 3937 loss=13.594, nll_loss=10.215, mask_ins=1.91, word_ins_ml=10.896, word_reposition=0.789, ppl=12367.3, wps=5885.2, ups=3.47, wpb=1694.8, bsz=51.6, num_updates=18800, lr=0.000364662, gnorm=1.114, clip=0, loss_scale=512, train_wall=29, wall=5535
2022-10-19 18:37:07 | INFO | train_inner | epoch 005:   3153 / 3937 loss=13.538, nll_loss=10.194, mask_ins=1.925, word_ins_ml=10.877, word_reposition=0.736, ppl=11892.4, wps=5809.3, ups=3.44, wpb=1686.9, bsz=51.2, num_updates=18900, lr=0.000363696, gnorm=1.162, clip=0, loss_scale=512, train_wall=29, wall=5564
2022-10-19 18:37:36 | INFO | train_inner | epoch 005:   3253 / 3937 loss=13.536, nll_loss=10.192, mask_ins=1.888, word_ins_ml=10.875, word_reposition=0.773, ppl=11877.8, wps=5854.2, ups=3.45, wpb=1696.9, bsz=51.7, num_updates=19000, lr=0.000362738, gnorm=1.154, clip=0, loss_scale=512, train_wall=29, wall=5593
2022-10-19 18:38:04 | INFO | train_inner | epoch 005:   3353 / 3937 loss=13.511, nll_loss=10.171, mask_ins=1.89, word_ins_ml=10.858, word_reposition=0.764, ppl=11672.8, wps=5629.1, ups=3.5, wpb=1606.4, bsz=48.6, num_updates=19100, lr=0.000361787, gnorm=1.28, clip=0, loss_scale=512, train_wall=28, wall=5621
2022-10-19 18:38:33 | INFO | train_inner | epoch 005:   3453 / 3937 loss=13.55, nll_loss=10.199, mask_ins=1.896, word_ins_ml=10.882, word_reposition=0.772, ppl=11994.1, wps=6140.4, ups=3.47, wpb=1769, bsz=53.2, num_updates=19200, lr=0.000360844, gnorm=1.109, clip=0, loss_scale=512, train_wall=29, wall=5650
2022-10-19 18:39:02 | INFO | train_inner | epoch 005:   3553 / 3937 loss=13.526, nll_loss=10.193, mask_ins=1.874, word_ins_ml=10.875, word_reposition=0.776, ppl=11793.8, wps=6180.1, ups=3.45, wpb=1792.8, bsz=53.9, num_updates=19300, lr=0.000359908, gnorm=1.066, clip=0, loss_scale=512, train_wall=29, wall=5679
2022-10-19 18:39:31 | INFO | train_inner | epoch 005:   3653 / 3937 loss=13.533, nll_loss=10.174, mask_ins=1.917, word_ins_ml=10.859, word_reposition=0.757, ppl=11850.2, wps=5674.9, ups=3.46, wpb=1638.4, bsz=49.9, num_updates=19400, lr=0.000358979, gnorm=1.482, clip=1, loss_scale=512, train_wall=29, wall=5708
2022-10-19 18:39:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-10-19 18:40:00 | INFO | train_inner | epoch 005:   3754 / 3937 loss=13.478, nll_loss=10.156, mask_ins=1.898, word_ins_ml=10.843, word_reposition=0.737, ppl=11409.1, wps=6037.7, ups=3.41, wpb=1771.1, bsz=52.9, num_updates=19500, lr=0.000358057, gnorm=0.985, clip=0, loss_scale=537, train_wall=29, wall=5737
2022-10-19 18:40:29 | INFO | train_inner | epoch 005:   3854 / 3937 loss=13.456, nll_loss=10.178, mask_ins=1.839, word_ins_ml=10.863, word_reposition=0.754, ppl=11238.8, wps=5924.4, ups=3.46, wpb=1713.8, bsz=51.4, num_updates=19600, lr=0.000357143, gnorm=1.208, clip=0, loss_scale=512, train_wall=29, wall=5766
2022-10-19 18:40:53 | INFO | train | epoch 005 | loss 13.556 | nll_loss 10.183 | mask_ins 1.913 | word_ins_ml 10.868 | word_reposition 0.776 | ppl 12045.1 | wps 5756.4 | ups 3.39 | wpb 1696.3 | bsz 51.5 | num_updates 19683 | lr 0.000356389 | gnorm 1.282 | clip 0.2 | loss_scale 513 | train_wall 1129 | wall 5790
2022-10-19 18:41:04 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 22.195 | nll_loss 14.035 | mask_ins 5.718 | word_ins_ml 14.119 | word_reposition 2.357 | ppl 4.80013e+06 | wps 27570.8 | wpb 1503.2 | bsz 51.5 | num_updates 19683 | best_loss 14.267
2022-10-19 18:41:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 5 @ 19683 updates, score 22.195) (writing took 12.094860899960622 seconds)
2022-10-19 18:41:22 | INFO | train_inner | epoch 006:     17 / 3937 loss=13.547, nll_loss=10.196, mask_ins=1.89, word_ins_ml=10.877, word_reposition=0.779, ppl=11965, wps=3053.1, ups=1.91, wpb=1599.7, bsz=48.2, num_updates=19700, lr=0.000356235, gnorm=1.335, clip=0, loss_scale=512, train_wall=28, wall=5818
2022-10-19 18:41:50 | INFO | train_inner | epoch 006:    117 / 3937 loss=13.623, nll_loss=10.19, mask_ins=1.96, word_ins_ml=10.873, word_reposition=0.79, ppl=12615.7, wps=5838.9, ups=3.47, wpb=1684.1, bsz=51, num_updates=19800, lr=0.000355335, gnorm=1.255, clip=0, loss_scale=512, train_wall=29, wall=5847
2022-10-19 18:42:19 | INFO | train_inner | epoch 006:    217 / 3937 loss=13.522, nll_loss=10.182, mask_ins=1.906, word_ins_ml=10.866, word_reposition=0.75, ppl=11764.8, wps=5602.6, ups=3.46, wpb=1621.2, bsz=49.8, num_updates=19900, lr=0.000354441, gnorm=1.092, clip=0, loss_scale=512, train_wall=29, wall=5876
2022-10-19 18:42:48 | INFO | train_inner | epoch 006:    317 / 3937 loss=13.499, nll_loss=10.184, mask_ins=1.866, word_ins_ml=10.868, word_reposition=0.765, ppl=11580.4, wps=5740.2, ups=3.46, wpb=1659.3, bsz=50.1, num_updates=20000, lr=0.000353553, gnorm=1.132, clip=0, loss_scale=512, train_wall=29, wall=5905
2022-10-19 18:43:17 | INFO | train_inner | epoch 006:    417 / 3937 loss=13.506, nll_loss=10.17, mask_ins=1.898, word_ins_ml=10.857, word_reposition=0.75, ppl=11632.5, wps=5740.5, ups=3.45, wpb=1662.1, bsz=50.1, num_updates=20100, lr=0.000352673, gnorm=1.062, clip=0, loss_scale=512, train_wall=29, wall=5934
2022-10-19 18:43:46 | INFO | train_inner | epoch 006:    517 / 3937 loss=13.578, nll_loss=10.184, mask_ins=1.943, word_ins_ml=10.868, word_reposition=0.767, ppl=12228.5, wps=5474.1, ups=3.47, wpb=1578.3, bsz=48, num_updates=20200, lr=0.000351799, gnorm=1.228, clip=0, loss_scale=512, train_wall=29, wall=5963
2022-10-19 18:44:15 | INFO | train_inner | epoch 006:    617 / 3937 loss=13.478, nll_loss=10.176, mask_ins=1.867, word_ins_ml=10.862, word_reposition=0.749, ppl=11406.7, wps=5775.5, ups=3.41, wpb=1691.6, bsz=52.1, num_updates=20300, lr=0.000350931, gnorm=1.156, clip=0, loss_scale=512, train_wall=29, wall=5992
2022-10-19 18:44:44 | INFO | train_inner | epoch 006:    717 / 3937 loss=13.518, nll_loss=10.16, mask_ins=1.888, word_ins_ml=10.847, word_reposition=0.784, ppl=11734.5, wps=5570.2, ups=3.46, wpb=1610.3, bsz=48.7, num_updates=20400, lr=0.00035007, gnorm=1.241, clip=0, loss_scale=512, train_wall=29, wall=6021
2022-10-19 18:45:13 | INFO | train_inner | epoch 006:    817 / 3937 loss=13.565, nll_loss=10.205, mask_ins=1.913, word_ins_ml=10.887, word_reposition=0.765, ppl=12121.2, wps=5713, ups=3.45, wpb=1656.2, bsz=49.4, num_updates=20500, lr=0.000349215, gnorm=1.034, clip=0, loss_scale=512, train_wall=29, wall=6050
2022-10-19 18:45:42 | INFO | train_inner | epoch 006:    917 / 3937 loss=13.577, nll_loss=10.211, mask_ins=1.92, word_ins_ml=10.892, word_reposition=0.765, ppl=12218.7, wps=5863.1, ups=3.45, wpb=1698.1, bsz=52, num_updates=20600, lr=0.000348367, gnorm=1.177, clip=0, loss_scale=512, train_wall=29, wall=6079
2022-10-19 18:46:11 | INFO | train_inner | epoch 006:   1017 / 3937 loss=13.469, nll_loss=10.168, mask_ins=1.894, word_ins_ml=10.855, word_reposition=0.719, ppl=11341.1, wps=6238.8, ups=3.46, wpb=1802.8, bsz=54.1, num_updates=20700, lr=0.000347524, gnorm=0.987, clip=0, loss_scale=512, train_wall=29, wall=6108
2022-10-19 18:46:40 | INFO | train_inner | epoch 006:   1117 / 3937 loss=13.512, nll_loss=10.189, mask_ins=1.87, word_ins_ml=10.873, word_reposition=0.769, ppl=11683.3, wps=5939.4, ups=3.46, wpb=1718.9, bsz=51.8, num_updates=20800, lr=0.000346688, gnorm=1.031, clip=0, loss_scale=512, train_wall=29, wall=6137
2022-10-19 18:47:09 | INFO | train_inner | epoch 006:   1217 / 3937 loss=13.457, nll_loss=10.132, mask_ins=1.852, word_ins_ml=10.823, word_reposition=0.782, ppl=11243, wps=6176, ups=3.46, wpb=1784.5, bsz=54.1, num_updates=20900, lr=0.000345857, gnorm=1.953, clip=1, loss_scale=512, train_wall=29, wall=6166
2022-10-19 18:47:38 | INFO | train_inner | epoch 006:   1317 / 3937 loss=13.508, nll_loss=10.179, mask_ins=1.911, word_ins_ml=10.864, word_reposition=0.733, ppl=11648.2, wps=5996.6, ups=3.45, wpb=1740.2, bsz=53.1, num_updates=21000, lr=0.000345033, gnorm=1.244, clip=0, loss_scale=512, train_wall=29, wall=6195
2022-10-19 18:48:07 | INFO | train_inner | epoch 006:   1417 / 3937 loss=13.427, nll_loss=10.156, mask_ins=1.853, word_ins_ml=10.844, word_reposition=0.73, ppl=11014.1, wps=5582.6, ups=3.49, wpb=1601.8, bsz=48.9, num_updates=21100, lr=0.000344214, gnorm=1.141, clip=0, loss_scale=512, train_wall=28, wall=6223
2022-10-19 18:48:36 | INFO | train_inner | epoch 006:   1517 / 3937 loss=13.49, nll_loss=10.187, mask_ins=1.856, word_ins_ml=10.871, word_reposition=0.763, ppl=11504.4, wps=5936.7, ups=3.42, wpb=1737.5, bsz=52, num_updates=21200, lr=0.000343401, gnorm=1.016, clip=0, loss_scale=512, train_wall=29, wall=6253
2022-10-19 18:49:05 | INFO | train_inner | epoch 006:   1617 / 3937 loss=13.551, nll_loss=10.143, mask_ins=1.942, word_ins_ml=10.833, word_reposition=0.777, ppl=11999.2, wps=6111.1, ups=3.45, wpb=1771.2, bsz=53.9, num_updates=21300, lr=0.000342594, gnorm=1.076, clip=0, loss_scale=512, train_wall=29, wall=6282
2022-10-19 18:49:34 | INFO | train_inner | epoch 006:   1717 / 3937 loss=13.469, nll_loss=10.154, mask_ins=1.871, word_ins_ml=10.843, word_reposition=0.755, ppl=11335.8, wps=5943.2, ups=3.44, wpb=1728.2, bsz=53.8, num_updates=21400, lr=0.000341793, gnorm=1.144, clip=0, loss_scale=512, train_wall=29, wall=6311
2022-10-19 18:50:03 | INFO | train_inner | epoch 006:   1817 / 3937 loss=13.521, nll_loss=10.163, mask_ins=1.911, word_ins_ml=10.85, word_reposition=0.761, ppl=11758.6, wps=5941.6, ups=3.41, wpb=1741.5, bsz=53.5, num_updates=21500, lr=0.000340997, gnorm=1.162, clip=0, loss_scale=512, train_wall=29, wall=6340
2022-10-19 18:50:32 | INFO | train_inner | epoch 006:   1917 / 3937 loss=13.627, nll_loss=10.174, mask_ins=1.966, word_ins_ml=10.86, word_reposition=0.801, ppl=12649.5, wps=5798.5, ups=3.45, wpb=1682.6, bsz=51.4, num_updates=21600, lr=0.000340207, gnorm=1.211, clip=0, loss_scale=512, train_wall=29, wall=6369
2022-10-19 18:51:01 | INFO | train_inner | epoch 006:   2017 / 3937 loss=13.512, nll_loss=10.151, mask_ins=1.882, word_ins_ml=10.84, word_reposition=0.791, ppl=11683.9, wps=5932.3, ups=3.45, wpb=1718.5, bsz=53.1, num_updates=21700, lr=0.000339422, gnorm=1.948, clip=0, loss_scale=512, train_wall=29, wall=6398
2022-10-19 18:51:30 | INFO | train_inner | epoch 006:   2117 / 3937 loss=13.445, nll_loss=10.187, mask_ins=1.836, word_ins_ml=10.87, word_reposition=0.738, ppl=11148.7, wps=6186.5, ups=3.46, wpb=1786.9, bsz=54.9, num_updates=21800, lr=0.000338643, gnorm=1.115, clip=0, loss_scale=512, train_wall=29, wall=6427
2022-10-19 18:51:59 | INFO | train_inner | epoch 006:   2217 / 3937 loss=13.566, nll_loss=10.184, mask_ins=1.95, word_ins_ml=10.867, word_reposition=0.749, ppl=12130.2, wps=5549, ups=3.48, wpb=1592.4, bsz=48, num_updates=21900, lr=0.000337869, gnorm=1.159, clip=0, loss_scale=512, train_wall=28, wall=6456
2022-10-19 18:52:28 | INFO | train_inner | epoch 006:   2317 / 3937 loss=13.545, nll_loss=10.201, mask_ins=1.901, word_ins_ml=10.883, word_reposition=0.762, ppl=11950.6, wps=5912, ups=3.49, wpb=1693.3, bsz=51.2, num_updates=22000, lr=0.0003371, gnorm=1.171, clip=0, loss_scale=512, train_wall=28, wall=6484
2022-10-19 18:52:57 | INFO | train_inner | epoch 006:   2417 / 3937 loss=13.522, nll_loss=10.159, mask_ins=1.906, word_ins_ml=10.847, word_reposition=0.769, ppl=11764.2, wps=5968.3, ups=3.43, wpb=1740.7, bsz=52.2, num_updates=22100, lr=0.000336336, gnorm=1.36, clip=0, loss_scale=512, train_wall=29, wall=6514
2022-10-19 18:53:25 | INFO | train_inner | epoch 006:   2517 / 3937 loss=13.666, nll_loss=10.166, mask_ins=1.967, word_ins_ml=10.852, word_reposition=0.847, ppl=13001.4, wps=6196.8, ups=3.47, wpb=1785.4, bsz=53.2, num_updates=22200, lr=0.000335578, gnorm=1.267, clip=0, loss_scale=512, train_wall=29, wall=6542
2022-10-19 18:53:55 | INFO | train_inner | epoch 006:   2617 / 3937 loss=13.523, nll_loss=10.146, mask_ins=1.917, word_ins_ml=10.835, word_reposition=0.771, ppl=11773.8, wps=5632.1, ups=3.43, wpb=1640.6, bsz=50.1, num_updates=22300, lr=0.000334825, gnorm=1.305, clip=0, loss_scale=512, train_wall=29, wall=6571
2022-10-19 18:54:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-10-19 18:54:24 | INFO | train_inner | epoch 006:   2718 / 3937 loss=13.724, nll_loss=10.205, mask_ins=1.932, word_ins_ml=10.887, word_reposition=0.905, ppl=13532.5, wps=5989.4, ups=3.42, wpb=1750.8, bsz=53.1, num_updates=22400, lr=0.000334077, gnorm=2.792, clip=1, loss_scale=337, train_wall=29, wall=6601
2022-10-19 18:54:53 | INFO | train_inner | epoch 006:   2818 / 3937 loss=13.539, nll_loss=10.185, mask_ins=1.921, word_ins_ml=10.87, word_reposition=0.749, ppl=11902.4, wps=5838.7, ups=3.47, wpb=1680.8, bsz=50.5, num_updates=22500, lr=0.000333333, gnorm=1.463, clip=1, loss_scale=256, train_wall=29, wall=6629
2022-10-19 18:55:22 | INFO | train_inner | epoch 006:   2918 / 3937 loss=13.609, nll_loss=10.169, mask_ins=1.96, word_ins_ml=10.855, word_reposition=0.794, ppl=12497.5, wps=5786.2, ups=3.46, wpb=1671.4, bsz=49.6, num_updates=22600, lr=0.000332595, gnorm=2.448, clip=1, loss_scale=256, train_wall=29, wall=6658
2022-10-19 18:55:51 | INFO | train_inner | epoch 006:   3018 / 3937 loss=13.534, nll_loss=10.189, mask_ins=1.909, word_ins_ml=10.873, word_reposition=0.753, ppl=11861.5, wps=5785.3, ups=3.43, wpb=1688.6, bsz=50.4, num_updates=22700, lr=0.000331862, gnorm=1.149, clip=0, loss_scale=256, train_wall=29, wall=6688
2022-10-19 18:56:20 | INFO | train_inner | epoch 006:   3118 / 3937 loss=13.531, nll_loss=10.167, mask_ins=1.937, word_ins_ml=10.853, word_reposition=0.741, ppl=11835.8, wps=5764, ups=3.45, wpb=1672.9, bsz=51.9, num_updates=22800, lr=0.000331133, gnorm=1.111, clip=0, loss_scale=256, train_wall=29, wall=6717
2022-10-19 18:56:49 | INFO | train_inner | epoch 006:   3218 / 3937 loss=13.573, nll_loss=10.191, mask_ins=1.909, word_ins_ml=10.875, word_reposition=0.79, ppl=12188.7, wps=5636.6, ups=3.44, wpb=1640.3, bsz=48.5, num_updates=22900, lr=0.000330409, gnorm=2.343, clip=2, loss_scale=256, train_wall=29, wall=6746
2022-10-19 18:57:18 | INFO | train_inner | epoch 006:   3318 / 3937 loss=13.544, nll_loss=10.162, mask_ins=1.921, word_ins_ml=10.849, word_reposition=0.773, ppl=11942.9, wps=5816.2, ups=3.44, wpb=1692.6, bsz=51.9, num_updates=23000, lr=0.00032969, gnorm=1.331, clip=0, loss_scale=256, train_wall=29, wall=6775
2022-10-19 18:57:47 | INFO | train_inner | epoch 006:   3418 / 3937 loss=13.483, nll_loss=10.158, mask_ins=1.888, word_ins_ml=10.846, word_reposition=0.749, ppl=11452.6, wps=5856.7, ups=3.47, wpb=1687.2, bsz=51.4, num_updates=23100, lr=0.000328976, gnorm=1.582, clip=1, loss_scale=256, train_wall=29, wall=6804
2022-10-19 18:58:15 | INFO | train_inner | epoch 006:   3518 / 3937 loss=13.516, nll_loss=10.19, mask_ins=1.879, word_ins_ml=10.873, word_reposition=0.764, ppl=11713.7, wps=5865.2, ups=3.49, wpb=1678.4, bsz=50.4, num_updates=23200, lr=0.000328266, gnorm=1.083, clip=0, loss_scale=256, train_wall=28, wall=6832
2022-10-19 18:58:44 | INFO | train_inner | epoch 006:   3618 / 3937 loss=13.604, nll_loss=10.159, mask_ins=1.971, word_ins_ml=10.846, word_reposition=0.788, ppl=12453.6, wps=6099.6, ups=3.45, wpb=1765.8, bsz=54.6, num_updates=23300, lr=0.000327561, gnorm=1.333, clip=0, loss_scale=256, train_wall=29, wall=6861
2022-10-19 18:59:13 | INFO | train_inner | epoch 006:   3718 / 3937 loss=13.499, nll_loss=10.15, mask_ins=1.894, word_ins_ml=10.838, word_reposition=0.767, ppl=11579, wps=5995.6, ups=3.44, wpb=1745.2, bsz=54, num_updates=23400, lr=0.00032686, gnorm=1.252, clip=0, loss_scale=256, train_wall=29, wall=6890
2022-10-19 18:59:42 | INFO | train_inner | epoch 006:   3818 / 3937 loss=13.441, nll_loss=10.154, mask_ins=1.874, word_ins_ml=10.842, word_reposition=0.724, ppl=11117.9, wps=5821.9, ups=3.45, wpb=1686.3, bsz=51.8, num_updates=23500, lr=0.000326164, gnorm=1.185, clip=0, loss_scale=256, train_wall=29, wall=6919
2022-10-19 19:00:12 | INFO | train_inner | epoch 006:   3918 / 3937 loss=13.487, nll_loss=10.201, mask_ins=1.866, word_ins_ml=10.883, word_reposition=0.739, ppl=11485.1, wps=5831.8, ups=3.42, wpb=1707, bsz=51.3, num_updates=23600, lr=0.000325472, gnorm=1.192, clip=0, loss_scale=256, train_wall=29, wall=6949
2022-10-19 19:00:17 | INFO | train | epoch 006 | loss 13.532 | nll_loss 10.174 | mask_ins 1.904 | word_ins_ml 10.86 | word_reposition 0.768 | ppl 11843.6 | wps 5733.4 | ups 3.38 | wpb 1696 | bsz 51.5 | num_updates 23619 | lr 0.000325341 | gnorm 1.328 | clip 0.2 | loss_scale 428 | train_wall 1131 | wall 6954
2022-10-19 19:00:29 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 23.837 | nll_loss 15.062 | mask_ins 6 | word_ins_ml 15.044 | word_reposition 2.793 | ppl 1.49806e+07 | wps 27566.4 | wpb 1503.2 | bsz 51.5 | num_updates 23619 | best_loss 14.267
2022-10-19 19:00:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 6 @ 23619 updates, score 23.837) (writing took 11.937401473056525 seconds)
2022-10-19 19:01:04 | INFO | train_inner | epoch 007:     81 / 3937 loss=13.458, nll_loss=10.141, mask_ins=1.866, word_ins_ml=10.832, word_reposition=0.761, ppl=11255.8, wps=3241.6, ups=1.9, wpb=1708, bsz=52.6, num_updates=23700, lr=0.000324785, gnorm=1.102, clip=0, loss_scale=256, train_wall=29, wall=7001
2022-10-19 19:01:33 | INFO | train_inner | epoch 007:    181 / 3937 loss=13.49, nll_loss=10.161, mask_ins=1.868, word_ins_ml=10.848, word_reposition=0.773, ppl=11502.9, wps=6182.3, ups=3.44, wpb=1798.2, bsz=55, num_updates=23800, lr=0.000324102, gnorm=1.24, clip=0, loss_scale=256, train_wall=29, wall=7030
2022-10-19 19:02:03 | INFO | train_inner | epoch 007:    281 / 3937 loss=13.481, nll_loss=10.196, mask_ins=1.849, word_ins_ml=10.879, word_reposition=0.753, ppl=11436.3, wps=5703.9, ups=3.43, wpb=1660.9, bsz=49.7, num_updates=23900, lr=0.000323423, gnorm=1.181, clip=0, loss_scale=256, train_wall=29, wall=7059
2022-10-19 19:02:32 | INFO | train_inner | epoch 007:    381 / 3937 loss=13.442, nll_loss=10.171, mask_ins=1.83, word_ins_ml=10.856, word_reposition=0.755, ppl=11126.8, wps=5616.3, ups=3.41, wpb=1645.8, bsz=49, num_updates=24000, lr=0.000322749, gnorm=1.125, clip=0, loss_scale=256, train_wall=29, wall=7089
2022-10-19 19:03:01 | INFO | train_inner | epoch 007:    481 / 3937 loss=13.517, nll_loss=10.155, mask_ins=1.916, word_ins_ml=10.842, word_reposition=0.759, ppl=11722.4, wps=5717.6, ups=3.46, wpb=1652.6, bsz=50.1, num_updates=24100, lr=0.000322078, gnorm=1.134, clip=0, loss_scale=256, train_wall=29, wall=7118
2022-10-19 19:03:30 | INFO | train_inner | epoch 007:    581 / 3937 loss=13.545, nll_loss=10.16, mask_ins=1.909, word_ins_ml=10.848, word_reposition=0.789, ppl=11956, wps=5726.4, ups=3.41, wpb=1677.9, bsz=50.4, num_updates=24200, lr=0.000321412, gnorm=2.607, clip=1, loss_scale=256, train_wall=29, wall=7147
2022-10-19 19:03:59 | INFO | train_inner | epoch 007:    681 / 3937 loss=13.456, nll_loss=10.158, mask_ins=1.861, word_ins_ml=10.846, word_reposition=0.748, ppl=11234.4, wps=5743.9, ups=3.44, wpb=1667.6, bsz=50.3, num_updates=24300, lr=0.00032075, gnorm=1.03, clip=0, loss_scale=256, train_wall=29, wall=7176
2022-10-19 19:04:28 | INFO | train_inner | epoch 007:    781 / 3937 loss=13.438, nll_loss=10.169, mask_ins=1.836, word_ins_ml=10.854, word_reposition=0.748, ppl=11101.6, wps=6233.1, ups=3.45, wpb=1809, bsz=55.9, num_updates=24400, lr=0.000320092, gnorm=1.025, clip=0, loss_scale=256, train_wall=29, wall=7205
2022-10-19 19:04:57 | INFO | train_inner | epoch 007:    881 / 3937 loss=13.475, nll_loss=10.156, mask_ins=1.894, word_ins_ml=10.844, word_reposition=0.737, ppl=11385.5, wps=6196.6, ups=3.44, wpb=1799.5, bsz=55.2, num_updates=24500, lr=0.000319438, gnorm=1.053, clip=0, loss_scale=256, train_wall=29, wall=7234
2022-10-19 19:05:26 | INFO | train_inner | epoch 007:    981 / 3937 loss=13.498, nll_loss=10.168, mask_ins=1.883, word_ins_ml=10.854, word_reposition=0.761, ppl=11572.2, wps=6267.9, ups=3.45, wpb=1816, bsz=56, num_updates=24600, lr=0.000318788, gnorm=1.025, clip=0, loss_scale=256, train_wall=29, wall=7263
2022-10-19 19:05:55 | INFO | train_inner | epoch 007:   1081 / 3937 loss=13.436, nll_loss=10.146, mask_ins=1.862, word_ins_ml=10.836, word_reposition=0.738, ppl=11084.3, wps=6073.8, ups=3.46, wpb=1756.3, bsz=54.4, num_updates=24700, lr=0.000318142, gnorm=1.036, clip=0, loss_scale=256, train_wall=29, wall=7292
2022-10-19 19:06:24 | INFO | train_inner | epoch 007:   1181 / 3937 loss=13.392, nll_loss=10.167, mask_ins=1.814, word_ins_ml=10.853, word_reposition=0.725, ppl=10750.4, wps=5785, ups=3.48, wpb=1662.6, bsz=50.6, num_updates=24800, lr=0.0003175, gnorm=1.066, clip=0, loss_scale=256, train_wall=28, wall=7321
2022-10-19 19:06:53 | INFO | train_inner | epoch 007:   1281 / 3937 loss=13.542, nll_loss=10.215, mask_ins=1.911, word_ins_ml=10.894, word_reposition=0.737, ppl=11924, wps=6068.7, ups=3.44, wpb=1766.3, bsz=53.1, num_updates=24900, lr=0.000316862, gnorm=1.098, clip=0, loss_scale=256, train_wall=29, wall=7350
2022-10-19 19:07:22 | INFO | train_inner | epoch 007:   1381 / 3937 loss=13.514, nll_loss=10.176, mask_ins=1.891, word_ins_ml=10.861, word_reposition=0.762, ppl=11694.3, wps=6206.6, ups=3.43, wpb=1810.9, bsz=54.7, num_updates=25000, lr=0.000316228, gnorm=1.15, clip=0, loss_scale=256, train_wall=29, wall=7379
2022-10-19 19:07:51 | INFO | train_inner | epoch 007:   1481 / 3937 loss=13.536, nll_loss=10.188, mask_ins=1.883, word_ins_ml=10.871, word_reposition=0.781, ppl=11878.4, wps=5384.5, ups=3.43, wpb=1569.5, bsz=46.8, num_updates=25100, lr=0.000315597, gnorm=1.039, clip=0, loss_scale=256, train_wall=29, wall=7408
2022-10-19 19:08:20 | INFO | train_inner | epoch 007:   1581 / 3937 loss=13.573, nll_loss=10.176, mask_ins=1.957, word_ins_ml=10.862, word_reposition=0.753, ppl=12182.7, wps=5810, ups=3.43, wpb=1694.2, bsz=51.3, num_updates=25200, lr=0.00031497, gnorm=1.252, clip=0, loss_scale=256, train_wall=29, wall=7437
2022-10-19 19:08:49 | INFO | train_inner | epoch 007:   1681 / 3937 loss=13.462, nll_loss=10.129, mask_ins=1.868, word_ins_ml=10.821, word_reposition=0.773, ppl=11283.5, wps=6050.6, ups=3.44, wpb=1757.6, bsz=54.2, num_updates=25300, lr=0.000314347, gnorm=1.069, clip=0, loss_scale=256, train_wall=29, wall=7466
2022-10-19 19:09:18 | INFO | train_inner | epoch 007:   1781 / 3937 loss=13.564, nll_loss=10.198, mask_ins=1.892, word_ins_ml=10.881, word_reposition=0.792, ppl=12113, wps=5674, ups=3.47, wpb=1636.5, bsz=50.1, num_updates=25400, lr=0.000313728, gnorm=3.48, clip=1, loss_scale=256, train_wall=29, wall=7495
2022-10-19 19:09:47 | INFO | train_inner | epoch 007:   1881 / 3937 loss=13.501, nll_loss=10.174, mask_ins=1.879, word_ins_ml=10.859, word_reposition=0.763, ppl=11591.3, wps=5949.9, ups=3.47, wpb=1716.1, bsz=50.8, num_updates=25500, lr=0.000313112, gnorm=1.117, clip=0, loss_scale=256, train_wall=29, wall=7524
2022-10-19 19:10:16 | INFO | train_inner | epoch 007:   1981 / 3937 loss=13.499, nll_loss=10.178, mask_ins=1.896, word_ins_ml=10.863, word_reposition=0.74, ppl=11575, wps=5567.7, ups=3.43, wpb=1621.9, bsz=48.7, num_updates=25600, lr=0.0003125, gnorm=1.116, clip=0, loss_scale=256, train_wall=29, wall=7553
2022-10-19 19:10:45 | INFO | train_inner | epoch 007:   2081 / 3937 loss=13.486, nll_loss=10.186, mask_ins=1.876, word_ins_ml=10.87, word_reposition=0.74, ppl=11476.4, wps=6073.4, ups=3.49, wpb=1740.9, bsz=52.7, num_updates=25700, lr=0.000311891, gnorm=1.029, clip=0, loss_scale=256, train_wall=28, wall=7582
2022-10-19 19:11:14 | INFO | train_inner | epoch 007:   2181 / 3937 loss=13.491, nll_loss=10.165, mask_ins=1.901, word_ins_ml=10.852, word_reposition=0.737, ppl=11511.6, wps=5684.4, ups=3.47, wpb=1638.8, bsz=49.7, num_updates=25800, lr=0.000311286, gnorm=1.166, clip=0, loss_scale=256, train_wall=29, wall=7611
2022-10-19 19:11:42 | INFO | train_inner | epoch 007:   2281 / 3937 loss=13.53, nll_loss=10.189, mask_ins=1.885, word_ins_ml=10.871, word_reposition=0.773, ppl=11827.5, wps=6133.7, ups=3.49, wpb=1759.9, bsz=52.8, num_updates=25900, lr=0.000310685, gnorm=1.05, clip=0, loss_scale=256, train_wall=28, wall=7639
2022-10-19 19:12:11 | INFO | train_inner | epoch 007:   2381 / 3937 loss=13.495, nll_loss=10.142, mask_ins=1.882, word_ins_ml=10.833, word_reposition=0.78, ppl=11544.7, wps=5463.1, ups=3.46, wpb=1580.3, bsz=47.8, num_updates=26000, lr=0.000310087, gnorm=1.393, clip=0, loss_scale=256, train_wall=29, wall=7668
2022-10-19 19:12:40 | INFO | train_inner | epoch 007:   2481 / 3937 loss=13.475, nll_loss=10.168, mask_ins=1.84, word_ins_ml=10.855, word_reposition=0.779, ppl=11384.2, wps=5764.4, ups=3.44, wpb=1676.5, bsz=50.6, num_updates=26100, lr=0.000309492, gnorm=1.213, clip=0, loss_scale=256, train_wall=29, wall=7697
2022-10-19 19:13:10 | INFO | train_inner | epoch 007:   2581 / 3937 loss=13.537, nll_loss=10.18, mask_ins=1.899, word_ins_ml=10.864, word_reposition=0.774, ppl=11883.1, wps=6137.3, ups=3.4, wpb=1802.6, bsz=54.6, num_updates=26200, lr=0.000308901, gnorm=1.693, clip=1, loss_scale=256, train_wall=29, wall=7727
2022-10-19 19:13:39 | INFO | train_inner | epoch 007:   2681 / 3937 loss=13.517, nll_loss=10.176, mask_ins=1.917, word_ins_ml=10.86, word_reposition=0.739, ppl=11719.1, wps=5635, ups=3.48, wpb=1618.9, bsz=49.9, num_updates=26300, lr=0.000308313, gnorm=1.152, clip=0, loss_scale=256, train_wall=28, wall=7755
2022-10-19 19:14:07 | INFO | train_inner | epoch 007:   2781 / 3937 loss=13.534, nll_loss=10.168, mask_ins=1.897, word_ins_ml=10.854, word_reposition=0.782, ppl=11858.3, wps=5806.3, ups=3.48, wpb=1670.6, bsz=50.2, num_updates=26400, lr=0.000307729, gnorm=1.308, clip=0, loss_scale=256, train_wall=28, wall=7784
2022-10-19 19:14:36 | INFO | train_inner | epoch 007:   2881 / 3937 loss=13.412, nll_loss=10.162, mask_ins=1.87, word_ins_ml=10.849, word_reposition=0.693, ppl=10896.6, wps=5624.8, ups=3.46, wpb=1623.4, bsz=49.4, num_updates=26500, lr=0.000307148, gnorm=1.147, clip=0, loss_scale=443, train_wall=29, wall=7813
2022-10-19 19:15:05 | INFO | train_inner | epoch 007:   2981 / 3937 loss=13.552, nll_loss=10.177, mask_ins=1.951, word_ins_ml=10.862, word_reposition=0.739, ppl=12007.9, wps=6007.4, ups=3.44, wpb=1745.4, bsz=52.3, num_updates=26600, lr=0.00030657, gnorm=1.048, clip=0, loss_scale=512, train_wall=29, wall=7842
2022-10-19 19:15:35 | INFO | train_inner | epoch 007:   3081 / 3937 loss=13.485, nll_loss=10.144, mask_ins=1.925, word_ins_ml=10.834, word_reposition=0.726, ppl=11466.8, wps=5794.7, ups=3.41, wpb=1697.5, bsz=52.2, num_updates=26700, lr=0.000305995, gnorm=1.06, clip=0, loss_scale=512, train_wall=29, wall=7871
2022-10-19 19:16:03 | INFO | train_inner | epoch 007:   3181 / 3937 loss=13.567, nll_loss=10.202, mask_ins=1.936, word_ins_ml=10.883, word_reposition=0.748, ppl=12136.2, wps=5188.6, ups=3.47, wpb=1495.3, bsz=45.5, num_updates=26800, lr=0.000305424, gnorm=1.109, clip=0, loss_scale=512, train_wall=29, wall=7900
2022-10-19 19:16:32 | INFO | train_inner | epoch 007:   3281 / 3937 loss=13.552, nll_loss=10.186, mask_ins=1.915, word_ins_ml=10.87, word_reposition=0.768, ppl=12011.7, wps=5620.6, ups=3.47, wpb=1620.6, bsz=48.2, num_updates=26900, lr=0.000304855, gnorm=1.059, clip=0, loss_scale=512, train_wall=29, wall=7929
2022-10-19 19:17:01 | INFO | train_inner | epoch 007:   3381 / 3937 loss=13.482, nll_loss=10.176, mask_ins=1.872, word_ins_ml=10.861, word_reposition=0.749, ppl=11441.2, wps=6016.6, ups=3.44, wpb=1750.8, bsz=53.8, num_updates=27000, lr=0.00030429, gnorm=1.038, clip=0, loss_scale=512, train_wall=29, wall=7958
2022-10-19 19:17:30 | INFO | train_inner | epoch 007:   3481 / 3937 loss=13.47, nll_loss=10.162, mask_ins=1.86, word_ins_ml=10.849, word_reposition=0.761, ppl=11348.9, wps=6090.7, ups=3.43, wpb=1777.6, bsz=54.8, num_updates=27100, lr=0.000303728, gnorm=1.125, clip=0, loss_scale=512, train_wall=29, wall=7987
2022-10-19 19:18:00 | INFO | train_inner | epoch 007:   3581 / 3937 loss=13.451, nll_loss=10.142, mask_ins=1.867, word_ins_ml=10.832, word_reposition=0.751, ppl=11201.8, wps=6062.2, ups=3.43, wpb=1768.3, bsz=53, num_updates=27200, lr=0.00030317, gnorm=1.047, clip=0, loss_scale=512, train_wall=29, wall=8016
2022-10-19 19:18:29 | INFO | train_inner | epoch 007:   3681 / 3937 loss=13.448, nll_loss=10.192, mask_ins=1.826, word_ins_ml=10.875, word_reposition=0.747, ppl=11173.4, wps=5797.7, ups=3.46, wpb=1674.5, bsz=50.3, num_updates=27300, lr=0.000302614, gnorm=1.114, clip=0, loss_scale=512, train_wall=29, wall=8045
2022-10-19 19:18:58 | INFO | train_inner | epoch 007:   3781 / 3937 loss=13.473, nll_loss=10.167, mask_ins=1.903, word_ins_ml=10.854, word_reposition=0.717, ppl=11373.5, wps=5957.9, ups=3.45, wpb=1728.4, bsz=53.1, num_updates=27400, lr=0.000302061, gnorm=1.08, clip=0, loss_scale=512, train_wall=29, wall=8074
2022-10-19 19:19:26 | INFO | train_inner | epoch 007:   3881 / 3937 loss=13.558, nll_loss=10.158, mask_ins=1.951, word_ins_ml=10.846, word_reposition=0.761, ppl=12061.5, wps=5586.6, ups=3.46, wpb=1616.7, bsz=50, num_updates=27500, lr=0.000301511, gnorm=1.023, clip=0, loss_scale=512, train_wall=29, wall=8103
2022-10-19 19:19:43 | INFO | train | epoch 007 | loss 13.496 | nll_loss 10.17 | mask_ins 1.886 | word_ins_ml 10.856 | word_reposition 0.754 | ppl 11555.8 | wps 5730 | ups 3.38 | wpb 1696.2 | bsz 51.5 | num_updates 27556 | lr 0.000301205 | gnorm 1.224 | clip 0.1 | loss_scale 329 | train_wall 1131 | wall 8119
2022-10-19 19:19:54 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 24.435 | nll_loss 15.7 | mask_ins 5.997 | word_ins_ml 15.618 | word_reposition 2.82 | ppl 2.26749e+07 | wps 27629.7 | wpb 1503.2 | bsz 51.5 | num_updates 27556 | best_loss 14.267
2022-10-19 19:20:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 7 @ 27556 updates, score 24.435) (writing took 11.374989108066075 seconds)
2022-10-19 19:20:18 | INFO | train_inner | epoch 008:     44 / 3937 loss=13.491, nll_loss=10.183, mask_ins=1.859, word_ins_ml=10.868, word_reposition=0.764, ppl=11511.8, wps=3055.9, ups=1.93, wpb=1580.6, bsz=48, num_updates=27600, lr=0.000300965, gnorm=1.147, clip=0, loss_scale=512, train_wall=28, wall=8155
2022-10-19 19:20:47 | INFO | train_inner | epoch 008:    144 / 3937 loss=13.532, nll_loss=10.183, mask_ins=1.922, word_ins_ml=10.867, word_reposition=0.743, ppl=11848.4, wps=5897.5, ups=3.51, wpb=1679.4, bsz=50.5, num_updates=27700, lr=0.000300421, gnorm=1.179, clip=0, loss_scale=512, train_wall=28, wall=8184
2022-10-19 19:21:16 | INFO | train_inner | epoch 008:    244 / 3937 loss=13.47, nll_loss=10.149, mask_ins=1.895, word_ins_ml=10.838, word_reposition=0.737, ppl=11348.7, wps=5946.3, ups=3.46, wpb=1717, bsz=53.1, num_updates=27800, lr=0.00029988, gnorm=1.032, clip=0, loss_scale=512, train_wall=29, wall=8212
2022-10-19 19:21:44 | INFO | train_inner | epoch 008:    344 / 3937 loss=13.493, nll_loss=10.193, mask_ins=1.843, word_ins_ml=10.875, word_reposition=0.775, ppl=11526, wps=5796.8, ups=3.49, wpb=1662.1, bsz=49.7, num_updates=27900, lr=0.000299342, gnorm=1.146, clip=0, loss_scale=512, train_wall=28, wall=8241
2022-10-19 19:22:13 | INFO | train_inner | epoch 008:    444 / 3937 loss=13.517, nll_loss=10.167, mask_ins=1.92, word_ins_ml=10.853, word_reposition=0.743, ppl=11719.2, wps=6012.4, ups=3.45, wpb=1741.1, bsz=53.4, num_updates=28000, lr=0.000298807, gnorm=0.991, clip=0, loss_scale=512, train_wall=29, wall=8270
2022-10-19 19:22:42 | INFO | train_inner | epoch 008:    544 / 3937 loss=13.534, nll_loss=10.167, mask_ins=1.938, word_ins_ml=10.853, word_reposition=0.744, ppl=11861.3, wps=5761.8, ups=3.43, wpb=1680.9, bsz=52.6, num_updates=28100, lr=0.000298275, gnorm=1.037, clip=0, loss_scale=512, train_wall=29, wall=8299
2022-10-19 19:23:11 | INFO | train_inner | epoch 008:    644 / 3937 loss=13.487, nll_loss=10.177, mask_ins=1.856, word_ins_ml=10.861, word_reposition=0.77, ppl=11485.2, wps=5412.8, ups=3.48, wpb=1556.2, bsz=46.9, num_updates=28200, lr=0.000297746, gnorm=1.072, clip=0, loss_scale=512, train_wall=29, wall=8328
2022-10-19 19:23:40 | INFO | train_inner | epoch 008:    744 / 3937 loss=13.528, nll_loss=10.184, mask_ins=1.898, word_ins_ml=10.868, word_reposition=0.762, ppl=11816, wps=5359.9, ups=3.44, wpb=1559.5, bsz=46.5, num_updates=28300, lr=0.000297219, gnorm=1.454, clip=0, loss_scale=512, train_wall=29, wall=8357
2022-10-19 19:24:09 | INFO | train_inner | epoch 008:    844 / 3937 loss=13.487, nll_loss=10.19, mask_ins=1.865, word_ins_ml=10.874, word_reposition=0.748, ppl=11478.9, wps=6021.4, ups=3.47, wpb=1736.4, bsz=54, num_updates=28400, lr=0.000296695, gnorm=1.072, clip=0, loss_scale=512, train_wall=29, wall=8386
2022-10-19 19:24:39 | INFO | train_inner | epoch 008:    944 / 3937 loss=13.458, nll_loss=10.134, mask_ins=1.876, word_ins_ml=10.825, word_reposition=0.757, ppl=11254.5, wps=5655.1, ups=3.39, wpb=1668.3, bsz=50.1, num_updates=28500, lr=0.000296174, gnorm=1.238, clip=0, loss_scale=512, train_wall=29, wall=8415
2022-10-19 19:25:07 | INFO | train_inner | epoch 008:   1044 / 3937 loss=13.444, nll_loss=10.184, mask_ins=1.811, word_ins_ml=10.869, word_reposition=0.763, ppl=11140.7, wps=5323.5, ups=3.47, wpb=1532.5, bsz=45.4, num_updates=28600, lr=0.000295656, gnorm=1.053, clip=0, loss_scale=512, train_wall=29, wall=8444
2022-10-19 19:25:36 | INFO | train_inner | epoch 008:   1144 / 3937 loss=13.525, nll_loss=10.146, mask_ins=1.927, word_ins_ml=10.835, word_reposition=0.763, ppl=11787.6, wps=6119.5, ups=3.44, wpb=1778.6, bsz=54.9, num_updates=28700, lr=0.000295141, gnorm=1.218, clip=0, loss_scale=512, train_wall=29, wall=8473
2022-10-19 19:26:05 | INFO | train_inner | epoch 008:   1244 / 3937 loss=13.457, nll_loss=10.155, mask_ins=1.884, word_ins_ml=10.844, word_reposition=0.729, ppl=11245.2, wps=6229.1, ups=3.44, wpb=1810, bsz=55.8, num_updates=28800, lr=0.000294628, gnorm=1.157, clip=0, loss_scale=512, train_wall=29, wall=8502
2022-10-19 19:26:35 | INFO | train_inner | epoch 008:   1344 / 3937 loss=13.478, nll_loss=10.123, mask_ins=1.925, word_ins_ml=10.816, word_reposition=0.736, ppl=11413.6, wps=6268.7, ups=3.43, wpb=1827.2, bsz=56.1, num_updates=28900, lr=0.000294118, gnorm=1.019, clip=0, loss_scale=512, train_wall=29, wall=8531
2022-10-19 19:27:03 | INFO | train_inner | epoch 008:   1444 / 3937 loss=13.524, nll_loss=10.136, mask_ins=1.922, word_ins_ml=10.827, word_reposition=0.775, ppl=11781.6, wps=5986.5, ups=3.46, wpb=1728.9, bsz=53.2, num_updates=29000, lr=0.00029361, gnorm=1.16, clip=0, loss_scale=512, train_wall=29, wall=8560
2022-10-19 19:27:33 | INFO | train_inner | epoch 008:   1544 / 3937 loss=13.586, nll_loss=10.061, mask_ins=1.884, word_ins_ml=10.761, word_reposition=0.94, ppl=12293.4, wps=5782, ups=3.44, wpb=1681.5, bsz=50.5, num_updates=29100, lr=0.000293105, gnorm=1.285, clip=0, loss_scale=512, train_wall=29, wall=8589
2022-10-19 19:28:01 | INFO | train_inner | epoch 008:   1644 / 3937 loss=13.59, nll_loss=10.125, mask_ins=1.894, word_ins_ml=10.816, word_reposition=0.879, ppl=12327.8, wps=5489.2, ups=3.49, wpb=1574.1, bsz=46.9, num_updates=29200, lr=0.000292603, gnorm=2.48, clip=1, loss_scale=512, train_wall=28, wall=8618
2022-10-19 19:28:30 | INFO | train_inner | epoch 008:   1744 / 3937 loss=13.574, nll_loss=10.156, mask_ins=1.937, word_ins_ml=10.843, word_reposition=0.795, ppl=12197.5, wps=6178.5, ups=3.48, wpb=1776.5, bsz=54, num_updates=29300, lr=0.000292103, gnorm=2.201, clip=1, loss_scale=512, train_wall=28, wall=8647
2022-10-19 19:28:59 | INFO | train_inner | epoch 008:   1844 / 3937 loss=13.508, nll_loss=10.167, mask_ins=1.908, word_ins_ml=10.853, word_reposition=0.747, ppl=11652.8, wps=5766.7, ups=3.47, wpb=1660.1, bsz=50, num_updates=29400, lr=0.000291606, gnorm=1.175, clip=0, loss_scale=512, train_wall=29, wall=8676
2022-10-19 19:29:28 | INFO | train_inner | epoch 008:   1944 / 3937 loss=13.525, nll_loss=10.183, mask_ins=1.917, word_ins_ml=10.866, word_reposition=0.742, ppl=11791.1, wps=5968, ups=3.47, wpb=1721.5, bsz=52.4, num_updates=29500, lr=0.000291111, gnorm=1.067, clip=0, loss_scale=512, train_wall=29, wall=8704
2022-10-19 19:29:57 | INFO | train_inner | epoch 008:   2044 / 3937 loss=13.449, nll_loss=10.142, mask_ins=1.887, word_ins_ml=10.832, word_reposition=0.73, ppl=11179, wps=6025.1, ups=3.46, wpb=1740.7, bsz=52.8, num_updates=29600, lr=0.000290619, gnorm=0.967, clip=0, loss_scale=512, train_wall=29, wall=8733
2022-10-19 19:30:25 | INFO | train_inner | epoch 008:   2144 / 3937 loss=13.564, nll_loss=10.178, mask_ins=1.902, word_ins_ml=10.863, word_reposition=0.799, ppl=12112.7, wps=5595.9, ups=3.47, wpb=1612.6, bsz=48.7, num_updates=29700, lr=0.000290129, gnorm=1.223, clip=0, loss_scale=512, train_wall=29, wall=8762
2022-10-19 19:30:54 | INFO | train_inner | epoch 008:   2244 / 3937 loss=13.507, nll_loss=10.167, mask_ins=1.903, word_ins_ml=10.854, word_reposition=0.75, ppl=11645.5, wps=5899.6, ups=3.44, wpb=1715.4, bsz=52.2, num_updates=29800, lr=0.000289642, gnorm=2.278, clip=2, loss_scale=512, train_wall=29, wall=8791
2022-10-19 19:31:23 | INFO | train_inner | epoch 008:   2344 / 3937 loss=13.533, nll_loss=10.165, mask_ins=1.915, word_ins_ml=10.852, word_reposition=0.766, ppl=11852.5, wps=6011.5, ups=3.47, wpb=1729.9, bsz=51.3, num_updates=29900, lr=0.000289157, gnorm=1.076, clip=0, loss_scale=512, train_wall=29, wall=8820
2022-10-19 19:31:52 | INFO | train_inner | epoch 008:   2444 / 3937 loss=13.555, nll_loss=10.168, mask_ins=1.947, word_ins_ml=10.854, word_reposition=0.754, ppl=12038.2, wps=5945, ups=3.46, wpb=1719.5, bsz=52.2, num_updates=30000, lr=0.000288675, gnorm=0.988, clip=0, loss_scale=512, train_wall=29, wall=8849
2022-10-19 19:32:21 | INFO | train_inner | epoch 008:   2544 / 3937 loss=13.456, nll_loss=10.155, mask_ins=1.855, word_ins_ml=10.843, word_reposition=0.759, ppl=11237.2, wps=6021.9, ups=3.47, wpb=1734, bsz=51.7, num_updates=30100, lr=0.000288195, gnorm=1.151, clip=0, loss_scale=512, train_wall=29, wall=8878
2022-10-19 19:32:50 | INFO | train_inner | epoch 008:   2644 / 3937 loss=13.555, nll_loss=10.15, mask_ins=1.942, word_ins_ml=10.838, word_reposition=0.776, ppl=12034, wps=5856, ups=3.46, wpb=1694.8, bsz=52.4, num_updates=30200, lr=0.000287718, gnorm=0.928, clip=0, loss_scale=512, train_wall=29, wall=8907
2022-10-19 19:33:19 | INFO | train_inner | epoch 008:   2744 / 3937 loss=13.512, nll_loss=10.18, mask_ins=1.891, word_ins_ml=10.865, word_reposition=0.755, ppl=11679.2, wps=5891.8, ups=3.45, wpb=1707.5, bsz=51.6, num_updates=30300, lr=0.000287242, gnorm=0.992, clip=0, loss_scale=512, train_wall=29, wall=8936
2022-10-19 19:33:48 | INFO | train_inner | epoch 008:   2844 / 3937 loss=13.464, nll_loss=10.177, mask_ins=1.852, word_ins_ml=10.862, word_reposition=0.751, ppl=11302.7, wps=5679.8, ups=3.48, wpb=1633.6, bsz=49.1, num_updates=30400, lr=0.00028677, gnorm=0.97, clip=0, loss_scale=512, train_wall=28, wall=8964
2022-10-19 19:34:17 | INFO | train_inner | epoch 008:   2944 / 3937 loss=13.53, nll_loss=10.173, mask_ins=1.918, word_ins_ml=10.858, word_reposition=0.754, ppl=11826.8, wps=5574.7, ups=3.44, wpb=1619.3, bsz=49.2, num_updates=30500, lr=0.000286299, gnorm=1.06, clip=0, loss_scale=512, train_wall=29, wall=8994
2022-10-19 19:34:46 | INFO | train_inner | epoch 008:   3044 / 3937 loss=13.499, nll_loss=10.152, mask_ins=1.898, word_ins_ml=10.84, word_reposition=0.762, ppl=11578.6, wps=6186.2, ups=3.45, wpb=1793.3, bsz=55, num_updates=30600, lr=0.000285831, gnorm=1.109, clip=0, loss_scale=906, train_wall=29, wall=9022
2022-10-19 19:35:14 | INFO | train_inner | epoch 008:   3144 / 3937 loss=13.511, nll_loss=10.169, mask_ins=1.906, word_ins_ml=10.855, word_reposition=0.75, ppl=11675, wps=6147.4, ups=3.48, wpb=1766.8, bsz=53.7, num_updates=30700, lr=0.000285365, gnorm=2.008, clip=1, loss_scale=1024, train_wall=28, wall=9051
2022-10-19 19:35:43 | INFO | train_inner | epoch 008:   3244 / 3937 loss=13.498, nll_loss=10.172, mask_ins=1.879, word_ins_ml=10.859, word_reposition=0.76, ppl=11570.7, wps=6046.4, ups=3.46, wpb=1745.7, bsz=53.3, num_updates=30800, lr=0.000284901, gnorm=1.219, clip=0, loss_scale=1024, train_wall=29, wall=9080
2022-10-19 19:36:12 | INFO | train_inner | epoch 008:   3344 / 3937 loss=13.477, nll_loss=10.179, mask_ins=1.884, word_ins_ml=10.864, word_reposition=0.73, ppl=11402.7, wps=5823.1, ups=3.46, wpb=1684.5, bsz=51.5, num_updates=30900, lr=0.00028444, gnorm=0.931, clip=0, loss_scale=1024, train_wall=29, wall=9109
2022-10-19 19:36:41 | INFO | train_inner | epoch 008:   3444 / 3937 loss=13.497, nll_loss=10.152, mask_ins=1.89, word_ins_ml=10.841, word_reposition=0.765, ppl=11557.6, wps=5496.2, ups=3.49, wpb=1576.3, bsz=47.6, num_updates=31000, lr=0.000283981, gnorm=1.056, clip=0, loss_scale=1024, train_wall=28, wall=9138
2022-10-19 19:37:10 | INFO | train_inner | epoch 008:   3544 / 3937 loss=13.483, nll_loss=10.189, mask_ins=1.84, word_ins_ml=10.873, word_reposition=0.77, ppl=11448.6, wps=5991, ups=3.47, wpb=1727.9, bsz=51.8, num_updates=31100, lr=0.000283524, gnorm=1.125, clip=0, loss_scale=1024, train_wall=29, wall=9167
2022-10-19 19:37:39 | INFO | train_inner | epoch 008:   3644 / 3937 loss=13.55, nll_loss=10.198, mask_ins=1.924, word_ins_ml=10.88, word_reposition=0.746, ppl=11996.2, wps=5866.3, ups=3.47, wpb=1689.6, bsz=50.6, num_updates=31200, lr=0.000283069, gnorm=1.034, clip=0, loss_scale=1024, train_wall=29, wall=9195
2022-10-19 19:38:08 | INFO | train_inner | epoch 008:   3744 / 3937 loss=13.501, nll_loss=10.133, mask_ins=1.928, word_ins_ml=10.824, word_reposition=0.749, ppl=11590.4, wps=6048.7, ups=3.43, wpb=1764.4, bsz=54.5, num_updates=31300, lr=0.000282617, gnorm=1.201, clip=0, loss_scale=1024, train_wall=29, wall=9225
2022-10-19 19:38:36 | INFO | train_inner | epoch 008:   3844 / 3937 loss=13.501, nll_loss=10.177, mask_ins=1.886, word_ins_ml=10.862, word_reposition=0.753, ppl=11591.5, wps=6420.7, ups=3.52, wpb=1824.9, bsz=56.4, num_updates=31400, lr=0.000282166, gnorm=1.12, clip=0, loss_scale=1024, train_wall=28, wall=9253
2022-10-19 19:39:03 | INFO | train | epoch 008 | loss 13.509 | nll_loss 10.163 | mask_ins 1.896 | word_ins_ml 10.85 | word_reposition 0.763 | ppl 11659.9 | wps 5755.8 | ups 3.39 | wpb 1696.2 | bsz 51.5 | num_updates 31493 | lr 0.000281749 | gnorm 1.223 | clip 0.1 | loss_scale 638 | train_wall 1127 | wall 9280
2022-10-19 19:39:15 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 25.909 | nll_loss 16.552 | mask_ins 7.215 | word_ins_ml 16.385 | word_reposition 2.309 | ppl 6.29856e+07 | wps 27317 | wpb 1503.2 | bsz 51.5 | num_updates 31493 | best_loss 14.267
2022-10-19 19:39:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 8 @ 31493 updates, score 25.909) (writing took 10.13335633999668 seconds)
2022-10-19 19:39:27 | INFO | train_inner | epoch 009:      7 / 3937 loss=13.526, nll_loss=10.196, mask_ins=1.9, word_ins_ml=10.879, word_reposition=0.747, ppl=11792.9, wps=3164.2, ups=1.97, wpb=1602.9, bsz=47.9, num_updates=31500, lr=0.000281718, gnorm=1.175, clip=0, loss_scale=1024, train_wall=28, wall=9304
2022-10-19 19:39:55 | INFO | train_inner | epoch 009:    107 / 3937 loss=13.436, nll_loss=10.163, mask_ins=1.851, word_ins_ml=10.849, word_reposition=0.736, ppl=11081, wps=5733.6, ups=3.53, wpb=1624.3, bsz=49.3, num_updates=31600, lr=0.000281272, gnorm=1.158, clip=0, loss_scale=1024, train_wall=28, wall=9332
2022-10-19 19:40:24 | INFO | train_inner | epoch 009:    207 / 3937 loss=13.482, nll_loss=10.145, mask_ins=1.9, word_ins_ml=10.834, word_reposition=0.747, ppl=11438.3, wps=5852, ups=3.46, wpb=1690.4, bsz=51.8, num_updates=31700, lr=0.000280828, gnorm=1.112, clip=0, loss_scale=1024, train_wall=29, wall=9361
2022-10-19 19:40:53 | INFO | train_inner | epoch 009:    307 / 3937 loss=13.516, nll_loss=10.169, mask_ins=1.925, word_ins_ml=10.854, word_reposition=0.737, ppl=11714.4, wps=5717.1, ups=3.42, wpb=1669.5, bsz=50.1, num_updates=31800, lr=0.000280386, gnorm=1.036, clip=0, loss_scale=1024, train_wall=29, wall=9390
2022-10-19 19:41:22 | INFO | train_inner | epoch 009:    407 / 3937 loss=13.48, nll_loss=10.192, mask_ins=1.88, word_ins_ml=10.876, word_reposition=0.725, ppl=11427.4, wps=5480.6, ups=3.5, wpb=1565.9, bsz=46.4, num_updates=31900, lr=0.000279946, gnorm=1.106, clip=0, loss_scale=1024, train_wall=28, wall=9419
2022-10-19 19:41:50 | INFO | train_inner | epoch 009:    507 / 3937 loss=13.489, nll_loss=10.157, mask_ins=1.892, word_ins_ml=10.844, word_reposition=0.754, ppl=11498.8, wps=5811.7, ups=3.49, wpb=1666.9, bsz=50.9, num_updates=32000, lr=0.000279508, gnorm=0.898, clip=0, loss_scale=1024, train_wall=28, wall=9447
2022-10-19 19:42:19 | INFO | train_inner | epoch 009:    607 / 3937 loss=13.485, nll_loss=10.139, mask_ins=1.91, word_ins_ml=10.828, word_reposition=0.747, ppl=11464.7, wps=6061, ups=3.45, wpb=1756.3, bsz=53.9, num_updates=32100, lr=0.000279073, gnorm=1.09, clip=0, loss_scale=1024, train_wall=29, wall=9476
2022-10-19 19:42:48 | INFO | train_inner | epoch 009:    707 / 3937 loss=13.504, nll_loss=10.142, mask_ins=1.874, word_ins_ml=10.832, word_reposition=0.798, ppl=11620.7, wps=6127.8, ups=3.44, wpb=1780.1, bsz=55.8, num_updates=32200, lr=0.000278639, gnorm=2.255, clip=1, loss_scale=1024, train_wall=29, wall=9505
2022-10-19 19:43:17 | INFO | train_inner | epoch 009:    807 / 3937 loss=13.49, nll_loss=10.156, mask_ins=1.895, word_ins_ml=10.845, word_reposition=0.751, ppl=11507.8, wps=5904.8, ups=3.46, wpb=1706.8, bsz=51.9, num_updates=32300, lr=0.000278207, gnorm=0.999, clip=0, loss_scale=1024, train_wall=29, wall=9534
2022-10-19 19:43:46 | INFO | train_inner | epoch 009:    907 / 3937 loss=13.537, nll_loss=10.178, mask_ins=1.925, word_ins_ml=10.864, word_reposition=0.749, ppl=11889.1, wps=5852.2, ups=3.46, wpb=1692.3, bsz=51.3, num_updates=32400, lr=0.000277778, gnorm=0.963, clip=0, loss_scale=1024, train_wall=29, wall=9563
2022-10-19 19:44:15 | INFO | train_inner | epoch 009:   1007 / 3937 loss=13.489, nll_loss=10.182, mask_ins=1.891, word_ins_ml=10.866, word_reposition=0.732, ppl=11496.4, wps=6010.7, ups=3.52, wpb=1707.7, bsz=52.7, num_updates=32500, lr=0.00027735, gnorm=0.988, clip=0, loss_scale=1024, train_wall=28, wall=9592
2022-10-19 19:44:43 | INFO | train_inner | epoch 009:   1107 / 3937 loss=13.488, nll_loss=10.153, mask_ins=1.9, word_ins_ml=10.841, word_reposition=0.748, ppl=11488.2, wps=5974.1, ups=3.48, wpb=1718.6, bsz=52.6, num_updates=32600, lr=0.000276924, gnorm=1.208, clip=0, loss_scale=1024, train_wall=29, wall=9620
2022-10-19 19:45:12 | INFO | train_inner | epoch 009:   1207 / 3937 loss=13.464, nll_loss=10.158, mask_ins=1.874, word_ins_ml=10.846, word_reposition=0.744, ppl=11303.5, wps=5913.7, ups=3.52, wpb=1682.2, bsz=50.7, num_updates=32700, lr=0.000276501, gnorm=1.193, clip=0, loss_scale=1024, train_wall=28, wall=9649
2022-10-19 19:45:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-10-19 19:45:41 | INFO | train_inner | epoch 009:   1308 / 3937 loss=13.463, nll_loss=10.167, mask_ins=1.882, word_ins_ml=10.853, word_reposition=0.728, ppl=11295.6, wps=5828.2, ups=3.44, wpb=1692.3, bsz=51.4, num_updates=32800, lr=0.000276079, gnorm=1.1, clip=0, loss_scale=720, train_wall=29, wall=9678
2022-10-19 19:46:10 | INFO | train_inner | epoch 009:   1408 / 3937 loss=13.45, nll_loss=10.126, mask_ins=1.869, word_ins_ml=10.817, word_reposition=0.764, ppl=11190.4, wps=5713.3, ups=3.44, wpb=1663, bsz=50.4, num_updates=32900, lr=0.000275659, gnorm=1.335, clip=0, loss_scale=512, train_wall=29, wall=9707
2022-10-19 19:46:39 | INFO | train_inner | epoch 009:   1508 / 3937 loss=13.496, nll_loss=10.155, mask_ins=1.894, word_ins_ml=10.843, word_reposition=0.76, ppl=11556.5, wps=5973.6, ups=3.41, wpb=1754.1, bsz=54.5, num_updates=33000, lr=0.000275241, gnorm=0.959, clip=0, loss_scale=512, train_wall=29, wall=9736
2022-10-19 19:47:08 | INFO | train_inner | epoch 009:   1608 / 3937 loss=13.511, nll_loss=10.181, mask_ins=1.899, word_ins_ml=10.865, word_reposition=0.747, ppl=11671.9, wps=5757.1, ups=3.5, wpb=1644.8, bsz=49.8, num_updates=33100, lr=0.000274825, gnorm=1.18, clip=0, loss_scale=512, train_wall=28, wall=9765
2022-10-19 19:47:37 | INFO | train_inner | epoch 009:   1708 / 3937 loss=13.473, nll_loss=10.17, mask_ins=1.864, word_ins_ml=10.857, word_reposition=0.752, ppl=11371.1, wps=5950.6, ups=3.46, wpb=1719.5, bsz=52.7, num_updates=33200, lr=0.000274411, gnorm=1.014, clip=0, loss_scale=512, train_wall=29, wall=9794
2022-10-19 19:48:06 | INFO | train_inner | epoch 009:   1808 / 3937 loss=13.466, nll_loss=10.16, mask_ins=1.897, word_ins_ml=10.848, word_reposition=0.721, ppl=11313.3, wps=5988.1, ups=3.43, wpb=1746.8, bsz=52.4, num_updates=33300, lr=0.000273998, gnorm=0.917, clip=0, loss_scale=512, train_wall=29, wall=9823
2022-10-19 19:48:35 | INFO | train_inner | epoch 009:   1908 / 3937 loss=13.552, nll_loss=10.194, mask_ins=1.914, word_ins_ml=10.877, word_reposition=0.761, ppl=12006.7, wps=5860.9, ups=3.46, wpb=1693.4, bsz=50.9, num_updates=33400, lr=0.000273588, gnorm=0.941, clip=0, loss_scale=512, train_wall=29, wall=9852
2022-10-19 19:49:04 | INFO | train_inner | epoch 009:   2008 / 3937 loss=13.479, nll_loss=10.165, mask_ins=1.883, word_ins_ml=10.852, word_reposition=0.744, ppl=11417.1, wps=5809.6, ups=3.44, wpb=1686.5, bsz=50.1, num_updates=33500, lr=0.000273179, gnorm=1.075, clip=0, loss_scale=512, train_wall=29, wall=9881
2022-10-19 19:49:33 | INFO | train_inner | epoch 009:   2108 / 3937 loss=13.541, nll_loss=10.174, mask_ins=1.94, word_ins_ml=10.86, word_reposition=0.742, ppl=11920.5, wps=5892.2, ups=3.44, wpb=1713.4, bsz=51.4, num_updates=33600, lr=0.000272772, gnorm=0.95, clip=0, loss_scale=512, train_wall=29, wall=9910
2022-10-19 19:50:02 | INFO | train_inner | epoch 009:   2208 / 3937 loss=13.472, nll_loss=10.188, mask_ins=1.852, word_ins_ml=10.873, word_reposition=0.748, ppl=11364.4, wps=6068.3, ups=3.43, wpb=1769.9, bsz=53, num_updates=33700, lr=0.000272367, gnorm=1.003, clip=0, loss_scale=512, train_wall=29, wall=9939
2022-10-19 19:50:31 | INFO | train_inner | epoch 009:   2308 / 3937 loss=13.544, nll_loss=10.182, mask_ins=1.916, word_ins_ml=10.865, word_reposition=0.763, ppl=11947.3, wps=5744.2, ups=3.46, wpb=1660.8, bsz=50.8, num_updates=33800, lr=0.000271964, gnorm=0.979, clip=0, loss_scale=512, train_wall=29, wall=9968
2022-10-19 19:51:00 | INFO | train_inner | epoch 009:   2408 / 3937 loss=13.553, nll_loss=10.165, mask_ins=1.934, word_ins_ml=10.852, word_reposition=0.767, ppl=12017, wps=5814.4, ups=3.43, wpb=1694.4, bsz=52, num_updates=33900, lr=0.000271563, gnorm=0.918, clip=0, loss_scale=512, train_wall=29, wall=9997
2022-10-19 19:51:29 | INFO | train_inner | epoch 009:   2508 / 3937 loss=13.55, nll_loss=10.163, mask_ins=1.947, word_ins_ml=10.849, word_reposition=0.754, ppl=11995.7, wps=6003.8, ups=3.43, wpb=1752.9, bsz=53.5, num_updates=34000, lr=0.000271163, gnorm=0.955, clip=0, loss_scale=512, train_wall=29, wall=10026
2022-10-19 19:51:58 | INFO | train_inner | epoch 009:   2608 / 3937 loss=13.504, nll_loss=10.152, mask_ins=1.924, word_ins_ml=10.84, word_reposition=0.74, ppl=11613.7, wps=5802.5, ups=3.45, wpb=1682.5, bsz=51.1, num_updates=34100, lr=0.000270765, gnorm=1.049, clip=0, loss_scale=512, train_wall=29, wall=10055
2022-10-19 19:52:27 | INFO | train_inner | epoch 009:   2708 / 3937 loss=13.468, nll_loss=10.146, mask_ins=1.909, word_ins_ml=10.834, word_reposition=0.724, ppl=11328.5, wps=5455.7, ups=3.45, wpb=1582.3, bsz=47.9, num_updates=34200, lr=0.000270369, gnorm=0.948, clip=0, loss_scale=512, train_wall=29, wall=10084
2022-10-19 19:52:56 | INFO | train_inner | epoch 009:   2808 / 3937 loss=13.398, nll_loss=10.127, mask_ins=1.837, word_ins_ml=10.818, word_reposition=0.743, ppl=10792.4, wps=5804.9, ups=3.48, wpb=1669.5, bsz=50.5, num_updates=34300, lr=0.000269975, gnorm=0.925, clip=0, loss_scale=512, train_wall=28, wall=10113
2022-10-19 19:53:25 | INFO | train_inner | epoch 009:   2908 / 3937 loss=13.453, nll_loss=10.154, mask_ins=1.88, word_ins_ml=10.842, word_reposition=0.731, ppl=11214.5, wps=6376.5, ups=3.42, wpb=1863, bsz=56.6, num_updates=34400, lr=0.000269582, gnorm=0.854, clip=0, loss_scale=512, train_wall=29, wall=10142
2022-10-19 19:53:54 | INFO | train_inner | epoch 009:   3008 / 3937 loss=13.48, nll_loss=10.161, mask_ins=1.893, word_ins_ml=10.85, word_reposition=0.738, ppl=11426.3, wps=5728.5, ups=3.46, wpb=1654.1, bsz=49.9, num_updates=34500, lr=0.000269191, gnorm=0.921, clip=0, loss_scale=512, train_wall=29, wall=10171
2022-10-19 19:54:23 | INFO | train_inner | epoch 009:   3108 / 3937 loss=13.479, nll_loss=10.17, mask_ins=1.876, word_ins_ml=10.854, word_reposition=0.75, ppl=11421.6, wps=5648.6, ups=3.47, wpb=1627.6, bsz=48.9, num_updates=34600, lr=0.000268802, gnorm=0.921, clip=0, loss_scale=512, train_wall=29, wall=10200
2022-10-19 19:54:52 | INFO | train_inner | epoch 009:   3208 / 3937 loss=13.422, nll_loss=10.146, mask_ins=1.848, word_ins_ml=10.836, word_reposition=0.738, ppl=10972.7, wps=6021.1, ups=3.44, wpb=1749.5, bsz=53, num_updates=34700, lr=0.000268414, gnorm=0.984, clip=0, loss_scale=512, train_wall=29, wall=10229
2022-10-19 19:55:22 | INFO | train_inner | epoch 009:   3308 / 3937 loss=13.455, nll_loss=10.166, mask_ins=1.874, word_ins_ml=10.852, word_reposition=0.729, ppl=11225.6, wps=6045.9, ups=3.41, wpb=1772.9, bsz=53.3, num_updates=34800, lr=0.000268028, gnorm=0.893, clip=0, loss_scale=512, train_wall=29, wall=10258
2022-10-19 19:55:51 | INFO | train_inner | epoch 009:   3408 / 3937 loss=13.509, nll_loss=10.198, mask_ins=1.898, word_ins_ml=10.881, word_reposition=0.73, ppl=11659.6, wps=6069.6, ups=3.41, wpb=1778.8, bsz=54.9, num_updates=34900, lr=0.000267644, gnorm=1.209, clip=0, loss_scale=512, train_wall=29, wall=10288
2022-10-19 19:56:20 | INFO | train_inner | epoch 009:   3508 / 3937 loss=13.565, nll_loss=10.192, mask_ins=1.887, word_ins_ml=10.875, word_reposition=0.803, ppl=12116.5, wps=6044.4, ups=3.43, wpb=1763, bsz=54, num_updates=35000, lr=0.000267261, gnorm=2.498, clip=2, loss_scale=512, train_wall=29, wall=10317
2022-10-19 19:56:49 | INFO | train_inner | epoch 009:   3608 / 3937 loss=13.606, nll_loss=10.166, mask_ins=1.972, word_ins_ml=10.853, word_reposition=0.782, ppl=12467.2, wps=5761.9, ups=3.46, wpb=1666.9, bsz=49.8, num_updates=35100, lr=0.00026688, gnorm=1.057, clip=0, loss_scale=512, train_wall=29, wall=10346
2022-10-19 19:57:18 | INFO | train_inner | epoch 009:   3708 / 3937 loss=13.552, nll_loss=10.154, mask_ins=1.944, word_ins_ml=10.841, word_reposition=0.767, ppl=12010.7, wps=5671, ups=3.44, wpb=1648.3, bsz=50, num_updates=35200, lr=0.000266501, gnorm=1.743, clip=1, loss_scale=512, train_wall=29, wall=10375
2022-10-19 19:57:47 | INFO | train_inner | epoch 009:   3808 / 3937 loss=13.536, nll_loss=10.194, mask_ins=1.924, word_ins_ml=10.877, word_reposition=0.735, ppl=11876.8, wps=5643, ups=3.49, wpb=1615.4, bsz=48.8, num_updates=35300, lr=0.000266123, gnorm=1.069, clip=0, loss_scale=512, train_wall=28, wall=10403
2022-10-19 19:58:15 | INFO | train_inner | epoch 009:   3908 / 3937 loss=13.49, nll_loss=10.168, mask_ins=1.892, word_ins_ml=10.854, word_reposition=0.743, ppl=11501.7, wps=5614.6, ups=3.47, wpb=1616.2, bsz=48.9, num_updates=35400, lr=0.000265747, gnorm=0.958, clip=0, loss_scale=512, train_wall=29, wall=10432
2022-10-19 19:58:24 | INFO | train | epoch 009 | loss 13.496 | nll_loss 10.164 | mask_ins 1.897 | word_ins_ml 10.851 | word_reposition 0.748 | ppl 11549.4 | wps 5750.8 | ups 3.39 | wpb 1696.3 | bsz 51.5 | num_updates 35429 | lr 0.000265638 | gnorm 1.11 | clip 0.1 | loss_scale 674 | train_wall 1129 | wall 10441
2022-10-19 19:58:36 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 23.468 | nll_loss 15.535 | mask_ins 5.157 | word_ins_ml 15.469 | word_reposition 2.843 | ppl 1.16045e+07 | wps 27386.5 | wpb 1503.2 | bsz 51.5 | num_updates 35429 | best_loss 14.267
2022-10-19 19:58:46 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 9 @ 35429 updates, score 23.468) (writing took 10.494685929035768 seconds)
2022-10-19 19:59:07 | INFO | train_inner | epoch 010:     71 / 3937 loss=13.498, nll_loss=10.168, mask_ins=1.877, word_ins_ml=10.854, word_reposition=0.766, ppl=11570.5, wps=3295.1, ups=1.96, wpb=1683.8, bsz=51.9, num_updates=35500, lr=0.000265372, gnorm=1.132, clip=0, loss_scale=512, train_wall=29, wall=10483
2022-10-19 19:59:35 | INFO | train_inner | epoch 010:    171 / 3937 loss=13.475, nll_loss=10.159, mask_ins=1.881, word_ins_ml=10.846, word_reposition=0.747, ppl=11383.3, wps=5414.5, ups=3.48, wpb=1554.5, bsz=46.8, num_updates=35600, lr=0.000264999, gnorm=1.168, clip=0, loss_scale=512, train_wall=28, wall=10512
2022-10-19 20:00:04 | INFO | train_inner | epoch 010:    271 / 3937 loss=13.474, nll_loss=10.148, mask_ins=1.903, word_ins_ml=10.837, word_reposition=0.734, ppl=11380.2, wps=5726.7, ups=3.48, wpb=1643.5, bsz=49.8, num_updates=35700, lr=0.000264628, gnorm=0.979, clip=0, loss_scale=512, train_wall=28, wall=10541
2022-10-19 20:00:33 | INFO | train_inner | epoch 010:    371 / 3937 loss=13.497, nll_loss=10.138, mask_ins=1.921, word_ins_ml=10.828, word_reposition=0.747, ppl=11559.9, wps=6352.7, ups=3.44, wpb=1847, bsz=57.2, num_updates=35800, lr=0.000264258, gnorm=0.919, clip=0, loss_scale=512, train_wall=29, wall=10570
2022-10-19 20:01:02 | INFO | train_inner | epoch 010:    471 / 3937 loss=13.418, nll_loss=10.109, mask_ins=1.87, word_ins_ml=10.803, word_reposition=0.745, ppl=10942.3, wps=5860, ups=3.44, wpb=1705.5, bsz=51.9, num_updates=35900, lr=0.00026389, gnorm=1.025, clip=0, loss_scale=512, train_wall=29, wall=10599
2022-10-19 20:01:31 | INFO | train_inner | epoch 010:    571 / 3937 loss=13.54, nll_loss=10.176, mask_ins=1.922, word_ins_ml=10.861, word_reposition=0.758, ppl=11912.6, wps=5894.9, ups=3.47, wpb=1698.4, bsz=51.5, num_updates=36000, lr=0.000263523, gnorm=0.956, clip=0, loss_scale=512, train_wall=29, wall=10628
2022-10-19 20:01:59 | INFO | train_inner | epoch 010:    671 / 3937 loss=13.537, nll_loss=10.157, mask_ins=1.938, word_ins_ml=10.844, word_reposition=0.755, ppl=11889.1, wps=5748.6, ups=3.5, wpb=1640.9, bsz=49.8, num_updates=36100, lr=0.000263158, gnorm=1.178, clip=0, loss_scale=512, train_wall=28, wall=10656
2022-10-19 20:02:29 | INFO | train_inner | epoch 010:    771 / 3937 loss=13.442, nll_loss=10.148, mask_ins=1.85, word_ins_ml=10.836, word_reposition=0.756, ppl=11127.6, wps=5897.9, ups=3.44, wpb=1713.6, bsz=51.8, num_updates=36200, lr=0.000262794, gnorm=0.903, clip=0, loss_scale=512, train_wall=29, wall=10685
2022-10-19 20:02:57 | INFO | train_inner | epoch 010:    871 / 3937 loss=13.456, nll_loss=10.15, mask_ins=1.894, word_ins_ml=10.838, word_reposition=0.724, ppl=11240.4, wps=6128.1, ups=3.45, wpb=1775.8, bsz=53.4, num_updates=36300, lr=0.000262432, gnorm=0.878, clip=0, loss_scale=512, train_wall=29, wall=10714
2022-10-19 20:03:26 | INFO | train_inner | epoch 010:    971 / 3937 loss=13.423, nll_loss=10.156, mask_ins=1.859, word_ins_ml=10.843, word_reposition=0.721, ppl=10984.5, wps=6213.5, ups=3.45, wpb=1800.1, bsz=56.7, num_updates=36400, lr=0.000262071, gnorm=0.91, clip=0, loss_scale=512, train_wall=29, wall=10743
2022-10-19 20:03:56 | INFO | train_inner | epoch 010:   1071 / 3937 loss=13.488, nll_loss=10.15, mask_ins=1.921, word_ins_ml=10.838, word_reposition=0.729, ppl=11488.3, wps=6020.1, ups=3.41, wpb=1765.1, bsz=53.5, num_updates=36500, lr=0.000261712, gnorm=1.057, clip=0, loss_scale=512, train_wall=29, wall=10773
2022-10-19 20:04:25 | INFO | train_inner | epoch 010:   1171 / 3937 loss=13.512, nll_loss=10.177, mask_ins=1.9, word_ins_ml=10.862, word_reposition=0.75, ppl=11681, wps=6178.2, ups=3.48, wpb=1773.7, bsz=53.6, num_updates=36600, lr=0.000261354, gnorm=1.364, clip=1, loss_scale=512, train_wall=28, wall=10801
2022-10-19 20:04:54 | INFO | train_inner | epoch 010:   1271 / 3937 loss=13.435, nll_loss=10.17, mask_ins=1.836, word_ins_ml=10.856, word_reposition=0.743, ppl=11071.9, wps=5919.3, ups=3.4, wpb=1740.4, bsz=53.3, num_updates=36700, lr=0.000260998, gnorm=0.96, clip=0, loss_scale=512, train_wall=29, wall=10831
2022-10-19 20:05:23 | INFO | train_inner | epoch 010:   1371 / 3937 loss=13.506, nll_loss=10.154, mask_ins=1.931, word_ins_ml=10.842, word_reposition=0.732, ppl=11631.1, wps=5976.8, ups=3.43, wpb=1742.2, bsz=52.3, num_updates=36800, lr=0.000260643, gnorm=0.938, clip=0, loss_scale=512, train_wall=29, wall=10860
2022-10-19 20:05:52 | INFO | train_inner | epoch 010:   1471 / 3937 loss=13.5, nll_loss=10.161, mask_ins=1.912, word_ins_ml=10.848, word_reposition=0.739, ppl=11582.7, wps=5650.8, ups=3.47, wpb=1629.4, bsz=49.2, num_updates=36900, lr=0.00026029, gnorm=0.954, clip=0, loss_scale=840, train_wall=29, wall=10889
2022-10-19 20:06:21 | INFO | train_inner | epoch 010:   1571 / 3937 loss=13.499, nll_loss=10.156, mask_ins=1.936, word_ins_ml=10.844, word_reposition=0.719, ppl=11580, wps=6098.1, ups=3.39, wpb=1799.4, bsz=54.4, num_updates=37000, lr=0.000259938, gnorm=0.945, clip=0, loss_scale=1024, train_wall=29, wall=10918
2022-10-19 20:06:50 | INFO | train_inner | epoch 010:   1671 / 3937 loss=13.482, nll_loss=10.156, mask_ins=1.872, word_ins_ml=10.845, word_reposition=0.766, ppl=11441, wps=5976, ups=3.46, wpb=1728.3, bsz=53.5, num_updates=37100, lr=0.000259587, gnorm=1.865, clip=1, loss_scale=1024, train_wall=29, wall=10947
2022-10-19 20:07:19 | INFO | train_inner | epoch 010:   1771 / 3937 loss=13.445, nll_loss=10.167, mask_ins=1.858, word_ins_ml=10.853, word_reposition=0.734, ppl=11148.1, wps=5595.1, ups=3.48, wpb=1609.5, bsz=48.8, num_updates=37200, lr=0.000259238, gnorm=0.889, clip=0, loss_scale=1024, train_wall=29, wall=10976
2022-10-19 20:07:48 | INFO | train_inner | epoch 010:   1871 / 3937 loss=13.49, nll_loss=10.148, mask_ins=1.911, word_ins_ml=10.837, word_reposition=0.743, ppl=11507.8, wps=5713.5, ups=3.44, wpb=1663.2, bsz=51.3, num_updates=37300, lr=0.00025889, gnorm=1.12, clip=0, loss_scale=1024, train_wall=29, wall=11005
2022-10-19 20:08:17 | INFO | train_inner | epoch 010:   1971 / 3937 loss=13.524, nll_loss=10.154, mask_ins=1.893, word_ins_ml=10.842, word_reposition=0.789, ppl=11782.1, wps=5363.8, ups=3.47, wpb=1546.1, bsz=46.6, num_updates=37400, lr=0.000258544, gnorm=1.76, clip=1, loss_scale=1024, train_wall=29, wall=11034
2022-10-19 20:08:46 | INFO | train_inner | epoch 010:   2071 / 3937 loss=13.453, nll_loss=10.153, mask_ins=1.874, word_ins_ml=10.842, word_reposition=0.737, ppl=11213.4, wps=6219.8, ups=3.43, wpb=1813.6, bsz=55.5, num_updates=37500, lr=0.000258199, gnorm=0.974, clip=0, loss_scale=1024, train_wall=29, wall=11063
2022-10-19 20:09:15 | INFO | train_inner | epoch 010:   2171 / 3937 loss=13.503, nll_loss=10.168, mask_ins=1.875, word_ins_ml=10.855, word_reposition=0.773, ppl=11611.4, wps=5765.9, ups=3.44, wpb=1677.6, bsz=50.9, num_updates=37600, lr=0.000257855, gnorm=1.41, clip=1, loss_scale=1024, train_wall=29, wall=11092
2022-10-19 20:09:44 | INFO | train_inner | epoch 010:   2271 / 3937 loss=13.548, nll_loss=10.201, mask_ins=1.92, word_ins_ml=10.883, word_reposition=0.745, ppl=11977.7, wps=5531.6, ups=3.5, wpb=1581.5, bsz=47.3, num_updates=37700, lr=0.000257513, gnorm=0.984, clip=0, loss_scale=1024, train_wall=28, wall=11121
2022-10-19 20:10:13 | INFO | train_inner | epoch 010:   2371 / 3937 loss=13.472, nll_loss=10.161, mask_ins=1.857, word_ins_ml=10.848, word_reposition=0.766, ppl=11362, wps=5770, ups=3.45, wpb=1673.8, bsz=50.8, num_updates=37800, lr=0.000257172, gnorm=0.869, clip=0, loss_scale=1024, train_wall=29, wall=11150
2022-10-19 20:10:42 | INFO | train_inner | epoch 010:   2471 / 3937 loss=13.456, nll_loss=10.177, mask_ins=1.836, word_ins_ml=10.862, word_reposition=0.758, ppl=11235.7, wps=6158.6, ups=3.48, wpb=1767.9, bsz=52.7, num_updates=37900, lr=0.000256833, gnorm=0.988, clip=0, loss_scale=1024, train_wall=28, wall=11178
2022-10-19 20:11:11 | INFO | train_inner | epoch 010:   2571 / 3937 loss=13.494, nll_loss=10.135, mask_ins=1.88, word_ins_ml=10.826, word_reposition=0.788, ppl=11538, wps=5877.7, ups=3.44, wpb=1709.2, bsz=52.4, num_updates=38000, lr=0.000256495, gnorm=1.267, clip=0, loss_scale=1024, train_wall=29, wall=11208
2022-10-19 20:11:39 | INFO | train_inner | epoch 010:   2671 / 3937 loss=13.539, nll_loss=10.166, mask_ins=1.901, word_ins_ml=10.852, word_reposition=0.786, ppl=11900.3, wps=5944.2, ups=3.49, wpb=1701.5, bsz=51.5, num_updates=38100, lr=0.000256158, gnorm=1.053, clip=0, loss_scale=1024, train_wall=28, wall=11236
2022-10-19 20:12:08 | INFO | train_inner | epoch 010:   2771 / 3937 loss=13.52, nll_loss=10.178, mask_ins=1.907, word_ins_ml=10.863, word_reposition=0.75, ppl=11748.8, wps=5979.3, ups=3.43, wpb=1741.7, bsz=52.1, num_updates=38200, lr=0.000255822, gnorm=0.96, clip=0, loss_scale=1024, train_wall=29, wall=11265
2022-10-19 20:12:39 | INFO | train_inner | epoch 010:   2871 / 3937 loss=13.463, nll_loss=10.154, mask_ins=1.9, word_ins_ml=10.842, word_reposition=0.721, ppl=11291.6, wps=5156.1, ups=3.29, wpb=1568, bsz=46.6, num_updates=38300, lr=0.000255488, gnorm=1.049, clip=0, loss_scale=1024, train_wall=30, wall=11296
2022-10-19 20:13:11 | INFO | train_inner | epoch 010:   2971 / 3937 loss=13.492, nll_loss=10.155, mask_ins=1.902, word_ins_ml=10.843, word_reposition=0.748, ppl=11523.1, wps=5190.7, ups=3.13, wpb=1660, bsz=50.4, num_updates=38400, lr=0.000255155, gnorm=1.084, clip=0, loss_scale=1024, train_wall=32, wall=11328
2022-10-19 20:13:38 | INFO | train_inner | epoch 010:   3071 / 3937 loss=13.546, nll_loss=10.168, mask_ins=1.919, word_ins_ml=10.855, word_reposition=0.772, ppl=11957.8, wps=5871.3, ups=3.61, wpb=1625.1, bsz=48.5, num_updates=38500, lr=0.000254824, gnorm=1.078, clip=0, loss_scale=1024, train_wall=27, wall=11355
2022-10-19 20:14:05 | INFO | train_inner | epoch 010:   3171 / 3937 loss=13.5, nll_loss=10.15, mask_ins=1.884, word_ins_ml=10.839, word_reposition=0.777, ppl=11588.8, wps=6049.8, ups=3.7, wpb=1633.9, bsz=49.2, num_updates=38600, lr=0.000254493, gnorm=1.081, clip=0, loss_scale=1024, train_wall=27, wall=11382
2022-10-19 20:14:33 | INFO | train_inner | epoch 010:   3271 / 3937 loss=13.44, nll_loss=10.185, mask_ins=1.819, word_ins_ml=10.87, word_reposition=0.751, ppl=11109.8, wps=6057.3, ups=3.7, wpb=1637.9, bsz=49.8, num_updates=38700, lr=0.000254164, gnorm=1.067, clip=0, loss_scale=1024, train_wall=27, wall=11409
2022-10-19 20:15:00 | INFO | train_inner | epoch 010:   3371 / 3937 loss=13.474, nll_loss=10.13, mask_ins=1.924, word_ins_ml=10.821, word_reposition=0.729, ppl=11376.2, wps=6220.1, ups=3.7, wpb=1681.5, bsz=51, num_updates=38800, lr=0.000253837, gnorm=0.971, clip=0, loss_scale=1024, train_wall=27, wall=11436
2022-10-19 20:15:27 | INFO | train_inner | epoch 010:   3471 / 3937 loss=13.474, nll_loss=10.145, mask_ins=1.91, word_ins_ml=10.834, word_reposition=0.73, ppl=11374.9, wps=6280.6, ups=3.64, wpb=1725.7, bsz=52.1, num_updates=38900, lr=0.00025351, gnorm=1.069, clip=0, loss_scale=1024, train_wall=27, wall=11464
2022-10-19 20:15:54 | INFO | train_inner | epoch 010:   3571 / 3937 loss=13.423, nll_loss=10.148, mask_ins=1.882, word_ins_ml=10.838, word_reposition=0.704, ppl=10986, wps=6116.6, ups=3.69, wpb=1658.4, bsz=51.2, num_updates=39000, lr=0.000253185, gnorm=1.393, clip=1, loss_scale=1024, train_wall=27, wall=11491
2022-10-19 20:16:22 | INFO | train_inner | epoch 010:   3671 / 3937 loss=13.475, nll_loss=10.176, mask_ins=1.856, word_ins_ml=10.862, word_reposition=0.757, ppl=11382.6, wps=6363.8, ups=3.6, wpb=1769.3, bsz=54.6, num_updates=39100, lr=0.000252861, gnorm=1.028, clip=0, loss_scale=1024, train_wall=28, wall=11519
2022-10-19 20:16:49 | INFO | train_inner | epoch 010:   3771 / 3937 loss=13.476, nll_loss=10.164, mask_ins=1.864, word_ins_ml=10.851, word_reposition=0.761, ppl=11396.4, wps=6494.3, ups=3.64, wpb=1782.2, bsz=53.6, num_updates=39200, lr=0.000252538, gnorm=0.904, clip=0, loss_scale=1024, train_wall=27, wall=11546
2022-10-19 20:17:17 | INFO | train_inner | epoch 010:   3871 / 3937 loss=13.5, nll_loss=10.154, mask_ins=1.892, word_ins_ml=10.842, word_reposition=0.766, ppl=11588.1, wps=6285.4, ups=3.63, wpb=1730.3, bsz=52.3, num_updates=39300, lr=0.000252217, gnorm=1.008, clip=0, loss_scale=1024, train_wall=27, wall=11574
2022-10-19 20:17:35 | INFO | train | epoch 010 | loss 13.485 | nll_loss 10.158 | mask_ins 1.89 | word_ins_ml 10.846 | word_reposition 0.749 | ppl 11464.5 | wps 5801.8 | ups 3.42 | wpb 1696.2 | bsz 51.5 | num_updates 39366 | lr 0.000252005 | gnorm 1.082 | clip 0.1 | loss_scale 841 | train_wall 1119 | wall 11592
2022-10-19 20:17:46 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 32.737 | nll_loss 19.777 | mask_ins 11.338 | word_ins_ml 19.321 | word_reposition 2.077 | ppl 7.15627e+09 | wps 27770.2 | wpb 1503.2 | bsz 51.5 | num_updates 39366 | best_loss 14.267
2022-10-19 20:17:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 10 @ 39366 updates, score 32.737) (writing took 2.8445033179596066 seconds)
2022-10-19 20:17:58 | INFO | train_inner | epoch 011:     34 / 3937 loss=13.509, nll_loss=10.161, mask_ins=1.909, word_ins_ml=10.848, word_reposition=0.751, ppl=11657.6, wps=4038.2, ups=2.41, wpb=1674.9, bsz=51.6, num_updates=39400, lr=0.000251896, gnorm=0.969, clip=0, loss_scale=1024, train_wall=27, wall=11615
2022-10-19 20:18:26 | INFO | train_inner | epoch 011:    134 / 3937 loss=13.455, nll_loss=10.143, mask_ins=1.901, word_ins_ml=10.832, word_reposition=0.723, ppl=11229.6, wps=6277.7, ups=3.66, wpb=1715, bsz=53.4, num_updates=39500, lr=0.000251577, gnorm=0.895, clip=0, loss_scale=1024, train_wall=27, wall=11643
2022-10-19 20:18:53 | INFO | train_inner | epoch 011:    234 / 3937 loss=13.476, nll_loss=10.157, mask_ins=1.877, word_ins_ml=10.845, word_reposition=0.754, ppl=11393.8, wps=6195.7, ups=3.68, wpb=1683.3, bsz=50.6, num_updates=39600, lr=0.000251259, gnorm=1.151, clip=0, loss_scale=1024, train_wall=27, wall=11670
2022-10-19 20:19:20 | INFO | train_inner | epoch 011:    334 / 3937 loss=13.439, nll_loss=10.163, mask_ins=1.855, word_ins_ml=10.85, word_reposition=0.733, ppl=11105.3, wps=6057.4, ups=3.64, wpb=1662.2, bsz=50.3, num_updates=39700, lr=0.000250943, gnorm=1.017, clip=0, loss_scale=1024, train_wall=27, wall=11697
2022-10-19 20:19:47 | INFO | train_inner | epoch 011:    434 / 3937 loss=13.434, nll_loss=10.15, mask_ins=1.873, word_ins_ml=10.84, word_reposition=0.721, ppl=11063.9, wps=6014, ups=3.69, wpb=1629.2, bsz=48.8, num_updates=39800, lr=0.000250627, gnorm=0.924, clip=0, loss_scale=1024, train_wall=27, wall=11724
2022-10-19 20:20:15 | INFO | train_inner | epoch 011:    534 / 3937 loss=13.446, nll_loss=10.161, mask_ins=1.865, word_ins_ml=10.847, word_reposition=0.734, ppl=11159.4, wps=6442.4, ups=3.64, wpb=1771.7, bsz=54.4, num_updates=39900, lr=0.000250313, gnorm=0.871, clip=0, loss_scale=1024, train_wall=27, wall=11752
2022-10-19 20:20:42 | INFO | train_inner | epoch 011:    634 / 3937 loss=13.427, nll_loss=10.15, mask_ins=1.851, word_ins_ml=10.839, word_reposition=0.738, ppl=11016.1, wps=6012, ups=3.68, wpb=1631.6, bsz=49, num_updates=40000, lr=0.00025, gnorm=0.955, clip=0, loss_scale=1024, train_wall=27, wall=11779
2022-10-19 20:21:09 | INFO | train_inner | epoch 011:    734 / 3937 loss=13.46, nll_loss=10.168, mask_ins=1.879, word_ins_ml=10.856, word_reposition=0.726, ppl=11270.2, wps=6284.3, ups=3.69, wpb=1704, bsz=51.1, num_updates=40100, lr=0.000249688, gnorm=0.948, clip=0, loss_scale=1024, train_wall=27, wall=11806
2022-10-19 20:21:36 | INFO | train_inner | epoch 011:    834 / 3937 loss=13.519, nll_loss=10.157, mask_ins=1.914, word_ins_ml=10.845, word_reposition=0.76, ppl=11736.6, wps=6150.9, ups=3.67, wpb=1674.1, bsz=50.9, num_updates=40200, lr=0.000249377, gnorm=1.12, clip=0, loss_scale=1024, train_wall=27, wall=11833
2022-10-19 20:22:04 | INFO | train_inner | epoch 011:    934 / 3937 loss=13.445, nll_loss=10.154, mask_ins=1.849, word_ins_ml=10.843, word_reposition=0.754, ppl=11153.8, wps=5872.6, ups=3.66, wpb=1606.1, bsz=48, num_updates=40300, lr=0.000249068, gnorm=1.011, clip=0, loss_scale=1024, train_wall=27, wall=11861
2022-10-19 20:22:31 | INFO | train_inner | epoch 011:   1034 / 3937 loss=13.485, nll_loss=10.159, mask_ins=1.885, word_ins_ml=10.847, word_reposition=0.752, ppl=11462.7, wps=6146.2, ups=3.69, wpb=1665.4, bsz=50, num_updates=40400, lr=0.000248759, gnorm=0.974, clip=0, loss_scale=1024, train_wall=27, wall=11888
2022-10-19 20:22:58 | INFO | train_inner | epoch 011:   1134 / 3937 loss=13.48, nll_loss=10.182, mask_ins=1.863, word_ins_ml=10.868, word_reposition=0.749, ppl=11423.6, wps=6331.7, ups=3.68, wpb=1718.8, bsz=53.7, num_updates=40500, lr=0.000248452, gnorm=1.217, clip=0, loss_scale=1024, train_wall=27, wall=11915
2022-10-19 20:23:25 | INFO | train_inner | epoch 011:   1234 / 3937 loss=13.483, nll_loss=10.149, mask_ins=1.897, word_ins_ml=10.839, word_reposition=0.748, ppl=11451.3, wps=5841.9, ups=3.66, wpb=1594.4, bsz=49.2, num_updates=40600, lr=0.000248146, gnorm=0.909, clip=0, loss_scale=1024, train_wall=27, wall=11942
2022-10-19 20:23:52 | INFO | train_inner | epoch 011:   1334 / 3937 loss=13.457, nll_loss=10.156, mask_ins=1.869, word_ins_ml=10.844, word_reposition=0.744, ppl=11241.2, wps=6114.4, ups=3.68, wpb=1662.3, bsz=49.6, num_updates=40700, lr=0.000247841, gnorm=0.949, clip=0, loss_scale=1024, train_wall=27, wall=11969
2022-10-19 20:24:20 | INFO | train_inner | epoch 011:   1434 / 3937 loss=13.49, nll_loss=10.153, mask_ins=1.91, word_ins_ml=10.843, word_reposition=0.737, ppl=11505.3, wps=6342.3, ups=3.69, wpb=1719.3, bsz=51.6, num_updates=40800, lr=0.000247537, gnorm=0.969, clip=0, loss_scale=1024, train_wall=27, wall=11996
2022-10-19 20:24:47 | INFO | train_inner | epoch 011:   1534 / 3937 loss=13.511, nll_loss=10.176, mask_ins=1.9, word_ins_ml=10.862, word_reposition=0.75, ppl=11677.6, wps=6382.1, ups=3.64, wpb=1752.9, bsz=53.2, num_updates=40900, lr=0.000247234, gnorm=0.95, clip=0, loss_scale=1024, train_wall=27, wall=12024
2022-10-19 20:25:14 | INFO | train_inner | epoch 011:   1634 / 3937 loss=13.467, nll_loss=10.165, mask_ins=1.901, word_ins_ml=10.851, word_reposition=0.715, ppl=11325.3, wps=6105.6, ups=3.68, wpb=1657.8, bsz=50.5, num_updates=41000, lr=0.000246932, gnorm=0.951, clip=0, loss_scale=1720, train_wall=27, wall=12051
2022-10-19 20:25:41 | INFO | train_inner | epoch 011:   1734 / 3937 loss=13.456, nll_loss=10.179, mask_ins=1.83, word_ins_ml=10.864, word_reposition=0.762, ppl=11236, wps=6080.9, ups=3.68, wpb=1652.4, bsz=49.6, num_updates=41100, lr=0.000246632, gnorm=1.131, clip=0, loss_scale=2048, train_wall=27, wall=12078
2022-10-19 20:26:09 | INFO | train_inner | epoch 011:   1834 / 3937 loss=13.465, nll_loss=10.145, mask_ins=1.874, word_ins_ml=10.835, word_reposition=0.756, ppl=11308.4, wps=6067.4, ups=3.68, wpb=1646.8, bsz=49.4, num_updates=41200, lr=0.000246332, gnorm=1.312, clip=0, loss_scale=2048, train_wall=27, wall=12105
2022-10-19 20:26:36 | INFO | train_inner | epoch 011:   1934 / 3937 loss=13.397, nll_loss=10.181, mask_ins=1.801, word_ins_ml=10.866, word_reposition=0.73, ppl=10788.3, wps=6225.9, ups=3.67, wpb=1695.5, bsz=51.7, num_updates=41300, lr=0.000246034, gnorm=0.965, clip=0, loss_scale=2048, train_wall=27, wall=12133
2022-10-19 20:27:03 | INFO | train_inner | epoch 011:   2034 / 3937 loss=13.458, nll_loss=10.173, mask_ins=1.863, word_ins_ml=10.859, word_reposition=0.737, ppl=11256.5, wps=6578.7, ups=3.68, wpb=1788.2, bsz=54.3, num_updates=41400, lr=0.000245737, gnorm=0.972, clip=0, loss_scale=2048, train_wall=27, wall=12160
2022-10-19 20:27:30 | INFO | train_inner | epoch 011:   2134 / 3937 loss=13.473, nll_loss=10.192, mask_ins=1.848, word_ins_ml=10.876, word_reposition=0.75, ppl=11372, wps=5983.3, ups=3.69, wpb=1620.1, bsz=49.3, num_updates=41500, lr=0.00024544, gnorm=0.887, clip=0, loss_scale=2048, train_wall=27, wall=12187
2022-10-19 20:27:57 | INFO | train_inner | epoch 011:   2234 / 3937 loss=13.541, nll_loss=10.183, mask_ins=1.925, word_ins_ml=10.867, word_reposition=0.749, ppl=11918.2, wps=6249.6, ups=3.66, wpb=1709.8, bsz=51.4, num_updates=41600, lr=0.000245145, gnorm=0.911, clip=0, loss_scale=2048, train_wall=27, wall=12214
2022-10-19 20:28:25 | INFO | train_inner | epoch 011:   2334 / 3937 loss=13.526, nll_loss=10.195, mask_ins=1.896, word_ins_ml=10.879, word_reposition=0.751, ppl=11798, wps=5944.9, ups=3.66, wpb=1625.1, bsz=48.5, num_updates=41700, lr=0.000244851, gnorm=0.883, clip=0, loss_scale=2048, train_wall=27, wall=12242
2022-10-19 20:28:52 | INFO | train_inner | epoch 011:   2434 / 3937 loss=13.432, nll_loss=10.129, mask_ins=1.873, word_ins_ml=10.821, word_reposition=0.738, ppl=11055.3, wps=6446.4, ups=3.73, wpb=1730.4, bsz=52.3, num_updates=41800, lr=0.000244558, gnorm=0.916, clip=0, loss_scale=2048, train_wall=27, wall=12268
2022-10-19 20:29:18 | INFO | train_inner | epoch 011:   2534 / 3937 loss=13.496, nll_loss=10.195, mask_ins=1.872, word_ins_ml=10.877, word_reposition=0.747, ppl=11552, wps=5662.2, ups=3.71, wpb=1525, bsz=45.5, num_updates=41900, lr=0.000244266, gnorm=1.056, clip=0, loss_scale=2048, train_wall=27, wall=12295
2022-10-19 20:29:46 | INFO | train_inner | epoch 011:   2634 / 3937 loss=13.447, nll_loss=10.12, mask_ins=1.885, word_ins_ml=10.814, word_reposition=0.748, ppl=11167.9, wps=6267.2, ups=3.69, wpb=1699.9, bsz=52.3, num_updates=42000, lr=0.000243975, gnorm=1.074, clip=0, loss_scale=2048, train_wall=27, wall=12322
2022-10-19 20:30:13 | INFO | train_inner | epoch 011:   2734 / 3937 loss=13.504, nll_loss=10.155, mask_ins=1.898, word_ins_ml=10.843, word_reposition=0.763, ppl=11616.7, wps=6276.2, ups=3.67, wpb=1708.8, bsz=51.3, num_updates=42100, lr=0.000243685, gnorm=0.859, clip=0, loss_scale=2048, train_wall=27, wall=12350
2022-10-19 20:30:40 | INFO | train_inner | epoch 011:   2834 / 3937 loss=13.464, nll_loss=10.148, mask_ins=1.899, word_ins_ml=10.837, word_reposition=0.728, ppl=11300.5, wps=6468.1, ups=3.66, wpb=1769.6, bsz=54.7, num_updates=42200, lr=0.000243396, gnorm=1.011, clip=0, loss_scale=2048, train_wall=27, wall=12377
2022-10-19 20:31:07 | INFO | train_inner | epoch 011:   2934 / 3937 loss=13.492, nll_loss=10.149, mask_ins=1.896, word_ins_ml=10.838, word_reposition=0.757, ppl=11520.6, wps=6178.6, ups=3.72, wpb=1661, bsz=50.1, num_updates=42300, lr=0.000243108, gnorm=1.093, clip=0, loss_scale=2048, train_wall=27, wall=12404
2022-10-19 20:31:34 | INFO | train_inner | epoch 011:   3034 / 3937 loss=13.467, nll_loss=10.13, mask_ins=1.914, word_ins_ml=10.821, word_reposition=0.731, ppl=11319.9, wps=6497.7, ups=3.67, wpb=1770.6, bsz=54.7, num_updates=42400, lr=0.000242821, gnorm=0.911, clip=0, loss_scale=2048, train_wall=27, wall=12431
2022-10-19 20:32:02 | INFO | train_inner | epoch 011:   3134 / 3937 loss=13.443, nll_loss=10.141, mask_ins=1.876, word_ins_ml=10.831, word_reposition=0.737, ppl=11139, wps=6300.5, ups=3.66, wpb=1723.6, bsz=52.8, num_updates=42500, lr=0.000242536, gnorm=0.985, clip=0, loss_scale=2048, train_wall=27, wall=12459
2022-10-19 20:32:29 | INFO | train_inner | epoch 011:   3234 / 3937 loss=13.408, nll_loss=10.156, mask_ins=1.844, word_ins_ml=10.843, word_reposition=0.721, ppl=10866.5, wps=6685.4, ups=3.7, wpb=1806.8, bsz=55, num_updates=42600, lr=0.000242251, gnorm=0.94, clip=0, loss_scale=2048, train_wall=27, wall=12486
2022-10-19 20:32:56 | INFO | train_inner | epoch 011:   3334 / 3937 loss=13.48, nll_loss=10.156, mask_ins=1.895, word_ins_ml=10.844, word_reposition=0.741, ppl=11425.6, wps=6327.8, ups=3.64, wpb=1740.1, bsz=53.7, num_updates=42700, lr=0.000241967, gnorm=1.043, clip=0, loss_scale=2048, train_wall=27, wall=12513
2022-10-19 20:33:23 | INFO | train_inner | epoch 011:   3434 / 3937 loss=13.445, nll_loss=10.166, mask_ins=1.855, word_ins_ml=10.853, word_reposition=0.737, ppl=11155.2, wps=6241.8, ups=3.73, wpb=1675, bsz=50.3, num_updates=42800, lr=0.000241684, gnorm=0.917, clip=0, loss_scale=2048, train_wall=27, wall=12540
2022-10-19 20:33:50 | INFO | train_inner | epoch 011:   3534 / 3937 loss=13.46, nll_loss=10.166, mask_ins=1.883, word_ins_ml=10.852, word_reposition=0.725, ppl=11271.4, wps=6480.1, ups=3.68, wpb=1762.9, bsz=54.7, num_updates=42900, lr=0.000241402, gnorm=1.023, clip=0, loss_scale=2048, train_wall=27, wall=12567
2022-10-19 20:34:18 | INFO | train_inner | epoch 011:   3634 / 3937 loss=13.503, nll_loss=10.162, mask_ins=1.903, word_ins_ml=10.849, word_reposition=0.751, ppl=11607.1, wps=6460.8, ups=3.63, wpb=1780, bsz=55, num_updates=43000, lr=0.000241121, gnorm=0.926, clip=0, loss_scale=2048, train_wall=27, wall=12595
2022-10-19 20:34:45 | INFO | train_inner | epoch 011:   3734 / 3937 loss=13.547, nll_loss=10.233, mask_ins=1.857, word_ins_ml=10.91, word_reposition=0.781, ppl=11971.1, wps=6198.4, ups=3.7, wpb=1676.6, bsz=49.6, num_updates=43100, lr=0.000240842, gnorm=0.935, clip=0, loss_scale=2048, train_wall=27, wall=12622
2022-10-19 20:35:12 | INFO | train_inner | epoch 011:   3834 / 3937 loss=13.464, nll_loss=10.156, mask_ins=1.887, word_ins_ml=10.844, word_reposition=0.734, ppl=11302, wps=6499.5, ups=3.71, wpb=1750.4, bsz=53.8, num_updates=43200, lr=0.000240563, gnorm=0.993, clip=0, loss_scale=2048, train_wall=27, wall=12649
2022-10-19 20:35:39 | INFO | train_inner | epoch 011:   3934 / 3937 loss=13.462, nll_loss=10.146, mask_ins=1.887, word_ins_ml=10.834, word_reposition=0.741, ppl=11286.8, wps=6637.4, ups=3.67, wpb=1806.7, bsz=54.9, num_updates=43300, lr=0.000240285, gnorm=0.93, clip=0, loss_scale=2048, train_wall=27, wall=12676
2022-10-19 20:35:40 | INFO | train | epoch 011 | loss 13.47 | nll_loss 10.162 | mask_ins 1.878 | word_ins_ml 10.849 | word_reposition 0.742 | ppl 11343.4 | wps 6154.9 | ups 3.63 | wpb 1696.2 | bsz 51.5 | num_updates 43303 | lr 0.000240276 | gnorm 0.985 | clip 0 | loss_scale 1641 | train_wall 1061 | wall 12677
2022-10-19 20:35:51 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 27.04 | nll_loss 17.171 | mask_ins 7.357 | word_ins_ml 16.953 | word_reposition 2.73 | ppl 1.37948e+08 | wps 27728.8 | wpb 1503.2 | bsz 51.5 | num_updates 43303 | best_loss 14.267
2022-10-19 20:35:54 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 11 @ 43303 updates, score 27.04) (writing took 2.813424119958654 seconds)
2022-10-19 20:36:21 | INFO | train_inner | epoch 012:     97 / 3937 loss=13.463, nll_loss=10.162, mask_ins=1.863, word_ins_ml=10.849, word_reposition=0.752, ppl=11294, wps=3830.9, ups=2.41, wpb=1591.2, bsz=47.9, num_updates=43400, lr=0.000240008, gnorm=1.061, clip=0, loss_scale=2048, train_wall=27, wall=12717
2022-10-19 20:36:48 | INFO | train_inner | epoch 012:    197 / 3937 loss=13.468, nll_loss=10.173, mask_ins=1.866, word_ins_ml=10.858, word_reposition=0.743, ppl=11327.4, wps=6246.9, ups=3.7, wpb=1689.5, bsz=50.2, num_updates=43500, lr=0.000239732, gnorm=0.907, clip=0, loss_scale=2048, train_wall=27, wall=12744
2022-10-19 20:37:15 | INFO | train_inner | epoch 012:    297 / 3937 loss=13.397, nll_loss=10.165, mask_ins=1.799, word_ins_ml=10.852, word_reposition=0.746, ppl=10786.3, wps=6256.1, ups=3.68, wpb=1698.2, bsz=51.6, num_updates=43600, lr=0.000239457, gnorm=0.861, clip=0, loss_scale=2048, train_wall=27, wall=12772
2022-10-19 20:37:42 | INFO | train_inner | epoch 012:    397 / 3937 loss=13.457, nll_loss=10.145, mask_ins=1.885, word_ins_ml=10.834, word_reposition=0.738, ppl=11241.5, wps=6217.1, ups=3.62, wpb=1717.6, bsz=52.3, num_updates=43700, lr=0.000239182, gnorm=0.975, clip=0, loss_scale=2048, train_wall=27, wall=12799
2022-10-19 20:38:10 | INFO | train_inner | epoch 012:    497 / 3937 loss=13.449, nll_loss=10.17, mask_ins=1.868, word_ins_ml=10.855, word_reposition=0.727, ppl=11185, wps=6442.5, ups=3.68, wpb=1749, bsz=54, num_updates=43800, lr=0.000238909, gnorm=1.036, clip=0, loss_scale=2048, train_wall=27, wall=12826
2022-10-19 20:38:37 | INFO | train_inner | epoch 012:    597 / 3937 loss=13.5, nll_loss=10.159, mask_ins=1.874, word_ins_ml=10.847, word_reposition=0.779, ppl=11584, wps=6178.4, ups=3.68, wpb=1677.5, bsz=50.8, num_updates=43900, lr=0.000238637, gnorm=1.033, clip=0, loss_scale=2048, train_wall=27, wall=12854
2022-10-19 20:39:04 | INFO | train_inner | epoch 012:    697 / 3937 loss=13.429, nll_loss=10.15, mask_ins=1.861, word_ins_ml=10.838, word_reposition=0.731, ppl=11032, wps=6224.9, ups=3.65, wpb=1703.2, bsz=51.4, num_updates=44000, lr=0.000238366, gnorm=0.9, clip=0, loss_scale=2048, train_wall=27, wall=12881
2022-10-19 20:39:31 | INFO | train_inner | epoch 012:    797 / 3937 loss=13.434, nll_loss=10.137, mask_ins=1.874, word_ins_ml=10.827, word_reposition=0.733, ppl=11063.5, wps=6770.7, ups=3.67, wpb=1847.2, bsz=56.3, num_updates=44100, lr=0.000238095, gnorm=0.942, clip=0, loss_scale=2048, train_wall=27, wall=12908
2022-10-19 20:39:58 | INFO | train_inner | epoch 012:    897 / 3937 loss=13.502, nll_loss=10.174, mask_ins=1.879, word_ins_ml=10.859, word_reposition=0.765, ppl=11602.1, wps=5695.7, ups=3.69, wpb=1543.9, bsz=45.2, num_updates=44200, lr=0.000237826, gnorm=0.972, clip=0, loss_scale=2048, train_wall=27, wall=12935
2022-10-19 20:40:25 | INFO | train_inner | epoch 012:    997 / 3937 loss=13.463, nll_loss=10.175, mask_ins=1.863, word_ins_ml=10.861, word_reposition=0.739, ppl=11290.1, wps=6188.1, ups=3.71, wpb=1667.9, bsz=51, num_updates=44300, lr=0.000237557, gnorm=0.92, clip=0, loss_scale=2048, train_wall=27, wall=12962
2022-10-19 20:40:53 | INFO | train_inner | epoch 012:   1097 / 3937 loss=13.474, nll_loss=10.141, mask_ins=1.923, word_ins_ml=10.831, word_reposition=0.72, ppl=11382.2, wps=6784.8, ups=3.68, wpb=1846, bsz=56, num_updates=44400, lr=0.000237289, gnorm=0.993, clip=0, loss_scale=2048, train_wall=27, wall=12989
2022-10-19 20:41:20 | INFO | train_inner | epoch 012:   1197 / 3937 loss=13.488, nll_loss=10.156, mask_ins=1.888, word_ins_ml=10.843, word_reposition=0.757, ppl=11489.2, wps=6373.5, ups=3.66, wpb=1741.3, bsz=52.3, num_updates=44500, lr=0.000237023, gnorm=0.994, clip=0, loss_scale=2048, train_wall=27, wall=13017
2022-10-19 20:41:47 | INFO | train_inner | epoch 012:   1297 / 3937 loss=13.475, nll_loss=10.185, mask_ins=1.857, word_ins_ml=10.869, word_reposition=0.75, ppl=11388.2, wps=5881.8, ups=3.71, wpb=1584.2, bsz=47, num_updates=44600, lr=0.000236757, gnorm=0.968, clip=0, loss_scale=2048, train_wall=27, wall=13044
2022-10-19 20:42:14 | INFO | train_inner | epoch 012:   1397 / 3937 loss=13.52, nll_loss=10.177, mask_ins=1.933, word_ins_ml=10.862, word_reposition=0.725, ppl=11750.4, wps=6130.4, ups=3.69, wpb=1659.4, bsz=50.5, num_updates=44700, lr=0.000236492, gnorm=0.895, clip=0, loss_scale=2048, train_wall=27, wall=13071
2022-10-19 20:42:41 | INFO | train_inner | epoch 012:   1497 / 3937 loss=13.447, nll_loss=10.163, mask_ins=1.85, word_ins_ml=10.851, word_reposition=0.745, ppl=11164.4, wps=6581.6, ups=3.68, wpb=1786.6, bsz=54.2, num_updates=44800, lr=0.000236228, gnorm=0.942, clip=0, loss_scale=2048, train_wall=27, wall=13098
2022-10-19 20:43:08 | INFO | train_inner | epoch 012:   1597 / 3937 loss=13.45, nll_loss=10.155, mask_ins=1.872, word_ins_ml=10.843, word_reposition=0.734, ppl=11188.2, wps=6267.8, ups=3.66, wpb=1712.7, bsz=52.5, num_updates=44900, lr=0.000235965, gnorm=1.031, clip=0, loss_scale=2048, train_wall=27, wall=13125
2022-10-19 20:43:36 | INFO | train_inner | epoch 012:   1697 / 3937 loss=13.492, nll_loss=10.149, mask_ins=1.901, word_ins_ml=10.837, word_reposition=0.754, ppl=11517.9, wps=6100.3, ups=3.67, wpb=1661.3, bsz=49.5, num_updates=45000, lr=0.000235702, gnorm=0.953, clip=0, loss_scale=2048, train_wall=27, wall=13152
2022-10-19 20:44:03 | INFO | train_inner | epoch 012:   1797 / 3937 loss=13.511, nll_loss=10.159, mask_ins=1.897, word_ins_ml=10.846, word_reposition=0.767, ppl=11671.9, wps=6114.4, ups=3.68, wpb=1661.7, bsz=49.9, num_updates=45100, lr=0.000235441, gnorm=0.901, clip=0, loss_scale=3523, train_wall=27, wall=13180
2022-10-19 20:44:30 | INFO | train_inner | epoch 012:   1897 / 3937 loss=13.502, nll_loss=10.169, mask_ins=1.914, word_ins_ml=10.856, word_reposition=0.732, ppl=11602.4, wps=5806.5, ups=3.69, wpb=1572.3, bsz=46.8, num_updates=45200, lr=0.00023518, gnorm=0.944, clip=0, loss_scale=4096, train_wall=27, wall=13207
2022-10-19 20:44:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-10-19 20:44:57 | INFO | train_inner | epoch 012:   1998 / 3937 loss=13.432, nll_loss=10.167, mask_ins=1.842, word_ins_ml=10.853, word_reposition=0.736, ppl=11048.8, wps=6404.8, ups=3.63, wpb=1763.9, bsz=53.3, num_updates=45300, lr=0.00023492, gnorm=1.163, clip=0, loss_scale=2819, train_wall=27, wall=13234
2022-10-19 20:45:25 | INFO | train_inner | epoch 012:   2098 / 3937 loss=13.459, nll_loss=10.166, mask_ins=1.882, word_ins_ml=10.853, word_reposition=0.724, ppl=11258.1, wps=6712.7, ups=3.63, wpb=1847, bsz=56.6, num_updates=45400, lr=0.000234662, gnorm=0.872, clip=0, loss_scale=2048, train_wall=27, wall=13262
2022-10-19 20:45:52 | INFO | train_inner | epoch 012:   2198 / 3937 loss=13.396, nll_loss=10.151, mask_ins=1.815, word_ins_ml=10.84, word_reposition=0.741, ppl=10781.5, wps=6990.2, ups=3.64, wpb=1920, bsz=58.4, num_updates=45500, lr=0.000234404, gnorm=0.881, clip=0, loss_scale=2048, train_wall=27, wall=13289
2022-10-19 20:46:20 | INFO | train_inner | epoch 012:   2298 / 3937 loss=13.441, nll_loss=10.141, mask_ins=1.889, word_ins_ml=10.83, word_reposition=0.722, ppl=11122.4, wps=6710, ups=3.64, wpb=1841.9, bsz=57.7, num_updates=45600, lr=0.000234146, gnorm=0.897, clip=0, loss_scale=2048, train_wall=27, wall=13317
2022-10-19 20:46:47 | INFO | train_inner | epoch 012:   2398 / 3937 loss=13.471, nll_loss=10.163, mask_ins=1.884, word_ins_ml=10.85, word_reposition=0.737, ppl=11357.2, wps=5771.6, ups=3.69, wpb=1562.6, bsz=46.9, num_updates=45700, lr=0.00023389, gnorm=0.909, clip=0, loss_scale=2048, train_wall=27, wall=13344
2022-10-19 20:47:14 | INFO | train_inner | epoch 012:   2498 / 3937 loss=13.496, nll_loss=10.156, mask_ins=1.88, word_ins_ml=10.844, word_reposition=0.772, ppl=11550.8, wps=6389.7, ups=3.65, wpb=1749.8, bsz=53, num_updates=45800, lr=0.000233635, gnorm=1.009, clip=0, loss_scale=2048, train_wall=27, wall=13371
2022-10-19 20:47:42 | INFO | train_inner | epoch 012:   2598 / 3937 loss=13.516, nll_loss=10.164, mask_ins=1.91, word_ins_ml=10.849, word_reposition=0.756, ppl=11712.1, wps=5963.2, ups=3.66, wpb=1628.6, bsz=49.9, num_updates=45900, lr=0.00023338, gnorm=1.083, clip=0, loss_scale=2048, train_wall=27, wall=13398
2022-10-19 20:48:09 | INFO | train_inner | epoch 012:   2698 / 3937 loss=13.467, nll_loss=10.142, mask_ins=1.885, word_ins_ml=10.833, word_reposition=0.75, ppl=11326.3, wps=6616.7, ups=3.64, wpb=1818.1, bsz=56, num_updates=46000, lr=0.000233126, gnorm=0.968, clip=0, loss_scale=2048, train_wall=27, wall=13426
2022-10-19 20:48:36 | INFO | train_inner | epoch 012:   2798 / 3937 loss=13.428, nll_loss=10.122, mask_ins=1.873, word_ins_ml=10.814, word_reposition=0.741, ppl=11019.1, wps=5945.6, ups=3.67, wpb=1619.7, bsz=50, num_updates=46100, lr=0.000232873, gnorm=0.927, clip=0, loss_scale=2048, train_wall=27, wall=13453
2022-10-19 20:49:03 | INFO | train_inner | epoch 012:   2898 / 3937 loss=13.485, nll_loss=10.175, mask_ins=1.886, word_ins_ml=10.86, word_reposition=0.739, ppl=11463.4, wps=5807, ups=3.7, wpb=1567.8, bsz=48, num_updates=46200, lr=0.000232621, gnorm=0.947, clip=0, loss_scale=2048, train_wall=27, wall=13480
2022-10-19 20:49:30 | INFO | train_inner | epoch 012:   2998 / 3937 loss=13.438, nll_loss=10.163, mask_ins=1.858, word_ins_ml=10.85, word_reposition=0.731, ppl=11098.6, wps=6061.1, ups=3.69, wpb=1641.4, bsz=49.4, num_updates=46300, lr=0.00023237, gnorm=1.142, clip=0, loss_scale=2048, train_wall=27, wall=13507
2022-10-19 20:49:58 | INFO | train_inner | epoch 012:   3098 / 3937 loss=13.486, nll_loss=10.148, mask_ins=1.907, word_ins_ml=10.836, word_reposition=0.743, ppl=11475, wps=6016.6, ups=3.66, wpb=1642, bsz=50.4, num_updates=46400, lr=0.000232119, gnorm=1.004, clip=0, loss_scale=2048, train_wall=27, wall=13535
2022-10-19 20:50:26 | INFO | train_inner | epoch 012:   3198 / 3937 loss=13.383, nll_loss=10.134, mask_ins=1.799, word_ins_ml=10.825, word_reposition=0.759, ppl=10681.3, wps=6665.2, ups=3.59, wpb=1856.2, bsz=57.2, num_updates=46500, lr=0.000231869, gnorm=1.015, clip=0, loss_scale=2048, train_wall=28, wall=13562
2022-10-19 20:50:53 | INFO | train_inner | epoch 012:   3298 / 3937 loss=13.509, nll_loss=10.124, mask_ins=1.954, word_ins_ml=10.816, word_reposition=0.739, ppl=11661.2, wps=6082.7, ups=3.67, wpb=1659.3, bsz=50.6, num_updates=46600, lr=0.000231621, gnorm=1.003, clip=0, loss_scale=2048, train_wall=27, wall=13590
2022-10-19 20:51:20 | INFO | train_inner | epoch 012:   3398 / 3937 loss=13.396, nll_loss=10.11, mask_ins=1.859, word_ins_ml=10.804, word_reposition=0.733, ppl=10781.1, wps=5893.9, ups=3.68, wpb=1601, bsz=49.1, num_updates=46700, lr=0.000231372, gnorm=0.984, clip=0, loss_scale=2048, train_wall=27, wall=13617
2022-10-19 20:51:47 | INFO | train_inner | epoch 012:   3498 / 3937 loss=13.431, nll_loss=10.143, mask_ins=1.868, word_ins_ml=10.831, word_reposition=0.731, ppl=11040.8, wps=5660.6, ups=3.67, wpb=1542.8, bsz=46.8, num_updates=46800, lr=0.000231125, gnorm=0.93, clip=0, loss_scale=2048, train_wall=27, wall=13644
2022-10-19 20:52:15 | INFO | train_inner | epoch 012:   3598 / 3937 loss=13.447, nll_loss=10.146, mask_ins=1.862, word_ins_ml=10.835, word_reposition=0.75, ppl=11165.1, wps=6564, ups=3.67, wpb=1790.8, bsz=54.6, num_updates=46900, lr=0.000230879, gnorm=0.996, clip=0, loss_scale=2048, train_wall=27, wall=13671
2022-10-19 20:52:42 | INFO | train_inner | epoch 012:   3698 / 3937 loss=13.491, nll_loss=10.153, mask_ins=1.894, word_ins_ml=10.841, word_reposition=0.756, ppl=11511, wps=6137.9, ups=3.66, wpb=1675.6, bsz=50.2, num_updates=47000, lr=0.000230633, gnorm=0.98, clip=0, loss_scale=2048, train_wall=27, wall=13699
2022-10-19 20:53:09 | INFO | train_inner | epoch 012:   3798 / 3937 loss=13.494, nll_loss=10.139, mask_ins=1.935, word_ins_ml=10.829, word_reposition=0.73, ppl=11540.9, wps=6025.5, ups=3.68, wpb=1638.5, bsz=49.5, num_updates=47100, lr=0.000230388, gnorm=0.955, clip=0, loss_scale=2048, train_wall=27, wall=13726
2022-10-19 20:53:36 | INFO | train_inner | epoch 012:   3898 / 3937 loss=13.498, nll_loss=10.191, mask_ins=1.883, word_ins_ml=10.875, word_reposition=0.74, ppl=11571.1, wps=6082, ups=3.7, wpb=1642.8, bsz=49.6, num_updates=47200, lr=0.000230144, gnorm=0.979, clip=0, loss_scale=2048, train_wall=27, wall=13753
2022-10-19 20:53:47 | INFO | train | epoch 012 | loss 13.464 | nll_loss 10.156 | mask_ins 1.878 | word_ins_ml 10.843 | word_reposition 0.743 | ppl 11301.8 | wps 6142.2 | ups 3.62 | wpb 1696.2 | bsz 51.5 | num_updates 47239 | lr 0.000230049 | gnorm 0.971 | clip 0 | loss_scale 2157 | train_wall 1062 | wall 13764
2022-10-19 20:53:58 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 24.741 | nll_loss 16.284 | mask_ins 6.141 | word_ins_ml 16.144 | word_reposition 2.456 | ppl 2.80468e+07 | wps 27603.6 | wpb 1503.2 | bsz 51.5 | num_updates 47239 | best_loss 14.267
2022-10-19 20:54:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 12 @ 47239 updates, score 24.741) (writing took 3.0258559670764953 seconds)
2022-10-19 20:54:18 | INFO | train_inner | epoch 013:     61 / 3937 loss=13.448, nll_loss=10.159, mask_ins=1.871, word_ins_ml=10.846, word_reposition=0.731, ppl=11174.8, wps=3984.2, ups=2.38, wpb=1676.5, bsz=51.2, num_updates=47300, lr=0.0002299, gnorm=1.179, clip=0, loss_scale=2048, train_wall=27, wall=13795
2022-10-19 20:54:45 | INFO | train_inner | epoch 013:    161 / 3937 loss=13.549, nll_loss=10.156, mask_ins=1.947, word_ins_ml=10.844, word_reposition=0.758, ppl=11981.9, wps=6176.7, ups=3.69, wpb=1674.5, bsz=50.4, num_updates=47400, lr=0.000229658, gnorm=1.3, clip=0, loss_scale=2048, train_wall=27, wall=13822
2022-10-19 20:55:13 | INFO | train_inner | epoch 013:    261 / 3937 loss=13.514, nll_loss=10.152, mask_ins=1.927, word_ins_ml=10.84, word_reposition=0.747, ppl=11699.3, wps=6252.6, ups=3.66, wpb=1706.5, bsz=51.8, num_updates=47500, lr=0.000229416, gnorm=1.021, clip=0, loss_scale=2048, train_wall=27, wall=13849
2022-10-19 20:55:40 | INFO | train_inner | epoch 013:    361 / 3937 loss=13.476, nll_loss=10.126, mask_ins=1.911, word_ins_ml=10.817, word_reposition=0.749, ppl=11392.4, wps=6509.1, ups=3.63, wpb=1791.6, bsz=54.8, num_updates=47600, lr=0.000229175, gnorm=1.006, clip=0, loss_scale=2048, train_wall=27, wall=13877
2022-10-19 20:56:07 | INFO | train_inner | epoch 013:    461 / 3937 loss=13.412, nll_loss=10.154, mask_ins=1.826, word_ins_ml=10.842, word_reposition=0.744, ppl=10898.4, wps=6147.8, ups=3.67, wpb=1676, bsz=50.5, num_updates=47700, lr=0.000228934, gnorm=1.039, clip=0, loss_scale=2048, train_wall=27, wall=13904
2022-10-19 20:56:35 | INFO | train_inner | epoch 013:    561 / 3937 loss=13.505, nll_loss=10.133, mask_ins=1.913, word_ins_ml=10.824, word_reposition=0.769, ppl=11628.9, wps=6362.2, ups=3.67, wpb=1733.2, bsz=52.9, num_updates=47800, lr=0.000228695, gnorm=1.253, clip=0, loss_scale=2048, train_wall=27, wall=13931
2022-10-19 20:57:02 | INFO | train_inner | epoch 013:    661 / 3937 loss=13.485, nll_loss=10.128, mask_ins=1.914, word_ins_ml=10.819, word_reposition=0.751, ppl=11466.1, wps=6645.3, ups=3.66, wpb=1814.9, bsz=53.8, num_updates=47900, lr=0.000228456, gnorm=1.087, clip=0, loss_scale=2048, train_wall=27, wall=13959
2022-10-19 20:57:29 | INFO | train_inner | epoch 013:    761 / 3937 loss=13.529, nll_loss=10.191, mask_ins=1.904, word_ins_ml=10.874, word_reposition=0.751, ppl=11821.7, wps=6140.9, ups=3.67, wpb=1672.4, bsz=49.9, num_updates=48000, lr=0.000228218, gnorm=0.989, clip=0, loss_scale=2048, train_wall=27, wall=13986
2022-10-19 20:57:56 | INFO | train_inner | epoch 013:    861 / 3937 loss=13.427, nll_loss=10.133, mask_ins=1.879, word_ins_ml=10.824, word_reposition=0.723, ppl=11011.8, wps=5789.1, ups=3.68, wpb=1572.3, bsz=48.1, num_updates=48100, lr=0.00022798, gnorm=1.08, clip=0, loss_scale=2048, train_wall=27, wall=14013
2022-10-19 20:58:23 | INFO | train_inner | epoch 013:    961 / 3937 loss=13.429, nll_loss=10.135, mask_ins=1.873, word_ins_ml=10.826, word_reposition=0.731, ppl=11029.4, wps=6488.4, ups=3.7, wpb=1754.3, bsz=55.1, num_updates=48200, lr=0.000227744, gnorm=0.989, clip=0, loss_scale=2048, train_wall=27, wall=14040
2022-10-19 20:58:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-10-19 20:58:51 | INFO | train_inner | epoch 013:   1062 / 3937 loss=13.442, nll_loss=10.132, mask_ins=1.866, word_ins_ml=10.823, word_reposition=0.753, ppl=11127.6, wps=6418.8, ups=3.62, wpb=1772, bsz=54.1, num_updates=48300, lr=0.000227508, gnorm=1.446, clip=1, loss_scale=1653, train_wall=27, wall=14068
2022-10-19 20:59:18 | INFO | train_inner | epoch 013:   1162 / 3937 loss=13.441, nll_loss=10.161, mask_ins=1.853, word_ins_ml=10.848, word_reposition=0.74, ppl=11119.6, wps=5860.9, ups=3.68, wpb=1593, bsz=48.5, num_updates=48400, lr=0.000227273, gnorm=1.138, clip=0, loss_scale=1024, train_wall=27, wall=14095
2022-10-19 20:59:45 | INFO | train_inner | epoch 013:   1262 / 3937 loss=13.456, nll_loss=10.16, mask_ins=1.874, word_ins_ml=10.847, word_reposition=0.735, ppl=11237.5, wps=5732.1, ups=3.69, wpb=1553.5, bsz=46.2, num_updates=48500, lr=0.000227038, gnorm=1.02, clip=0, loss_scale=1024, train_wall=27, wall=14122
2022-10-19 21:00:13 | INFO | train_inner | epoch 013:   1362 / 3937 loss=13.467, nll_loss=10.148, mask_ins=1.888, word_ins_ml=10.838, word_reposition=0.742, ppl=11321, wps=6387.5, ups=3.66, wpb=1746.8, bsz=52.6, num_updates=48600, lr=0.000226805, gnorm=1.162, clip=0, loss_scale=1024, train_wall=27, wall=14149
2022-10-19 21:00:39 | INFO | train_inner | epoch 013:   1462 / 3937 loss=13.464, nll_loss=10.151, mask_ins=1.903, word_ins_ml=10.839, word_reposition=0.722, ppl=11297.8, wps=6068.8, ups=3.71, wpb=1633.9, bsz=49.6, num_updates=48700, lr=0.000226572, gnorm=0.998, clip=0, loss_scale=1024, train_wall=27, wall=14176
2022-10-19 21:01:07 | INFO | train_inner | epoch 013:   1562 / 3937 loss=13.471, nll_loss=10.152, mask_ins=1.862, word_ins_ml=10.84, word_reposition=0.769, ppl=11355.1, wps=6316, ups=3.63, wpb=1737.9, bsz=52.5, num_updates=48800, lr=0.000226339, gnorm=0.988, clip=0, loss_scale=1024, train_wall=27, wall=14204
2022-10-19 21:01:35 | INFO | train_inner | epoch 013:   1662 / 3937 loss=13.477, nll_loss=10.143, mask_ins=1.894, word_ins_ml=10.832, word_reposition=0.751, ppl=11398.9, wps=6388.9, ups=3.63, wpb=1760.8, bsz=53.2, num_updates=48900, lr=0.000226108, gnorm=1.14, clip=0, loss_scale=1024, train_wall=27, wall=14231
2022-10-19 21:02:02 | INFO | train_inner | epoch 013:   1762 / 3937 loss=13.398, nll_loss=10.12, mask_ins=1.852, word_ins_ml=10.813, word_reposition=0.733, ppl=10791.2, wps=5930.2, ups=3.66, wpb=1618.3, bsz=49.8, num_updates=49000, lr=0.000225877, gnorm=1.29, clip=0, loss_scale=1024, train_wall=27, wall=14259
2022-10-19 21:02:29 | INFO | train_inner | epoch 013:   1862 / 3937 loss=13.426, nll_loss=10.134, mask_ins=1.865, word_ins_ml=10.825, word_reposition=0.737, ppl=11003.9, wps=6497.9, ups=3.68, wpb=1764.5, bsz=53.7, num_updates=49100, lr=0.000225647, gnorm=0.966, clip=0, loss_scale=1024, train_wall=27, wall=14286
2022-10-19 21:02:56 | INFO | train_inner | epoch 013:   1962 / 3937 loss=13.386, nll_loss=10.134, mask_ins=1.818, word_ins_ml=10.825, word_reposition=0.743, ppl=10702.6, wps=6315.6, ups=3.7, wpb=1707.9, bsz=51.5, num_updates=49200, lr=0.000225417, gnorm=1.235, clip=0, loss_scale=1024, train_wall=27, wall=14313
2022-10-19 21:03:23 | INFO | train_inner | epoch 013:   2062 / 3937 loss=13.473, nll_loss=10.144, mask_ins=1.872, word_ins_ml=10.833, word_reposition=0.768, ppl=11368.6, wps=6558.4, ups=3.7, wpb=1772.6, bsz=53.7, num_updates=49300, lr=0.000225189, gnorm=1.663, clip=0, loss_scale=1024, train_wall=27, wall=14340
2022-10-19 21:03:50 | INFO | train_inner | epoch 013:   2162 / 3937 loss=13.414, nll_loss=10.116, mask_ins=1.845, word_ins_ml=10.809, word_reposition=0.76, ppl=10917.7, wps=6016.9, ups=3.66, wpb=1642, bsz=49.5, num_updates=49400, lr=0.000224961, gnorm=1.416, clip=0, loss_scale=1024, train_wall=27, wall=14367
2022-10-19 21:04:17 | INFO | train_inner | epoch 013:   2262 / 3937 loss=13.481, nll_loss=10.14, mask_ins=1.909, word_ins_ml=10.829, word_reposition=0.743, ppl=11433.4, wps=5804.2, ups=3.71, wpb=1564, bsz=47.6, num_updates=49500, lr=0.000224733, gnorm=1.15, clip=0, loss_scale=1024, train_wall=27, wall=14394
2022-10-19 21:04:45 | INFO | train_inner | epoch 013:   2362 / 3937 loss=13.446, nll_loss=10.149, mask_ins=1.882, word_ins_ml=10.837, word_reposition=0.728, ppl=11162, wps=6555.1, ups=3.66, wpb=1791.2, bsz=54.7, num_updates=49600, lr=0.000224507, gnorm=1.593, clip=0, loss_scale=1024, train_wall=27, wall=14421
2022-10-19 21:05:12 | INFO | train_inner | epoch 013:   2462 / 3937 loss=13.456, nll_loss=10.125, mask_ins=1.871, word_ins_ml=10.817, word_reposition=0.768, ppl=11234, wps=6457.6, ups=3.61, wpb=1789.5, bsz=55, num_updates=49700, lr=0.000224281, gnorm=1.385, clip=0, loss_scale=1024, train_wall=27, wall=14449
2022-10-19 21:05:39 | INFO | train_inner | epoch 013:   2562 / 3937 loss=13.469, nll_loss=10.13, mask_ins=1.875, word_ins_ml=10.822, word_reposition=0.772, ppl=11342, wps=6133.1, ups=3.71, wpb=1652.8, bsz=50.5, num_updates=49800, lr=0.000224055, gnorm=1.244, clip=0, loss_scale=1024, train_wall=27, wall=14476
2022-10-19 21:05:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-10-19 21:06:07 | INFO | train_inner | epoch 013:   2663 / 3937 loss=13.511, nll_loss=10.154, mask_ins=1.921, word_ins_ml=10.84, word_reposition=0.749, ppl=11674.9, wps=5934.5, ups=3.66, wpb=1619.9, bsz=48.8, num_updates=49900, lr=0.000223831, gnorm=1.803, clip=1, loss_scale=836, train_wall=27, wall=14503
2022-10-19 21:06:34 | INFO | train_inner | epoch 013:   2763 / 3937 loss=13.435, nll_loss=10.149, mask_ins=1.866, word_ins_ml=10.838, word_reposition=0.73, ppl=11073, wps=6255.6, ups=3.65, wpb=1712.7, bsz=53.2, num_updates=50000, lr=0.000223607, gnorm=1.096, clip=0, loss_scale=512, train_wall=27, wall=14531
2022-10-19 21:07:01 | INFO | train_inner | epoch 013:   2863 / 3937 loss=13.458, nll_loss=10.154, mask_ins=1.862, word_ins_ml=10.841, word_reposition=0.755, ppl=11254, wps=6300.4, ups=3.69, wpb=1707.3, bsz=52, num_updates=50100, lr=0.000223384, gnorm=1.615, clip=0, loss_scale=512, train_wall=27, wall=14558
2022-10-19 21:07:28 | INFO | train_inner | epoch 013:   2963 / 3937 loss=13.471, nll_loss=10.144, mask_ins=1.882, word_ins_ml=10.833, word_reposition=0.757, ppl=11358.2, wps=6427.3, ups=3.72, wpb=1728.8, bsz=51.5, num_updates=50200, lr=0.000223161, gnorm=1.488, clip=0, loss_scale=512, train_wall=27, wall=14585
2022-10-19 21:07:55 | INFO | train_inner | epoch 013:   3063 / 3937 loss=13.43, nll_loss=10.125, mask_ins=1.869, word_ins_ml=10.817, word_reposition=0.744, ppl=11039.5, wps=6332.1, ups=3.68, wpb=1719.9, bsz=51.7, num_updates=50300, lr=0.000222939, gnorm=1.126, clip=0, loss_scale=512, train_wall=27, wall=14612
2022-10-19 21:08:22 | INFO | train_inner | epoch 013:   3163 / 3937 loss=13.503, nll_loss=10.175, mask_ins=1.888, word_ins_ml=10.86, word_reposition=0.756, ppl=11611.4, wps=5843.7, ups=3.67, wpb=1590.4, bsz=47.9, num_updates=50400, lr=0.000222718, gnorm=1.037, clip=0, loss_scale=512, train_wall=27, wall=14639
2022-10-19 21:08:50 | INFO | train_inner | epoch 013:   3263 / 3937 loss=13.471, nll_loss=10.139, mask_ins=1.889, word_ins_ml=10.83, word_reposition=0.751, ppl=11354.2, wps=6046.1, ups=3.64, wpb=1658.8, bsz=50.6, num_updates=50500, lr=0.000222497, gnorm=1.328, clip=0, loss_scale=512, train_wall=27, wall=14667
2022-10-19 21:09:17 | INFO | train_inner | epoch 013:   3363 / 3937 loss=13.5, nll_loss=10.157, mask_ins=1.908, word_ins_ml=10.845, word_reposition=0.747, ppl=11587.6, wps=6065, ups=3.71, wpb=1635, bsz=49.3, num_updates=50600, lr=0.000222277, gnorm=1.055, clip=0, loss_scale=512, train_wall=27, wall=14694
2022-10-19 21:09:44 | INFO | train_inner | epoch 013:   3463 / 3937 loss=13.45, nll_loss=10.155, mask_ins=1.844, word_ins_ml=10.843, word_reposition=0.763, ppl=11189.8, wps=6666.5, ups=3.67, wpb=1816, bsz=55.4, num_updates=50700, lr=0.000222058, gnorm=0.946, clip=0, loss_scale=512, train_wall=27, wall=14721
2022-10-19 21:10:11 | INFO | train_inner | epoch 013:   3563 / 3937 loss=13.377, nll_loss=10.111, mask_ins=1.833, word_ins_ml=10.806, word_reposition=0.738, ppl=10638, wps=6090.8, ups=3.69, wpb=1652.4, bsz=51.1, num_updates=50800, lr=0.000221839, gnorm=1.42, clip=1, loss_scale=512, train_wall=27, wall=14748
2022-10-19 21:10:38 | INFO | train_inner | epoch 013:   3663 / 3937 loss=13.341, nll_loss=10.141, mask_ins=1.79, word_ins_ml=10.831, word_reposition=0.719, ppl=10376.1, wps=6146.5, ups=3.68, wpb=1670.3, bsz=51.2, num_updates=50900, lr=0.000221621, gnorm=1.173, clip=0, loss_scale=512, train_wall=27, wall=14775
2022-10-19 21:11:05 | INFO | train_inner | epoch 013:   3763 / 3937 loss=13.421, nll_loss=10.132, mask_ins=1.864, word_ins_ml=10.822, word_reposition=0.736, ppl=10969.5, wps=6490, ups=3.7, wpb=1752.3, bsz=53.2, num_updates=51000, lr=0.000221404, gnorm=1.075, clip=0, loss_scale=512, train_wall=27, wall=14802
2022-10-19 21:11:33 | INFO | train_inner | epoch 013:   3863 / 3937 loss=13.454, nll_loss=10.103, mask_ins=1.894, word_ins_ml=10.798, word_reposition=0.762, ppl=11225.4, wps=6374.9, ups=3.63, wpb=1754.3, bsz=53.8, num_updates=51100, lr=0.000221187, gnorm=1.052, clip=0, loss_scale=512, train_wall=27, wall=14830
2022-10-19 21:11:53 | INFO | train | epoch 013 | loss 13.454 | nll_loss 10.142 | mask_ins 1.877 | word_ins_ml 10.831 | word_reposition 0.747 | ppl 11224.9 | wps 6145.6 | ups 3.62 | wpb 1696.3 | bsz 51.5 | num_updates 51174 | lr 0.000221027 | gnorm 1.209 | clip 0.1 | loss_scale 1120 | train_wall 1061 | wall 14850
2022-10-19 21:12:04 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 27.239 | nll_loss 17.292 | mask_ins 7.804 | word_ins_ml 17.062 | word_reposition 2.373 | ppl 1.58394e+08 | wps 27828.9 | wpb 1503.2 | bsz 51.5 | num_updates 51174 | best_loss 14.267
2022-10-19 21:12:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 13 @ 51174 updates, score 27.239) (writing took 2.990408053039573 seconds)
2022-10-19 21:12:15 | INFO | train_inner | epoch 014:     26 / 3937 loss=13.442, nll_loss=10.12, mask_ins=1.904, word_ins_ml=10.812, word_reposition=0.726, ppl=11129.4, wps=4111.5, ups=2.4, wpb=1716.3, bsz=51.8, num_updates=51200, lr=0.000220971, gnorm=1.199, clip=1, loss_scale=512, train_wall=27, wall=14871
2022-10-19 21:12:42 | INFO | train_inner | epoch 014:    126 / 3937 loss=13.443, nll_loss=10.149, mask_ins=1.866, word_ins_ml=10.837, word_reposition=0.74, ppl=11139.2, wps=5770.7, ups=3.71, wpb=1555.2, bsz=46.5, num_updates=51300, lr=0.000220755, gnorm=1.019, clip=0, loss_scale=512, train_wall=27, wall=14898
2022-10-19 21:13:09 | INFO | train_inner | epoch 014:    226 / 3937 loss=13.485, nll_loss=10.127, mask_ins=1.91, word_ins_ml=10.818, word_reposition=0.757, ppl=11466.8, wps=6238.6, ups=3.69, wpb=1689.3, bsz=51.1, num_updates=51400, lr=0.000220541, gnorm=1.158, clip=0, loss_scale=512, train_wall=27, wall=14925
2022-10-19 21:13:36 | INFO | train_inner | epoch 014:    326 / 3937 loss=13.444, nll_loss=10.144, mask_ins=1.88, word_ins_ml=10.832, word_reposition=0.732, ppl=11145.7, wps=6718.6, ups=3.69, wpb=1823, bsz=56.7, num_updates=51500, lr=0.000220326, gnorm=1.089, clip=0, loss_scale=512, train_wall=27, wall=14953
2022-10-19 21:14:03 | INFO | train_inner | epoch 014:    426 / 3937 loss=13.466, nll_loss=10.118, mask_ins=1.899, word_ins_ml=10.811, word_reposition=0.756, ppl=11314.8, wps=6443.9, ups=3.71, wpb=1737, bsz=51.9, num_updates=51600, lr=0.000220113, gnorm=1.198, clip=0, loss_scale=512, train_wall=27, wall=14980
2022-10-19 21:14:30 | INFO | train_inner | epoch 014:    526 / 3937 loss=13.45, nll_loss=10.12, mask_ins=1.874, word_ins_ml=10.812, word_reposition=0.764, ppl=11190, wps=6020.8, ups=3.69, wpb=1633.4, bsz=50, num_updates=51700, lr=0.0002199, gnorm=1.382, clip=0, loss_scale=512, train_wall=27, wall=15007
2022-10-19 21:14:57 | INFO | train_inner | epoch 014:    626 / 3937 loss=13.412, nll_loss=10.099, mask_ins=1.867, word_ins_ml=10.796, word_reposition=0.749, ppl=10900.5, wps=6814.3, ups=3.64, wpb=1873.7, bsz=58, num_updates=51800, lr=0.000219687, gnorm=1.22, clip=0, loss_scale=512, train_wall=27, wall=15034
2022-10-19 21:15:24 | INFO | train_inner | epoch 014:    726 / 3937 loss=13.45, nll_loss=10.132, mask_ins=1.887, word_ins_ml=10.823, word_reposition=0.74, ppl=11188.9, wps=6221.9, ups=3.68, wpb=1691, bsz=51.2, num_updates=51900, lr=0.000219476, gnorm=1.517, clip=0, loss_scale=512, train_wall=27, wall=15061
2022-10-19 21:15:52 | INFO | train_inner | epoch 014:    826 / 3937 loss=13.5, nll_loss=10.144, mask_ins=1.889, word_ins_ml=10.832, word_reposition=0.779, ppl=11583.6, wps=6410.3, ups=3.62, wpb=1769.7, bsz=54.4, num_updates=52000, lr=0.000219265, gnorm=1.19, clip=0, loss_scale=512, train_wall=27, wall=15089
2022-10-19 21:16:19 | INFO | train_inner | epoch 014:    926 / 3937 loss=13.505, nll_loss=10.152, mask_ins=1.912, word_ins_ml=10.84, word_reposition=0.753, ppl=11622.1, wps=6128.6, ups=3.73, wpb=1645, bsz=50.6, num_updates=52100, lr=0.000219054, gnorm=2.159, clip=1, loss_scale=512, train_wall=27, wall=15116
2022-10-19 21:16:46 | INFO | train_inner | epoch 014:   1026 / 3937 loss=13.488, nll_loss=10.14, mask_ins=1.906, word_ins_ml=10.83, word_reposition=0.752, ppl=11491.2, wps=6082.5, ups=3.68, wpb=1650.8, bsz=49.6, num_updates=52200, lr=0.000218844, gnorm=0.94, clip=0, loss_scale=512, train_wall=27, wall=15143
2022-10-19 21:17:13 | INFO | train_inner | epoch 014:   1126 / 3937 loss=13.452, nll_loss=10.151, mask_ins=1.86, word_ins_ml=10.84, word_reposition=0.752, ppl=11206.2, wps=5932.6, ups=3.71, wpb=1597, bsz=47.8, num_updates=52300, lr=0.000218635, gnorm=0.968, clip=0, loss_scale=512, train_wall=27, wall=15170
2022-10-19 21:17:40 | INFO | train_inner | epoch 014:   1226 / 3937 loss=13.435, nll_loss=10.124, mask_ins=1.896, word_ins_ml=10.816, word_reposition=0.722, ppl=11071.5, wps=6132.5, ups=3.67, wpb=1672.7, bsz=50.8, num_updates=52400, lr=0.000218426, gnorm=0.923, clip=0, loss_scale=512, train_wall=27, wall=15197
2022-10-19 21:18:07 | INFO | train_inner | epoch 014:   1326 / 3937 loss=13.381, nll_loss=10.128, mask_ins=1.849, word_ins_ml=10.82, word_reposition=0.711, ppl=10667.8, wps=6299.5, ups=3.71, wpb=1697.3, bsz=51.5, num_updates=52500, lr=0.000218218, gnorm=0.996, clip=0, loss_scale=512, train_wall=27, wall=15224
2022-10-19 21:18:35 | INFO | train_inner | epoch 014:   1426 / 3937 loss=13.457, nll_loss=10.158, mask_ins=1.887, word_ins_ml=10.845, word_reposition=0.726, ppl=11248.3, wps=6215.2, ups=3.64, wpb=1708.8, bsz=52, num_updates=52600, lr=0.00021801, gnorm=0.994, clip=0, loss_scale=512, train_wall=27, wall=15252
2022-10-19 21:19:02 | INFO | train_inner | epoch 014:   1526 / 3937 loss=13.438, nll_loss=10.118, mask_ins=1.874, word_ins_ml=10.811, word_reposition=0.753, ppl=11095.3, wps=6378.7, ups=3.67, wpb=1737.1, bsz=53.3, num_updates=52700, lr=0.000217803, gnorm=1.097, clip=0, loss_scale=512, train_wall=27, wall=15279
2022-10-19 21:19:29 | INFO | train_inner | epoch 014:   1626 / 3937 loss=13.422, nll_loss=10.139, mask_ins=1.846, word_ins_ml=10.828, word_reposition=0.748, ppl=10972.9, wps=6110.8, ups=3.7, wpb=1650.2, bsz=49.6, num_updates=52800, lr=0.000217597, gnorm=1.174, clip=0, loss_scale=512, train_wall=27, wall=15306
2022-10-19 21:19:56 | INFO | train_inner | epoch 014:   1726 / 3937 loss=13.479, nll_loss=10.157, mask_ins=1.891, word_ins_ml=10.845, word_reposition=0.744, ppl=11421.4, wps=6685.3, ups=3.67, wpb=1819.6, bsz=55, num_updates=52900, lr=0.000217391, gnorm=1.316, clip=0, loss_scale=512, train_wall=27, wall=15333
2022-10-19 21:20:23 | INFO | train_inner | epoch 014:   1826 / 3937 loss=13.419, nll_loss=10.116, mask_ins=1.863, word_ins_ml=10.809, word_reposition=0.747, ppl=10955.1, wps=6038.1, ups=3.68, wpb=1640.1, bsz=50.8, num_updates=53000, lr=0.000217186, gnorm=1.201, clip=0, loss_scale=512, train_wall=27, wall=15360
2022-10-19 21:20:51 | INFO | train_inner | epoch 014:   1926 / 3937 loss=13.394, nll_loss=10.134, mask_ins=1.834, word_ins_ml=10.825, word_reposition=0.736, ppl=10767.2, wps=6260.5, ups=3.65, wpb=1716.2, bsz=52.3, num_updates=53100, lr=0.000216982, gnorm=1.266, clip=0, loss_scale=512, train_wall=27, wall=15388
2022-10-19 21:21:18 | INFO | train_inner | epoch 014:   2026 / 3937 loss=13.426, nll_loss=10.165, mask_ins=1.847, word_ins_ml=10.853, word_reposition=0.726, ppl=11007, wps=5939.8, ups=3.67, wpb=1617.2, bsz=48, num_updates=53200, lr=0.000216777, gnorm=1.158, clip=0, loss_scale=512, train_wall=27, wall=15415
2022-10-19 21:21:45 | INFO | train_inner | epoch 014:   2126 / 3937 loss=13.478, nll_loss=10.116, mask_ins=1.923, word_ins_ml=10.809, word_reposition=0.746, ppl=11408, wps=6358, ups=3.66, wpb=1738.6, bsz=53.2, num_updates=53300, lr=0.000216574, gnorm=1.055, clip=0, loss_scale=512, train_wall=27, wall=15442
2022-10-19 21:22:12 | INFO | train_inner | epoch 014:   2226 / 3937 loss=13.455, nll_loss=10.141, mask_ins=1.882, word_ins_ml=10.831, word_reposition=0.742, ppl=11229.8, wps=6583.8, ups=3.71, wpb=1773.5, bsz=54.5, num_updates=53400, lr=0.000216371, gnorm=1.067, clip=0, loss_scale=512, train_wall=27, wall=15469
2022-10-19 21:22:40 | INFO | train_inner | epoch 014:   2326 / 3937 loss=13.499, nll_loss=10.178, mask_ins=1.889, word_ins_ml=10.863, word_reposition=0.747, ppl=11579.5, wps=6121.1, ups=3.67, wpb=1670, bsz=50, num_updates=53500, lr=0.000216169, gnorm=0.921, clip=0, loss_scale=512, train_wall=27, wall=15496
2022-10-19 21:23:07 | INFO | train_inner | epoch 014:   2426 / 3937 loss=13.406, nll_loss=10.1, mask_ins=1.884, word_ins_ml=10.796, word_reposition=0.726, ppl=10855.6, wps=5989.6, ups=3.67, wpb=1630, bsz=50, num_updates=53600, lr=0.000215967, gnorm=1.23, clip=0, loss_scale=512, train_wall=27, wall=15524
2022-10-19 21:23:34 | INFO | train_inner | epoch 014:   2526 / 3937 loss=13.472, nll_loss=10.142, mask_ins=1.917, word_ins_ml=10.831, word_reposition=0.724, ppl=11363.3, wps=6380.2, ups=3.68, wpb=1734.2, bsz=52.7, num_updates=53700, lr=0.000215766, gnorm=1.111, clip=0, loss_scale=512, train_wall=27, wall=15551
2022-10-19 21:24:01 | INFO | train_inner | epoch 014:   2626 / 3937 loss=13.458, nll_loss=10.134, mask_ins=1.872, word_ins_ml=10.825, word_reposition=0.762, ppl=11255.6, wps=6584.3, ups=3.67, wpb=1795, bsz=54.1, num_updates=53800, lr=0.000215565, gnorm=1.347, clip=0, loss_scale=512, train_wall=27, wall=15578
2022-10-19 21:24:28 | INFO | train_inner | epoch 014:   2726 / 3937 loss=13.449, nll_loss=10.168, mask_ins=1.86, word_ins_ml=10.854, word_reposition=0.734, ppl=11183.4, wps=6173.9, ups=3.69, wpb=1675.1, bsz=50.6, num_updates=53900, lr=0.000215365, gnorm=1.38, clip=0, loss_scale=512, train_wall=27, wall=15605
2022-10-19 21:24:56 | INFO | train_inner | epoch 014:   2826 / 3937 loss=13.465, nll_loss=10.156, mask_ins=1.861, word_ins_ml=10.845, word_reposition=0.759, ppl=11306.4, wps=6225, ups=3.67, wpb=1697.6, bsz=51, num_updates=54000, lr=0.000215166, gnorm=1.174, clip=0, loss_scale=722, train_wall=27, wall=15632
2022-10-19 21:25:23 | INFO | train_inner | epoch 014:   2926 / 3937 loss=13.508, nll_loss=10.155, mask_ins=1.932, word_ins_ml=10.843, word_reposition=0.733, ppl=11651.4, wps=6215.3, ups=3.66, wpb=1699.5, bsz=51.3, num_updates=54100, lr=0.000214967, gnorm=1.264, clip=0, loss_scale=1024, train_wall=27, wall=15660
2022-10-19 21:25:50 | INFO | train_inner | epoch 014:   3026 / 3937 loss=13.446, nll_loss=10.123, mask_ins=1.884, word_ins_ml=10.816, word_reposition=0.746, ppl=11159.6, wps=6203.1, ups=3.64, wpb=1702.5, bsz=52, num_updates=54200, lr=0.000214768, gnorm=1.108, clip=0, loss_scale=1024, train_wall=27, wall=15687
2022-10-19 21:26:18 | INFO | train_inner | epoch 014:   3126 / 3937 loss=13.45, nll_loss=10.167, mask_ins=1.842, word_ins_ml=10.854, word_reposition=0.754, ppl=11191.3, wps=6086.7, ups=3.69, wpb=1651.6, bsz=49.8, num_updates=54300, lr=0.000214571, gnorm=0.916, clip=0, loss_scale=1024, train_wall=27, wall=15714
2022-10-19 21:26:45 | INFO | train_inner | epoch 014:   3226 / 3937 loss=13.449, nll_loss=10.182, mask_ins=1.834, word_ins_ml=10.866, word_reposition=0.75, ppl=11184.1, wps=6203.4, ups=3.69, wpb=1681.7, bsz=51.3, num_updates=54400, lr=0.000214373, gnorm=1.025, clip=0, loss_scale=1024, train_wall=27, wall=15741
2022-10-19 21:27:12 | INFO | train_inner | epoch 014:   3326 / 3937 loss=13.464, nll_loss=10.167, mask_ins=1.873, word_ins_ml=10.853, word_reposition=0.738, ppl=11300.7, wps=5638.3, ups=3.68, wpb=1530.8, bsz=45, num_updates=54500, lr=0.000214176, gnorm=0.99, clip=0, loss_scale=1024, train_wall=27, wall=15769
2022-10-19 21:27:39 | INFO | train_inner | epoch 014:   3426 / 3937 loss=13.471, nll_loss=10.144, mask_ins=1.876, word_ins_ml=10.834, word_reposition=0.761, ppl=11352.9, wps=5871.9, ups=3.67, wpb=1600.6, bsz=47.2, num_updates=54600, lr=0.00021398, gnorm=0.931, clip=0, loss_scale=1024, train_wall=27, wall=15796
2022-10-19 21:28:06 | INFO | train_inner | epoch 014:   3526 / 3937 loss=13.424, nll_loss=10.125, mask_ins=1.835, word_ins_ml=10.818, word_reposition=0.771, ppl=10993.1, wps=6150.5, ups=3.68, wpb=1673, bsz=51.7, num_updates=54700, lr=0.000213785, gnorm=1.103, clip=0, loss_scale=1024, train_wall=27, wall=15823
2022-10-19 21:28:33 | INFO | train_inner | epoch 014:   3626 / 3937 loss=13.448, nll_loss=10.137, mask_ins=1.898, word_ins_ml=10.827, word_reposition=0.724, ppl=11176.6, wps=6860.8, ups=3.69, wpb=1857.4, bsz=58, num_updates=54800, lr=0.000213589, gnorm=0.901, clip=0, loss_scale=1024, train_wall=27, wall=15850
2022-10-19 21:29:00 | INFO | train_inner | epoch 014:   3726 / 3937 loss=13.487, nll_loss=10.13, mask_ins=1.916, word_ins_ml=10.822, word_reposition=0.749, ppl=11479.3, wps=6268.5, ups=3.71, wpb=1690, bsz=51.6, num_updates=54900, lr=0.000213395, gnorm=1.209, clip=0, loss_scale=1024, train_wall=27, wall=15877
2022-10-19 21:29:27 | INFO | train_inner | epoch 014:   3826 / 3937 loss=13.429, nll_loss=10.167, mask_ins=1.836, word_ins_ml=10.853, word_reposition=0.74, ppl=11027.5, wps=6204.5, ups=3.7, wpb=1679, bsz=51, num_updates=55000, lr=0.000213201, gnorm=1.047, clip=0, loss_scale=1024, train_wall=27, wall=15904
2022-10-19 21:29:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-10-19 21:29:55 | INFO | train_inner | epoch 014:   3927 / 3937 loss=13.437, nll_loss=10.132, mask_ins=1.852, word_ins_ml=10.823, word_reposition=0.763, ppl=11093.6, wps=6141.9, ups=3.64, wpb=1685.3, bsz=50.3, num_updates=55100, lr=0.000213007, gnorm=1.182, clip=0, loss_scale=760, train_wall=27, wall=15932
2022-10-19 21:29:58 | INFO | train | epoch 014 | loss 13.453 | nll_loss 10.14 | mask_ins 1.878 | word_ins_ml 10.83 | word_reposition 0.745 | ppl 11213.2 | wps 6155.7 | ups 3.63 | wpb 1696.4 | bsz 51.5 | num_updates 55110 | lr 0.000212988 | gnorm 1.15 | clip 0 | loss_scale 654 | train_wall 1060 | wall 15934
2022-10-19 21:30:09 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 27.821 | nll_loss 17.911 | mask_ins 7.989 | word_ins_ml 17.619 | word_reposition 2.214 | ppl 2.37098e+08 | wps 27642.3 | wpb 1503.2 | bsz 51.5 | num_updates 55110 | best_loss 14.267
2022-10-19 21:30:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 14 @ 55110 updates, score 27.821) (writing took 2.974853780004196 seconds)
2022-10-19 21:30:37 | INFO | train_inner | epoch 015:     90 / 3937 loss=13.403, nll_loss=10.111, mask_ins=1.861, word_ins_ml=10.806, word_reposition=0.737, ppl=10834.3, wps=4133.5, ups=2.4, wpb=1724.8, bsz=52.9, num_updates=55200, lr=0.000212814, gnorm=0.985, clip=0, loss_scale=512, train_wall=27, wall=15973
2022-10-19 21:31:04 | INFO | train_inner | epoch 015:    190 / 3937 loss=13.389, nll_loss=10.114, mask_ins=1.833, word_ins_ml=10.806, word_reposition=0.75, ppl=10729.4, wps=6037.9, ups=3.67, wpb=1646, bsz=49.5, num_updates=55300, lr=0.000212622, gnorm=1.038, clip=0, loss_scale=512, train_wall=27, wall=16001
2022-10-19 21:31:31 | INFO | train_inner | epoch 015:    290 / 3937 loss=13.521, nll_loss=10.143, mask_ins=1.94, word_ins_ml=10.832, word_reposition=0.749, ppl=11757.7, wps=5920.9, ups=3.7, wpb=1601.9, bsz=48.9, num_updates=55400, lr=0.00021243, gnorm=0.932, clip=0, loss_scale=512, train_wall=27, wall=16028
2022-10-19 21:31:58 | INFO | train_inner | epoch 015:    390 / 3937 loss=13.472, nll_loss=10.127, mask_ins=1.912, word_ins_ml=10.819, word_reposition=0.741, ppl=11365.5, wps=6024.9, ups=3.69, wpb=1634.7, bsz=48.9, num_updates=55500, lr=0.000212238, gnorm=1.082, clip=0, loss_scale=512, train_wall=27, wall=16055
2022-10-19 21:32:25 | INFO | train_inner | epoch 015:    490 / 3937 loss=13.464, nll_loss=10.149, mask_ins=1.885, word_ins_ml=10.837, word_reposition=0.743, ppl=11303.3, wps=6345.8, ups=3.69, wpb=1718, bsz=52.7, num_updates=55600, lr=0.000212047, gnorm=1.184, clip=0, loss_scale=512, train_wall=27, wall=16082
2022-10-19 21:32:52 | INFO | train_inner | epoch 015:    590 / 3937 loss=13.462, nll_loss=10.131, mask_ins=1.887, word_ins_ml=10.822, word_reposition=0.754, ppl=11287.2, wps=6239.5, ups=3.71, wpb=1682.8, bsz=51, num_updates=55700, lr=0.000211857, gnorm=0.987, clip=0, loss_scale=512, train_wall=27, wall=16109
2022-10-19 21:33:19 | INFO | train_inner | epoch 015:    690 / 3937 loss=13.458, nll_loss=10.148, mask_ins=1.892, word_ins_ml=10.837, word_reposition=0.728, ppl=11250.2, wps=6527.3, ups=3.66, wpb=1782.2, bsz=54.1, num_updates=55800, lr=0.000211667, gnorm=1.081, clip=0, loss_scale=512, train_wall=27, wall=16136
2022-10-19 21:33:46 | INFO | train_inner | epoch 015:    790 / 3937 loss=13.383, nll_loss=10.099, mask_ins=1.843, word_ins_ml=10.795, word_reposition=0.744, ppl=10680.5, wps=6376.2, ups=3.69, wpb=1728.7, bsz=53, num_updates=55900, lr=0.000211477, gnorm=1.126, clip=0, loss_scale=512, train_wall=27, wall=16163
2022-10-19 21:34:13 | INFO | train_inner | epoch 015:    890 / 3937 loss=13.476, nll_loss=10.127, mask_ins=1.896, word_ins_ml=10.819, word_reposition=0.762, ppl=11393.8, wps=6276.3, ups=3.71, wpb=1693.1, bsz=51.5, num_updates=56000, lr=0.000211289, gnorm=2.081, clip=1, loss_scale=512, train_wall=27, wall=16190
2022-10-19 21:34:41 | INFO | train_inner | epoch 015:    990 / 3937 loss=13.462, nll_loss=10.163, mask_ins=1.883, word_ins_ml=10.85, word_reposition=0.729, ppl=11281.3, wps=6232.4, ups=3.68, wpb=1691.9, bsz=51, num_updates=56100, lr=0.0002111, gnorm=1.962, clip=1, loss_scale=512, train_wall=27, wall=16217
2022-10-19 21:35:07 | INFO | train_inner | epoch 015:   1090 / 3937 loss=13.445, nll_loss=10.132, mask_ins=1.869, word_ins_ml=10.824, word_reposition=0.753, ppl=11152.2, wps=6204.4, ups=3.72, wpb=1665.9, bsz=50.3, num_updates=56200, lr=0.000210912, gnorm=1.957, clip=0, loss_scale=512, train_wall=27, wall=16244
2022-10-19 21:35:35 | INFO | train_inner | epoch 015:   1190 / 3937 loss=13.525, nll_loss=10.16, mask_ins=1.933, word_ins_ml=10.847, word_reposition=0.745, ppl=11784.4, wps=6445.5, ups=3.69, wpb=1746.9, bsz=53.5, num_updates=56300, lr=0.000210725, gnorm=1.735, clip=1, loss_scale=512, train_wall=27, wall=16271
2022-10-19 21:36:01 | INFO | train_inner | epoch 015:   1290 / 3937 loss=13.519, nll_loss=10.175, mask_ins=1.885, word_ins_ml=10.861, word_reposition=0.773, ppl=11736.8, wps=6155.6, ups=3.72, wpb=1655.9, bsz=48.5, num_updates=56400, lr=0.000210538, gnorm=1.447, clip=0, loss_scale=512, train_wall=27, wall=16298
2022-10-19 21:36:29 | INFO | train_inner | epoch 015:   1390 / 3937 loss=13.407, nll_loss=10.139, mask_ins=1.839, word_ins_ml=10.831, word_reposition=0.737, ppl=10860.7, wps=6480.9, ups=3.69, wpb=1756.3, bsz=54, num_updates=56500, lr=0.000210352, gnorm=1.216, clip=0, loss_scale=512, train_wall=27, wall=16325
2022-10-19 21:36:56 | INFO | train_inner | epoch 015:   1490 / 3937 loss=13.502, nll_loss=10.138, mask_ins=1.909, word_ins_ml=10.827, word_reposition=0.766, ppl=11603.7, wps=6403.7, ups=3.64, wpb=1758.5, bsz=54.3, num_updates=56600, lr=0.000210166, gnorm=2.921, clip=2, loss_scale=512, train_wall=27, wall=16353
2022-10-19 21:37:23 | INFO | train_inner | epoch 015:   1590 / 3937 loss=13.501, nll_loss=10.149, mask_ins=1.902, word_ins_ml=10.838, word_reposition=0.761, ppl=11591.5, wps=6127.6, ups=3.71, wpb=1653.6, bsz=50.1, num_updates=56700, lr=0.00020998, gnorm=1.109, clip=0, loss_scale=512, train_wall=27, wall=16380
2022-10-19 21:37:50 | INFO | train_inner | epoch 015:   1690 / 3937 loss=13.459, nll_loss=10.147, mask_ins=1.888, word_ins_ml=10.837, word_reposition=0.733, ppl=11262.3, wps=6175.7, ups=3.69, wpb=1675.5, bsz=50.7, num_updates=56800, lr=0.000209795, gnorm=1.104, clip=0, loss_scale=512, train_wall=27, wall=16407
2022-10-19 21:38:17 | INFO | train_inner | epoch 015:   1790 / 3937 loss=13.417, nll_loss=10.152, mask_ins=1.819, word_ins_ml=10.842, word_reposition=0.756, ppl=10941, wps=5520.6, ups=3.69, wpb=1495.2, bsz=44.9, num_updates=56900, lr=0.000209611, gnorm=1.065, clip=0, loss_scale=512, train_wall=27, wall=16434
2022-10-19 21:38:45 | INFO | train_inner | epoch 015:   1890 / 3937 loss=13.506, nll_loss=10.157, mask_ins=1.899, word_ins_ml=10.844, word_reposition=0.763, ppl=11631.4, wps=6150.9, ups=3.64, wpb=1689.6, bsz=51.3, num_updates=57000, lr=0.000209427, gnorm=1.276, clip=0, loss_scale=512, train_wall=27, wall=16461
2022-10-19 21:39:12 | INFO | train_inner | epoch 015:   1990 / 3937 loss=13.477, nll_loss=10.098, mask_ins=1.877, word_ins_ml=10.795, word_reposition=0.806, ppl=11404.7, wps=6193.7, ups=3.72, wpb=1666.7, bsz=50.3, num_updates=57100, lr=0.000209243, gnorm=3.768, clip=3, loss_scale=512, train_wall=27, wall=16488
2022-10-19 21:39:39 | INFO | train_inner | epoch 015:   2090 / 3937 loss=13.471, nll_loss=10.107, mask_ins=1.923, word_ins_ml=10.801, word_reposition=0.747, ppl=11358.2, wps=6323, ups=3.65, wpb=1730.2, bsz=52.4, num_updates=57200, lr=0.000209061, gnorm=1.101, clip=0, loss_scale=512, train_wall=27, wall=16516
2022-10-19 21:40:06 | INFO | train_inner | epoch 015:   2190 / 3937 loss=13.402, nll_loss=10.136, mask_ins=1.844, word_ins_ml=10.827, word_reposition=0.731, ppl=10824.7, wps=6248.3, ups=3.7, wpb=1689.1, bsz=51.5, num_updates=57300, lr=0.000208878, gnorm=1.233, clip=0, loss_scale=512, train_wall=27, wall=16543
2022-10-19 21:40:33 | INFO | train_inner | epoch 015:   2290 / 3937 loss=13.436, nll_loss=10.157, mask_ins=1.842, word_ins_ml=10.845, word_reposition=0.748, ppl=11079.3, wps=6017.9, ups=3.64, wpb=1654, bsz=49.4, num_updates=57400, lr=0.000208696, gnorm=1.055, clip=0, loss_scale=512, train_wall=27, wall=16570
2022-10-19 21:41:01 | INFO | train_inner | epoch 015:   2390 / 3937 loss=13.403, nll_loss=10.139, mask_ins=1.831, word_ins_ml=10.83, word_reposition=0.742, ppl=10833.4, wps=6391, ups=3.67, wpb=1742.4, bsz=52.1, num_updates=57500, lr=0.000208514, gnorm=1.059, clip=0, loss_scale=512, train_wall=27, wall=16598
2022-10-19 21:41:28 | INFO | train_inner | epoch 015:   2490 / 3937 loss=13.451, nll_loss=10.177, mask_ins=1.859, word_ins_ml=10.863, word_reposition=0.729, ppl=11198.7, wps=6018.2, ups=3.69, wpb=1629.4, bsz=49.8, num_updates=57600, lr=0.000208333, gnorm=1.869, clip=1, loss_scale=512, train_wall=27, wall=16625
2022-10-19 21:41:55 | INFO | train_inner | epoch 015:   2590 / 3937 loss=13.452, nll_loss=10.129, mask_ins=1.884, word_ins_ml=10.821, word_reposition=0.747, ppl=11204, wps=5977.6, ups=3.71, wpb=1612.8, bsz=49.4, num_updates=57700, lr=0.000208153, gnorm=1.691, clip=0, loss_scale=512, train_wall=27, wall=16652
2022-10-19 21:42:22 | INFO | train_inner | epoch 015:   2690 / 3937 loss=13.407, nll_loss=10.135, mask_ins=1.845, word_ins_ml=10.826, word_reposition=0.736, ppl=10859.5, wps=6345.9, ups=3.68, wpb=1722.2, bsz=52.2, num_updates=57800, lr=0.000207973, gnorm=1.087, clip=0, loss_scale=512, train_wall=27, wall=16679
2022-10-19 21:42:49 | INFO | train_inner | epoch 015:   2790 / 3937 loss=13.501, nll_loss=10.17, mask_ins=1.887, word_ins_ml=10.856, word_reposition=0.758, ppl=11593.1, wps=6333.9, ups=3.64, wpb=1740.3, bsz=53.5, num_updates=57900, lr=0.000207793, gnorm=1.125, clip=0, loss_scale=512, train_wall=27, wall=16706
2022-10-19 21:43:17 | INFO | train_inner | epoch 015:   2890 / 3937 loss=13.528, nll_loss=10.158, mask_ins=1.918, word_ins_ml=10.846, word_reposition=0.764, ppl=11811.8, wps=6551.2, ups=3.67, wpb=1785.8, bsz=54, num_updates=58000, lr=0.000207614, gnorm=1.765, clip=1, loss_scale=512, train_wall=27, wall=16733
2022-10-19 21:43:44 | INFO | train_inner | epoch 015:   2990 / 3937 loss=13.515, nll_loss=10.158, mask_ins=1.928, word_ins_ml=10.846, word_reposition=0.741, ppl=11704.3, wps=7151.3, ups=3.67, wpb=1949.3, bsz=61.2, num_updates=58100, lr=0.000207435, gnorm=1.384, clip=0, loss_scale=512, train_wall=27, wall=16761
2022-10-19 21:44:11 | INFO | train_inner | epoch 015:   3090 / 3937 loss=13.494, nll_loss=10.141, mask_ins=1.915, word_ins_ml=10.832, word_reposition=0.747, ppl=11535.5, wps=6103.6, ups=3.7, wpb=1648.7, bsz=49.6, num_updates=58200, lr=0.000207257, gnorm=1.272, clip=0, loss_scale=512, train_wall=27, wall=16788
2022-10-19 21:44:38 | INFO | train_inner | epoch 015:   3190 / 3937 loss=13.397, nll_loss=10.134, mask_ins=1.845, word_ins_ml=10.825, word_reposition=0.727, ppl=10788.2, wps=6378, ups=3.65, wpb=1748.6, bsz=53, num_updates=58300, lr=0.000207079, gnorm=1.135, clip=0, loss_scale=512, train_wall=27, wall=16815
2022-10-19 21:45:06 | INFO | train_inner | epoch 015:   3290 / 3937 loss=13.462, nll_loss=10.154, mask_ins=1.837, word_ins_ml=10.842, word_reposition=0.783, ppl=11282.6, wps=6202.8, ups=3.68, wpb=1686.3, bsz=50.5, num_updates=58400, lr=0.000206901, gnorm=1.691, clip=1, loss_scale=512, train_wall=27, wall=16842
2022-10-19 21:45:33 | INFO | train_inner | epoch 015:   3390 / 3937 loss=13.415, nll_loss=10.12, mask_ins=1.855, word_ins_ml=10.814, word_reposition=0.746, ppl=10921.6, wps=6509.8, ups=3.66, wpb=1778.6, bsz=53.1, num_updates=58500, lr=0.000206725, gnorm=1.577, clip=0, loss_scale=512, train_wall=27, wall=16870
2022-10-19 21:46:00 | INFO | train_inner | epoch 015:   3490 / 3937 loss=13.478, nll_loss=10.155, mask_ins=1.859, word_ins_ml=10.844, word_reposition=0.775, ppl=11407.8, wps=6051.6, ups=3.67, wpb=1650.2, bsz=48.9, num_updates=58600, lr=0.000206548, gnorm=1.998, clip=1, loss_scale=512, train_wall=27, wall=16897
2022-10-19 21:46:27 | INFO | train_inner | epoch 015:   3590 / 3937 loss=13.444, nll_loss=10.151, mask_ins=1.876, word_ins_ml=10.84, word_reposition=0.728, ppl=11142.2, wps=6295, ups=3.7, wpb=1700.5, bsz=51.8, num_updates=58700, lr=0.000206372, gnorm=2.531, clip=1, loss_scale=512, train_wall=27, wall=16924
2022-10-19 21:46:54 | INFO | train_inner | epoch 015:   3690 / 3937 loss=13.484, nll_loss=10.156, mask_ins=1.891, word_ins_ml=10.844, word_reposition=0.749, ppl=11459.4, wps=5951.6, ups=3.71, wpb=1604.9, bsz=48.4, num_updates=58800, lr=0.000206197, gnorm=1.439, clip=0, loss_scale=512, train_wall=27, wall=16951
2022-10-19 21:47:21 | INFO | train_inner | epoch 015:   3790 / 3937 loss=13.4, nll_loss=10.129, mask_ins=1.873, word_ins_ml=10.821, word_reposition=0.706, ppl=10811.2, wps=6099.3, ups=3.69, wpb=1654.1, bsz=51.4, num_updates=58900, lr=0.000206021, gnorm=1.635, clip=1, loss_scale=512, train_wall=27, wall=16978
2022-10-19 21:47:48 | INFO | train_inner | epoch 015:   3890 / 3937 loss=13.401, nll_loss=10.117, mask_ins=1.854, word_ins_ml=10.812, word_reposition=0.735, ppl=10820.5, wps=6327.9, ups=3.68, wpb=1721.3, bsz=53.2, num_updates=59000, lr=0.000205847, gnorm=1.797, clip=1, loss_scale=512, train_wall=27, wall=17005
2022-10-19 21:48:01 | INFO | train | epoch 015 | loss 13.457 | nll_loss 10.141 | mask_ins 1.877 | word_ins_ml 10.831 | word_reposition 0.748 | ppl 11242 | wps 6162.3 | ups 3.63 | wpb 1696.2 | bsz 51.5 | num_updates 59047 | lr 0.000205765 | gnorm 1.499 | clip 0.4 | loss_scale 512 | train_wall 1059 | wall 17018
2022-10-19 21:48:13 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 24.05 | nll_loss 15.889 | mask_ins 5.713 | word_ins_ml 15.805 | word_reposition 2.532 | ppl 1.73734e+07 | wps 27752.3 | wpb 1503.2 | bsz 51.5 | num_updates 59047 | best_loss 14.267
2022-10-19 21:48:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 15 @ 59047 updates, score 24.05) (writing took 12.169158898061141 seconds)
2022-10-19 21:48:39 | INFO | train_inner | epoch 016:     53 / 3937 loss=13.405, nll_loss=10.166, mask_ins=1.831, word_ins_ml=10.852, word_reposition=0.721, ppl=10844.9, wps=3347.9, ups=1.96, wpb=1706.2, bsz=51.9, num_updates=59100, lr=0.000205673, gnorm=1.225, clip=0, loss_scale=512, train_wall=27, wall=17056
2022-10-19 21:49:07 | INFO | train_inner | epoch 016:    153 / 3937 loss=13.385, nll_loss=10.129, mask_ins=1.834, word_ins_ml=10.821, word_reposition=0.73, ppl=10696.3, wps=6223.2, ups=3.68, wpb=1692.1, bsz=50.5, num_updates=59200, lr=0.000205499, gnorm=1.51, clip=0, loss_scale=799, train_wall=27, wall=17083
2022-10-19 21:49:34 | INFO | train_inner | epoch 016:    253 / 3937 loss=13.477, nll_loss=10.143, mask_ins=1.875, word_ins_ml=10.832, word_reposition=0.77, ppl=11401.8, wps=6068.1, ups=3.69, wpb=1642.5, bsz=48.9, num_updates=59300, lr=0.000205325, gnorm=3.846, clip=2, loss_scale=1024, train_wall=27, wall=17110
2022-10-19 21:50:01 | INFO | train_inner | epoch 016:    353 / 3937 loss=13.406, nll_loss=10.09, mask_ins=1.884, word_ins_ml=10.787, word_reposition=0.735, ppl=10857.6, wps=6810.7, ups=3.64, wpb=1870, bsz=58.4, num_updates=59400, lr=0.000205152, gnorm=1.17, clip=0, loss_scale=1024, train_wall=27, wall=17138
2022-10-19 21:50:28 | INFO | train_inner | epoch 016:    453 / 3937 loss=13.407, nll_loss=10.118, mask_ins=1.861, word_ins_ml=10.811, word_reposition=0.734, ppl=10858.4, wps=5882.1, ups=3.68, wpb=1597.1, bsz=48.5, num_updates=59500, lr=0.00020498, gnorm=1.464, clip=1, loss_scale=1024, train_wall=27, wall=17165
2022-10-19 21:50:55 | INFO | train_inner | epoch 016:    553 / 3937 loss=13.448, nll_loss=10.129, mask_ins=1.9, word_ins_ml=10.82, word_reposition=0.727, ppl=11172.1, wps=6500.2, ups=3.72, wpb=1746.7, bsz=53, num_updates=59600, lr=0.000204808, gnorm=1.462, clip=0, loss_scale=1024, train_wall=27, wall=17192
2022-10-19 21:51:22 | INFO | train_inner | epoch 016:    653 / 3937 loss=13.518, nll_loss=10.179, mask_ins=1.915, word_ins_ml=10.864, word_reposition=0.739, ppl=11729, wps=5964.2, ups=3.7, wpb=1612.1, bsz=48.7, num_updates=59700, lr=0.000204636, gnorm=1.56, clip=0, loss_scale=1024, train_wall=27, wall=17219
2022-10-19 21:51:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-10-19 21:51:49 | INFO | train_inner | epoch 016:    754 / 3937 loss=13.459, nll_loss=10.157, mask_ins=1.862, word_ins_ml=10.845, word_reposition=0.753, ppl=11262.1, wps=6212.3, ups=3.66, wpb=1697, bsz=51.2, num_updates=59800, lr=0.000204465, gnorm=2.978, clip=2, loss_scale=816, train_wall=27, wall=17246
2022-10-19 21:52:16 | INFO | train_inner | epoch 016:    854 / 3937 loss=13.599, nll_loss=10.131, mask_ins=1.912, word_ins_ml=10.824, word_reposition=0.863, ppl=12404.6, wps=6138.1, ups=3.71, wpb=1654, bsz=49.9, num_updates=59900, lr=0.000204294, gnorm=5.053, clip=3, loss_scale=512, train_wall=27, wall=17273
2022-10-19 21:52:43 | INFO | train_inner | epoch 016:    954 / 3937 loss=13.445, nll_loss=10.165, mask_ins=1.854, word_ins_ml=10.852, word_reposition=0.74, ppl=11155.3, wps=6850.9, ups=3.69, wpb=1856.1, bsz=57.1, num_updates=60000, lr=0.000204124, gnorm=1.583, clip=0, loss_scale=512, train_wall=27, wall=17300
2022-10-19 21:53:11 | INFO | train_inner | epoch 016:   1054 / 3937 loss=13.46, nll_loss=10.138, mask_ins=1.901, word_ins_ml=10.829, word_reposition=0.73, ppl=11268.9, wps=6789.9, ups=3.67, wpb=1849.1, bsz=57.7, num_updates=60100, lr=0.000203954, gnorm=1.488, clip=0, loss_scale=512, train_wall=27, wall=17328
2022-10-19 21:53:38 | INFO | train_inner | epoch 016:   1154 / 3937 loss=13.422, nll_loss=10.125, mask_ins=1.863, word_ins_ml=10.817, word_reposition=0.742, ppl=10972.9, wps=5996.9, ups=3.66, wpb=1637.3, bsz=49.8, num_updates=60200, lr=0.000203785, gnorm=1.318, clip=0, loss_scale=512, train_wall=27, wall=17355
2022-10-19 21:54:05 | INFO | train_inner | epoch 016:   1254 / 3937 loss=13.449, nll_loss=10.125, mask_ins=1.883, word_ins_ml=10.817, word_reposition=0.748, ppl=11179.7, wps=6161.1, ups=3.66, wpb=1683.3, bsz=50.6, num_updates=60300, lr=0.000203616, gnorm=1.46, clip=0, loss_scale=512, train_wall=27, wall=17382
2022-10-19 21:54:32 | INFO | train_inner | epoch 016:   1354 / 3937 loss=13.503, nll_loss=10.12, mask_ins=1.919, word_ins_ml=10.813, word_reposition=0.771, ppl=11608.5, wps=6254, ups=3.69, wpb=1695.7, bsz=52.1, num_updates=60400, lr=0.000203447, gnorm=2.02, clip=1, loss_scale=512, train_wall=27, wall=17409
2022-10-19 21:54:59 | INFO | train_inner | epoch 016:   1454 / 3937 loss=13.482, nll_loss=10.148, mask_ins=1.884, word_ins_ml=10.837, word_reposition=0.762, ppl=11445.5, wps=5935.1, ups=3.7, wpb=1602.8, bsz=47.8, num_updates=60500, lr=0.000203279, gnorm=1.247, clip=0, loss_scale=512, train_wall=27, wall=17436
2022-10-19 21:55:26 | INFO | train_inner | epoch 016:   1554 / 3937 loss=13.445, nll_loss=10.125, mask_ins=1.895, word_ins_ml=10.818, word_reposition=0.733, ppl=11153.8, wps=6410.3, ups=3.71, wpb=1728.8, bsz=52.7, num_updates=60600, lr=0.000203111, gnorm=1.063, clip=0, loss_scale=512, train_wall=27, wall=17463
2022-10-19 21:55:54 | INFO | train_inner | epoch 016:   1654 / 3937 loss=13.467, nll_loss=10.146, mask_ins=1.88, word_ins_ml=10.836, word_reposition=0.752, ppl=11322.5, wps=6081.5, ups=3.69, wpb=1648.8, bsz=50.5, num_updates=60700, lr=0.000202944, gnorm=1.283, clip=0, loss_scale=512, train_wall=27, wall=17490
2022-10-19 21:56:21 | INFO | train_inner | epoch 016:   1754 / 3937 loss=13.455, nll_loss=10.141, mask_ins=1.886, word_ins_ml=10.832, word_reposition=0.738, ppl=11230.7, wps=6221.7, ups=3.67, wpb=1693.8, bsz=51.9, num_updates=60800, lr=0.000202777, gnorm=1.434, clip=0, loss_scale=512, train_wall=27, wall=17518
2022-10-19 21:56:48 | INFO | train_inner | epoch 016:   1854 / 3937 loss=13.472, nll_loss=10.131, mask_ins=1.919, word_ins_ml=10.822, word_reposition=0.731, ppl=11361.1, wps=5920.7, ups=3.69, wpb=1605.2, bsz=48.9, num_updates=60900, lr=0.00020261, gnorm=1.2, clip=0, loss_scale=512, train_wall=27, wall=17545
2022-10-19 21:57:15 | INFO | train_inner | epoch 016:   1954 / 3937 loss=13.448, nll_loss=10.143, mask_ins=1.897, word_ins_ml=10.833, word_reposition=0.718, ppl=11171.4, wps=6334.3, ups=3.69, wpb=1715.1, bsz=51.6, num_updates=61000, lr=0.000202444, gnorm=2.013, clip=1, loss_scale=512, train_wall=27, wall=17572
2022-10-19 21:57:42 | INFO | train_inner | epoch 016:   2054 / 3937 loss=13.482, nll_loss=10.153, mask_ins=1.883, word_ins_ml=10.842, word_reposition=0.758, ppl=11443.3, wps=6033.9, ups=3.71, wpb=1627.1, bsz=48.4, num_updates=61100, lr=0.000202278, gnorm=1.087, clip=0, loss_scale=512, train_wall=27, wall=17599
2022-10-19 21:58:09 | INFO | train_inner | epoch 016:   2154 / 3937 loss=13.394, nll_loss=10.148, mask_ins=1.838, word_ins_ml=10.838, word_reposition=0.718, ppl=10762.1, wps=6489.9, ups=3.7, wpb=1752, bsz=52.8, num_updates=61200, lr=0.000202113, gnorm=1.264, clip=0, loss_scale=512, train_wall=27, wall=17626
2022-10-19 21:58:36 | INFO | train_inner | epoch 016:   2254 / 3937 loss=13.472, nll_loss=10.143, mask_ins=1.885, word_ins_ml=10.832, word_reposition=0.754, ppl=11358.6, wps=6194.7, ups=3.68, wpb=1683.8, bsz=50.7, num_updates=61300, lr=0.000201948, gnorm=1.167, clip=0, loss_scale=512, train_wall=27, wall=17653
2022-10-19 21:59:03 | INFO | train_inner | epoch 016:   2354 / 3937 loss=13.485, nll_loss=10.157, mask_ins=1.847, word_ins_ml=10.845, word_reposition=0.793, ppl=11465.4, wps=6202.5, ups=3.7, wpb=1678.1, bsz=49.8, num_updates=61400, lr=0.000201784, gnorm=2.234, clip=1, loss_scale=512, train_wall=27, wall=17680
2022-10-19 21:59:30 | INFO | train_inner | epoch 016:   2454 / 3937 loss=13.467, nll_loss=10.166, mask_ins=1.87, word_ins_ml=10.853, word_reposition=0.744, ppl=11324.3, wps=6299.4, ups=3.72, wpb=1694, bsz=52, num_updates=61500, lr=0.000201619, gnorm=1.377, clip=0, loss_scale=512, train_wall=27, wall=17707
2022-10-19 21:59:57 | INFO | train_inner | epoch 016:   2554 / 3937 loss=13.503, nll_loss=10.143, mask_ins=1.912, word_ins_ml=10.833, word_reposition=0.758, ppl=11611.7, wps=6392.3, ups=3.68, wpb=1738, bsz=52.7, num_updates=61600, lr=0.000201456, gnorm=1.504, clip=0, loss_scale=512, train_wall=27, wall=17734
2022-10-19 22:00:24 | INFO | train_inner | epoch 016:   2654 / 3937 loss=13.47, nll_loss=10.145, mask_ins=1.898, word_ins_ml=10.834, word_reposition=0.739, ppl=11349.1, wps=6201.2, ups=3.71, wpb=1669.3, bsz=51.5, num_updates=61700, lr=0.000201292, gnorm=1.484, clip=0, loss_scale=512, train_wall=27, wall=17761
2022-10-19 22:00:51 | INFO | train_inner | epoch 016:   2754 / 3937 loss=13.432, nll_loss=10.14, mask_ins=1.862, word_ins_ml=10.831, word_reposition=0.739, ppl=11050.3, wps=6278.3, ups=3.68, wpb=1705.2, bsz=51.5, num_updates=61800, lr=0.000201129, gnorm=1.939, clip=2, loss_scale=512, train_wall=27, wall=17788
2022-10-19 22:01:19 | INFO | train_inner | epoch 016:   2854 / 3937 loss=13.494, nll_loss=10.152, mask_ins=1.891, word_ins_ml=10.84, word_reposition=0.763, ppl=11539.3, wps=5593.1, ups=3.68, wpb=1519.8, bsz=45.2, num_updates=61900, lr=0.000200967, gnorm=1.886, clip=1, loss_scale=512, train_wall=27, wall=17815
2022-10-19 22:01:46 | INFO | train_inner | epoch 016:   2954 / 3937 loss=13.496, nll_loss=10.149, mask_ins=1.895, word_ins_ml=10.838, word_reposition=0.763, ppl=11549.9, wps=6424.7, ups=3.64, wpb=1764.8, bsz=53.6, num_updates=62000, lr=0.000200805, gnorm=1.97, clip=1, loss_scale=512, train_wall=27, wall=17843
2022-10-19 22:02:13 | INFO | train_inner | epoch 016:   3054 / 3937 loss=13.459, nll_loss=10.138, mask_ins=1.891, word_ins_ml=10.828, word_reposition=0.74, ppl=11263.2, wps=6129.1, ups=3.7, wpb=1654.8, bsz=49.9, num_updates=62100, lr=0.000200643, gnorm=1.378, clip=0, loss_scale=512, train_wall=27, wall=17870
2022-10-19 22:02:40 | INFO | train_inner | epoch 016:   3154 / 3937 loss=13.417, nll_loss=10.114, mask_ins=1.879, word_ins_ml=10.808, word_reposition=0.729, ppl=10934.6, wps=6306.7, ups=3.67, wpb=1720.2, bsz=53.3, num_updates=62200, lr=0.000200482, gnorm=1.43, clip=0, loss_scale=512, train_wall=27, wall=17897
2022-10-19 22:03:07 | INFO | train_inner | epoch 016:   3254 / 3937 loss=13.38, nll_loss=10.144, mask_ins=1.845, word_ins_ml=10.833, word_reposition=0.702, ppl=10659.4, wps=5844.5, ups=3.68, wpb=1586.4, bsz=48.1, num_updates=62300, lr=0.000200321, gnorm=1.09, clip=0, loss_scale=512, train_wall=27, wall=17924
2022-10-19 22:03:35 | INFO | train_inner | epoch 016:   3354 / 3937 loss=13.444, nll_loss=10.144, mask_ins=1.881, word_ins_ml=10.833, word_reposition=0.73, ppl=11147.4, wps=6669.1, ups=3.67, wpb=1818.3, bsz=55.5, num_updates=62400, lr=0.00020016, gnorm=1.201, clip=0, loss_scale=512, train_wall=27, wall=17952
2022-10-19 22:04:02 | INFO | train_inner | epoch 016:   3454 / 3937 loss=13.496, nll_loss=10.167, mask_ins=1.902, word_ins_ml=10.854, word_reposition=0.74, ppl=11550.8, wps=6297.8, ups=3.7, wpb=1703.4, bsz=51.3, num_updates=62500, lr=0.0002, gnorm=1.236, clip=0, loss_scale=512, train_wall=27, wall=17979
2022-10-19 22:04:29 | INFO | train_inner | epoch 016:   3554 / 3937 loss=13.41, nll_loss=10.116, mask_ins=1.856, word_ins_ml=10.809, word_reposition=0.745, ppl=10886.9, wps=6692.8, ups=3.6, wpb=1858.3, bsz=57.4, num_updates=62600, lr=0.00019984, gnorm=1.209, clip=0, loss_scale=512, train_wall=27, wall=18006
2022-10-19 22:04:57 | INFO | train_inner | epoch 016:   3654 / 3937 loss=13.516, nll_loss=10.17, mask_ins=1.883, word_ins_ml=10.855, word_reposition=0.778, ppl=11711.2, wps=6137.2, ups=3.68, wpb=1669, bsz=50.1, num_updates=62700, lr=0.000199681, gnorm=1.526, clip=0, loss_scale=512, train_wall=27, wall=18034
2022-10-19 22:05:24 | INFO | train_inner | epoch 016:   3754 / 3937 loss=13.458, nll_loss=10.115, mask_ins=1.902, word_ins_ml=10.809, word_reposition=0.748, ppl=11253.8, wps=6428.7, ups=3.67, wpb=1752.6, bsz=53.7, num_updates=62800, lr=0.000199522, gnorm=2.051, clip=1, loss_scale=512, train_wall=27, wall=18061
2022-10-19 22:05:51 | INFO | train_inner | epoch 016:   3854 / 3937 loss=13.388, nll_loss=10.117, mask_ins=1.846, word_ins_ml=10.81, word_reposition=0.732, ppl=10721.3, wps=6331.6, ups=3.71, wpb=1708.6, bsz=52.2, num_updates=62900, lr=0.000199363, gnorm=1.389, clip=0, loss_scale=512, train_wall=27, wall=18088
2022-10-19 22:06:13 | INFO | train | epoch 016 | loss 13.456 | nll_loss 10.139 | mask_ins 1.88 | word_ins_ml 10.829 | word_reposition 0.746 | ppl 11234.4 | wps 6111.6 | ups 3.6 | wpb 1695.9 | bsz 51.5 | num_updates 62983 | lr 0.000199232 | gnorm 1.668 | clip 0.4 | loss_scale 592 | train_wall 1058 | wall 18110
2022-10-19 22:06:25 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 21.138 | nll_loss 14.665 | mask_ins 4.109 | word_ins_ml 14.709 | word_reposition 2.32 | ppl 2.3076e+06 | wps 27828 | wpb 1503.2 | bsz 51.5 | num_updates 62983 | best_loss 14.267
2022-10-19 22:06:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 16 @ 62983 updates, score 21.138) (writing took 2.9877073670504615 seconds)
2022-10-19 22:06:33 | INFO | train_inner | epoch 017:     17 / 3937 loss=13.432, nll_loss=10.114, mask_ins=1.883, word_ins_ml=10.807, word_reposition=0.742, ppl=11048.7, wps=3905.4, ups=2.4, wpb=1625.7, bsz=48.9, num_updates=63000, lr=0.000199205, gnorm=1.641, clip=1, loss_scale=512, train_wall=27, wall=18129
2022-10-19 22:07:00 | INFO | train_inner | epoch 017:    117 / 3937 loss=13.422, nll_loss=10.135, mask_ins=1.875, word_ins_ml=10.826, word_reposition=0.721, ppl=10972.9, wps=6232.7, ups=3.65, wpb=1706.8, bsz=52, num_updates=63100, lr=0.000199047, gnorm=1.229, clip=0, loss_scale=512, train_wall=27, wall=18157
2022-10-19 22:07:27 | INFO | train_inner | epoch 017:    217 / 3937 loss=13.413, nll_loss=10.163, mask_ins=1.847, word_ins_ml=10.85, word_reposition=0.716, ppl=10909.6, wps=6123.5, ups=3.7, wpb=1656.9, bsz=50.5, num_updates=63200, lr=0.000198889, gnorm=1.206, clip=0, loss_scale=512, train_wall=27, wall=18184
2022-10-19 22:07:54 | INFO | train_inner | epoch 017:    317 / 3937 loss=13.278, nll_loss=10.08, mask_ins=1.805, word_ins_ml=10.777, word_reposition=0.697, ppl=9935.67, wps=6361, ups=3.68, wpb=1728.1, bsz=53.5, num_updates=63300, lr=0.000198732, gnorm=1.263, clip=0, loss_scale=512, train_wall=27, wall=18211
2022-10-19 22:08:22 | INFO | train_inner | epoch 017:    417 / 3937 loss=13.466, nll_loss=10.127, mask_ins=1.89, word_ins_ml=10.818, word_reposition=0.758, ppl=11317.2, wps=6521.1, ups=3.65, wpb=1784.6, bsz=54.6, num_updates=63400, lr=0.000198575, gnorm=1.345, clip=0, loss_scale=512, train_wall=27, wall=18238
2022-10-19 22:08:49 | INFO | train_inner | epoch 017:    517 / 3937 loss=13.434, nll_loss=10.133, mask_ins=1.882, word_ins_ml=10.825, word_reposition=0.727, ppl=11067.8, wps=6382.7, ups=3.7, wpb=1723.5, bsz=53, num_updates=63500, lr=0.000198419, gnorm=1.904, clip=1, loss_scale=512, train_wall=27, wall=18265
2022-10-19 22:09:16 | INFO | train_inner | epoch 017:    617 / 3937 loss=13.367, nll_loss=10.119, mask_ins=1.806, word_ins_ml=10.811, word_reposition=0.75, ppl=10565.3, wps=6670.9, ups=3.68, wpb=1813.2, bsz=54.9, num_updates=63600, lr=0.000198263, gnorm=1.303, clip=0, loss_scale=512, train_wall=27, wall=18293
2022-10-19 22:09:43 | INFO | train_inner | epoch 017:    717 / 3937 loss=13.456, nll_loss=10.122, mask_ins=1.866, word_ins_ml=10.815, word_reposition=0.775, ppl=11239.7, wps=6041.2, ups=3.69, wpb=1636.5, bsz=48.4, num_updates=63700, lr=0.000198107, gnorm=1.791, clip=0, loss_scale=512, train_wall=27, wall=18320
2022-10-19 22:10:10 | INFO | train_inner | epoch 017:    817 / 3937 loss=13.488, nll_loss=10.139, mask_ins=1.919, word_ins_ml=10.828, word_reposition=0.74, ppl=11490.2, wps=6042, ups=3.68, wpb=1641.6, bsz=49.3, num_updates=63800, lr=0.000197952, gnorm=1.459, clip=0, loss_scale=512, train_wall=27, wall=18347
2022-10-19 22:10:37 | INFO | train_inner | epoch 017:    917 / 3937 loss=13.467, nll_loss=10.122, mask_ins=1.915, word_ins_ml=10.813, word_reposition=0.739, ppl=11322.2, wps=6193.2, ups=3.68, wpb=1682.9, bsz=51.4, num_updates=63900, lr=0.000197797, gnorm=1.217, clip=0, loss_scale=742, train_wall=27, wall=18374
2022-10-19 22:11:04 | INFO | train_inner | epoch 017:   1017 / 3937 loss=13.483, nll_loss=10.152, mask_ins=1.896, word_ins_ml=10.841, word_reposition=0.747, ppl=11451.2, wps=6164.3, ups=3.71, wpb=1661.7, bsz=49.9, num_updates=64000, lr=0.000197642, gnorm=1.575, clip=1, loss_scale=1024, train_wall=27, wall=18401
2022-10-19 22:11:32 | INFO | train_inner | epoch 017:   1117 / 3937 loss=13.436, nll_loss=10.117, mask_ins=1.854, word_ins_ml=10.81, word_reposition=0.772, ppl=11084.6, wps=6405.3, ups=3.65, wpb=1755.5, bsz=54.1, num_updates=64100, lr=0.000197488, gnorm=1.409, clip=0, loss_scale=1024, train_wall=27, wall=18428
2022-10-19 22:11:59 | INFO | train_inner | epoch 017:   1217 / 3937 loss=13.423, nll_loss=10.125, mask_ins=1.881, word_ins_ml=10.816, word_reposition=0.725, ppl=10983.6, wps=6170.7, ups=3.62, wpb=1703.2, bsz=53, num_updates=64200, lr=0.000197334, gnorm=1.302, clip=0, loss_scale=1024, train_wall=27, wall=18456
2022-10-19 22:12:26 | INFO | train_inner | epoch 017:   1317 / 3937 loss=13.447, nll_loss=10.113, mask_ins=1.904, word_ins_ml=10.806, word_reposition=0.737, ppl=11166.8, wps=6238.3, ups=3.69, wpb=1692.1, bsz=50.4, num_updates=64300, lr=0.000197181, gnorm=1.158, clip=0, loss_scale=1024, train_wall=27, wall=18483
2022-10-19 22:12:53 | INFO | train_inner | epoch 017:   1417 / 3937 loss=13.491, nll_loss=10.152, mask_ins=1.89, word_ins_ml=10.84, word_reposition=0.761, ppl=11515, wps=5957.2, ups=3.68, wpb=1617.6, bsz=48.3, num_updates=64400, lr=0.000197028, gnorm=1.852, clip=1, loss_scale=1024, train_wall=27, wall=18510
2022-10-19 22:13:21 | INFO | train_inner | epoch 017:   1517 / 3937 loss=13.384, nll_loss=10.118, mask_ins=1.817, word_ins_ml=10.811, word_reposition=0.756, ppl=10686.9, wps=6343.3, ups=3.67, wpb=1727.2, bsz=52.3, num_updates=64500, lr=0.000196875, gnorm=1.402, clip=0, loss_scale=1024, train_wall=27, wall=18537
2022-10-19 22:13:48 | INFO | train_inner | epoch 017:   1617 / 3937 loss=13.467, nll_loss=10.185, mask_ins=1.855, word_ins_ml=10.868, word_reposition=0.743, ppl=11321.4, wps=6024.6, ups=3.68, wpb=1635.3, bsz=48.9, num_updates=64600, lr=0.000196722, gnorm=1.164, clip=0, loss_scale=1024, train_wall=27, wall=18565
2022-10-19 22:14:15 | INFO | train_inner | epoch 017:   1717 / 3937 loss=13.425, nll_loss=10.165, mask_ins=1.841, word_ins_ml=10.852, word_reposition=0.731, ppl=10997.1, wps=6285.3, ups=3.69, wpb=1705.2, bsz=51.3, num_updates=64700, lr=0.00019657, gnorm=1.914, clip=0, loss_scale=1024, train_wall=27, wall=18592
2022-10-19 22:14:42 | INFO | train_inner | epoch 017:   1817 / 3937 loss=13.481, nll_loss=10.138, mask_ins=1.884, word_ins_ml=10.828, word_reposition=0.768, ppl=11432.5, wps=6063.6, ups=3.68, wpb=1649.5, bsz=50.3, num_updates=64800, lr=0.000196419, gnorm=1.976, clip=1, loss_scale=1024, train_wall=27, wall=18619
2022-10-19 22:15:10 | INFO | train_inner | epoch 017:   1917 / 3937 loss=13.429, nll_loss=10.173, mask_ins=1.823, word_ins_ml=10.858, word_reposition=0.748, ppl=11032, wps=6110.7, ups=3.64, wpb=1679.6, bsz=50.5, num_updates=64900, lr=0.000196267, gnorm=1.972, clip=1, loss_scale=1024, train_wall=27, wall=18646
2022-10-19 22:15:37 | INFO | train_inner | epoch 017:   2017 / 3937 loss=13.421, nll_loss=10.153, mask_ins=1.842, word_ins_ml=10.842, word_reposition=0.737, ppl=10967.5, wps=6221.2, ups=3.7, wpb=1680, bsz=51.3, num_updates=65000, lr=0.000196116, gnorm=1.22, clip=0, loss_scale=1024, train_wall=27, wall=18673
2022-10-19 22:16:04 | INFO | train_inner | epoch 017:   2117 / 3937 loss=13.453, nll_loss=10.154, mask_ins=1.885, word_ins_ml=10.842, word_reposition=0.726, ppl=11216.7, wps=6073.6, ups=3.68, wpb=1652.7, bsz=50.5, num_updates=65100, lr=0.000195965, gnorm=1.577, clip=0, loss_scale=1024, train_wall=27, wall=18701
2022-10-19 22:16:31 | INFO | train_inner | epoch 017:   2217 / 3937 loss=13.482, nll_loss=10.17, mask_ins=1.891, word_ins_ml=10.856, word_reposition=0.734, ppl=11443, wps=6105.2, ups=3.7, wpb=1649.3, bsz=50, num_updates=65200, lr=0.000195815, gnorm=1.788, clip=1, loss_scale=1024, train_wall=27, wall=18728
2022-10-19 22:16:58 | INFO | train_inner | epoch 017:   2317 / 3937 loss=13.521, nll_loss=10.149, mask_ins=1.936, word_ins_ml=10.838, word_reposition=0.747, ppl=11758.2, wps=6342.2, ups=3.66, wpb=1732.4, bsz=53.4, num_updates=65300, lr=0.000195665, gnorm=2.107, clip=2, loss_scale=1024, train_wall=27, wall=18755
2022-10-19 22:17:25 | INFO | train_inner | epoch 017:   2417 / 3937 loss=13.466, nll_loss=10.152, mask_ins=1.902, word_ins_ml=10.84, word_reposition=0.724, ppl=11314.4, wps=6090, ups=3.74, wpb=1629.6, bsz=49.2, num_updates=65400, lr=0.000195515, gnorm=1.303, clip=0, loss_scale=1024, train_wall=26, wall=18782
2022-10-19 22:17:52 | INFO | train_inner | epoch 017:   2517 / 3937 loss=13.464, nll_loss=10.145, mask_ins=1.891, word_ins_ml=10.835, word_reposition=0.738, ppl=11301.3, wps=6346, ups=3.66, wpb=1734.5, bsz=52.5, num_updates=65500, lr=0.000195366, gnorm=1.273, clip=0, loss_scale=1024, train_wall=27, wall=18809
2022-10-19 22:18:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-10-19 22:18:19 | INFO | train_inner | epoch 017:   2618 / 3937 loss=13.451, nll_loss=10.14, mask_ins=1.89, word_ins_ml=10.831, word_reposition=0.731, ppl=11199.8, wps=5883, ups=3.67, wpb=1604.5, bsz=49.1, num_updates=65600, lr=0.000195217, gnorm=1.924, clip=1, loss_scale=715, train_wall=27, wall=18836
2022-10-19 22:18:47 | INFO | train_inner | epoch 017:   2718 / 3937 loss=13.466, nll_loss=10.152, mask_ins=1.877, word_ins_ml=10.842, word_reposition=0.747, ppl=11317, wps=6383.5, ups=3.7, wpb=1725.6, bsz=52.3, num_updates=65700, lr=0.000195069, gnorm=1.47, clip=0, loss_scale=512, train_wall=27, wall=18863
2022-10-19 22:19:13 | INFO | train_inner | epoch 017:   2818 / 3937 loss=13.379, nll_loss=10.145, mask_ins=1.837, word_ins_ml=10.834, word_reposition=0.707, ppl=10652.5, wps=6457.2, ups=3.73, wpb=1731.1, bsz=52.8, num_updates=65800, lr=0.00019492, gnorm=1.385, clip=0, loss_scale=512, train_wall=26, wall=18890
2022-10-19 22:19:41 | INFO | train_inner | epoch 017:   2918 / 3937 loss=13.46, nll_loss=10.146, mask_ins=1.899, word_ins_ml=10.835, word_reposition=0.727, ppl=11271.4, wps=5884.9, ups=3.68, wpb=1599.7, bsz=48.8, num_updates=65900, lr=0.000194772, gnorm=1.317, clip=0, loss_scale=512, train_wall=27, wall=18917
2022-10-19 22:20:08 | INFO | train_inner | epoch 017:   3018 / 3937 loss=13.484, nll_loss=10.124, mask_ins=1.936, word_ins_ml=10.816, word_reposition=0.732, ppl=11455.3, wps=6140.3, ups=3.7, wpb=1657.5, bsz=50.3, num_updates=66000, lr=0.000194625, gnorm=1.448, clip=0, loss_scale=512, train_wall=27, wall=18944
2022-10-19 22:20:35 | INFO | train_inner | epoch 017:   3118 / 3937 loss=13.395, nll_loss=10.108, mask_ins=1.87, word_ins_ml=10.802, word_reposition=0.723, ppl=10771.8, wps=6641.5, ups=3.62, wpb=1835.8, bsz=56.7, num_updates=66100, lr=0.000194477, gnorm=1.36, clip=0, loss_scale=512, train_wall=27, wall=18972
2022-10-19 22:21:03 | INFO | train_inner | epoch 017:   3218 / 3937 loss=13.458, nll_loss=10.152, mask_ins=1.87, word_ins_ml=10.841, word_reposition=0.746, ppl=11249.2, wps=6373.2, ups=3.62, wpb=1758.2, bsz=54, num_updates=66200, lr=0.000194331, gnorm=1.437, clip=0, loss_scale=512, train_wall=27, wall=19000
2022-10-19 22:21:30 | INFO | train_inner | epoch 017:   3318 / 3937 loss=13.366, nll_loss=10.113, mask_ins=1.844, word_ins_ml=10.807, word_reposition=0.715, ppl=10558.7, wps=6218.4, ups=3.67, wpb=1694.5, bsz=51.1, num_updates=66300, lr=0.000194184, gnorm=1.293, clip=0, loss_scale=512, train_wall=27, wall=19027
2022-10-19 22:21:57 | INFO | train_inner | epoch 017:   3418 / 3937 loss=13.408, nll_loss=10.127, mask_ins=1.828, word_ins_ml=10.818, word_reposition=0.761, ppl=10868.8, wps=6395.9, ups=3.66, wpb=1746, bsz=53.2, num_updates=66400, lr=0.000194038, gnorm=2.378, clip=1, loss_scale=512, train_wall=27, wall=19054
2022-10-19 22:22:24 | INFO | train_inner | epoch 017:   3518 / 3937 loss=13.47, nll_loss=10.155, mask_ins=1.886, word_ins_ml=10.843, word_reposition=0.741, ppl=11343.6, wps=6233.6, ups=3.7, wpb=1684.3, bsz=50.5, num_updates=66500, lr=0.000193892, gnorm=1.13, clip=0, loss_scale=512, train_wall=27, wall=19081
2022-10-19 22:22:51 | INFO | train_inner | epoch 017:   3618 / 3937 loss=13.405, nll_loss=10.117, mask_ins=1.851, word_ins_ml=10.811, word_reposition=0.744, ppl=10844, wps=6396.9, ups=3.69, wpb=1731.4, bsz=53, num_updates=66600, lr=0.000193746, gnorm=1.37, clip=0, loss_scale=512, train_wall=27, wall=19108
2022-10-19 22:23:18 | INFO | train_inner | epoch 017:   3718 / 3937 loss=13.451, nll_loss=10.135, mask_ins=1.877, word_ins_ml=10.825, word_reposition=0.749, ppl=11200.2, wps=6141.2, ups=3.72, wpb=1648.7, bsz=49.6, num_updates=66700, lr=0.000193601, gnorm=1.338, clip=0, loss_scale=512, train_wall=27, wall=19135
2022-10-19 22:23:45 | INFO | train_inner | epoch 017:   3818 / 3937 loss=13.47, nll_loss=10.165, mask_ins=1.878, word_ins_ml=10.852, word_reposition=0.74, ppl=11350, wps=6365, ups=3.69, wpb=1723.8, bsz=52, num_updates=66800, lr=0.000193456, gnorm=1.318, clip=0, loss_scale=512, train_wall=27, wall=19162
2022-10-19 22:24:13 | INFO | train_inner | epoch 017:   3918 / 3937 loss=13.469, nll_loss=10.148, mask_ins=1.871, word_ins_ml=10.837, word_reposition=0.76, ppl=11337.1, wps=6421.5, ups=3.68, wpb=1746.3, bsz=51.9, num_updates=66900, lr=0.000193311, gnorm=1.394, clip=0, loss_scale=512, train_wall=27, wall=19189
2022-10-19 22:24:18 | INFO | train | epoch 017 | loss 13.44 | nll_loss 10.139 | mask_ins 1.872 | word_ins_ml 10.829 | word_reposition 0.739 | ppl 11114.8 | wps 6157.9 | ups 3.63 | wpb 1696.2 | bsz 51.5 | num_updates 66919 | lr 0.000193284 | gnorm 1.492 | clip 0.3 | loss_scale 731 | train_wall 1059 | wall 19194
2022-10-19 22:24:29 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 23.998 | nll_loss 15.641 | mask_ins 6.072 | word_ins_ml 15.588 | word_reposition 2.338 | ppl 1.67562e+07 | wps 27726.7 | wpb 1503.2 | bsz 51.5 | num_updates 66919 | best_loss 14.267
2022-10-19 22:24:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 17 @ 66919 updates, score 23.998) (writing took 3.0391680529573932 seconds)
2022-10-19 22:24:55 | INFO | train_inner | epoch 018:     81 / 3937 loss=13.401, nll_loss=10.142, mask_ins=1.849, word_ins_ml=10.831, word_reposition=0.721, ppl=10818.2, wps=4399.8, ups=2.38, wpb=1847.6, bsz=56.6, num_updates=67000, lr=0.000193167, gnorm=1.324, clip=0, loss_scale=512, train_wall=27, wall=19231
2022-10-19 22:25:22 | INFO | train_inner | epoch 018:    181 / 3937 loss=13.377, nll_loss=10.114, mask_ins=1.834, word_ins_ml=10.806, word_reposition=0.737, ppl=10638.2, wps=6566.6, ups=3.67, wpb=1790.3, bsz=54.8, num_updates=67100, lr=0.000193023, gnorm=1.387, clip=0, loss_scale=512, train_wall=27, wall=19259
2022-10-19 22:25:49 | INFO | train_inner | epoch 018:    281 / 3937 loss=13.477, nll_loss=10.146, mask_ins=1.883, word_ins_ml=10.836, word_reposition=0.758, ppl=11404.9, wps=6499.8, ups=3.66, wpb=1774.4, bsz=54, num_updates=67200, lr=0.000192879, gnorm=1.701, clip=1, loss_scale=512, train_wall=27, wall=19286
2022-10-19 22:26:16 | INFO | train_inner | epoch 018:    381 / 3937 loss=13.358, nll_loss=10.118, mask_ins=1.806, word_ins_ml=10.811, word_reposition=0.741, ppl=10497.1, wps=6354.2, ups=3.67, wpb=1730.7, bsz=53, num_updates=67300, lr=0.000192736, gnorm=1.228, clip=0, loss_scale=512, train_wall=27, wall=19313
2022-10-19 22:26:44 | INFO | train_inner | epoch 018:    481 / 3937 loss=13.444, nll_loss=10.114, mask_ins=1.9, word_ins_ml=10.807, word_reposition=0.737, ppl=11148, wps=6103.8, ups=3.66, wpb=1668.4, bsz=50.4, num_updates=67400, lr=0.000192593, gnorm=1.299, clip=0, loss_scale=512, train_wall=27, wall=19340
2022-10-19 22:27:11 | INFO | train_inner | epoch 018:    581 / 3937 loss=13.414, nll_loss=10.132, mask_ins=1.832, word_ins_ml=10.824, word_reposition=0.758, ppl=10913.7, wps=6673.9, ups=3.69, wpb=1806.8, bsz=54.4, num_updates=67500, lr=0.00019245, gnorm=1.737, clip=1, loss_scale=512, train_wall=27, wall=19368
2022-10-19 22:27:38 | INFO | train_inner | epoch 018:    681 / 3937 loss=13.412, nll_loss=10.122, mask_ins=1.844, word_ins_ml=10.813, word_reposition=0.755, ppl=10896, wps=6610.1, ups=3.63, wpb=1820.9, bsz=55.5, num_updates=67600, lr=0.000192308, gnorm=1.519, clip=0, loss_scale=512, train_wall=27, wall=19395
2022-10-19 22:28:05 | INFO | train_inner | epoch 018:    781 / 3937 loss=13.425, nll_loss=10.139, mask_ins=1.856, word_ins_ml=10.829, word_reposition=0.74, ppl=11001.6, wps=6080.3, ups=3.67, wpb=1654.5, bsz=49.8, num_updates=67700, lr=0.000192166, gnorm=1.23, clip=0, loss_scale=512, train_wall=27, wall=19422
2022-10-19 22:28:32 | INFO | train_inner | epoch 018:    881 / 3937 loss=13.511, nll_loss=10.157, mask_ins=1.901, word_ins_ml=10.844, word_reposition=0.766, ppl=11673.5, wps=6147, ups=3.7, wpb=1660.1, bsz=50.2, num_updates=67800, lr=0.000192024, gnorm=1.492, clip=0, loss_scale=512, train_wall=27, wall=19449
2022-10-19 22:28:59 | INFO | train_inner | epoch 018:    981 / 3937 loss=13.384, nll_loss=10.125, mask_ins=1.813, word_ins_ml=10.816, word_reposition=0.755, ppl=10690.5, wps=6139.9, ups=3.73, wpb=1648.2, bsz=49.9, num_updates=67900, lr=0.000191882, gnorm=1.818, clip=1, loss_scale=512, train_wall=27, wall=19476
2022-10-19 22:29:26 | INFO | train_inner | epoch 018:   1081 / 3937 loss=13.433, nll_loss=10.131, mask_ins=1.872, word_ins_ml=10.822, word_reposition=0.74, ppl=11061.3, wps=5760, ups=3.7, wpb=1554.7, bsz=47.5, num_updates=68000, lr=0.000191741, gnorm=3.613, clip=1, loss_scale=512, train_wall=27, wall=19503
2022-10-19 22:29:54 | INFO | train_inner | epoch 018:   1181 / 3937 loss=13.442, nll_loss=10.129, mask_ins=1.877, word_ins_ml=10.821, word_reposition=0.744, ppl=11128.7, wps=6444.6, ups=3.66, wpb=1758.7, bsz=52.4, num_updates=68100, lr=0.0001916, gnorm=1.793, clip=1, loss_scale=512, train_wall=27, wall=19530
2022-10-19 22:30:21 | INFO | train_inner | epoch 018:   1281 / 3937 loss=13.447, nll_loss=10.129, mask_ins=1.898, word_ins_ml=10.821, word_reposition=0.729, ppl=11165.5, wps=6850.4, ups=3.66, wpb=1872.9, bsz=58.3, num_updates=68200, lr=0.00019146, gnorm=1.543, clip=0, loss_scale=512, train_wall=27, wall=19558
2022-10-19 22:30:48 | INFO | train_inner | epoch 018:   1381 / 3937 loss=13.441, nll_loss=10.14, mask_ins=1.857, word_ins_ml=10.83, word_reposition=0.753, ppl=11118.3, wps=6476.8, ups=3.68, wpb=1759.1, bsz=52.9, num_updates=68300, lr=0.00019132, gnorm=1.687, clip=0, loss_scale=512, train_wall=27, wall=19585
2022-10-19 22:31:15 | INFO | train_inner | epoch 018:   1481 / 3937 loss=13.505, nll_loss=10.179, mask_ins=1.883, word_ins_ml=10.864, word_reposition=0.758, ppl=11624.6, wps=6070.9, ups=3.71, wpb=1638.2, bsz=49.1, num_updates=68400, lr=0.00019118, gnorm=1.233, clip=0, loss_scale=512, train_wall=27, wall=19612
2022-10-19 22:31:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-10-19 22:31:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-10-19 22:31:43 | INFO | train_inner | epoch 018:   1583 / 3937 loss=13.431, nll_loss=10.141, mask_ins=1.863, word_ins_ml=10.831, word_reposition=0.736, ppl=11046, wps=5838.4, ups=3.64, wpb=1604.3, bsz=48.2, num_updates=68500, lr=0.00019104, gnorm=1.244, clip=0, loss_scale=257, train_wall=27, wall=19639
2022-10-19 22:32:10 | INFO | train_inner | epoch 018:   1683 / 3937 loss=13.378, nll_loss=10.102, mask_ins=1.826, word_ins_ml=10.799, word_reposition=0.754, ppl=10645.7, wps=5652, ups=3.66, wpb=1542.7, bsz=47.4, num_updates=68600, lr=0.000190901, gnorm=1.956, clip=1, loss_scale=128, train_wall=27, wall=19667
2022-10-19 22:32:37 | INFO | train_inner | epoch 018:   1783 / 3937 loss=13.475, nll_loss=10.143, mask_ins=1.896, word_ins_ml=10.832, word_reposition=0.748, ppl=11388.4, wps=6254.5, ups=3.69, wpb=1696.2, bsz=51.8, num_updates=68700, lr=0.000190762, gnorm=1.257, clip=0, loss_scale=128, train_wall=27, wall=19694
2022-10-19 22:32:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2022-10-19 22:33:05 | INFO | train_inner | epoch 018:   1884 / 3937 loss=13.349, nll_loss=10.135, mask_ins=1.781, word_ins_ml=10.825, word_reposition=0.744, ppl=10435.3, wps=6589.5, ups=3.61, wpb=1827.8, bsz=56.7, num_updates=68800, lr=0.000190623, gnorm=1.783, clip=0, loss_scale=106, train_wall=27, wall=19722
2022-10-19 22:33:32 | INFO | train_inner | epoch 018:   1984 / 3937 loss=13.5, nll_loss=10.14, mask_ins=1.91, word_ins_ml=10.83, word_reposition=0.76, ppl=11584.7, wps=6187, ups=3.7, wpb=1672.3, bsz=51.1, num_updates=68900, lr=0.000190485, gnorm=1.416, clip=0, loss_scale=64, train_wall=27, wall=19749
2022-10-19 22:33:59 | INFO | train_inner | epoch 018:   2084 / 3937 loss=13.45, nll_loss=10.141, mask_ins=1.869, word_ins_ml=10.832, word_reposition=0.749, ppl=11189.1, wps=5983.4, ups=3.69, wpb=1623.6, bsz=48.5, num_updates=69000, lr=0.000190347, gnorm=1.423, clip=0, loss_scale=64, train_wall=27, wall=19776
2022-10-19 22:34:26 | INFO | train_inner | epoch 018:   2184 / 3937 loss=13.427, nll_loss=10.133, mask_ins=1.859, word_ins_ml=10.823, word_reposition=0.745, ppl=11010.7, wps=6408, ups=3.68, wpb=1741.1, bsz=52.3, num_updates=69100, lr=0.000190209, gnorm=1.457, clip=0, loss_scale=64, train_wall=27, wall=19803
2022-10-19 22:34:53 | INFO | train_inner | epoch 018:   2284 / 3937 loss=13.452, nll_loss=10.161, mask_ins=1.868, word_ins_ml=10.848, word_reposition=0.735, ppl=11202.9, wps=6463.4, ups=3.65, wpb=1770.4, bsz=52.7, num_updates=69200, lr=0.000190071, gnorm=1.413, clip=0, loss_scale=64, train_wall=27, wall=19830
2022-10-19 22:35:21 | INFO | train_inner | epoch 018:   2384 / 3937 loss=13.451, nll_loss=10.135, mask_ins=1.878, word_ins_ml=10.827, word_reposition=0.746, ppl=11198.1, wps=6413.7, ups=3.65, wpb=1757.7, bsz=53.6, num_updates=69300, lr=0.000189934, gnorm=1.604, clip=0, loss_scale=64, train_wall=27, wall=19858
2022-10-19 22:35:48 | INFO | train_inner | epoch 018:   2484 / 3937 loss=13.404, nll_loss=10.121, mask_ins=1.868, word_ins_ml=10.813, word_reposition=0.722, ppl=10836.4, wps=6283.8, ups=3.69, wpb=1701.7, bsz=51.2, num_updates=69400, lr=0.000189797, gnorm=1.464, clip=0, loss_scale=64, train_wall=27, wall=19885
2022-10-19 22:36:15 | INFO | train_inner | epoch 018:   2584 / 3937 loss=13.48, nll_loss=10.136, mask_ins=1.919, word_ins_ml=10.826, word_reposition=0.735, ppl=11427.9, wps=6277.2, ups=3.7, wpb=1694.8, bsz=51.4, num_updates=69500, lr=0.000189661, gnorm=1.303, clip=0, loss_scale=64, train_wall=27, wall=19912
2022-10-19 22:36:42 | INFO | train_inner | epoch 018:   2684 / 3937 loss=13.441, nll_loss=10.155, mask_ins=1.87, word_ins_ml=10.843, word_reposition=0.727, ppl=11120.9, wps=6169.6, ups=3.7, wpb=1666.3, bsz=50.4, num_updates=69600, lr=0.000189525, gnorm=1.956, clip=1, loss_scale=64, train_wall=27, wall=19939
2022-10-19 22:37:09 | INFO | train_inner | epoch 018:   2784 / 3937 loss=13.448, nll_loss=10.147, mask_ins=1.884, word_ins_ml=10.836, word_reposition=0.728, ppl=11171.4, wps=6214.1, ups=3.69, wpb=1686, bsz=51, num_updates=69700, lr=0.000189389, gnorm=1.285, clip=0, loss_scale=64, train_wall=27, wall=19966
2022-10-19 22:37:36 | INFO | train_inner | epoch 018:   2884 / 3937 loss=13.414, nll_loss=10.13, mask_ins=1.828, word_ins_ml=10.821, word_reposition=0.765, ppl=10911.8, wps=6200.1, ups=3.7, wpb=1673.8, bsz=51.8, num_updates=69800, lr=0.000189253, gnorm=1.665, clip=0, loss_scale=64, train_wall=27, wall=19993
2022-10-19 22:38:03 | INFO | train_inner | epoch 018:   2984 / 3937 loss=13.422, nll_loss=10.122, mask_ins=1.875, word_ins_ml=10.814, word_reposition=0.734, ppl=10977.5, wps=6524.7, ups=3.67, wpb=1777.3, bsz=54.8, num_updates=69900, lr=0.000189117, gnorm=1.718, clip=0, loss_scale=64, train_wall=27, wall=20020
2022-10-19 22:38:22 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2022-10-19 22:38:31 | INFO | train_inner | epoch 018:   3085 / 3937 loss=13.443, nll_loss=10.128, mask_ins=1.881, word_ins_ml=10.819, word_reposition=0.742, ppl=11135.7, wps=6236.6, ups=3.68, wpb=1694.7, bsz=51.3, num_updates=70000, lr=0.000188982, gnorm=1.288, clip=0, loss_scale=54, train_wall=27, wall=20047
2022-10-19 22:38:57 | INFO | train_inner | epoch 018:   3185 / 3937 loss=13.455, nll_loss=10.141, mask_ins=1.884, word_ins_ml=10.83, word_reposition=0.74, ppl=11231.1, wps=6193.5, ups=3.71, wpb=1671, bsz=49.8, num_updates=70100, lr=0.000188847, gnorm=1.512, clip=0, loss_scale=32, train_wall=27, wall=20074
2022-10-19 22:39:25 | INFO | train_inner | epoch 018:   3285 / 3937 loss=13.477, nll_loss=10.138, mask_ins=1.891, word_ins_ml=10.827, word_reposition=0.759, ppl=11402.9, wps=6080.7, ups=3.7, wpb=1645.1, bsz=49.9, num_updates=70200, lr=0.000188713, gnorm=2.131, clip=1, loss_scale=32, train_wall=27, wall=20101
2022-10-19 22:39:52 | INFO | train_inner | epoch 018:   3385 / 3937 loss=13.457, nll_loss=10.158, mask_ins=1.878, word_ins_ml=10.845, word_reposition=0.733, ppl=11243.4, wps=5637.5, ups=3.71, wpb=1521.4, bsz=46.3, num_updates=70300, lr=0.000188579, gnorm=1.297, clip=0, loss_scale=32, train_wall=27, wall=20128
2022-10-19 22:40:19 | INFO | train_inner | epoch 018:   3485 / 3937 loss=13.443, nll_loss=10.159, mask_ins=1.837, word_ins_ml=10.847, word_reposition=0.759, ppl=11135.9, wps=6032.1, ups=3.71, wpb=1627.3, bsz=48.2, num_updates=70400, lr=0.000188445, gnorm=1.879, clip=0, loss_scale=32, train_wall=27, wall=20155
2022-10-19 22:40:46 | INFO | train_inner | epoch 018:   3585 / 3937 loss=13.416, nll_loss=10.127, mask_ins=1.867, word_ins_ml=10.818, word_reposition=0.73, ppl=10927.6, wps=6282.4, ups=3.69, wpb=1702.6, bsz=52.1, num_updates=70500, lr=0.000188311, gnorm=1.362, clip=0, loss_scale=32, train_wall=27, wall=20182
2022-10-19 22:41:13 | INFO | train_inner | epoch 018:   3685 / 3937 loss=13.443, nll_loss=10.121, mask_ins=1.88, word_ins_ml=10.812, word_reposition=0.75, ppl=11137.2, wps=5694.1, ups=3.67, wpb=1551.8, bsz=47.8, num_updates=70600, lr=0.000188177, gnorm=1.938, clip=1, loss_scale=32, train_wall=27, wall=20210
2022-10-19 22:41:40 | INFO | train_inner | epoch 018:   3785 / 3937 loss=13.42, nll_loss=10.132, mask_ins=1.866, word_ins_ml=10.824, word_reposition=0.73, ppl=10957.7, wps=6327.5, ups=3.66, wpb=1727.9, bsz=53, num_updates=70700, lr=0.000188044, gnorm=1.643, clip=0, loss_scale=32, train_wall=27, wall=20237
2022-10-19 22:42:07 | INFO | train_inner | epoch 018:   3885 / 3937 loss=13.466, nll_loss=10.142, mask_ins=1.867, word_ins_ml=10.83, word_reposition=0.769, ppl=11317.2, wps=6094.6, ups=3.68, wpb=1657.3, bsz=49.8, num_updates=70800, lr=0.000187912, gnorm=1.463, clip=0, loss_scale=32, train_wall=27, wall=20264
2022-10-19 22:42:22 | INFO | train | epoch 018 | loss 13.437 | nll_loss 10.136 | mask_ins 1.866 | word_ins_ml 10.826 | word_reposition 0.745 | ppl 11089.6 | wps 6155.6 | ups 3.63 | wpb 1696.5 | bsz 51.5 | num_updates 70852 | lr 0.000187843 | gnorm 1.604 | clip 0.3 | loss_scale 235 | train_wall 1059 | wall 20278
2022-10-19 22:42:33 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 21.828 | nll_loss 14.719 | mask_ins 5.061 | word_ins_ml 14.76 | word_reposition 2.006 | ppl 3.72171e+06 | wps 27764.7 | wpb 1503.2 | bsz 51.5 | num_updates 70852 | best_loss 14.267
2022-10-19 22:42:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_transformer_transformer_cased_uf1_XSum/checkpoint_last.pt (epoch 18 @ 70852 updates, score 21.828) (writing took 2.8748538410291076 seconds)
2022-10-19 22:42:49 | INFO | train_inner | epoch 019:     48 / 3937 loss=13.506, nll_loss=10.136, mask_ins=1.906, word_ins_ml=10.827, word_reposition=0.773, ppl=11635.9, wps=3860.1, ups=2.39, wpb=1613.5, bsz=49.2, num_updates=70900, lr=0.000187779, gnorm=1.951, clip=1, loss_scale=32, train_wall=27, wall=20306
2022-10-19 22:43:16 | INFO | train_inner | epoch 019:    148 / 3937 loss=13.377, nll_loss=10.123, mask_ins=1.812, word_ins_ml=10.815, word_reposition=0.75, ppl=10635.7, wps=6128.9, ups=3.71, wpb=1653.8, bsz=50.2, num_updates=71000, lr=0.000187647, gnorm=1.353, clip=0, loss_scale=32, train_wall=27, wall=20333
2022-10-19 22:43:44 | INFO | train_inner | epoch 019:    248 / 3937 loss=13.485, nll_loss=10.127, mask_ins=1.905, word_ins_ml=10.818, word_reposition=0.763, ppl=11468.8, wps=6275, ups=3.65, wpb=1718.4, bsz=51.7, num_updates=71100, lr=0.000187515, gnorm=3.92, clip=2, loss_scale=32, train_wall=27, wall=20360
2022-10-19 22:44:11 | INFO | train_inner | epoch 019:    348 / 3937 loss=13.501, nll_loss=10.15, mask_ins=1.909, word_ins_ml=10.839, word_reposition=0.753, ppl=11596.9, wps=6031.2, ups=3.69, wpb=1634, bsz=49.3, num_updates=71200, lr=0.000187383, gnorm=1.97, clip=1, loss_scale=32, train_wall=27, wall=20387
2022-10-19 22:44:38 | INFO | train_inner | epoch 019:    448 / 3937 loss=13.427, nll_loss=10.149, mask_ins=1.818, word_ins_ml=10.837, word_reposition=0.772, ppl=11012, wps=6614.7, ups=3.65, wpb=1811.2, bsz=55.9, num_updates=71300, lr=0.000187251, gnorm=1.475, clip=0, loss_scale=32, train_wall=27, wall=20415
2022-10-19 22:45:05 | INFO | train_inner | epoch 019:    548 / 3937 loss=13.424, nll_loss=10.148, mask_ins=1.834, word_ins_ml=10.836, word_reposition=0.755, ppl=10993.4, wps=6332.3, ups=3.69, wpb=1715.5, bsz=51.4, num_updates=71400, lr=0.00018712, gnorm=1.515, clip=0, loss_scale=32, train_wall=27, wall=20442
2022-10-19 22:45:22 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2022-10-19 22:45:32 | INFO | train_inner | epoch 019:    649 / 3937 loss=13.484, nll_loss=10.139, mask_ins=1.919, word_ins_ml=10.828, word_reposition=0.737, ppl=11455.1, wps=5932.5, ups=3.68, wpb=1610.5, bsz=48.2, num_updates=71500, lr=0.000186989, gnorm=2.438, clip=1, loss_scale=26, train_wall=27, wall=20469
2022-10-19 22:45:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2022-10-19 22:45:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2022-10-19 22:45:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2022-10-19 22:45:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1.0
2022-10-19 22:46:00 | INFO | train_inner | epoch 019:    753 / 3937 loss=13.392, nll_loss=10.133, mask_ins=1.844, word_ins_ml=10.826, word_reposition=0.722, ppl=10750, wps=5693.7, ups=3.57, wpb=1592.7, bsz=47.9, num_updates=71600, lr=0.000186859, gnorm=2.109, clip=1, loss_scale=4, train_wall=28, wall=20497
2022-10-19 22:46:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 0.5
2022-10-19 22:46:28 | INFO | train_inner | epoch 019:    854 / 3937 loss=13.443, nll_loss=10.118, mask_ins=1.866, word_ins_ml=10.821, word_reposition=0.756, ppl=11135.2, wps=6295.1, ups=3.64, wpb=1728.2, bsz=54.2, num_updates=71700, lr=0.000186728, gnorm=2.162, clip=0, loss_scale=1, train_wall=27, wall=20525
Traceback (most recent call last):
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq_cli/train.py", line 369, in cli_main
    torch.multiprocessing.spawn(
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 130, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGTERM
