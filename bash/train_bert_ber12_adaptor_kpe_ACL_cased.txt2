nohup: ignoring input
2022-07-18 12:28:24 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:19342
2022-07-18 12:28:24 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:19342
2022-07-18 12:28:24 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:19342
2022-07-18 12:28:24 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:19342
2022-07-18 12:28:24 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2022-07-18 12:28:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2022-07-18 12:28:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2022-07-18 12:28:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2022-07-18 12:28:25 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-07-18 12:28:25 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 0
2022-07-18 12:28:25 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-07-18 12:28:25 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 3
2022-07-18 12:28:25 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-07-18 12:28:25 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 1
2022-07-18 12:28:25 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-07-18 12:28:25 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 2
2022-07-18 12:28:29 | INFO | fairseq_cli.train | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir='', seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, criterion='nat_loss', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', task='translation_lev', num_workers=0, skip_invalid_size_inputs_valid_test=True, max_tokens=None, max_sentences=8, required_batch_size_multiple=8, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, fixed_validation_seed=7, disable_validation=False, max_tokens_valid=None, max_sentences_valid=8, curriculum=0, distributed_world_size=4, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:19342', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, arch='kpe_editor_transformer_with_adapter', max_epoch=0, max_update=100000, clip_norm=25, sentence_avg=False, update_freq=[8], lr=[0.0005], min_lr=1e-09, use_bmuf=False, save_dir='../checkpoints_bert_bert12_adaptor_kpe_target_ACL_cased', restore_file='checkpoint_last.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, keep_best_checkpoints=3, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, no_token_positional_embeddings=False, no_cross_attention=False, cross_self_attention=False, encoder_layerdrop=0, decoder_layerdrop=0, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, early_exit='12,12,12', layers_num='12,12,12', finetune_embeddings=False, finetune_whole_encoder=False, decoder_adapter_dimention=2048, finetune_position_embeddings=False, use_adapter_bert=True, keywords_num=40, label_smoothing=0.1, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, warmup_updates=5000, warmup_init_lr=1e-07, data='../data-bin-ACL-bert-cased-510', source_lang=None, target_lang=None, load_alignments=False, left_pad_source='False', left_pad_target='False', max_source_positions=512, max_target_positions=512, upsample_primary=1, truncate_source=False, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, noise='random_delete_shuffle', random_seed=1, cached_features_dir='/data/yukangliang/数据集/preprocess/ACL-bert-cased-510/cached_examples_bert_cased_510', tokenizer_dir='/data/yukangliang/预训练模型/bert-base-cased', encoder_adapter_dimention=2048, decoder_input='target', kpe=True, share_all_embeddings=True, no_share_discriminator=True, dropout=0.3, decoder_learned_pos=True, encoder_learned_pos=True, apply_bert_init=True, cache_dir='/data/yukangliang/预训练模型/bert-base-cased', decoder_cache_dir='/data/yukangliang/预训练模型/bert-base-cased-decoder', share_decoder_input_output_embed=False, encoder='bert_adaptor', decoder='bert_adaptor', encoder_embed_path=None, encoder_embed_dim=768, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_attention_heads=8, encoder_normalize_before=False, decoder_embed_path=None, decoder_embed_dim=768, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_input=False, decoder_output_dim=768, decoder_input_dim=768, no_share_maskpredictor=False, share_discriminator_maskpredictor=False, no_share_last_layer=False, cached_dir='/data/yukangliang/预训练模型/bert-base-cased')
2022-07-18 12:28:29 | INFO | fairseq.tasks.translation | [source] dictionary: 28996 types
2022-07-18 12:28:29 | INFO | fairseq.tasks.translation | [target] dictionary: 28996 types
start load cached examples valid ...
0it [00:00, ?it/s]start load cached examples valid ...
0it [00:00, ?it/s]2022-07-18 12:28:29 | INFO | fairseq.data.data_utils | loaded 13368 examples from: ../data-bin-ACL-bert-cased-510/valid.source-target.source
2022-07-18 12:28:29 | INFO | fairseq.data.data_utils | loaded 13368 examples from: ../data-bin-ACL-bert-cased-510/valid.source-target.target
2022-07-18 12:28:29 | INFO | fairseq.tasks.translation | ../data-bin-ACL-bert-cased-510 valid source-target 13368 examples
start load cached examples valid ...
0it [00:00, ?it/s]start load cached examples valid ...
0it [00:00, ?it/s]415it [00:00, 4139.61it/s]410it [00:00, 4090.37it/s]407it [00:00, 4058.85it/s]409it [00:00, 4089.04it/s]820it [00:00, 3769.24it/s]829it [00:00, 3717.83it/s]813it [00:00, 3577.25it/s]818it [00:00, 3550.54it/s]1206it [00:00, 3790.96it/s]1218it [00:00, 3790.96it/s]1199it [00:00, 3694.58it/s]1205it [00:00, 3684.98it/s]1587it [00:00, 3634.45it/s]1600it [00:00, 3594.68it/s]1572it [00:00, 3531.74it/s]1578it [00:00, 3427.61it/s]2005it [00:00, 3819.25it/s]2013it [00:00, 3775.48it/s]1985it [00:00, 3732.82it/s]1990it [00:00, 3657.28it/s]2389it [00:00, 3719.96it/s]2394it [00:00, 3700.75it/s]2361it [00:00, 3678.70it/s]2361it [00:00, 3619.66it/s]2821it [00:00, 3906.41it/s]2812it [00:00, 3848.77it/s]2784it [00:00, 3851.86it/s]2779it [00:00, 3772.18it/s]3214it [00:00, 3826.69it/s]3199it [00:00, 3777.51it/s]3172it [00:00, 3790.81it/s]3159it [00:00, 3714.47it/s]3628it [00:00, 3918.23it/s]3607it [00:00, 3867.72it/s]3589it [00:00, 3902.83it/s]3573it [00:00, 3839.74it/s]4022it [00:01, 3825.53it/s]3995it [00:01, 3773.66it/s]3981it [00:01, 3777.41it/s]3959it [00:01, 3633.36it/s]4425it [00:01, 3885.58it/s]4408it [00:01, 3876.68it/s]4386it [00:01, 3854.73it/s]4365it [00:01, 3755.17it/s]4815it [00:01, 3755.17it/s]4797it [00:01, 3700.66it/s]4773it [00:01, 3698.57it/s]4754it [00:01, 3569.56it/s]5220it [00:01, 3839.02it/s]5200it [00:01, 3792.99it/s]5167it [00:01, 3765.85it/s]5151it [00:01, 3680.79it/s]5587it [00:01, 3812.68it/s]5564it [00:01, 3824.42it/s]5606it [00:01, 3627.94it/s]5548it [00:01, 3762.86it/s]5983it [00:01, 3666.92it/s]5948it [00:01, 3634.32it/s]5970it [00:01, 3542.66it/s]5928it [00:01, 3559.34it/s]6353it [00:01, 3674.75it/s]6346it [00:01, 3602.53it/s]6315it [00:01, 3617.25it/s]6296it [00:01, 3591.46it/s]6723it [00:02, 2116.32it/s]6679it [00:02, 2038.66it/s]6710it [00:02, 2012.54it/s]6658it [00:02, 2023.71it/s]7099it [00:02, 2432.55it/s]7047it [00:02, 2346.59it/s]7078it [00:02, 2321.14it/s]7020it [00:02, 2321.78it/s]7415it [00:02, 2558.04it/s]7356it [00:02, 2482.76it/s]7387it [00:02, 2467.56it/s]7344it [00:02, 2466.11it/s]7795it [00:02, 2847.40it/s]7720it [00:02, 2749.46it/s]7765it [00:02, 2766.76it/s]7707it [00:02, 2731.40it/s]8175it [00:02, 3085.50it/s]8095it [00:02, 2996.44it/s]8143it [00:02, 3015.09it/s]8082it [00:02, 2980.00it/s]8521it [00:02, 3128.06it/s]8434it [00:02, 3048.40it/s]8486it [00:02, 3057.70it/s]8419it [00:02, 3027.91it/s]8900it [00:02, 3304.81it/s]8797it [00:02, 3203.26it/s]8866it [00:02, 3253.77it/s]8779it [00:02, 3179.81it/s]9251it [00:02, 3284.75it/s]9139it [00:02, 3203.24it/s]9215it [00:02, 3236.21it/s]9119it [00:02, 3178.84it/s]9626it [00:02, 3412.75it/s]9492it [00:02, 3293.24it/s]9592it [00:02, 3384.19it/s]9463it [00:02, 3251.37it/s]9979it [00:02, 3359.00it/s]9849it [00:02, 3259.98it/s]9943it [00:03, 3328.56it/s]9838it [00:03, 3393.20it/s]10350it [00:03, 3456.60it/s]10218it [00:03, 3379.93it/s]10302it [00:03, 3401.45it/s]10186it [00:03, 3285.75it/s]10704it [00:03, 3348.78it/s]10575it [00:03, 3433.42it/s]10677it [00:03, 3499.67it/s]10555it [00:03, 3400.31it/s]11084it [00:03, 3474.48it/s]10923it [00:03, 3355.30it/s]11032it [00:03, 3404.17it/s]10901it [00:03, 3305.15it/s]11467it [00:03, 3574.77it/s]11284it [00:03, 3426.84it/s]11409it [00:03, 3507.25it/s]11271it [00:03, 3417.27it/s]11828it [00:03, 3456.03it/s]11630it [00:03, 3350.40it/s]11763it [00:03, 3410.80it/s]11617it [00:03, 3336.99it/s]12213it [00:03, 3567.84it/s]12006it [00:03, 3466.61it/s]12134it [00:03, 3496.64it/s]11994it [00:03, 3460.04it/s]12573it [00:03, 3477.41it/s]12369it [00:03, 3352.27it/s]12486it [00:03, 3404.56it/s]12372it [00:03, 3551.54it/s]12944it [00:03, 3543.01it/s]12735it [00:03, 3438.77it/s]12865it [00:03, 3513.77it/s]12730it [00:03, 3317.23it/s]13301it [00:03, 3453.77it/s]13368it [00:03, 3397.16it/s]
13094it [00:03, 3480.45it/s]13224it [00:03, 3401.87it/s]13092it [00:03, 3400.66it/s]13368it [00:03, 3346.69it/s]
13368it [00:04, 3316.08it/s]
2022-07-18 12:28:33 | INFO | root | success load 13368 data
2022-07-18 12:28:33 | INFO | transformer.tokenization_utils | Model name '/data/yukangliang/预训练模型/bert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming '/data/yukangliang/预训练模型/bert-base-cased' is a path or url to a directory containing tokenizer files.
2022-07-18 12:28:33 | INFO | transformer.tokenization_utils | Didn't find file /data/yukangliang/预训练模型/bert-base-cased/added_tokens.json. We won't load it.
2022-07-18 12:28:33 | INFO | transformer.tokenization_utils | Didn't find file /data/yukangliang/预训练模型/bert-base-cased/special_tokens_map.json. We won't load it.
2022-07-18 12:28:33 | INFO | transformer.tokenization_utils | loading file /data/yukangliang/预训练模型/bert-base-cased/vocab.txt
2022-07-18 12:28:33 | INFO | transformer.tokenization_utils | loading file None
2022-07-18 12:28:33 | INFO | transformer.tokenization_utils | loading file None
2022-07-18 12:28:33 | INFO | transformer.tokenization_utils | loading file /data/yukangliang/预训练模型/bert-base-cased/tokenizer_config.json
13368it [00:04, 3281.09it/s]
2022-07-18 12:28:34 | INFO | transformer.configuration_utils | loading configuration file /data/yukangliang/预训练模型/bert-base-cased/config.json
2022-07-18 12:28:34 | INFO | transformer.configuration_utils | Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "pruned_heads": {},
  "torchscript": false,
  "transformers_version": "4.6.0.dev0",
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "use_cache": true,
  "vocab_size": 28996
}

2022-07-18 12:28:34 | INFO | transformer.modeling_utils | loading weights file /data/yukangliang/预训练模型/bert-base-cased/pytorch_model.bin
2022-07-18 12:28:37 | INFO | transformer.modeling_utils | Weights of BertEncoderWithAdaptor not initialized from pretrained model: ['bert.encoder.layer.0.adapter_ln.weight', 'bert.encoder.layer.0.adapter_ln.bias', 'bert.encoder.layer.0.adapter_w1.weight', 'bert.encoder.layer.0.adapter_w2.weight', 'bert.encoder.layer.1.adapter_ln.weight', 'bert.encoder.layer.1.adapter_ln.bias', 'bert.encoder.layer.1.adapter_w1.weight', 'bert.encoder.layer.1.adapter_w2.weight', 'bert.encoder.layer.2.adapter_ln.weight', 'bert.encoder.layer.2.adapter_ln.bias', 'bert.encoder.layer.2.adapter_w1.weight', 'bert.encoder.layer.2.adapter_w2.weight', 'bert.encoder.layer.3.adapter_ln.weight', 'bert.encoder.layer.3.adapter_ln.bias', 'bert.encoder.layer.3.adapter_w1.weight', 'bert.encoder.layer.3.adapter_w2.weight', 'bert.encoder.layer.4.adapter_ln.weight', 'bert.encoder.layer.4.adapter_ln.bias', 'bert.encoder.layer.4.adapter_w1.weight', 'bert.encoder.layer.4.adapter_w2.weight', 'bert.encoder.layer.5.adapter_ln.weight', 'bert.encoder.layer.5.adapter_ln.bias', 'bert.encoder.layer.5.adapter_w1.weight', 'bert.encoder.layer.5.adapter_w2.weight', 'bert.encoder.layer.6.adapter_ln.weight', 'bert.encoder.layer.6.adapter_ln.bias', 'bert.encoder.layer.6.adapter_w1.weight', 'bert.encoder.layer.6.adapter_w2.weight', 'bert.encoder.layer.7.adapter_ln.weight', 'bert.encoder.layer.7.adapter_ln.bias', 'bert.encoder.layer.7.adapter_w1.weight', 'bert.encoder.layer.7.adapter_w2.weight', 'bert.encoder.layer.8.adapter_ln.weight', 'bert.encoder.layer.8.adapter_ln.bias', 'bert.encoder.layer.8.adapter_w1.weight', 'bert.encoder.layer.8.adapter_w2.weight', 'bert.encoder.layer.9.adapter_ln.weight', 'bert.encoder.layer.9.adapter_ln.bias', 'bert.encoder.layer.9.adapter_w1.weight', 'bert.encoder.layer.9.adapter_w2.weight', 'bert.encoder.layer.10.adapter_ln.weight', 'bert.encoder.layer.10.adapter_ln.bias', 'bert.encoder.layer.10.adapter_w1.weight', 'bert.encoder.layer.10.adapter_w2.weight', 'bert.encoder.layer.11.adapter_ln.weight', 'bert.encoder.layer.11.adapter_ln.bias', 'bert.encoder.layer.11.adapter_w1.weight', 'bert.encoder.layer.11.adapter_w2.weight', 'kpe.cnn2gram.cnn_list.0.weight', 'kpe.cnn2gram.cnn_list.0.bias', 'kpe.classifier.weight', 'kpe.classifier.bias', 'kpe.chunk_classifier.weight', 'kpe.chunk_classifier.bias']
2022-07-18 12:28:37 | INFO | transformer.modeling_utils | Weights from pretrained model not used in BertEncoderWithAdaptor: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2022-07-18 12:28:37 | INFO | transformer.configuration_utils | loading configuration file /data/yukangliang/预训练模型/bert-base-cased/config.json
2022-07-18 12:28:37 | INFO | transformer.configuration_utils | Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "pruned_heads": {},
  "torchscript": false,
  "transformers_version": "4.6.0.dev0",
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "use_cache": true,
  "vocab_size": 28996
}

2022-07-18 12:28:37 | INFO | transformer.modeling_utils | loading weights file /data/yukangliang/预训练模型/bert-base-cased-decoder/pytorch_model.bin
Trained parameters: len 271
Trained parameters: ['encoder.bert.encoder.layer.0.adapter_ln.weight', 'encoder.bert.encoder.layer.0.adapter_ln.bias', 'encoder.bert.encoder.layer.0.adapter_w1.weight', 'encoder.bert.encoder.layer.0.adapter_w2.weight', 'encoder.bert.encoder.layer.1.adapter_ln.weight', 'encoder.bert.encoder.layer.1.adapter_ln.bias', 'encoder.bert.encoder.layer.1.adapter_w1.weight', 'encoder.bert.encoder.layer.1.adapter_w2.weight', 'encoder.bert.encoder.layer.2.adapter_ln.weight', 'encoder.bert.encoder.layer.2.adapter_ln.bias', 'encoder.bert.encoder.layer.2.adapter_w1.weight', 'encoder.bert.encoder.layer.2.adapter_w2.weight', 'encoder.bert.encoder.layer.3.adapter_ln.weight', 'encoder.bert.encoder.layer.3.adapter_ln.bias', 'encoder.bert.encoder.layer.3.adapter_w1.weight', 'encoder.bert.encoder.layer.3.adapter_w2.weight', 'encoder.bert.encoder.layer.4.adapter_ln.weight', 'encoder.bert.encoder.layer.4.adapter_ln.bias', 'encoder.bert.encoder.layer.4.adapter_w1.weight', 'encoder.bert.encoder.layer.4.adapter_w2.weight', 'encoder.bert.encoder.layer.5.adapter_ln.weight', 'encoder.bert.encoder.layer.5.adapter_ln.bias', 'encoder.bert.encoder.layer.5.adapter_w1.weight', 'encoder.bert.encoder.layer.5.adapter_w2.weight', 'encoder.bert.encoder.layer.6.adapter_ln.weight', 'encoder.bert.encoder.layer.6.adapter_ln.bias', 'encoder.bert.encoder.layer.6.adapter_w1.weight', 'encoder.bert.encoder.layer.6.adapter_w2.weight', 'encoder.bert.encoder.layer.7.adapter_ln.weight', 'encoder.bert.encoder.layer.7.adapter_ln.bias', 'encoder.bert.encoder.layer.7.adapter_w1.weight', 'encoder.bert.encoder.layer.7.adapter_w2.weight', 'encoder.bert.encoder.layer.8.adapter_ln.weight', 'encoder.bert.encoder.layer.8.adapter_ln.bias', 'encoder.bert.encoder.layer.8.adapter_w1.weight', 'encoder.bert.encoder.layer.8.adapter_w2.weight', 'encoder.bert.encoder.layer.9.adapter_ln.weight', 'encoder.bert.encoder.layer.9.adapter_ln.bias', 'encoder.bert.encoder.layer.9.adapter_w1.weight', 'encoder.bert.encoder.layer.9.adapter_w2.weight', 'encoder.bert.encoder.layer.10.adapter_ln.weight', 'encoder.bert.encoder.layer.10.adapter_ln.bias', 'encoder.bert.encoder.layer.10.adapter_w1.weight', 'encoder.bert.encoder.layer.10.adapter_w2.weight', 'encoder.bert.encoder.layer.11.adapter_ln.weight', 'encoder.bert.encoder.layer.11.adapter_ln.bias', 'encoder.bert.encoder.layer.11.adapter_w1.weight', 'encoder.bert.encoder.layer.11.adapter_w2.weight', 'encoder.kpe.cnn2gram.cnn_list.0.weight', 'encoder.kpe.cnn2gram.cnn_list.0.bias', 'encoder.kpe.classifier.weight', 'encoder.kpe.classifier.bias', 'encoder.kpe.chunk_classifier.weight', 'encoder.kpe.chunk_classifier.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.adapter.encoder_attn_fc1.weight', 'decoder.layers.0.adapter.encoder_attn_fc2.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.0.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.adapter.encoder_attn_fc1.weight', 'decoder.layers.1.adapter.encoder_attn_fc2.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.adapter.encoder_attn_fc1.weight', 'decoder.layers.2.adapter.encoder_attn_fc2.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.adapter.encoder_attn_fc1.weight', 'decoder.layers.3.adapter.encoder_attn_fc2.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.adapter.encoder_attn_fc1.weight', 'decoder.layers.4.adapter.encoder_attn_fc2.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.adapter.encoder_attn_fc1.weight', 'decoder.layers.5.adapter.encoder_attn_fc2.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.encoder_attn.k_proj.weight', 'decoder.layers.6.encoder_attn.k_proj.bias', 'decoder.layers.6.encoder_attn.v_proj.weight', 'decoder.layers.6.encoder_attn.v_proj.bias', 'decoder.layers.6.encoder_attn.q_proj.weight', 'decoder.layers.6.encoder_attn.q_proj.bias', 'decoder.layers.6.encoder_attn.out_proj.weight', 'decoder.layers.6.encoder_attn.out_proj.bias', 'decoder.layers.6.encoder_attn_layer_norm.weight', 'decoder.layers.6.encoder_attn_layer_norm.bias', 'decoder.layers.6.adapter.encoder_attn_fc1.weight', 'decoder.layers.6.adapter.encoder_attn_fc2.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.encoder_attn.k_proj.weight', 'decoder.layers.7.encoder_attn.k_proj.bias', 'decoder.layers.7.encoder_attn.v_proj.weight', 'decoder.layers.7.encoder_attn.v_proj.bias', 'decoder.layers.7.encoder_attn.q_proj.weight', 'decoder.layers.7.encoder_attn.q_proj.bias', 'decoder.layers.7.encoder_attn.out_proj.weight', 'decoder.layers.7.encoder_attn.out_proj.bias', 'decoder.layers.7.encoder_attn_layer_norm.weight', 'decoder.layers.7.encoder_attn_layer_norm.bias', 'decoder.layers.7.adapter.encoder_attn_fc1.weight', 'decoder.layers.7.adapter.encoder_attn_fc2.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.encoder_attn.k_proj.weight', 'decoder.layers.8.encoder_attn.k_proj.bias', 'decoder.layers.8.encoder_attn.v_proj.weight', 'decoder.layers.8.encoder_attn.v_proj.bias', 'decoder.layers.8.encoder_attn.q_proj.weight', 'decoder.layers.8.encoder_attn.q_proj.bias', 'decoder.layers.8.encoder_attn.out_proj.weight', 'decoder.layers.8.encoder_attn.out_proj.bias', 'decoder.layers.8.encoder_attn_layer_norm.weight', 'decoder.layers.8.encoder_attn_layer_norm.bias', 'decoder.layers.8.adapter.encoder_attn_fc1.weight', 'decoder.layers.8.adapter.encoder_attn_fc2.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.encoder_attn.k_proj.weight', 'decoder.layers.9.encoder_attn.k_proj.bias', 'decoder.layers.9.encoder_attn.v_proj.weight', 'decoder.layers.9.encoder_attn.v_proj.bias', 'decoder.layers.9.encoder_attn.q_proj.weight', 'decoder.layers.9.encoder_attn.q_proj.bias', 'decoder.layers.9.encoder_attn.out_proj.weight', 'decoder.layers.9.encoder_attn.out_proj.bias', 'decoder.layers.9.encoder_attn_layer_norm.weight', 'decoder.layers.9.encoder_attn_layer_norm.bias', 'decoder.layers.9.adapter.encoder_attn_fc1.weight', 'decoder.layers.9.adapter.encoder_attn_fc2.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.encoder_attn.k_proj.weight', 'decoder.layers.10.encoder_attn.k_proj.bias', 'decoder.layers.10.encoder_attn.v_proj.weight', 'decoder.layers.10.encoder_attn.v_proj.bias', 'decoder.layers.10.encoder_attn.q_proj.weight', 'decoder.layers.10.encoder_attn.q_proj.bias', 'decoder.layers.10.encoder_attn.out_proj.weight', 'decoder.layers.10.encoder_attn.out_proj.bias', 'decoder.layers.10.encoder_attn_layer_norm.weight', 'decoder.layers.10.encoder_attn_layer_norm.bias', 'decoder.layers.10.adapter.encoder_attn_fc1.weight', 'decoder.layers.10.adapter.encoder_attn_fc2.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.encoder_attn.k_proj.weight', 'decoder.layers.11.encoder_attn.k_proj.bias', 'decoder.layers.11.encoder_attn.v_proj.weight', 'decoder.layers.11.encoder_attn.v_proj.bias', 'decoder.layers.11.encoder_attn.q_proj.weight', 'decoder.layers.11.encoder_attn.q_proj.bias', 'decoder.layers.11.encoder_attn.out_proj.weight', 'decoder.layers.11.encoder_attn.out_proj.bias', 'decoder.layers.11.encoder_attn_layer_norm.weight', 'decoder.layers.11.encoder_attn_layer_norm.bias', 'decoder.layers.11.adapter.encoder_attn_fc1.weight', 'decoder.layers.11.adapter.encoder_attn_fc2.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.bias']Trained parameters: len 271
Trained parameters: ['encoder.bert.encoder.layer.0.adapter_ln.weight', 'encoder.bert.encoder.layer.0.adapter_ln.bias', 'encoder.bert.encoder.layer.0.adapter_w1.weight', 'encoder.bert.encoder.layer.0.adapter_w2.weight', 'encoder.bert.encoder.layer.1.adapter_ln.weight', 'encoder.bert.encoder.layer.1.adapter_ln.bias', 'encoder.bert.encoder.layer.1.adapter_w1.weight', 'encoder.bert.encoder.layer.1.adapter_w2.weight', 'encoder.bert.encoder.layer.2.adapter_ln.weight', 'encoder.bert.encoder.layer.2.adapter_ln.bias', 'encoder.bert.encoder.layer.2.adapter_w1.weight', 'encoder.bert.encoder.layer.2.adapter_w2.weight', 'encoder.bert.encoder.layer.3.adapter_ln.weight', 'encoder.bert.encoder.layer.3.adapter_ln.bias', 'encoder.bert.encoder.layer.3.adapter_w1.weight', 'encoder.bert.encoder.layer.3.adapter_w2.weight', 'encoder.bert.encoder.layer.4.adapter_ln.weight', 'encoder.bert.encoder.layer.4.adapter_ln.bias', 'encoder.bert.encoder.layer.4.adapter_w1.weight', 'encoder.bert.encoder.layer.4.adapter_w2.weight', 'encoder.bert.encoder.layer.5.adapter_ln.weight', 'encoder.bert.encoder.layer.5.adapter_ln.bias', 'encoder.bert.encoder.layer.5.adapter_w1.weight', 'encoder.bert.encoder.layer.5.adapter_w2.weight', 'encoder.bert.encoder.layer.6.adapter_ln.weight', 'encoder.bert.encoder.layer.6.adapter_ln.bias', 'encoder.bert.encoder.layer.6.adapter_w1.weight', 'encoder.bert.encoder.layer.6.adapter_w2.weight', 'encoder.bert.encoder.layer.7.adapter_ln.weight', 'encoder.bert.encoder.layer.7.adapter_ln.bias', 'encoder.bert.encoder.layer.7.adapter_w1.weight', 'encoder.bert.encoder.layer.7.adapter_w2.weight', 'encoder.bert.encoder.layer.8.adapter_ln.weight', 'encoder.bert.encoder.layer.8.adapter_ln.bias', 'encoder.bert.encoder.layer.8.adapter_w1.weight', 'encoder.bert.encoder.layer.8.adapter_w2.weight', 'encoder.bert.encoder.layer.9.adapter_ln.weight', 'encoder.bert.encoder.layer.9.adapter_ln.bias', 'encoder.bert.encoder.layer.9.adapter_w1.weight', 'encoder.bert.encoder.layer.9.adapter_w2.weight', 'encoder.bert.encoder.layer.10.adapter_ln.weight', 'encoder.bert.encoder.layer.10.adapter_ln.bias', 'encoder.bert.encoder.layer.10.adapter_w1.weight', 'encoder.bert.encoder.layer.10.adapter_w2.weight', 'encoder.bert.encoder.layer.11.adapter_ln.weight', 'encoder.bert.encoder.layer.11.adapter_ln.bias', 'encoder.bert.encoder.layer.11.adapter_w1.weight', 'encoder.bert.encoder.layer.11.adapter_w2.weight', 'encoder.kpe.cnn2gram.cnn_list.0.weight', 'encoder.kpe.cnn2gram.cnn_list.0.bias', 'encoder.kpe.classifier.weight', 'encoder.kpe.classifier.bias', 'encoder.kpe.chunk_classifier.weight', 'encoder.kpe.chunk_classifier.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.adapter.encoder_attn_fc1.weight', 'decoder.layers.0.adapter.encoder_attn_fc2.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.0.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.adapter.encoder_attn_fc1.weight', 'decoder.layers.1.adapter.encoder_attn_fc2.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.adapter.encoder_attn_fc1.weight', 'decoder.layers.2.adapter.encoder_attn_fc2.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.adapter.encoder_attn_fc1.weight', 'decoder.layers.3.adapter.encoder_attn_fc2.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.adapter.encoder_attn_fc1.weight', 'decoder.layers.4.adapter.encoder_attn_fc2.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.adapter.encoder_attn_fc1.weight', 'decoder.layers.5.adapter.encoder_attn_fc2.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.encoder_attn.k_proj.weight', 'decoder.layers.6.encoder_attn.k_proj.bias', 'decoder.layers.6.encoder_attn.v_proj.weight', 'decoder.layers.6.encoder_attn.v_proj.bias', 'decoder.layers.6.encoder_attn.q_proj.weight', 'decoder.layers.6.encoder_attn.q_proj.bias', 'decoder.layers.6.encoder_attn.out_proj.weight', 'decoder.layers.6.encoder_attn.out_proj.bias', 'decoder.layers.6.encoder_attn_layer_norm.weight', 'decoder.layers.6.encoder_attn_layer_norm.bias', 'decoder.layers.6.adapter.encoder_attn_fc1.weight', 'decoder.layers.6.adapter.encoder_attn_fc2.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.encoder_attn.k_proj.weight', 'decoder.layers.7.encoder_attn.k_proj.bias', 'decoder.layers.7.encoder_attn.v_proj.weight', 'decoder.layers.7.encoder_attn.v_proj.bias', 'decoder.layers.7.encoder_attn.q_proj.weight', 'decoder.layers.7.encoder_attn.q_proj.bias', 'decoder.layers.7.encoder_attn.out_proj.weight', 'decoder.layers.7.encoder_attn.out_proj.bias', 'decoder.layers.7.encoder_attn_layer_norm.weight', 'decoder.layers.7.encoder_attn_layer_norm.bias', 'decoder.layers.7.adapter.encoder_attn_fc1.weight', 'decoder.layers.7.adapter.encoder_attn_fc2.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.encoder_attn.k_proj.weight', 'decoder.layers.8.encoder_attn.k_proj.bias', 'decoder.layers.8.encoder_attn.v_proj.weight', 'decoder.layers.8.encoder_attn.v_proj.bias', 'decoder.layers.8.encoder_attn.q_proj.weight', 'decoder.layers.8.encoder_attn.q_proj.bias', 'decoder.layers.8.encoder_attn.out_proj.weight', 'decoder.layers.8.encoder_attn.out_proj.bias', 'decoder.layers.8.encoder_attn_layer_norm.weight', 'decoder.layers.8.encoder_attn_layer_norm.bias', 'decoder.layers.8.adapter.encoder_attn_fc1.weight', 'decoder.layers.8.adapter.encoder_attn_fc2.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.encoder_attn.k_proj.weight', 'decoder.layers.9.encoder_attn.k_proj.bias', 'decoder.layers.9.encoder_attn.v_proj.weight', 'decoder.layers.9.encoder_attn.v_proj.bias', 'decoder.layers.9.encoder_attn.q_proj.weight', 'decoder.layers.9.encoder_attn.q_proj.bias', 'decoder.layers.9.encoder_attn.out_proj.weight', 'decoder.layers.9.encoder_attn.out_proj.bias', 'decoder.layers.9.encoder_attn_layer_norm.weight', 'decoder.layers.9.encoder_attn_layer_norm.bias', 'decoder.layers.9.adapter.encoder_attn_fc1.weight', 'decoder.layers.9.adapter.encoder_attn_fc2.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.encoder_attn.k_proj.weight', 'decoder.layers.10.encoder_attn.k_proj.bias', 'decoder.layers.10.encoder_attn.v_proj.weight', 'decoder.layers.10.encoder_attn.v_proj.bias', 'decoder.layers.10.encoder_attn.q_proj.weight', 'decoder.layers.10.encoder_attn.q_proj.bias', 'decoder.layers.10.encoder_attn.out_proj.weight', 'decoder.layers.10.encoder_attn.out_proj.bias', 'decoder.layers.10.encoder_attn_layer_norm.weight', 'decoder.layers.10.encoder_attn_layer_norm.bias', 'decoder.layers.10.adapter.encoder_attn_fc1.weight', 'decoder.layers.10.adapter.encoder_attn_fc2.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.encoder_attn.k_proj.weight', 'decoder.layers.11.encoder_attn.k_proj.bias', 'decoder.layers.11.encoder_attn.v_proj.weight', 'decoder.layers.11.encoder_attn.v_proj.bias', 'decoder.layers.11.encoder_attn.q_proj.weight', 'decoder.layers.11.encoder_attn.q_proj.bias', 'decoder.layers.11.encoder_attn.out_proj.weight', 'decoder.layers.11.encoder_attn.out_proj.bias', 'decoder.layers.11.encoder_attn_layer_norm.weight', 'decoder.layers.11.encoder_attn_layer_norm.bias', 'decoder.layers.11.adapter.encoder_attn_fc1.weight', 'decoder.layers.11.adapter.encoder_attn_fc2.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.bias']2022-07-18 12:28:39 | INFO | transformer.modeling_utils | Weights of BertDecoderWithAdaptor not initialized from pretrained model: ['embed_mask_ins.weight', 'layers.0.encoder_attn.k_proj.weight', 'layers.0.encoder_attn.k_proj.bias', 'layers.0.encoder_attn.v_proj.weight', 'layers.0.encoder_attn.v_proj.bias', 'layers.0.encoder_attn.q_proj.weight', 'layers.0.encoder_attn.q_proj.bias', 'layers.0.encoder_attn.out_proj.weight', 'layers.0.encoder_attn.out_proj.bias', 'layers.0.encoder_attn_layer_norm.weight', 'layers.0.encoder_attn_layer_norm.bias', 'layers.0.adapter.encoder_attn_fc1.weight', 'layers.0.adapter.encoder_attn_fc2.weight', 'layers.0.adapter.encoder_attn_final_layer_norm.weight', 'layers.0.adapter.encoder_attn_final_layer_norm.bias', 'layers.0.adapter_reposition.encoder_attn_fc1.weight', 'layers.0.adapter_reposition.encoder_attn_fc2.weight', 'layers.0.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.0.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.1.encoder_attn.k_proj.weight', 'layers.1.encoder_attn.k_proj.bias', 'layers.1.encoder_attn.v_proj.weight', 'layers.1.encoder_attn.v_proj.bias', 'layers.1.encoder_attn.q_proj.weight', 'layers.1.encoder_attn.q_proj.bias', 'layers.1.encoder_attn.out_proj.weight', 'layers.1.encoder_attn.out_proj.bias', 'layers.1.encoder_attn_layer_norm.weight', 'layers.1.encoder_attn_layer_norm.bias', 'layers.1.adapter.encoder_attn_fc1.weight', 'layers.1.adapter.encoder_attn_fc2.weight', 'layers.1.adapter.encoder_attn_final_layer_norm.weight', 'layers.1.adapter.encoder_attn_final_layer_norm.bias', 'layers.1.adapter_reposition.encoder_attn_fc1.weight', 'layers.1.adapter_reposition.encoder_attn_fc2.weight', 'layers.1.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.1.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.2.encoder_attn.k_proj.weight', 'layers.2.encoder_attn.k_proj.bias', 'layers.2.encoder_attn.v_proj.weight', 'layers.2.encoder_attn.v_proj.bias', 'layers.2.encoder_attn.q_proj.weight', 'layers.2.encoder_attn.q_proj.bias', 'layers.2.encoder_attn.out_proj.weight', 'layers.2.encoder_attn.out_proj.bias', 'layers.2.encoder_attn_layer_norm.weight', 'layers.2.encoder_attn_layer_norm.bias', 'layers.2.adapter.encoder_attn_fc1.weight', 'layers.2.adapter.encoder_attn_fc2.weight', 'layers.2.adapter.encoder_attn_final_layer_norm.weight', 'layers.2.adapter.encoder_attn_final_layer_norm.bias', 'layers.2.adapter_reposition.encoder_attn_fc1.weight', 'layers.2.adapter_reposition.encoder_attn_fc2.weight', 'layers.2.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.2.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.3.encoder_attn.k_proj.weight', 'layers.3.encoder_attn.k_proj.bias', 'layers.3.encoder_attn.v_proj.weight', 'layers.3.encoder_attn.v_proj.bias', 'layers.3.encoder_attn.q_proj.weight', 'layers.3.encoder_attn.q_proj.bias', 'layers.3.encoder_attn.out_proj.weight', 'layers.3.encoder_attn.out_proj.bias', 'layers.3.encoder_attn_layer_norm.weight', 'layers.3.encoder_attn_layer_norm.bias', 'layers.3.adapter.encoder_attn_fc1.weight', 'layers.3.adapter.encoder_attn_fc2.weight', 'layers.3.adapter.encoder_attn_final_layer_norm.weight', 'layers.3.adapter.encoder_attn_final_layer_norm.bias', 'layers.3.adapter_reposition.encoder_attn_fc1.weight', 'layers.3.adapter_reposition.encoder_attn_fc2.weight', 'layers.3.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.3.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.4.encoder_attn.k_proj.weight', 'layers.4.encoder_attn.k_proj.bias', 'layers.4.encoder_attn.v_proj.weight', 'layers.4.encoder_attn.v_proj.bias', 'layers.4.encoder_attn.q_proj.weight', 'layers.4.encoder_attn.q_proj.bias', 'layers.4.encoder_attn.out_proj.weight', 'layers.4.encoder_attn.out_proj.bias', 'layers.4.encoder_attn_layer_norm.weight', 'layers.4.encoder_attn_layer_norm.bias', 'layers.4.adapter.encoder_attn_fc1.weight', 'layers.4.adapter.encoder_attn_fc2.weight', 'layers.4.adapter.encoder_attn_final_layer_norm.weight', 'layers.4.adapter.encoder_attn_final_layer_norm.bias', 'layers.4.adapter_reposition.encoder_attn_fc1.weight', 'layers.4.adapter_reposition.encoder_attn_fc2.weight', 'layers.4.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.4.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.5.encoder_attn.k_proj.weight', 'layers.5.encoder_attn.k_proj.bias', 'layers.5.encoder_attn.v_proj.weight', 'layers.5.encoder_attn.v_proj.bias', 'layers.5.encoder_attn.q_proj.weight', 'layers.5.encoder_attn.q_proj.bias', 'layers.5.encoder_attn.out_proj.weight', 'layers.5.encoder_attn.out_proj.bias', 'layers.5.encoder_attn_layer_norm.weight', 'layers.5.encoder_attn_layer_norm.bias', 'layers.5.adapter.encoder_attn_fc1.weight', 'layers.5.adapter.encoder_attn_fc2.weight', 'layers.5.adapter.encoder_attn_final_layer_norm.weight', 'layers.5.adapter.encoder_attn_final_layer_norm.bias', 'layers.5.adapter_reposition.encoder_attn_fc1.weight', 'layers.5.adapter_reposition.encoder_attn_fc2.weight', 'layers.5.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.5.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.6.encoder_attn.k_proj.weight', 'layers.6.encoder_attn.k_proj.bias', 'layers.6.encoder_attn.v_proj.weight', 'layers.6.encoder_attn.v_proj.bias', 'layers.6.encoder_attn.q_proj.weight', 'layers.6.encoder_attn.q_proj.bias', 'layers.6.encoder_attn.out_proj.weight', 'layers.6.encoder_attn.out_proj.bias', 'layers.6.encoder_attn_layer_norm.weight', 'layers.6.encoder_attn_layer_norm.bias', 'layers.6.adapter.encoder_attn_fc1.weight', 'layers.6.adapter.encoder_attn_fc2.weight', 'layers.6.adapter.encoder_attn_final_layer_norm.weight', 'layers.6.adapter.encoder_attn_final_layer_norm.bias', 'layers.6.adapter_reposition.encoder_attn_fc1.weight', 'layers.6.adapter_reposition.encoder_attn_fc2.weight', 'layers.6.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.6.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.7.encoder_attn.k_proj.weight', 'layers.7.encoder_attn.k_proj.bias', 'layers.7.encoder_attn.v_proj.weight', 'layers.7.encoder_attn.v_proj.bias', 'layers.7.encoder_attn.q_proj.weight', 'layers.7.encoder_attn.q_proj.bias', 'layers.7.encoder_attn.out_proj.weight', 'layers.7.encoder_attn.out_proj.bias', 'layers.7.encoder_attn_layer_norm.weight', 'layers.7.encoder_attn_layer_norm.bias', 'layers.7.adapter.encoder_attn_fc1.weight', 'layers.7.adapter.encoder_attn_fc2.weight', 'layers.7.adapter.encoder_attn_final_layer_norm.weight', 'layers.7.adapter.encoder_attn_final_layer_norm.bias', 'layers.7.adapter_reposition.encoder_attn_fc1.weight', 'layers.7.adapter_reposition.encoder_attn_fc2.weight', 'layers.7.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.7.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.8.encoder_attn.k_proj.weight', 'layers.8.encoder_attn.k_proj.bias', 'layers.8.encoder_attn.v_proj.weight', 'layers.8.encoder_attn.v_proj.bias', 'layers.8.encoder_attn.q_proj.weight', 'layers.8.encoder_attn.q_proj.bias', 'layers.8.encoder_attn.out_proj.weight', 'layers.8.encoder_attn.out_proj.bias', 'layers.8.encoder_attn_layer_norm.weight', 'layers.8.encoder_attn_layer_norm.bias', 'layers.8.adapter.encoder_attn_fc1.weight', 'layers.8.adapter.encoder_attn_fc2.weight', 'layers.8.adapter.encoder_attn_final_layer_norm.weight', 'layers.8.adapter.encoder_attn_final_layer_norm.bias', 'layers.8.adapter_reposition.encoder_attn_fc1.weight', 'layers.8.adapter_reposition.encoder_attn_fc2.weight', 'layers.8.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.8.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.9.encoder_attn.k_proj.weight', 'layers.9.encoder_attn.k_proj.bias', 'layers.9.encoder_attn.v_proj.weight', 'layers.9.encoder_attn.v_proj.bias', 'layers.9.encoder_attn.q_proj.weight', 'layers.9.encoder_attn.q_proj.bias', 'layers.9.encoder_attn.out_proj.weight', 'layers.9.encoder_attn.out_proj.bias', 'layers.9.encoder_attn_layer_norm.weight', 'layers.9.encoder_attn_layer_norm.bias', 'layers.9.adapter.encoder_attn_fc1.weight', 'layers.9.adapter.encoder_attn_fc2.weight', 'layers.9.adapter.encoder_attn_final_layer_norm.weight', 'layers.9.adapter.encoder_attn_final_layer_norm.bias', 'layers.9.adapter_reposition.encoder_attn_fc1.weight', 'layers.9.adapter_reposition.encoder_attn_fc2.weight', 'layers.9.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.9.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.10.encoder_attn.k_proj.weight', 'layers.10.encoder_attn.k_proj.bias', 'layers.10.encoder_attn.v_proj.weight', 'layers.10.encoder_attn.v_proj.bias', 'layers.10.encoder_attn.q_proj.weight', 'layers.10.encoder_attn.q_proj.bias', 'layers.10.encoder_attn.out_proj.weight', 'layers.10.encoder_attn.out_proj.bias', 'layers.10.encoder_attn_layer_norm.weight', 'layers.10.encoder_attn_layer_norm.bias', 'layers.10.adapter.encoder_attn_fc1.weight', 'layers.10.adapter.encoder_attn_fc2.weight', 'layers.10.adapter.encoder_attn_final_layer_norm.weight', 'layers.10.adapter.encoder_attn_final_layer_norm.bias', 'layers.10.adapter_reposition.encoder_attn_fc1.weight', 'layers.10.adapter_reposition.encoder_attn_fc2.weight', 'layers.10.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.10.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.11.encoder_attn.k_proj.weight', 'layers.11.encoder_attn.k_proj.bias', 'layers.11.encoder_attn.v_proj.weight', 'layers.11.encoder_attn.v_proj.bias', 'layers.11.encoder_attn.q_proj.weight', 'layers.11.encoder_attn.q_proj.bias', 'layers.11.encoder_attn.out_proj.weight', 'layers.11.encoder_attn.out_proj.bias', 'layers.11.encoder_attn_layer_norm.weight', 'layers.11.encoder_attn_layer_norm.bias', 'layers.11.adapter.encoder_attn_fc1.weight', 'layers.11.adapter.encoder_attn_fc2.weight', 'layers.11.adapter.encoder_attn_final_layer_norm.weight', 'layers.11.adapter.encoder_attn_final_layer_norm.bias', 'layers.11.adapter_reposition.encoder_attn_fc1.weight', 'layers.11.adapter_reposition.encoder_attn_fc2.weight', 'layers.11.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.11.adapter_reposition.encoder_attn_final_layer_norm.bias', 'output_projection.weight']
2022-07-18 12:28:39 | INFO | transformer.modeling_utils | Weights from pretrained model not used in BertDecoderWithAdaptor: ['pooler.dense.weight', 'pooler.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
Trained parameters: len 271
Trained parameters: ['encoder.bert.encoder.layer.0.adapter_ln.weight', 'encoder.bert.encoder.layer.0.adapter_ln.bias', 'encoder.bert.encoder.layer.0.adapter_w1.weight', 'encoder.bert.encoder.layer.0.adapter_w2.weight', 'encoder.bert.encoder.layer.1.adapter_ln.weight', 'encoder.bert.encoder.layer.1.adapter_ln.bias', 'encoder.bert.encoder.layer.1.adapter_w1.weight', 'encoder.bert.encoder.layer.1.adapter_w2.weight', 'encoder.bert.encoder.layer.2.adapter_ln.weight', 'encoder.bert.encoder.layer.2.adapter_ln.bias', 'encoder.bert.encoder.layer.2.adapter_w1.weight', 'encoder.bert.encoder.layer.2.adapter_w2.weight', 'encoder.bert.encoder.layer.3.adapter_ln.weight', 'encoder.bert.encoder.layer.3.adapter_ln.bias', 'encoder.bert.encoder.layer.3.adapter_w1.weight', 'encoder.bert.encoder.layer.3.adapter_w2.weight', 'encoder.bert.encoder.layer.4.adapter_ln.weight', 'encoder.bert.encoder.layer.4.adapter_ln.bias', 'encoder.bert.encoder.layer.4.adapter_w1.weight', 'encoder.bert.encoder.layer.4.adapter_w2.weight', 'encoder.bert.encoder.layer.5.adapter_ln.weight', 'encoder.bert.encoder.layer.5.adapter_ln.bias', 'encoder.bert.encoder.layer.5.adapter_w1.weight', 'encoder.bert.encoder.layer.5.adapter_w2.weight', 'encoder.bert.encoder.layer.6.adapter_ln.weight', 'encoder.bert.encoder.layer.6.adapter_ln.bias', 'encoder.bert.encoder.layer.6.adapter_w1.weight', 'encoder.bert.encoder.layer.6.adapter_w2.weight', 'encoder.bert.encoder.layer.7.adapter_ln.weight', 'encoder.bert.encoder.layer.7.adapter_ln.bias', 'encoder.bert.encoder.layer.7.adapter_w1.weight', 'encoder.bert.encoder.layer.7.adapter_w2.weight', 'encoder.bert.encoder.layer.8.adapter_ln.weight', 'encoder.bert.encoder.layer.8.adapter_ln.bias', 'encoder.bert.encoder.layer.8.adapter_w1.weight', 'encoder.bert.encoder.layer.8.adapter_w2.weight', 'encoder.bert.encoder.layer.9.adapter_ln.weight', 'encoder.bert.encoder.layer.9.adapter_ln.bias', 'encoder.bert.encoder.layer.9.adapter_w1.weight', 'encoder.bert.encoder.layer.9.adapter_w2.weight', 'encoder.bert.encoder.layer.10.adapter_ln.weight', 'encoder.bert.encoder.layer.10.adapter_ln.bias', 'encoder.bert.encoder.layer.10.adapter_w1.weight', 'encoder.bert.encoder.layer.10.adapter_w2.weight', 'encoder.bert.encoder.layer.11.adapter_ln.weight', 'encoder.bert.encoder.layer.11.adapter_ln.bias', 'encoder.bert.encoder.layer.11.adapter_w1.weight', 'encoder.bert.encoder.layer.11.adapter_w2.weight', 'encoder.kpe.cnn2gram.cnn_list.0.weight', 'encoder.kpe.cnn2gram.cnn_list.0.bias', 'encoder.kpe.classifier.weight', 'encoder.kpe.classifier.bias', 'encoder.kpe.chunk_classifier.weight', 'encoder.kpe.chunk_classifier.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.adapter.encoder_attn_fc1.weight', 'decoder.layers.0.adapter.encoder_attn_fc2.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.0.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.adapter.encoder_attn_fc1.weight', 'decoder.layers.1.adapter.encoder_attn_fc2.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.adapter.encoder_attn_fc1.weight', 'decoder.layers.2.adapter.encoder_attn_fc2.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.adapter.encoder_attn_fc1.weight', 'decoder.layers.3.adapter.encoder_attn_fc2.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.adapter.encoder_attn_fc1.weight', 'decoder.layers.4.adapter.encoder_attn_fc2.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.adapter.encoder_attn_fc1.weight', 'decoder.layers.5.adapter.encoder_attn_fc2.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.encoder_attn.k_proj.weight', 'decoder.layers.6.encoder_attn.k_proj.bias', 'decoder.layers.6.encoder_attn.v_proj.weight', 'decoder.layers.6.encoder_attn.v_proj.bias', 'decoder.layers.6.encoder_attn.q_proj.weight', 'decoder.layers.6.encoder_attn.q_proj.bias', 'decoder.layers.6.encoder_attn.out_proj.weight', 'decoder.layers.6.encoder_attn.out_proj.bias', 'decoder.layers.6.encoder_attn_layer_norm.weight', 'decoder.layers.6.encoder_attn_layer_norm.bias', 'decoder.layers.6.adapter.encoder_attn_fc1.weight', 'decoder.layers.6.adapter.encoder_attn_fc2.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.encoder_attn.k_proj.weight', 'decoder.layers.7.encoder_attn.k_proj.bias', 'decoder.layers.7.encoder_attn.v_proj.weight', 'decoder.layers.7.encoder_attn.v_proj.bias', 'decoder.layers.7.encoder_attn.q_proj.weight', 'decoder.layers.7.encoder_attn.q_proj.bias', 'decoder.layers.7.encoder_attn.out_proj.weight', 'decoder.layers.7.encoder_attn.out_proj.bias', 'decoder.layers.7.encoder_attn_layer_norm.weight', 'decoder.layers.7.encoder_attn_layer_norm.bias', 'decoder.layers.7.adapter.encoder_attn_fc1.weight', 'decoder.layers.7.adapter.encoder_attn_fc2.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.encoder_attn.k_proj.weight', 'decoder.layers.8.encoder_attn.k_proj.bias', 'decoder.layers.8.encoder_attn.v_proj.weight', 'decoder.layers.8.encoder_attn.v_proj.bias', 'decoder.layers.8.encoder_attn.q_proj.weight', 'decoder.layers.8.encoder_attn.q_proj.bias', 'decoder.layers.8.encoder_attn.out_proj.weight', 'decoder.layers.8.encoder_attn.out_proj.bias', 'decoder.layers.8.encoder_attn_layer_norm.weight', 'decoder.layers.8.encoder_attn_layer_norm.bias', 'decoder.layers.8.adapter.encoder_attn_fc1.weight', 'decoder.layers.8.adapter.encoder_attn_fc2.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.encoder_attn.k_proj.weight', 'decoder.layers.9.encoder_attn.k_proj.bias', 'decoder.layers.9.encoder_attn.v_proj.weight', 'decoder.layers.9.encoder_attn.v_proj.bias', 'decoder.layers.9.encoder_attn.q_proj.weight', 'decoder.layers.9.encoder_attn.q_proj.bias', 'decoder.layers.9.encoder_attn.out_proj.weight', 'decoder.layers.9.encoder_attn.out_proj.bias', 'decoder.layers.9.encoder_attn_layer_norm.weight', 'decoder.layers.9.encoder_attn_layer_norm.bias', 'decoder.layers.9.adapter.encoder_attn_fc1.weight', 'decoder.layers.9.adapter.encoder_attn_fc2.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.encoder_attn.k_proj.weight', 'decoder.layers.10.encoder_attn.k_proj.bias', 'decoder.layers.10.encoder_attn.v_proj.weight', 'decoder.layers.10.encoder_attn.v_proj.bias', 'decoder.layers.10.encoder_attn.q_proj.weight', 'decoder.layers.10.encoder_attn.q_proj.bias', 'decoder.layers.10.encoder_attn.out_proj.weight', 'decoder.layers.10.encoder_attn.out_proj.bias', 'decoder.layers.10.encoder_attn_layer_norm.weight', 'decoder.layers.10.encoder_attn_layer_norm.bias', 'decoder.layers.10.adapter.encoder_attn_fc1.weight', 'decoder.layers.10.adapter.encoder_attn_fc2.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.encoder_attn.k_proj.weight', 'decoder.layers.11.encoder_attn.k_proj.bias', 'decoder.layers.11.encoder_attn.v_proj.weight', 'decoder.layers.11.encoder_attn.v_proj.bias', 'decoder.layers.11.encoder_attn.q_proj.weight', 'decoder.layers.11.encoder_attn.q_proj.bias', 'decoder.layers.11.encoder_attn.out_proj.weight', 'decoder.layers.11.encoder_attn.out_proj.bias', 'decoder.layers.11.encoder_attn_layer_norm.weight', 'decoder.layers.11.encoder_attn_layer_norm.bias', 'decoder.layers.11.adapter.encoder_attn_fc1.weight', 'decoder.layers.11.adapter.encoder_attn_fc2.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.bias']
Trained parameters not adapter: len 7
Trained parameters not adapter: ['encoder.kpe.cnn2gram.cnn_list.0.weight', 'encoder.kpe.cnn2gram.cnn_list.0.bias', 'encoder.kpe.classifier.weight', 'encoder.kpe.classifier.bias', 'encoder.kpe.chunk_classifier.weight', 'encoder.kpe.chunk_classifier.bias', 'decoder.embed_mask_ins.weight']
2022-07-18 12:28:39 | INFO | fairseq_cli.train | KPEEDITORTransformerModel(
  (encoder): BertEncoderWithAdaptor(
    (bert): BertModelWithAdapter(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(28996, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoderWithAdapter(
        (layer): ModuleList(
          (0): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (1): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (2): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (3): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (4): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (5): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (6): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (7): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (8): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (9): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (10): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (11): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
    (kpe): Kpe(
      (cnn2gram): NGramers(
        (cnn_list): ModuleList(
          (0): Conv1d(768, 512, kernel_size=(1,), stride=(1,))
        )
        (relu): ReLU()
        (dropout): Dropout(p=0.05, inplace=False)
      )
      (classifier): Linear(in_features=512, out_features=1, bias=True)
      (chunk_classifier): Linear(in_features=512, out_features=2, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (decoder): BertDecoderWithAdaptor(
    (embed_mask_ins): Embedding(256, 1536)
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(28996, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (layers): ModuleList(
      (0): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (6): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (7): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (8): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (9): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (10): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (11): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (output_projection): Linear(in_features=768, out_features=28996, bias=False)
  )
)
2022-07-18 12:28:39 | INFO | fairseq_cli.train | model kpe_editor_transformer_with_adapter, criterion LabelSmoothedDualImitationCriterion
2022-07-18 12:28:39 | INFO | fairseq_cli.train | num. model params: 380755715 (num. trained: 142456835)
2022-07-18 12:28:39 | INFO | fairseq_cli.train | num. Encoder model params: 146472707 (Encoder num. trained: 38162435)
2022-07-18 12:28:39 | INFO | fairseq_cli.train | num. Decoder model params: 234283008 (Decoder num. trained: 104294400)
Trained parameters: len 271
Trained parameters: ['encoder.bert.encoder.layer.0.adapter_ln.weight', 'encoder.bert.encoder.layer.0.adapter_ln.bias', 'encoder.bert.encoder.layer.0.adapter_w1.weight', 'encoder.bert.encoder.layer.0.adapter_w2.weight', 'encoder.bert.encoder.layer.1.adapter_ln.weight', 'encoder.bert.encoder.layer.1.adapter_ln.bias', 'encoder.bert.encoder.layer.1.adapter_w1.weight', 'encoder.bert.encoder.layer.1.adapter_w2.weight', 'encoder.bert.encoder.layer.2.adapter_ln.weight', 'encoder.bert.encoder.layer.2.adapter_ln.bias', 'encoder.bert.encoder.layer.2.adapter_w1.weight', 'encoder.bert.encoder.layer.2.adapter_w2.weight', 'encoder.bert.encoder.layer.3.adapter_ln.weight', 'encoder.bert.encoder.layer.3.adapter_ln.bias', 'encoder.bert.encoder.layer.3.adapter_w1.weight', 'encoder.bert.encoder.layer.3.adapter_w2.weight', 'encoder.bert.encoder.layer.4.adapter_ln.weight', 'encoder.bert.encoder.layer.4.adapter_ln.bias', 'encoder.bert.encoder.layer.4.adapter_w1.weight', 'encoder.bert.encoder.layer.4.adapter_w2.weight', 'encoder.bert.encoder.layer.5.adapter_ln.weight', 'encoder.bert.encoder.layer.5.adapter_ln.bias', 'encoder.bert.encoder.layer.5.adapter_w1.weight', 'encoder.bert.encoder.layer.5.adapter_w2.weight', 'encoder.bert.encoder.layer.6.adapter_ln.weight', 'encoder.bert.encoder.layer.6.adapter_ln.bias', 'encoder.bert.encoder.layer.6.adapter_w1.weight', 'encoder.bert.encoder.layer.6.adapter_w2.weight', 'encoder.bert.encoder.layer.7.adapter_ln.weight', 'encoder.bert.encoder.layer.7.adapter_ln.bias', 'encoder.bert.encoder.layer.7.adapter_w1.weight', 'encoder.bert.encoder.layer.7.adapter_w2.weight', 'encoder.bert.encoder.layer.8.adapter_ln.weight', 'encoder.bert.encoder.layer.8.adapter_ln.bias', 'encoder.bert.encoder.layer.8.adapter_w1.weight', 'encoder.bert.encoder.layer.8.adapter_w2.weight', 'encoder.bert.encoder.layer.9.adapter_ln.weight', 'encoder.bert.encoder.layer.9.adapter_ln.bias', 'encoder.bert.encoder.layer.9.adapter_w1.weight', 'encoder.bert.encoder.layer.9.adapter_w2.weight', 'encoder.bert.encoder.layer.10.adapter_ln.weight', 'encoder.bert.encoder.layer.10.adapter_ln.bias', 'encoder.bert.encoder.layer.10.adapter_w1.weight', 'encoder.bert.encoder.layer.10.adapter_w2.weight', 'encoder.bert.encoder.layer.11.adapter_ln.weight', 'encoder.bert.encoder.layer.11.adapter_ln.bias', 'encoder.bert.encoder.layer.11.adapter_w1.weight', 'encoder.bert.encoder.layer.11.adapter_w2.weight', 'encoder.kpe.cnn2gram.cnn_list.0.weight', 'encoder.kpe.cnn2gram.cnn_list.0.bias', 'encoder.kpe.classifier.weight', 'encoder.kpe.classifier.bias', 'encoder.kpe.chunk_classifier.weight', 'encoder.kpe.chunk_classifier.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.adapter.encoder_attn_fc1.weight', 'decoder.layers.0.adapter.encoder_attn_fc2.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.0.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.adapter.encoder_attn_fc1.weight', 'decoder.layers.1.adapter.encoder_attn_fc2.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.adapter.encoder_attn_fc1.weight', 'decoder.layers.2.adapter.encoder_attn_fc2.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.adapter.encoder_attn_fc1.weight', 'decoder.layers.3.adapter.encoder_attn_fc2.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.adapter.encoder_attn_fc1.weight', 'decoder.layers.4.adapter.encoder_attn_fc2.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.adapter.encoder_attn_fc1.weight', 'decoder.layers.5.adapter.encoder_attn_fc2.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.encoder_attn.k_proj.weight', 'decoder.layers.6.encoder_attn.k_proj.bias', 'decoder.layers.6.encoder_attn.v_proj.weight', 'decoder.layers.6.encoder_attn.v_proj.bias', 'decoder.layers.6.encoder_attn.q_proj.weight', 'decoder.layers.6.encoder_attn.q_proj.bias', 'decoder.layers.6.encoder_attn.out_proj.weight', 'decoder.layers.6.encoder_attn.out_proj.bias', 'decoder.layers.6.encoder_attn_layer_norm.weight', 'decoder.layers.6.encoder_attn_layer_norm.bias', 'decoder.layers.6.adapter.encoder_attn_fc1.weight', 'decoder.layers.6.adapter.encoder_attn_fc2.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.encoder_attn.k_proj.weight', 'decoder.layers.7.encoder_attn.k_proj.bias', 'decoder.layers.7.encoder_attn.v_proj.weight', 'decoder.layers.7.encoder_attn.v_proj.bias', 'decoder.layers.7.encoder_attn.q_proj.weight', 'decoder.layers.7.encoder_attn.q_proj.bias', 'decoder.layers.7.encoder_attn.out_proj.weight', 'decoder.layers.7.encoder_attn.out_proj.bias', 'decoder.layers.7.encoder_attn_layer_norm.weight', 'decoder.layers.7.encoder_attn_layer_norm.bias', 'decoder.layers.7.adapter.encoder_attn_fc1.weight', 'decoder.layers.7.adapter.encoder_attn_fc2.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.encoder_attn.k_proj.weight', 'decoder.layers.8.encoder_attn.k_proj.bias', 'decoder.layers.8.encoder_attn.v_proj.weight', 'decoder.layers.8.encoder_attn.v_proj.bias', 'decoder.layers.8.encoder_attn.q_proj.weight', 'decoder.layers.8.encoder_attn.q_proj.bias', 'decoder.layers.8.encoder_attn.out_proj.weight', 'decoder.layers.8.encoder_attn.out_proj.bias', 'decoder.layers.8.encoder_attn_layer_norm.weight', 'decoder.layers.8.encoder_attn_layer_norm.bias', 'decoder.layers.8.adapter.encoder_attn_fc1.weight', 'decoder.layers.8.adapter.encoder_attn_fc2.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.encoder_attn.k_proj.weight', 'decoder.layers.9.encoder_attn.k_proj.bias', 'decoder.layers.9.encoder_attn.v_proj.weight', 'decoder.layers.9.encoder_attn.v_proj.bias', 'decoder.layers.9.encoder_attn.q_proj.weight', 'decoder.layers.9.encoder_attn.q_proj.bias', 'decoder.layers.9.encoder_attn.out_proj.weight', 'decoder.layers.9.encoder_attn.out_proj.bias', 'decoder.layers.9.encoder_attn_layer_norm.weight', 'decoder.layers.9.encoder_attn_layer_norm.bias', 'decoder.layers.9.adapter.encoder_attn_fc1.weight', 'decoder.layers.9.adapter.encoder_attn_fc2.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.encoder_attn.k_proj.weight', 'decoder.layers.10.encoder_attn.k_proj.bias', 'decoder.layers.10.encoder_attn.v_proj.weight', 'decoder.layers.10.encoder_attn.v_proj.bias', 'decoder.layers.10.encoder_attn.q_proj.weight', 'decoder.layers.10.encoder_attn.q_proj.bias', 'decoder.layers.10.encoder_attn.out_proj.weight', 'decoder.layers.10.encoder_attn.out_proj.bias', 'decoder.layers.10.encoder_attn_layer_norm.weight', 'decoder.layers.10.encoder_attn_layer_norm.bias', 'decoder.layers.10.adapter.encoder_attn_fc1.weight', 'decoder.layers.10.adapter.encoder_attn_fc2.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.encoder_attn.k_proj.weight', 'decoder.layers.11.encoder_attn.k_proj.bias', 'decoder.layers.11.encoder_attn.v_proj.weight', 'decoder.layers.11.encoder_attn.v_proj.bias', 'decoder.layers.11.encoder_attn.q_proj.weight', 'decoder.layers.11.encoder_attn.q_proj.bias', 'decoder.layers.11.encoder_attn.out_proj.weight', 'decoder.layers.11.encoder_attn.out_proj.bias', 'decoder.layers.11.encoder_attn_layer_norm.weight', 'decoder.layers.11.encoder_attn_layer_norm.bias', 'decoder.layers.11.adapter.encoder_attn_fc1.weight', 'decoder.layers.11.adapter.encoder_attn_fc2.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.bias']
Trained parameters not adapter: len 7
Trained parameters not adapter: ['encoder.kpe.cnn2gram.cnn_list.0.weight', 'encoder.kpe.cnn2gram.cnn_list.0.bias', 'encoder.kpe.classifier.weight', 'encoder.kpe.classifier.bias', 'encoder.kpe.chunk_classifier.weight', 'encoder.kpe.chunk_classifier.bias', 'decoder.embed_mask_ins.weight']
start load cached examples train ...
0it [00:00, ?it/s]330it [00:00, 3291.07it/s]669it [00:00, 3346.65it/s]1004it [00:00, 3151.46it/s]1336it [00:00, 3212.91it/s]1689it [00:00, 3323.49it/s]2023it [00:00, 3178.86it/s]2372it [00:00, 3276.20it/s]2702it [00:00, 3152.97it/s]3021it [00:00, 3155.15it/s]3338it [00:01, 3152.88it/s]3655it [00:01, 3051.51it/s]3989it [00:01, 3132.79it/s]4326it [00:01, 3200.85it/s]4648it [00:01, 3113.64it/s]4981it [00:01, 3173.64it/s]5300it [00:01, 3069.89it/s]5642it [00:01, 3169.46it/s]5984it [00:01, 3240.29it/s]6310it [00:01, 3075.58it/s]6649it [00:02, 3163.78it/s]2022-07-18 12:28:43 | INFO | fairseq_cli.train | training on 4 GPUs
2022-07-18 12:28:43 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 8
6968it [00:02, 1193.83it/s]7364it [00:02, 1565.77it/s]7761it [00:02, 1952.61it/s]8080it [00:03, 2178.24it/s]8441it [00:03, 2478.64it/s]8772it [00:03, 2663.64it/s]9170it [00:03, 2989.59it/s]9520it [00:03, 3062.41it/s]9908it [00:03, 3281.14it/s]10293it [00:03, 3437.92it/s]2022-07-18 12:28:44 | INFO | fairseq.trainer | loaded checkpoint ../checkpoints_bert_bert12_adaptor_kpe_target_ACL_cased/checkpoint_last.pt (epoch 3 @ 3366 updates)

Trained parameters not adapter: len 7
Trained parameters not adapter: ['encoder.kpe.cnn2gram.cnn_list.0.weight', 'encoder.kpe.cnn2gram.cnn_list.0.bias', 'encoder.kpe.classifier.weight', 'encoder.kpe.classifier.bias', 'encoder.kpe.chunk_classifier.weight', 'encoder.kpe.chunk_classifier.bias', 'decoder.embed_mask_ins.weight']
start load cached examples train ...
0it [00:00, ?it/s]2022-07-18 12:28:44 | INFO | fairseq.trainer | loading train data for epoch 3
10658it [00:03, 3387.60it/s]386it [00:00, 3851.14it/s]11056it [00:03, 3553.32it/s]
Trained parameters not adapter: len 7
Trained parameters not adapter: ['encoder.kpe.cnn2gram.cnn_list.0.weight', 'encoder.kpe.cnn2gram.cnn_list.0.bias', 'encoder.kpe.classifier.weight', 'encoder.kpe.classifier.bias', 'encoder.kpe.chunk_classifier.weight', 'encoder.kpe.chunk_classifier.bias', 'decoder.embed_mask_ins.weight']
start load cached examples train ...
0it [00:00, ?it/s]2022-07-18 12:28:45 | INFO | fairseq.data.data_utils | loaded 287112 examples from: ../data-bin-ACL-bert-cased-510/train.source-target.source
2022-07-18 12:28:45 | INFO | fairseq.data.data_utils | loaded 287112 examples from: ../data-bin-ACL-bert-cased-510/train.source-target.target
2022-07-18 12:28:45 | INFO | fairseq.tasks.translation | ../data-bin-ACL-bert-cased-510 train source-target 287112 examples
start load cached examples train ...
0it [00:00, ?it/s]773it [00:00, 3858.55it/s]11423it [00:04, 3501.76it/s]382it [00:00, 3813.46it/s]383it [00:00, 3820.19it/s]1159it [00:00, 3517.87it/s]11796it [00:04, 3564.99it/s]766it [00:00, 3828.51it/s]774it [00:00, 3870.25it/s]1545it [00:00, 3645.29it/s]12159it [00:04, 3500.00it/s]1149it [00:00, 3520.34it/s]1162it [00:00, 3615.08it/s]1913it [00:00, 3522.50it/s]12570it [00:04, 3673.24it/s]1539it [00:00, 3661.39it/s]1541it [00:00, 3681.05it/s]2303it [00:00, 3644.11it/s]12942it [00:04, 3618.43it/s]1908it [00:00, 3511.48it/s]1911it [00:00, 3557.80it/s]2670it [00:00, 3531.63it/s]13358it [00:04, 3774.28it/s]2306it [00:00, 3661.55it/s]2298it [00:00, 3659.37it/s]3059it [00:00, 3637.53it/s]13738it [00:04, 3699.90it/s]2675it [00:00, 3505.53it/s]2670it [00:00, 3534.20it/s]3442it [00:00, 3695.22it/s]14149it [00:04, 3818.33it/s]3061it [00:00, 3610.30it/s]3041it [00:00, 3586.12it/s]3813it [00:01, 3577.62it/s]14533it [00:04, 3715.59it/s]3440it [00:00, 3659.40it/s]3435it [00:00, 3690.73it/s]4198it [00:01, 3655.78it/s]14927it [00:04, 3771.43it/s]3808it [00:01, 3525.76it/s]3806it [00:01, 3527.13it/s]4565it [00:01, 3463.21it/s]15325it [00:05, 3831.27it/s]4178it [00:01, 3574.67it/s]4196it [00:01, 3633.05it/s]4946it [00:01, 3556.83it/s]15710it [00:05, 3697.08it/s]4538it [00:01, 3489.87it/s]4562it [00:01, 3510.10it/s]5305it [00:01, 3487.34it/s]16082it [00:05, 3666.28it/s]4910it [00:01, 3550.30it/s]4951it [00:01, 3618.03it/s]5684it [00:01, 3574.12it/s]5267it [00:01, 3455.76it/s]5315it [00:01, 3499.92it/s]6044it [00:01, 3486.62it/s]5641it [00:01, 3536.60it/s]5704it [00:01, 3609.88it/s]6440it [00:01, 3622.64it/s]6022it [00:01, 3615.88it/s]6822it [00:01, 3677.96it/s]6067it [00:01, 3410.50it/s]6385it [00:01, 3369.97it/s]6457it [00:01, 3547.01it/s]6768it [00:01, 3497.30it/s]6838it [00:01, 3619.93it/s]16450it [00:06, 1093.45it/s]16854it [00:06, 1416.59it/s]17205it [00:06, 1699.69it/s]7192it [00:02, 1187.19it/s]17617it [00:06, 2091.65it/s]7583it [00:02, 1511.37it/s]17967it [00:06, 2355.50it/s]7916it [00:02, 1775.36it/s]18375it [00:06, 2720.42it/s]7203it [00:02, 1114.35it/s]7122it [00:02, 1054.06it/s]8307it [00:03, 2141.93it/s]18760it [00:06, 2979.50it/s]7571it [00:02, 1403.98it/s]7505it [00:02, 1357.72it/s]8645it [00:03, 2350.90it/s]19132it [00:06, 3086.23it/s]7883it [00:02, 1642.39it/s]7827it [00:03, 1609.48it/s]9034it [00:03, 2684.06it/s]19541it [00:06, 3337.93it/s]8276it [00:03, 2020.85it/s]8217it [00:03, 1979.83it/s]9431it [00:03, 2986.68it/s]19916it [00:07, 3372.10it/s]8620it [00:03, 2277.03it/s]8604it [00:03, 2334.06it/s]9794it [00:03, 3077.90it/s]20317it [00:07, 3544.65it/s]9005it [00:03, 2611.61it/s]8951it [00:03, 2551.49it/s]10182it [00:03, 3286.48it/s]20694it [00:07, 3482.90it/s]9398it [00:03, 2919.22it/s]9326it [00:03, 2826.67it/s]10546it [00:03, 3330.34it/s]21096it [00:07, 3631.05it/s]9759it [00:03, 2998.88it/s]9679it [00:03, 2947.74it/s]10924it [00:03, 3454.32it/s]21472it [00:07, 3591.56it/s]10147it [00:03, 3224.91it/s]10059it [00:03, 3166.76it/s]11288it [00:03, 3413.50it/s]21872it [00:07, 3707.15it/s]10508it [00:03, 3246.77it/s]10415it [00:03, 3221.33it/s]11657it [00:03, 3491.04it/s]22250it [00:07, 3562.53it/s]10887it [00:03, 3392.73it/s]10785it [00:03, 3350.48it/s]12016it [00:04, 3429.90it/s]22645it [00:07, 3671.43it/s]11247it [00:03, 3344.15it/s]11141it [00:03, 3336.21it/s]12424it [00:04, 3614.81it/s]23017it [00:07, 3614.73it/s]11642it [00:04, 3511.16it/s]11518it [00:04, 3457.19it/s]12820it [00:04, 3563.95it/s]23412it [00:08, 3709.13it/s]11910it [00:04, 3586.51it/s]12005it [00:04, 3436.75it/s]13231it [00:04, 3719.02it/s]23810it [00:08, 3619.56it/s]12277it [00:04, 3536.23it/s]12408it [00:04, 3582.00it/s]13641it [00:04, 3827.83it/s]24215it [00:08, 3740.35it/s]12680it [00:04, 3674.12it/s]12813it [00:04, 3714.86it/s]14027it [00:04, 3716.41it/s]24612it [00:08, 3806.24it/s]13052it [00:04, 3550.28it/s]13190it [00:04, 3585.77it/s]14437it [00:04, 3826.34it/s]24995it [00:08, 3680.52it/s]13456it [00:04, 3689.05it/s]13591it [00:04, 3704.60it/s]14822it [00:04, 3586.07it/s]25368it [00:08, 3694.04it/s]13829it [00:04, 3599.26it/s]13965it [00:04, 3592.93it/s]15223it [00:04, 3704.46it/s]25739it [00:08, 3600.24it/s]14217it [00:04, 3679.27it/s]14367it [00:04, 3713.02it/s]15598it [00:05, 3626.03it/s]26133it [00:08, 3697.80it/s]14588it [00:04, 3606.82it/s]14741it [00:04, 3592.46it/s]15992it [00:05, 3713.28it/s]26505it [00:08, 3600.00it/s]14996it [00:04, 3743.37it/s]15152it [00:04, 3738.34it/s]26898it [00:08, 3693.49it/s]15373it [00:05, 3657.97it/s]15529it [00:05, 3590.55it/s]27269it [00:09, 3627.63it/s]15762it [00:05, 3724.62it/s]15924it [00:05, 3691.19it/s]27676it [00:09, 3755.78it/s]16155it [00:05, 3781.82it/s]28053it [00:09, 3669.21it/s]16366it [00:06, 981.89it/s] 16773it [00:06, 1285.36it/s]17119it [00:06, 1552.88it/s]16296it [00:06, 968.55it/s] 17514it [00:06, 1911.18it/s]16535it [00:06, 1001.96it/s]16694it [00:06, 1261.68it/s]17926it [00:06, 2299.49it/s]16939it [00:06, 1306.16it/s]17090it [00:06, 1567.72it/s]18291it [00:06, 2530.92it/s]17279it [00:06, 1568.04it/s]28422it [00:10, 882.82it/s] 17480it [00:06, 1909.05it/s]18700it [00:06, 2873.79it/s]17689it [00:06, 1952.02it/s]28817it [00:10, 1160.28it/s]17885it [00:06, 2279.54it/s]19073it [00:06, 2988.14it/s]18038it [00:06, 2219.40it/s]29152it [00:10, 1410.71it/s]18246it [00:06, 2489.46it/s]19471it [00:06, 3229.54it/s]18435it [00:06, 2572.99it/s]29546it [00:10, 1765.82it/s]18651it [00:06, 2827.97it/s]19842it [00:07, 3277.53it/s]18797it [00:06, 2768.22it/s]29884it [00:10, 2032.10it/s]19018it [00:06, 2964.26it/s]20235it [00:07, 3451.89it/s]19195it [00:07, 3058.52it/s]30278it [00:10, 2398.97it/s]19406it [00:07, 3191.65it/s]20606it [00:07, 3429.09it/s]19602it [00:07, 3315.11it/s]30632it [00:11, 2612.54it/s]19773it [00:07, 3245.83it/s]20998it [00:07, 3563.41it/s]19982it [00:07, 3316.71it/s]31025it [00:11, 2919.42it/s]20170it [00:07, 3435.12it/s]21368it [00:07, 3491.62it/s]20380it [00:07, 3486.19it/s]31422it [00:11, 3181.40it/s]20540it [00:07, 3412.19it/s]21775it [00:07, 3653.90it/s]20754it [00:07, 3458.28it/s]31795it [00:11, 3248.04it/s]20923it [00:07, 3525.85it/s]22149it [00:07, 3551.26it/s]21151it [00:07, 3600.13it/s]32191it [00:11, 3437.83it/s]21290it [00:07, 3470.36it/s]22559it [00:07, 3705.36it/s]21525it [00:07, 3514.11it/s]32564it [00:11, 3410.19it/s]21689it [00:07, 3617.12it/s]22952it [00:07, 3770.03it/s]21923it [00:07, 3644.44it/s]32957it [00:11, 3552.03it/s]22087it [00:07, 3720.00it/s]23333it [00:08, 3641.29it/s]22296it [00:07, 3571.58it/s]33328it [00:11, 3496.27it/s]22465it [00:07, 3631.22it/s]23716it [00:08, 3693.96it/s]22703it [00:07, 3712.80it/s]33722it [00:11, 3621.37it/s]22866it [00:08, 3739.96it/s]24088it [00:08, 3585.68it/s]34093it [00:12, 3567.29it/s]23079it [00:08, 3588.60it/s]23244it [00:08, 3624.01it/s]24488it [00:08, 3704.35it/s]34491it [00:12, 3684.58it/s]23468it [00:08, 3673.09it/s]23632it [00:08, 3695.80it/s]24861it [00:08, 3563.45it/s]34865it [00:12, 3586.50it/s]23839it [00:08, 3574.44it/s]24005it [00:08, 3594.65it/s]25253it [00:08, 3663.04it/s]35259it [00:12, 3686.39it/s]24235it [00:08, 3684.27it/s]24396it [00:08, 3683.51it/s]24612it [00:08, 3707.13it/s]25622it [00:08, 3550.47it/s]35641it [00:12, 3591.89it/s]24767it [00:08, 3581.38it/s]26012it [00:08, 3648.75it/s]24985it [00:08, 3597.79it/s]36033it [00:12, 3685.49it/s]25157it [00:08, 3671.11it/s]25378it [00:08, 3691.76it/s]36422it [00:12, 3743.70it/s]26379it [00:08, 3526.51it/s]25526it [00:08, 3571.39it/s]26766it [00:09, 3624.35it/s]25749it [00:08, 3604.66it/s]36799it [00:12, 3626.65it/s]25921it [00:08, 3678.69it/s]27161it [00:09, 3716.01it/s]26140it [00:08, 3691.94it/s]37191it [00:12, 3710.72it/s]26312it [00:08, 3745.96it/s]27535it [00:09, 3613.33it/s]26511it [00:09, 3560.78it/s]37564it [00:12, 3596.63it/s]26688it [00:09, 3517.27it/s]27898it [00:09, 3576.89it/s]26902it [00:09, 3659.42it/s]37955it [00:13, 3685.78it/s]27086it [00:09, 3647.71it/s]27270it [00:09, 3593.19it/s]38326it [00:13, 3605.52it/s]27454it [00:09, 3572.06it/s]27673it [00:09, 3716.83it/s]38706it [00:13, 3661.19it/s]27855it [00:09, 3695.75it/s]28046it [00:09, 3585.28it/s]39074it [00:13, 3558.95it/s]39478it [00:13, 3695.08it/s]39849it [00:13, 3572.64it/s]40252it [00:13, 3702.23it/s]40643it [00:13, 3761.00it/s]41021it [00:13, 3648.25it/s]41423it [00:14, 3755.51it/s]41801it [00:14, 3639.34it/s]42205it [00:14, 3753.38it/s]42582it [00:14, 3646.08it/s]42979it [00:14, 3736.61it/s]28257it [00:10, 731.51it/s] 28407it [00:10, 856.93it/s] 28645it [00:10, 976.77it/s]28227it [00:10, 849.56it/s] 28798it [00:10, 1128.55it/s]28965it [00:10, 1198.28it/s]28616it [00:10, 1113.55it/s]29130it [00:10, 1375.09it/s]29357it [00:11, 1538.59it/s]28941it [00:10, 1349.10it/s]29521it [00:10, 1726.61it/s]29752it [00:11, 1904.03it/s]29323it [00:10, 1685.23it/s]29855it [00:11, 1980.09it/s]29711it [00:11, 2042.03it/s]30102it [00:11, 2153.64it/s]30247it [00:11, 2348.51it/s]30060it [00:11, 2290.57it/s]30496it [00:11, 2510.21it/s]30600it [00:11, 2560.48it/s]30453it [00:11, 2634.31it/s]30853it [00:11, 2672.74it/s]30992it [00:11, 2873.22it/s]30811it [00:11, 2773.78it/s]31244it [00:11, 2963.43it/s]31374it [00:11, 3106.68it/s]31205it [00:11, 3055.81it/s]31603it [00:11, 3045.09it/s]31739it [00:11, 3178.69it/s]31566it [00:11, 3132.35it/s]31999it [00:11, 3280.93it/s]32140it [00:11, 3399.51it/s]31959it [00:11, 3342.61it/s]32362it [00:11, 3252.80it/s]32510it [00:11, 3374.89it/s]32324it [00:11, 3327.15it/s]32742it [00:12, 3401.12it/s]32876it [00:11, 3453.06it/s]43355it [00:15, 779.20it/s] 32707it [00:11, 3464.64it/s]33119it [00:12, 3503.95it/s]43751it [00:15, 1032.30it/s]33237it [00:12, 3408.97it/s]33095it [00:12, 3580.55it/s]33484it [00:12, 3422.74it/s]33626it [00:12, 3544.13it/s]44110it [00:16, 1284.64it/s]33465it [00:12, 3500.46it/s]33876it [00:12, 3561.77it/s]44513it [00:16, 1631.68it/s]33989it [00:12, 3504.14it/s]33849it [00:12, 3595.14it/s]34240it [00:12, 3523.64it/s]44909it [00:16, 1987.87it/s]34382it [00:12, 3626.05it/s]34216it [00:12, 3541.06it/s]34624it [00:12, 3612.98it/s]34762it [00:12, 3675.28it/s]45268it [00:16, 2247.46it/s]34607it [00:12, 3644.72it/s]34990it [00:12, 3521.39it/s]45663it [00:16, 2590.67it/s]35133it [00:12, 3518.33it/s]34976it [00:12, 3533.32it/s]35376it [00:12, 3616.67it/s]35523it [00:12, 3626.73it/s]46028it [00:16, 2766.37it/s]35357it [00:12, 3612.51it/s]35741it [00:12, 3535.96it/s]46420it [00:16, 3036.53it/s]35889it [00:12, 3541.13it/s]35721it [00:12, 3517.84it/s]36129it [00:12, 3632.76it/s]36267it [00:12, 3608.04it/s]46786it [00:16, 3105.26it/s]36116it [00:12, 3639.98it/s]36495it [00:13, 3515.23it/s]47185it [00:16, 3334.90it/s]36630it [00:12, 3510.84it/s]36482it [00:12, 3523.80it/s]36875it [00:13, 3595.20it/s]37020it [00:13, 3621.90it/s]47553it [00:16, 3341.88it/s]36861it [00:13, 3598.05it/s]37261it [00:13, 3670.85it/s]47952it [00:17, 3516.99it/s]37384it [00:13, 3526.67it/s]37250it [00:13, 3675.17it/s]37630it [00:13, 3519.56it/s]37756it [00:13, 3581.67it/s]48323it [00:17, 3472.20it/s]37619it [00:13, 3549.16it/s]38020it [00:13, 3628.11it/s]38153it [00:13, 3694.24it/s]48723it [00:17, 3619.89it/s]38010it [00:13, 3652.26it/s]38385it [00:13, 3478.04it/s]49120it [00:17, 3718.39it/s]38524it [00:13, 3527.14it/s]38377it [00:13, 3511.61it/s]38765it [00:13, 3568.51it/s]49500it [00:17, 3613.36it/s]38913it [00:13, 3604.60it/s]38756it [00:13, 3589.94it/s]39125it [00:13, 3445.21it/s]49897it [00:17, 3714.82it/s]39276it [00:13, 3529.87it/s]39117it [00:13, 3497.02it/s]39518it [00:13, 3580.94it/s]39663it [00:13, 3626.52it/s]50273it [00:17, 3601.50it/s]39512it [00:13, 3625.48it/s]39879it [00:14, 3502.36it/s]50660it [00:17, 3676.37it/s]40028it [00:13, 3541.81it/s]39877it [00:13, 3500.59it/s]40261it [00:14, 3591.17it/s]40407it [00:14, 3611.92it/s]51031it [00:17, 3591.26it/s]40270it [00:14, 3620.77it/s]40648it [00:14, 3670.00it/s]51424it [00:18, 3687.77it/s]40770it [00:14, 3521.99it/s]40657it [00:14, 3691.42it/s]41017it [00:14, 3540.83it/s]41168it [00:14, 3653.17it/s]51795it [00:18, 3589.85it/s]41028it [00:14, 3556.43it/s]41409it [00:14, 3649.36it/s]52191it [00:18, 3695.49it/s]41535it [00:14, 3550.72it/s]41423it [00:14, 3667.70it/s]41776it [00:14, 3504.80it/s]41916it [00:14, 3624.41it/s]52563it [00:18, 3590.90it/s]41792it [00:14, 3567.09it/s]42168it [00:14, 3622.82it/s]42314it [00:14, 3727.29it/s]52956it [00:18, 3688.33it/s]42185it [00:14, 3669.92it/s]42533it [00:14, 3537.86it/s]42688it [00:14, 3619.38it/s]53350it [00:18, 3588.05it/s]42554it [00:14, 3546.57it/s]42913it [00:14, 3611.13it/s]43071it [00:14, 3679.15it/s]53741it [00:18, 3678.30it/s]42938it [00:14, 3629.18it/s]54140it [00:18, 3766.15it/s]54519it [00:18, 3635.59it/s]54909it [00:18, 3709.17it/s]55282it [00:19, 3591.56it/s]55667it [00:19, 3662.90it/s]56035it [00:19, 3576.71it/s]56431it [00:19, 3684.34it/s]56801it [00:19, 3599.23it/s]57202it [00:19, 3715.69it/s]57575it [00:19, 3610.87it/s]57972it [00:19, 3712.87it/s]58354it [00:19, 3743.04it/s]58730it [00:20, 3631.02it/s]59119it [00:20, 3703.90it/s]59491it [00:20, 3584.61it/s]59882it [00:20, 3677.82it/s]43276it [00:16, 596.53it/s] 43303it [00:16, 626.54it/s] 43441it [00:16, 619.67it/s] 60252it [00:20, 3582.83it/s]43664it [00:16, 807.01it/s]43689it [00:16, 841.87it/s]43830it [00:16, 834.34it/s]60641it [00:20, 3669.39it/s]44058it [00:16, 1069.76it/s]44073it [00:16, 1102.31it/s]44162it [00:16, 1047.44it/s]61010it [00:20, 3576.95it/s]44391it [00:16, 1311.49it/s]44405it [00:16, 1347.12it/s]44559it [00:16, 1366.08it/s]61404it [00:20, 3681.45it/s]44782it [00:17, 1655.98it/s]44796it [00:16, 1696.14it/s]44940it [00:16, 1695.20it/s]61774it [00:20, 3580.87it/s]45130it [00:17, 1930.89it/s]45142it [00:17, 1969.48it/s]45290it [00:17, 1968.48it/s]45506it [00:17, 2267.19it/s]45516it [00:17, 2301.00it/s]45681it [00:17, 2328.61it/s]45859it [00:17, 2487.92it/s]45867it [00:17, 2517.71it/s]46039it [00:17, 2541.62it/s]46245it [00:17, 2797.21it/s]46251it [00:17, 2820.54it/s]46409it [00:17, 2803.34it/s]46631it [00:17, 2933.22it/s]46629it [00:17, 2876.51it/s]46764it [00:17, 2861.94it/s]47005it [00:17, 3134.37it/s]47003it [00:17, 3090.77it/s]47149it [00:17, 3110.08it/s]47395it [00:17, 3335.20it/s]47395it [00:17, 3306.51it/s]47502it [00:17, 3090.14it/s]47762it [00:17, 3263.72it/s]47758it [00:17, 3266.27it/s]47885it [00:17, 3285.39it/s]48152it [00:18, 3434.90it/s]48150it [00:17, 3442.27it/s]48275it [00:17, 3453.51it/s]48514it [00:18, 3376.87it/s]48512it [00:17, 3381.63it/s]48638it [00:17, 3424.61it/s]48905it [00:18, 3523.12it/s]48905it [00:18, 3532.88it/s]49032it [00:18, 3568.81it/s]49268it [00:18, 3441.99it/s]49268it [00:18, 3465.98it/s]49399it [00:18, 3494.64it/s]49659it [00:18, 3574.03it/s]49658it [00:18, 3588.83it/s]49782it [00:18, 3588.73it/s]50023it [00:18, 3462.70it/s]50023it [00:18, 3427.95it/s]50147it [00:18, 3411.96it/s]50411it [00:18, 3579.47it/s]50411it [00:18, 3553.19it/s]50536it [00:18, 3544.44it/s]50775it [00:18, 3595.94it/s]50797it [00:18, 3639.58it/s]50895it [00:18, 3430.48it/s]62134it [00:22, 623.59it/s] 51138it [00:18, 3527.61it/s]51281it [00:18, 3550.18it/s]51165it [00:18, 3474.01it/s]62531it [00:22, 846.98it/s]51519it [00:18, 3607.89it/s]51551it [00:18, 3582.20it/s]51671it [00:18, 3476.74it/s]62863it [00:22, 1062.16it/s]51882it [00:19, 3523.77it/s]51913it [00:18, 3504.95it/s]52064it [00:18, 3603.04it/s]63259it [00:22, 1382.73it/s]52275it [00:19, 3638.82it/s]52301it [00:19, 3611.95it/s]52442it [00:19, 3652.76it/s]63594it [00:23, 1640.50it/s]52641it [00:19, 3542.74it/s]52665it [00:19, 3472.33it/s]52810it [00:19, 3546.98it/s]63990it [00:23, 2014.67it/s]53026it [00:19, 3629.05it/s]53053it [00:19, 3588.13it/s]53198it [00:19, 3640.78it/s]64340it [00:23, 2272.03it/s]53391it [00:19, 3530.51it/s]53415it [00:19, 3476.83it/s]53564it [00:19, 3507.79it/s]64732it [00:23, 2617.51it/s]53777it [00:19, 3625.20it/s]53796it [00:19, 3571.29it/s]53954it [00:19, 3619.30it/s]65096it [00:23, 2852.70it/s]54147it [00:19, 3645.57it/s]54171it [00:19, 3620.24it/s]54318it [00:19, 3493.04it/s]65457it [00:23, 2964.67it/s]54513it [00:19, 3534.29it/s]54535it [00:19, 3501.06it/s]54707it [00:19, 3605.57it/s]65849it [00:23, 3209.41it/s]54895it [00:19, 3616.55it/s]54919it [00:19, 3597.48it/s]55070it [00:19, 3502.69it/s]66212it [00:23, 3245.55it/s]55258it [00:20, 3519.28it/s]55281it [00:19, 3492.70it/s]55441it [00:19, 3561.68it/s]66603it [00:23, 3426.28it/s]55643it [00:20, 3613.18it/s]55651it [00:19, 3550.84it/s]55824it [00:20, 3637.55it/s]66969it [00:23, 3411.93it/s]56006it [00:20, 3500.60it/s]56008it [00:20, 3469.48it/s]56190it [00:20, 3547.30it/s]67360it [00:24, 3535.56it/s]56397it [00:20, 3617.00it/s]56388it [00:20, 3562.44it/s]56568it [00:20, 3612.41it/s]67726it [00:24, 3478.56it/s]56761it [00:20, 3516.08it/s]56746it [00:20, 3482.35it/s]56931it [00:20, 3513.94it/s]68094it [00:24, 3534.76it/s]57129it [00:20, 3561.53it/s]57112it [00:20, 3531.67it/s]57320it [00:20, 3620.83it/s]68476it [00:24, 3616.31it/s]57504it [00:20, 3614.85it/s]57498it [00:20, 3626.81it/s]57684it [00:20, 3512.24it/s]68843it [00:24, 3532.49it/s]57867it [00:20, 3510.54it/s]57862it [00:20, 3528.41it/s]58073it [00:20, 3619.55it/s]69235it [00:24, 3643.65it/s]58251it [00:20, 3603.21it/s]58249it [00:20, 3620.75it/s]58437it [00:20, 3333.59it/s]69603it [00:24, 3542.37it/s]58613it [00:20, 3507.29it/s]58613it [00:20, 3518.00it/s]58823it [00:20, 3478.18it/s]70001it [00:24, 3667.63it/s]58987it [00:21, 3573.37it/s]58988it [00:20, 3584.34it/s]59208it [00:20, 3582.25it/s]70371it [00:24, 3572.74it/s]59346it [00:21, 3160.77it/s]59348it [00:21, 3418.72it/s]59571it [00:21, 3458.65it/s]70761it [00:25, 3666.34it/s]59733it [00:21, 3351.29it/s]59724it [00:21, 3513.37it/s]59957it [00:21, 3572.36it/s]71130it [00:25, 3518.68it/s]60077it [00:21, 3319.57it/s]60078it [00:21, 3408.05it/s]60318it [00:21, 3461.57it/s]71497it [00:25, 3561.51it/s]60462it [00:21, 3468.30it/s]60457it [00:21, 3516.82it/s]60701it [00:21, 3561.28it/s]71886it [00:25, 3654.04it/s]60846it [00:21, 3573.27it/s]60843it [00:21, 3616.02it/s]61060it [00:21, 3488.41it/s]72253it [00:25, 3541.28it/s]61208it [00:21, 3502.38it/s]61207it [00:21, 3531.59it/s]61452it [00:21, 3610.44it/s]72645it [00:25, 3648.94it/s]61592it [00:21, 3597.87it/s]61594it [00:21, 3627.67it/s]61815it [00:21, 3512.45it/s]73012it [00:25, 3585.85it/s]73402it [00:25, 3674.73it/s]73771it [00:25, 3595.75it/s]74169it [00:25, 3706.26it/s]74541it [00:26, 3554.46it/s]74910it [00:26, 3580.70it/s]75270it [00:26, 3489.96it/s]75662it [00:26, 3613.27it/s]76045it [00:26, 3675.32it/s]76414it [00:26, 3556.59it/s]76800it [00:26, 3643.22it/s]77166it [00:26, 3534.09it/s]77558it [00:26, 3642.39it/s]77924it [00:27, 3466.47it/s]78313it [00:27, 3584.54it/s]78674it [00:27, 3482.35it/s]79058it [00:27, 3582.81it/s]79448it [00:27, 3673.52it/s]79818it [00:27, 3568.81it/s]80208it [00:27, 3663.02it/s]80576it [00:27, 3564.74it/s]62168it [00:23, 506.46it/s] 80937it [00:27, 3575.22it/s]62551it [00:23, 692.04it/s]81296it [00:27, 3469.59it/s]62860it [00:24, 869.06it/s]61959it [00:24, 467.04it/s] 81679it [00:28, 3570.82it/s]63252it [00:24, 1160.06it/s]62353it [00:24, 643.99it/s]61955it [00:24, 442.93it/s] 82038it [00:28, 3483.17it/s]63577it [00:24, 1407.48it/s]62678it [00:24, 820.71it/s]62303it [00:24, 590.61it/s]82415it [00:28, 3563.21it/s]63969it [00:24, 1774.01it/s]63028it [00:24, 1057.33it/s]62660it [00:24, 781.24it/s]82807it [00:28, 3666.82it/s]63421it [00:24, 1379.16it/s]64340it [00:24, 2052.19it/s]63053it [00:24, 1047.70it/s]83175it [00:28, 3547.54it/s]64721it [00:24, 2391.54it/s]63763it [00:24, 1644.03it/s]63447it [00:24, 1359.54it/s]83561it [00:28, 3636.72it/s]65103it [00:24, 2700.46it/s]64146it [00:24, 2000.43it/s]63795it [00:24, 1630.21it/s]83927it [00:28, 3482.21it/s]64496it [00:24, 2248.25it/s]65463it [00:24, 2823.59it/s]64147it [00:25, 1930.28it/s]84301it [00:28, 3554.39it/s]64881it [00:24, 2584.61it/s]65847it [00:24, 3072.97it/s]64492it [00:25, 2189.58it/s]84659it [00:28, 3470.56it/s]65236it [00:24, 2749.89it/s]66205it [00:25, 3126.56it/s]64877it [00:25, 2533.93it/s]85048it [00:29, 3589.63it/s]65616it [00:25, 3006.17it/s]66591it [00:25, 3320.13it/s]65231it [00:25, 2718.81it/s]85409it [00:29, 3497.15it/s]66007it [00:25, 3239.20it/s]66951it [00:25, 3289.50it/s]65610it [00:25, 2978.03it/s]66374it [00:25, 3242.87it/s]67343it [00:25, 3462.45it/s]66007it [00:25, 3232.36it/s]66764it [00:25, 3419.02it/s]67705it [00:25, 3361.20it/s]66376it [00:25, 3237.92it/s]68085it [00:25, 3483.52it/s]67129it [00:25, 3264.76it/s]66769it [00:25, 3424.95it/s]68471it [00:25, 3589.40it/s]67513it [00:25, 3419.55it/s]67136it [00:25, 3368.22it/s]68837it [00:25, 3454.48it/s]67869it [00:25, 3352.38it/s]67496it [00:25, 3430.97it/s]69219it [00:25, 3557.89it/s]68251it [00:25, 3482.08it/s]67852it [00:26, 3384.16it/s]69580it [00:25, 3478.43it/s]68607it [00:25, 3417.48it/s]68240it [00:26, 3522.38it/s]69958it [00:26, 3564.67it/s]68993it [00:26, 3541.57it/s]68600it [00:26, 3438.20it/s]70318it [00:26, 3483.71it/s]68989it [00:26, 3566.74it/s]69379it [00:26, 3462.57it/s]70709it [00:26, 3605.39it/s]69374it [00:26, 3648.08it/s]69746it [00:26, 3519.62it/s]70136it [00:26, 3626.73it/s]71072it [00:26, 3391.21it/s]69743it [00:26, 3520.92it/s]71456it [00:26, 3517.14it/s]70140it [00:26, 3649.00it/s]70502it [00:26, 3445.66it/s]71837it [00:26, 3598.30it/s]70884it [00:26, 3550.17it/s]70508it [00:26, 3456.79it/s]72200it [00:26, 3448.85it/s]70892it [00:26, 3562.83it/s]71242it [00:26, 3417.41it/s]72576it [00:26, 3535.02it/s]71625it [00:26, 3532.52it/s]71252it [00:27, 3441.25it/s]72933it [00:26, 3497.78it/s]71981it [00:26, 3464.29it/s]71638it [00:27, 3557.82it/s]73316it [00:27, 3591.99it/s]72364it [00:27, 3569.02it/s]71997it [00:27, 3470.90it/s]73677it [00:27, 3523.65it/s]72385it [00:27, 3587.03it/s]72739it [00:27, 3484.63it/s]74075it [00:27, 3653.71it/s]73122it [00:27, 3580.84it/s]72746it [00:27, 3484.48it/s]73502it [00:27, 3642.91it/s]74442it [00:27, 3464.11it/s]73149it [00:27, 3639.84it/s]74829it [00:27, 3579.21it/s]73868it [00:27, 3554.35it/s]73528it [00:27, 3682.06it/s]75200it [00:27, 3616.48it/s]74252it [00:27, 3636.77it/s]73898it [00:27, 3526.73it/s]75564it [00:27, 3419.62it/s]74617it [00:27, 3485.63it/s]74280it [00:27, 3605.90it/s]85761it [00:31, 443.24it/s] 75951it [00:27, 3545.27it/s]74997it [00:27, 3575.31it/s]74643it [00:27, 3525.23it/s]86156it [00:31, 616.56it/s]75023it [00:28, 3602.60it/s]75357it [00:27, 3473.22it/s]76309it [00:27, 3435.24it/s]86484it [00:31, 792.09it/s]75745it [00:27, 3588.20it/s]76692it [00:27, 3546.73it/s]75385it [00:28, 3511.51it/s]86870it [00:31, 1055.99it/s]75769it [00:28, 3604.68it/s]77050it [00:28, 3443.36it/s]87198it [00:32, 1299.05it/s]76106it [00:28, 3432.38it/s]77431it [00:28, 3538.02it/s]87592it [00:32, 1655.99it/s]76479it [00:28, 3514.86it/s]76131it [00:28, 3507.80it/s]76859it [00:28, 3596.22it/s]87940it [00:32, 1934.81it/s]76505it [00:28, 3573.57it/s]77787it [00:28, 3448.54it/s]88306it [00:32, 2255.74it/s]76870it [00:28, 3587.01it/s]78168it [00:28, 3550.51it/s]77221it [00:28, 3468.20it/s]88697it [00:32, 2603.44it/s]78537it [00:28, 3589.48it/s]77603it [00:28, 3568.16it/s]77230it [00:28, 3462.63it/s]89059it [00:32, 2780.42it/s]77623it [00:28, 3595.54it/s]78898it [00:28, 3480.87it/s]77962it [00:28, 3469.82it/s]89441it [00:32, 3034.08it/s]79280it [00:28, 3578.48it/s]78347it [00:28, 3578.14it/s]77985it [00:28, 3488.06it/s]89803it [00:32, 3116.65it/s]79640it [00:28, 3478.74it/s]78377it [00:29, 3610.68it/s]78707it [00:28, 3458.71it/s]90187it [00:32, 3307.36it/s]80030it [00:28, 3598.50it/s]79091it [00:28, 3565.39it/s]78740it [00:29, 3502.25it/s]90550it [00:32, 3283.85it/s]80392it [00:29, 3503.44it/s]79125it [00:29, 3600.50it/s]79459it [00:29, 3381.43it/s]90927it [00:33, 3416.95it/s]80774it [00:29, 3592.77it/s]79487it [00:29, 3487.53it/s]79841it [00:29, 3502.28it/s]91290it [00:33, 3344.24it/s]79879it [00:29, 3611.25it/s]81141it [00:29, 3427.52it/s]80225it [00:29, 3598.33it/s]91640it [00:33, 3385.55it/s]80242it [00:29, 3582.72it/s]81514it [00:29, 3512.70it/s]80588it [00:29, 3466.05it/s]92011it [00:33, 3476.81it/s]81899it [00:29, 3607.85it/s]80602it [00:29, 3506.88it/s]80969it [00:29, 3562.92it/s]92366it [00:33, 3388.12it/s]80982it [00:29, 3589.99it/s]82262it [00:29, 3499.15it/s]81328it [00:29, 3466.85it/s]92744it [00:33, 3498.22it/s]82649it [00:29, 3603.09it/s]81342it [00:29, 3500.28it/s]81698it [00:29, 3532.94it/s]93098it [00:33, 3388.36it/s]81716it [00:29, 3569.22it/s]83012it [00:29, 3501.10it/s]82053it [00:29, 3438.35it/s]93474it [00:33, 3492.01it/s]83396it [00:29, 3597.95it/s]82074it [00:30, 3490.20it/s]82439it [00:29, 3557.05it/s]82456it [00:30, 3585.21it/s]93826it [00:33, 3400.65it/s]82814it [00:29, 3611.16it/s]83758it [00:30, 3401.93it/s]94201it [00:34, 3498.69it/s]82820it [00:30, 3490.91it/s]84130it [00:30, 3491.05it/s]83177it [00:30, 3492.88it/s]94558it [00:34, 3516.57it/s]83175it [00:30, 3505.66it/s]83554it [00:30, 3572.38it/s]84501it [00:30, 3351.61it/s]83559it [00:30, 3600.74it/s]94912it [00:34, 3408.68it/s]83913it [00:30, 3431.76it/s]84879it [00:30, 3469.04it/s]95287it [00:34, 3506.74it/s]83920it [00:30, 3490.79it/s]85265it [00:30, 3579.90it/s]84295it [00:30, 3512.26it/s]84307it [00:30, 3598.08it/s]95640it [00:34, 3416.46it/s]84648it [00:30, 3426.04it/s]96019it [00:34, 3523.41it/s]84668it [00:30, 3485.43it/s]85035it [00:30, 3550.45it/s]96373it [00:34, 3430.73it/s]85058it [00:30, 3602.71it/s]85392it [00:30, 3453.67it/s]96747it [00:34, 3518.51it/s]97124it [00:34, 3591.69it/s]97485it [00:34, 3477.67it/s]97836it [00:35, 3485.95it/s]98186it [00:35, 3392.25it/s]98565it [00:35, 3505.80it/s]98917it [00:35, 3415.78it/s]99297it [00:35, 3524.68it/s]99679it [00:35, 3608.29it/s]100041it [00:35, 3469.44it/s]100404it [00:35, 3514.81it/s]100757it [00:35, 3378.25it/s]101128it [00:35, 3472.54it/s]101477it [00:36, 3393.42it/s]101857it [00:36, 3508.70it/s]102210it [00:36, 3410.15it/s]102587it [00:36, 3513.16it/s]102966it [00:36, 3592.05it/s]103327it [00:36, 3477.40it/s]103700it [00:36, 3548.75it/s]104057it [00:36, 3359.23it/s]104428it [00:36, 3457.42it/s]104777it [00:37, 3375.36it/s]105153it [00:37, 3484.80it/s]105532it [00:37, 3570.92it/s]85626it [00:33, 386.10it/s] 105891it [00:37, 3456.30it/s]86011it [00:33, 533.47it/s]85739it [00:33, 398.12it/s] 106270it [00:37, 3543.94it/s]86306it [00:33, 671.03it/s]86114it [00:33, 549.11it/s]106626it [00:37, 3430.08it/s]86692it [00:33, 911.88it/s]86427it [00:33, 705.07it/s]106983it [00:37, 3468.37it/s]87069it [00:33, 1190.29it/s]86802it [00:33, 946.99it/s]107332it [00:37, 3372.81it/s]85420it [00:34, 363.09it/s] 87407it [00:33, 1442.82it/s]87120it [00:33, 1172.68it/s]107700it [00:37, 3460.81it/s]85810it [00:34, 505.18it/s]87795it [00:34, 1801.74it/s]87510it [00:34, 1518.59it/s]108082it [00:37, 3563.39it/s]86203it [00:34, 691.06it/s]88143it [00:34, 2061.66it/s]87899it [00:34, 1882.23it/s]108440it [00:38, 3460.11it/s]86529it [00:34, 874.45it/s]88536it [00:34, 2428.68it/s]88253it [00:34, 2144.88it/s]108819it [00:38, 3555.05it/s]86915it [00:34, 1152.32it/s]88892it [00:34, 2629.71it/s]88645it [00:34, 2502.08it/s]87258it [00:34, 1413.23it/s]109176it [00:38, 3447.36it/s]89274it [00:34, 2908.37it/s]89004it [00:34, 2673.39it/s]87650it [00:34, 1771.50it/s]109556it [00:38, 3546.98it/s]89632it [00:34, 2993.37it/s]89373it [00:34, 2913.35it/s]88005it [00:34, 2039.83it/s]109913it [00:38, 3420.44it/s]90014it [00:34, 3205.65it/s]89727it [00:34, 2966.54it/s]88369it [00:34, 2347.10it/s]110263it [00:38, 3441.27it/s]90382it [00:34, 3331.54it/s]90100it [00:34, 3162.55it/s]88762it [00:34, 2688.10it/s]110610it [00:38, 3360.10it/s]90743it [00:34, 3270.56it/s]90451it [00:34, 3165.29it/s]89126it [00:35, 2851.89it/s]110990it [00:38, 3485.51it/s]91109it [00:34, 3376.52it/s]90824it [00:34, 3316.90it/s]89508it [00:35, 3091.51it/s]111365it [00:38, 3560.43it/s]91461it [00:35, 3313.94it/s]91198it [00:35, 3433.42it/s]89871it [00:35, 3152.54it/s]111723it [00:39, 3442.80it/s]91833it [00:35, 3427.11it/s]91555it [00:35, 3344.03it/s]90253it [00:35, 3330.33it/s]112101it [00:39, 3539.43it/s]92184it [00:35, 3348.99it/s]91918it [00:35, 3415.28it/s]90615it [00:35, 3273.95it/s]112457it [00:39, 3441.12it/s]92550it [00:35, 3427.52it/s]92267it [00:35, 3245.23it/s]90985it [00:35, 3389.14it/s]112829it [00:39, 3520.87it/s]92922it [00:35, 3511.25it/s]92636it [00:35, 3368.77it/s]91340it [00:35, 3263.76it/s]113183it [00:39, 3357.00it/s]93277it [00:35, 3390.95it/s]92979it [00:35, 3250.10it/s]91709it [00:35, 3371.71it/s]113550it [00:39, 3442.22it/s]93645it [00:35, 3471.60it/s]93349it [00:35, 3375.91it/s]92076it [00:35, 3454.95it/s]113931it [00:39, 3547.96it/s]93995it [00:35, 3349.66it/s]93721it [00:35, 3474.26it/s]92429it [00:36, 3373.13it/s]114288it [00:39, 3448.84it/s]94370it [00:35, 3463.17it/s]94072it [00:35, 3374.24it/s]92805it [00:36, 3483.31it/s]114667it [00:39, 3545.83it/s]94719it [00:36, 3381.77it/s]94446it [00:36, 3477.62it/s]93158it [00:36, 3394.46it/s]95092it [00:36, 3481.72it/s]94797it [00:36, 3358.94it/s]93529it [00:36, 3481.30it/s]95465it [00:36, 3553.47it/s]95161it [00:36, 3437.72it/s]93880it [00:36, 3392.67it/s]95822it [00:36, 3340.53it/s]95507it [00:36, 3335.92it/s]94257it [00:36, 3499.46it/s]96195it [00:36, 3449.08it/s]95879it [00:36, 3443.28it/s]94613it [00:36, 3516.66it/s]96543it [00:36, 3278.65it/s]96246it [00:36, 3508.44it/s]94967it [00:36, 3385.26it/s]96916it [00:36, 3403.51it/s]96599it [00:36, 3390.20it/s]95344it [00:36, 3493.69it/s]97260it [00:36, 3332.43it/s]96970it [00:36, 3480.88it/s]95696it [00:36, 3406.46it/s]97638it [00:36, 3459.00it/s]97320it [00:36, 3386.79it/s]96075it [00:37, 3515.72it/s]98011it [00:36, 3379.78it/s]97685it [00:36, 3461.67it/s]96429it [00:37, 3413.66it/s]98389it [00:37, 3492.61it/s]98033it [00:37, 3373.85it/s]96813it [00:37, 3535.19it/s]98761it [00:37, 3557.59it/s]98401it [00:37, 3460.33it/s]97169it [00:37, 3434.34it/s]99119it [00:37, 3380.49it/s]98774it [00:37, 3537.47it/s]97549it [00:37, 3538.10it/s]99479it [00:37, 3440.62it/s]99129it [00:37, 3401.77it/s]97905it [00:37, 3521.34it/s]99826it [00:37, 3309.67it/s]99499it [00:37, 3485.34it/s]98259it [00:37, 3411.59it/s]100196it [00:37, 3419.33it/s]99850it [00:37, 3381.44it/s]98638it [00:37, 3518.59it/s]100541it [00:37, 3342.11it/s]100214it [00:37, 3453.10it/s]98992it [00:37, 3420.50it/s]100919it [00:37, 3466.43it/s]100561it [00:37, 3364.40it/s]99364it [00:38, 3506.44it/s]101298it [00:37, 3560.05it/s]100937it [00:37, 3477.97it/s]99716it [00:38, 3399.55it/s]101656it [00:38, 3433.33it/s]101311it [00:38, 3552.61it/s]100098it [00:38, 3520.02it/s]102018it [00:38, 3485.24it/s]101668it [00:38, 3325.43it/s]100469it [00:38, 3574.28it/s]102369it [00:38, 3354.96it/s]102045it [00:38, 3450.11it/s]100828it [00:38, 3397.47it/s]102732it [00:38, 3431.56it/s]102394it [00:38, 3297.49it/s]101200it [00:38, 3489.21it/s]103077it [00:38, 3328.81it/s]102762it [00:38, 3402.71it/s]101552it [00:38, 3393.88it/s]103451it [00:38, 3445.13it/s]103106it [00:38, 3294.67it/s]101924it [00:38, 3486.88it/s]103823it [00:38, 3524.23it/s]103475it [00:38, 3406.30it/s]102275it [00:38, 3389.23it/s]104177it [00:38, 3413.55it/s]103849it [00:38, 3500.04it/s]102650it [00:38, 3491.58it/s]104551it [00:38, 3506.70it/s]104202it [00:38, 3397.85it/s]103030it [00:39, 3579.54it/s]104904it [00:38, 3310.52it/s]104564it [00:38, 3460.83it/s]103390it [00:39, 3452.23it/s]105277it [00:39, 3427.75it/s]104912it [00:39, 3357.18it/s]103764it [00:39, 3532.73it/s]105623it [00:39, 3289.50it/s]105279it [00:39, 3444.65it/s]115024it [00:43, 349.86it/s] 104119it [00:39, 3376.78it/s]105991it [00:39, 3390.08it/s]115396it [00:43, 482.54it/s]105625it [00:39, 3324.67it/s]104490it [00:39, 3471.21it/s]106365it [00:39, 3489.92it/s]115719it [00:43, 628.16it/s]105988it [00:39, 3409.84it/s]104840it [00:39, 3369.21it/s]116099it [00:43, 852.12it/s]106717it [00:39, 3388.86it/s]106359it [00:39, 3495.52it/s]105218it [00:39, 3485.85it/s]116484it [00:43, 1126.71it/s]107093it [00:39, 3492.86it/s]106710it [00:39, 3388.56it/s]105570it [00:39, 3388.11it/s]116825it [00:43, 1381.29it/s]107445it [00:39, 3394.22it/s]107085it [00:39, 3491.63it/s]105948it [00:39, 3498.27it/s]117206it [00:43, 1723.20it/s]107811it [00:39, 3462.99it/s]107436it [00:39, 3381.35it/s]106318it [00:40, 3554.35it/s]117555it [00:43, 1992.79it/s]108159it [00:39, 3354.88it/s]107803it [00:39, 3463.22it/s]106675it [00:40, 3440.87it/s]117936it [00:43, 2339.85it/s]108537it [00:40, 3474.96it/s]108151it [00:40, 3375.58it/s]107040it [00:40, 3476.78it/s]108909it [00:40, 3544.38it/s]118289it [00:44, 2503.92it/s]108507it [00:40, 3427.18it/s]107389it [00:40, 3372.05it/s]118665it [00:44, 2789.09it/s]108878it [00:40, 3509.38it/s]109265it [00:40, 3386.03it/s]107757it [00:40, 3458.79it/s]119037it [00:44, 3016.60it/s]109638it [00:40, 3483.68it/s]109230it [00:40, 3401.86it/s]108105it [00:40, 3387.39it/s]119393it [00:44, 3077.27it/s]109606it [00:40, 3504.02it/s]109989it [00:40, 3385.87it/s]108486it [00:40, 3508.92it/s]119770it [00:44, 3260.42it/s]110354it [00:40, 3458.89it/s]109958it [00:40, 3391.37it/s]108866it [00:40, 3593.39it/s]120126it [00:44, 3256.93it/s]110330it [00:40, 3485.47it/s]110702it [00:40, 3371.63it/s]109227it [00:40, 3458.02it/s]120506it [00:44, 3406.30it/s]111068it [00:40, 3453.38it/s]110680it [00:40, 3282.50it/s]109607it [00:40, 3554.86it/s]120863it [00:44, 3351.99it/s]111442it [00:40, 3535.16it/s]111056it [00:40, 3414.74it/s]109965it [00:41, 3442.06it/s]121219it [00:44, 3409.83it/s]111797it [00:40, 3397.18it/s]111414it [00:40, 3461.69it/s]110315it [00:41, 3456.79it/s]121591it [00:44, 3498.48it/s]112164it [00:41, 3475.36it/s]111763it [00:41, 3315.44it/s]110662it [00:41, 3356.71it/s]121947it [00:45, 3413.69it/s]112514it [00:41, 3376.26it/s]112139it [00:41, 3439.14it/s]111038it [00:41, 3471.68it/s]122326it [00:45, 3519.93it/s]112890it [00:41, 3484.21it/s]112486it [00:41, 3354.08it/s]111418it [00:41, 3566.05it/s]122682it [00:45, 3422.19it/s]113240it [00:41, 3349.85it/s]112857it [00:41, 3454.52it/s]111776it [00:41, 3451.72it/s]123062it [00:45, 3529.85it/s]113612it [00:41, 3454.52it/s]113205it [00:41, 3363.47it/s]112148it [00:41, 3528.98it/s]123418it [00:45, 3438.25it/s]113571it [00:41, 3445.89it/s]113971it [00:41, 3268.01it/s]112503it [00:41, 3426.79it/s]123790it [00:45, 3518.47it/s]113943it [00:41, 3523.30it/s]114343it [00:41, 3392.23it/s]112877it [00:41, 3516.47it/s]124144it [00:45, 3368.51it/s]114710it [00:41, 3468.85it/s]114297it [00:41, 3378.81it/s]113230it [00:42, 3347.29it/s]124515it [00:45, 3464.83it/s]114664it [00:41, 3461.22it/s]113603it [00:42, 3454.42it/s]124893it [00:45, 3553.33it/s]113970it [00:42, 3389.80it/s]125251it [00:46, 3454.11it/s]114352it [00:42, 3509.84it/s]125631it [00:46, 3552.30it/s]114723it [00:42, 3565.23it/s]125988it [00:46, 3463.54it/s]126361it [00:46, 3538.39it/s]126717it [00:46, 3444.27it/s]127096it [00:46, 3543.46it/s]127452it [00:46, 3547.78it/s]127808it [00:46, 3436.75it/s]128185it [00:46, 3532.14it/s]128540it [00:46, 3449.72it/s]128925it [00:47, 3565.40it/s]129283it [00:47, 3474.52it/s]129664it [00:47, 3570.25it/s]130023it [00:47, 3440.11it/s]130407it [00:47, 3553.17it/s]130764it [00:47, 3547.01it/s]131120it [00:47, 3431.86it/s]131497it [00:47, 3528.66it/s]131852it [00:47, 3438.29it/s]132234it [00:48, 3547.91it/s]132591it [00:48, 3448.94it/s]132974it [00:48, 3556.13it/s]133351it [00:48, 3616.74it/s]133714it [00:48, 3412.43it/s]134086it [00:48, 3497.10it/s]134439it [00:48, 3401.19it/s]134821it [00:48, 3518.23it/s]135175it [00:48, 3434.78it/s]135557it [00:48, 3544.06it/s]135914it [00:49, 3451.19it/s]136299it [00:49, 3558.61it/s]136680it [00:49, 3630.76it/s]137045it [00:49, 3453.49it/s]137406it [00:49, 3497.61it/s]137758it [00:49, 3408.72it/s]115012it [00:45, 295.02it/s] 115060it [00:45, 288.12it/s] 138138it [00:49, 3518.44it/s]115384it [00:45, 411.75it/s]115434it [00:45, 402.28it/s]138492it [00:49, 3427.91it/s]115717it [00:45, 544.86it/s]115742it [00:45, 523.06it/s]115082it [00:46, 307.97it/s] 138872it [00:49, 3533.41it/s]116093it [00:46, 743.91it/s]116119it [00:46, 719.60it/s]115459it [00:46, 428.04it/s]139239it [00:50, 3444.57it/s]116467it [00:46, 987.24it/s]116489it [00:46, 956.63it/s]115779it [00:46, 558.86it/s]139618it [00:50, 3543.35it/s]116800it [00:46, 1211.11it/s]116822it [00:46, 1178.93it/s]116154it [00:46, 760.34it/s]139995it [00:50, 3607.18it/s]117174it [00:46, 1533.32it/s]117194it [00:46, 1497.18it/s]116500it [00:46, 983.68it/s]140357it [00:50, 3417.68it/s]117510it [00:46, 1777.93it/s]117529it [00:46, 1746.05it/s]116829it [00:46, 1223.93it/s]140733it [00:50, 3513.31it/s]117887it [00:46, 2129.74it/s]117906it [00:46, 2101.42it/s]117209it [00:46, 1561.06it/s]141087it [00:50, 3409.21it/s]118237it [00:46, 2353.40it/s]118246it [00:46, 2319.66it/s]117552it [00:46, 1835.95it/s]141467it [00:50, 3519.53it/s]118601it [00:46, 2635.36it/s]118622it [00:46, 2635.51it/s]117928it [00:46, 2185.59it/s]141821it [00:50, 3429.17it/s]118977it [00:46, 2902.97it/s]118998it [00:46, 2902.88it/s]118276it [00:47, 2409.89it/s]142199it [00:50, 3529.06it/s]119329it [00:46, 2964.91it/s]119352it [00:47, 2967.51it/s]118658it [00:47, 2721.62it/s]142578it [00:50, 3604.12it/s]119692it [00:47, 3138.01it/s]119698it [00:47, 3095.44it/s]119034it [00:47, 2972.43it/s]142940it [00:51, 3483.57it/s]120039it [00:47, 3143.32it/s]120041it [00:47, 3112.56it/s]119393it [00:47, 2989.54it/s]143293it [00:51, 3495.97it/s]120407it [00:47, 3287.97it/s]120409it [00:47, 3263.30it/s]119761it [00:47, 3167.91it/s]143644it [00:51, 3401.25it/s]120757it [00:47, 3240.62it/s]120759it [00:47, 3226.81it/s]120111it [00:47, 3186.80it/s]144022it [00:51, 3508.67it/s]121119it [00:47, 3345.82it/s]121134it [00:47, 3372.02it/s]120489it [00:47, 3349.27it/s]144375it [00:51, 3420.00it/s]121494it [00:47, 3459.46it/s]121509it [00:47, 3479.65it/s]120842it [00:47, 3292.80it/s]144751it [00:51, 3516.20it/s]121848it [00:47, 3359.71it/s]121865it [00:47, 3368.41it/s]121223it [00:47, 3437.19it/s]145120it [00:51, 3431.67it/s]122222it [00:47, 3466.24it/s]122237it [00:47, 3466.14it/s]121598it [00:48, 3377.64it/s]145504it [00:51, 3547.19it/s]122573it [00:47, 3367.78it/s]122589it [00:47, 3325.93it/s]121967it [00:48, 3464.02it/s]145889it [00:51, 3633.98it/s]122941it [00:48, 3455.91it/s]122961it [00:48, 3436.02it/s]122347it [00:48, 3558.64it/s]146254it [00:52, 3501.02it/s]123290it [00:48, 3326.45it/s]123309it [00:48, 3314.03it/s]122708it [00:48, 3402.29it/s]146607it [00:52, 3508.94it/s]123659it [00:48, 3427.58it/s]123677it [00:48, 3416.19it/s]123085it [00:48, 3504.64it/s]146960it [00:52, 3426.63it/s]124021it [00:48, 3480.94it/s]124049it [00:48, 3502.78it/s]123439it [00:48, 3401.60it/s]147342it [00:52, 3538.33it/s]124372it [00:48, 3367.59it/s]124402it [00:48, 3383.46it/s]123818it [00:48, 3511.24it/s]147698it [00:52, 3449.02it/s]124747it [00:48, 3474.14it/s]124779it [00:48, 3491.94it/s]124172it [00:48, 3426.65it/s]148077it [00:52, 3545.59it/s]125097it [00:48, 3372.16it/s]125131it [00:48, 3385.65it/s]124550it [00:48, 3527.00it/s]148450it [00:52, 3598.82it/s]125470it [00:48, 3474.52it/s]125503it [00:48, 3479.73it/s]124922it [00:49, 3580.91it/s]148811it [00:52, 3484.77it/s]125820it [00:48, 3353.73it/s]125853it [00:48, 3332.87it/s]125282it [00:49, 3463.03it/s]149187it [00:52, 3562.62it/s]126198it [00:48, 3474.75it/s]126226it [00:49, 3443.83it/s]125639it [00:49, 3493.64it/s]149545it [00:53, 3393.88it/s]126567it [00:49, 3526.23it/s]126595it [00:49, 3512.77it/s]125990it [00:49, 3412.31it/s]149925it [00:53, 3507.34it/s]126922it [00:49, 3344.11it/s]126949it [00:49, 3375.60it/s]126358it [00:49, 3488.02it/s]150278it [00:53, 3426.03it/s]127299it [00:49, 3464.03it/s]127328it [00:49, 3491.99it/s]126708it [00:49, 3406.36it/s]150659it [00:53, 3534.22it/s]127648it [00:49, 3370.23it/s]127680it [00:49, 3390.51it/s]127088it [00:49, 3519.67it/s]151015it [00:53, 3441.55it/s]128026it [00:49, 3485.62it/s]128055it [00:49, 3491.67it/s]127472it [00:49, 3613.04it/s]128377it [00:49, 3379.27it/s]128406it [00:49, 3387.46it/s]127835it [00:49, 3454.38it/s]128741it [00:49, 3453.68it/s]128757it [00:49, 3420.00it/s]128217it [00:49, 3556.94it/s]129118it [00:49, 3545.18it/s]129135it [00:49, 3523.54it/s]128575it [00:50, 3459.94it/s]129474it [00:49, 3384.27it/s]129489it [00:49, 3400.52it/s]128930it [00:50, 3485.35it/s]129846it [00:50, 3479.02it/s]129859it [00:50, 3481.13it/s]129280it [00:50, 3397.71it/s]130197it [00:50, 3378.42it/s]130209it [00:50, 3378.28it/s]129659it [00:50, 3509.41it/s]130571it [00:50, 3480.14it/s]130584it [00:50, 3482.68it/s]130012it [00:50, 3422.78it/s]130921it [00:50, 3373.92it/s]130934it [00:50, 3375.73it/s]130395it [00:50, 3539.15it/s]131296it [00:50, 3480.24it/s]131309it [00:50, 3482.88it/s]130773it [00:50, 3608.24it/s]131660it [00:50, 3525.96it/s]131674it [00:50, 3530.96it/s]131135it [00:50, 3491.34it/s]132014it [00:50, 3356.81it/s]131509it [00:50, 3562.46it/s]132029it [00:50, 3329.58it/s]132373it [00:50, 3422.16it/s]132401it [00:50, 3437.70it/s]131867it [00:51, 3368.34it/s]132718it [00:50, 3281.15it/s]132243it [00:51, 3478.84it/s]132748it [00:50, 3296.52it/s]133089it [00:51, 3402.33it/s]133124it [00:51, 3426.35it/s]132594it [00:51, 3404.86it/s]133432it [00:51, 3312.16it/s]132976it [00:51, 3522.77it/s]133470it [00:51, 3330.46it/s]133806it [00:51, 3432.02it/s]133354it [00:51, 3596.87it/s]133845it [00:51, 3448.77it/s]134180it [00:51, 3520.02it/s]133716it [00:51, 3474.43it/s]134199it [00:51, 3350.90it/s]134534it [00:51, 3382.43it/s]134096it [00:51, 3567.49it/s]134548it [00:51, 3389.60it/s]134899it [00:51, 3457.94it/s]134914it [00:51, 3465.73it/s]134455it [00:51, 3450.44it/s]135247it [00:51, 3322.23it/s]134808it [00:51, 3470.86it/s]135262it [00:51, 3354.07it/s]135617it [00:51, 3428.18it/s]135633it [00:51, 3454.06it/s]135157it [00:51, 3378.73it/s]135962it [00:51, 3337.41it/s]135537it [00:52, 3497.84it/s]135980it [00:51, 3358.71it/s]136336it [00:51, 3451.06it/s]136355it [00:51, 3470.39it/s]135889it [00:52, 3406.78it/s]136712it [00:52, 3539.88it/s]136269it [00:52, 3518.56it/s]136720it [00:52, 3373.72it/s]136648it [00:52, 3597.47it/s]137068it [00:52, 3410.47it/s]137096it [00:52, 3483.46it/s]137441it [00:52, 3501.33it/s]137472it [00:52, 3560.55it/s]137009it [00:52, 3484.04it/s]137388it [00:52, 3570.94it/s]137793it [00:52, 3256.39it/s]137830it [00:52, 3329.95it/s]137747it [00:52, 3440.75it/s]138166it [00:52, 3387.56it/s]138202it [00:52, 3438.39it/s]138100it [00:52, 3465.11it/s]138509it [00:52, 3249.27it/s]138550it [00:52, 3264.02it/s]138448it [00:52, 3380.55it/s]138878it [00:52, 3370.77it/s]138925it [00:52, 3397.78it/s]138825it [00:52, 3490.05it/s]139237it [00:52, 3303.66it/s]139269it [00:52, 3337.18it/s]139208it [00:53, 3587.39it/s]139611it [00:52, 3424.43it/s]139648it [00:52, 3465.93it/s]139568it [00:53, 3478.49it/s]139986it [00:53, 3517.71it/s]140025it [00:53, 3552.78it/s]139948it [00:53, 3569.43it/s]140340it [00:53, 3407.21it/s]140383it [00:53, 3444.88it/s]140307it [00:53, 3469.93it/s]140696it [00:53, 3449.61it/s]140740it [00:53, 3479.96it/s]140656it [00:53, 3440.99it/s]141043it [00:53, 3345.02it/s]141090it [00:53, 3384.58it/s]141001it [00:53, 3329.54it/s]141410it [00:53, 3435.99it/s]141461it [00:53, 3476.37it/s]151361it [00:57, 278.79it/s] 141375it [00:53, 3445.34it/s]141757it [00:53, 3304.24it/s]141811it [00:53, 3341.20it/s]151742it [00:57, 392.26it/s]141753it [00:53, 3541.11it/s]142130it [00:53, 3424.84it/s]142187it [00:53, 3458.84it/s]152061it [00:57, 515.06it/s]142109it [00:53, 3436.60it/s]142505it [00:53, 3516.71it/s]142565it [00:53, 3549.06it/s]152444it [00:57, 710.57it/s]142488it [00:54, 3538.38it/s]142922it [00:53, 3449.68it/s]142859it [00:53, 3408.28it/s]152766it [00:57, 902.95it/s]142844it [00:54, 3442.12it/s]143300it [00:54, 3535.00it/s]143230it [00:53, 3462.83it/s]153149it [00:57, 1194.69it/s]143224it [00:54, 3543.35it/s]143578it [00:54, 3370.14it/s]143655it [00:54, 3415.89it/s]153529it [00:58, 1519.06it/s]143580it [00:54, 3439.88it/s]144022it [00:54, 3487.76it/s]143943it [00:54, 3448.62it/s]153880it [00:58, 1794.61it/s]143958it [00:54, 3535.30it/s]144373it [00:54, 3405.64it/s]144290it [00:54, 3362.36it/s]154234it [00:58, 2100.61it/s]144313it [00:54, 3348.94it/s]144748it [00:54, 3502.96it/s]144662it [00:54, 3464.79it/s]154580it [00:58, 2327.08it/s]144696it [00:54, 3482.71it/s]145034it [00:54, 3538.57it/s]145120it [00:54, 3408.39it/s]154961it [00:58, 2651.33it/s]145075it [00:54, 3568.88it/s]145389it [00:54, 3421.58it/s]145496it [00:54, 3508.30it/s]155311it [00:58, 2791.55it/s]145435it [00:54, 3469.20it/s]145764it [00:54, 3514.74it/s]145879it [00:54, 3599.29it/s]155687it [00:58, 3032.13it/s]145818it [00:54, 3571.32it/s]146117it [00:54, 3378.13it/s]146241it [00:54, 3470.84it/s]156061it [00:58, 3216.51it/s]146177it [00:55, 3467.42it/s]146491it [00:54, 3480.97it/s]146590it [00:54, 3378.13it/s]156419it [00:58, 3216.76it/s]146556it [00:55, 3557.81it/s]146841it [00:55, 3285.06it/s]146930it [00:55, 3238.68it/s]156791it [00:59, 3354.39it/s]146914it [00:55, 3420.36it/s]147213it [00:55, 3406.24it/s]147302it [00:55, 3373.12it/s]157146it [00:59, 3297.34it/s]147272it [00:55, 3464.51it/s]147583it [00:55, 3488.30it/s]147642it [00:55, 3275.55it/s]157499it [00:59, 3361.28it/s]147639it [00:55, 3384.94it/s]147935it [00:55, 3341.74it/s]148014it [00:55, 3401.35it/s]157845it [00:59, 3306.25it/s]148020it [00:55, 3504.63it/s]148311it [00:55, 3459.38it/s]148391it [00:55, 3507.55it/s]158220it [00:59, 3430.49it/s]148399it [00:55, 3585.95it/s]148660it [00:55, 3363.93it/s]148744it [00:55, 3412.55it/s]158600it [00:59, 3534.98it/s]148760it [00:55, 3466.63it/s]149018it [00:55, 3424.88it/s]149120it [00:55, 3510.66it/s]158958it [00:59, 3447.52it/s]149141it [00:55, 3564.48it/s]149363it [00:55, 3336.26it/s]149473it [00:55, 3415.68it/s]159330it [00:59, 3519.49it/s]149500it [00:56, 3465.42it/s]149737it [00:55, 3448.82it/s]149851it [00:55, 3518.08it/s]159685it [00:59, 3435.52it/s]149870it [00:56, 3531.97it/s]150101it [00:55, 3501.65it/s]150205it [00:56, 3395.27it/s]160058it [00:59, 3520.30it/s]150225it [00:56, 3426.90it/s]150453it [00:56, 3396.17it/s]150579it [00:56, 3492.37it/s]160412it [01:00, 3360.28it/s]150579it [00:56, 3457.87it/s]150822it [00:56, 3480.47it/s]150940it [00:56, 3525.17it/s]160791it [01:00, 3482.12it/s]150958it [00:56, 3553.09it/s]161150it [01:00, 3400.55it/s]161528it [01:00, 3507.29it/s]161906it [01:00, 3583.88it/s]162267it [01:00, 3483.31it/s]162649it [01:00, 3580.34it/s]163009it [01:00, 3480.08it/s]163390it [01:00, 3571.41it/s]163749it [01:01, 3413.08it/s]164136it [01:01, 3542.68it/s]164510it [01:01, 3426.66it/s]164903it [01:01, 3566.46it/s]165289it [01:01, 3650.43it/s]165657it [01:01, 3541.34it/s]166050it [01:01, 3648.44it/s]166417it [01:01, 3540.13it/s]166788it [01:01, 3586.99it/s]167149it [01:01, 3479.89it/s]167520it [01:02, 3541.93it/s]167876it [01:02, 3463.85it/s]168270it [01:02, 3598.76it/s]168658it [01:02, 3679.95it/s]169028it [01:02, 3561.54it/s]169411it [01:02, 3638.13it/s]169777it [01:02, 3517.73it/s]170142it [01:02, 3554.36it/s]170499it [01:02, 3391.22it/s]170888it [01:03, 3532.43it/s]171244it [01:03, 3450.18it/s]171631it [01:03, 3570.00it/s]172020it [01:03, 3661.68it/s]172388it [01:03, 3551.44it/s]172773it [01:03, 3636.54it/s]173139it [01:03, 3500.34it/s]173519it [01:03, 3583.38it/s]173880it [01:03, 3462.03it/s]174268it [01:03, 3579.61it/s]174628it [01:04, 3523.43it/s]175014it [01:04, 3619.42it/s]175402it [01:04, 3693.56it/s]175773it [01:04, 3581.06it/s]151315it [01:00, 274.68it/s] 151294it [01:00, 265.32it/s] 176144it [01:04, 3616.06it/s]151692it [01:00, 384.20it/s]151667it [01:00, 370.97it/s]151985it [01:00, 493.24it/s]176507it [01:04, 3423.66it/s]151969it [01:00, 481.53it/s]152361it [01:00, 681.62it/s]176896it [01:04, 3553.71it/s]152343it [01:00, 664.84it/s]152732it [01:01, 912.08it/s]151172it [01:00, 242.94it/s] 177254it [01:04, 3449.92it/s]152721it [01:00, 896.62it/s]153065it [01:01, 1144.13it/s]151541it [01:00, 340.24it/s]177632it [01:04, 3543.62it/s]153056it [01:01, 1126.15it/s]153444it [01:01, 1467.79it/s]151907it [01:01, 466.14it/s]177989it [01:05, 3471.43it/s]153430it [01:01, 1439.75it/s]153788it [01:01, 1743.76it/s]152280it [01:01, 636.40it/s]178372it [01:05, 3573.73it/s]153773it [01:01, 1704.02it/s]154163it [01:01, 2092.05it/s]152655it [01:01, 852.23it/s]178761it [01:05, 3663.19it/s]154142it [01:01, 2042.74it/s]154512it [01:01, 2328.59it/s]179129it [01:05, 3516.81it/s]152990it [01:01, 1061.37it/s]154486it [01:01, 2270.20it/s]154888it [01:01, 2639.55it/s]179501it [01:05, 3573.47it/s]153368it [01:01, 1367.07it/s]154854it [01:01, 2572.73it/s]155242it [01:01, 2852.63it/s]153706it [01:01, 1617.26it/s]179860it [01:05, 3439.23it/s]155224it [01:01, 2836.80it/s]155594it [01:01, 2929.06it/s]154076it [01:01, 1956.02it/s]180253it [01:05, 3577.64it/s]155576it [01:01, 2903.79it/s]155968it [01:01, 3136.61it/s]180613it [01:05, 3467.51it/s]154428it [01:01, 2180.67it/s]155950it [01:01, 3117.12it/s]156318it [01:02, 3156.47it/s]181005it [01:05, 3595.98it/s]154804it [01:01, 2506.64it/s]156299it [01:01, 3137.30it/s]156693it [01:02, 3318.91it/s]155179it [01:02, 2789.35it/s]181367it [01:05, 3489.99it/s]156660it [01:02, 3265.10it/s]157045it [01:02, 3288.96it/s]181748it [01:06, 3581.26it/s]155531it [01:02, 2886.68it/s]157007it [01:02, 3241.19it/s]157425it [01:02, 3432.24it/s]182134it [01:06, 3659.80it/s]155889it [01:02, 3062.83it/s]157369it [01:02, 3343.37it/s]157788it [01:02, 3357.28it/s]182502it [01:06, 3529.24it/s]156235it [01:02, 3083.95it/s]157746it [01:02, 3464.51it/s]158132it [01:02, 3362.56it/s]182869it [01:06, 3569.61it/s]156598it [01:02, 3226.42it/s]158101it [01:02, 3340.93it/s]158502it [01:02, 3458.07it/s]183228it [01:06, 3467.71it/s]156948it [01:02, 3190.96it/s]158468it [01:02, 3432.37it/s]158852it [01:02, 3386.88it/s]183613it [01:06, 3575.72it/s]157320it [01:02, 3337.40it/s]158817it [01:02, 3363.09it/s]159236it [01:02, 3515.25it/s]157679it [01:02, 3407.48it/s]183973it [01:06, 3484.25it/s]159194it [01:02, 3478.81it/s]159591it [01:03, 3429.03it/s]184364it [01:06, 3605.25it/s]158029it [01:02, 3327.56it/s]159545it [01:02, 3372.62it/s]159967it [01:03, 3523.91it/s]158402it [01:02, 3440.94it/s]184726it [01:06, 3500.03it/s]159921it [01:03, 3482.72it/s]160322it [01:03, 3428.81it/s]185112it [01:07, 3602.08it/s]160289it [01:03, 3537.40it/s]158751it [01:03, 3260.61it/s]160701it [01:03, 3532.40it/s]185489it [01:07, 3649.59it/s]159123it [01:03, 3387.88it/s]160645it [01:03, 3388.41it/s]161078it [01:03, 3592.32it/s]185856it [01:07, 3497.13it/s]161010it [01:03, 3461.28it/s]159468it [01:03, 3282.53it/s]161439it [01:03, 3394.79it/s]186243it [01:07, 3603.80it/s]159834it [01:03, 3389.02it/s]161359it [01:03, 3343.30it/s]161821it [01:03, 3515.10it/s]186606it [01:07, 3528.64it/s]160192it [01:03, 3442.80it/s]161735it [01:03, 3459.97it/s]162176it [01:03, 3430.43it/s]187013it [01:07, 3684.48it/s]160539it [01:03, 3358.54it/s]162083it [01:03, 3391.04it/s]162556it [01:03, 3535.89it/s]187384it [01:07, 3543.76it/s]160915it [01:03, 3473.68it/s]162449it [01:03, 3467.19it/s]162912it [01:03, 3445.83it/s]187777it [01:07, 3653.16it/s]161265it [01:03, 3384.07it/s]162829it [01:03, 3401.74it/s]163295it [01:04, 3554.85it/s]188145it [01:07, 3571.81it/s]161638it [01:03, 3477.04it/s]163204it [01:03, 3499.86it/s]163668it [01:04, 3472.41it/s]188533it [01:07, 3660.31it/s]161988it [01:04, 3362.93it/s]163576it [01:04, 3562.41it/s]164048it [01:04, 3565.01it/s]188901it [01:08, 3523.65it/s]162365it [01:04, 3477.99it/s]163934it [01:04, 3443.07it/s]164407it [01:04, 3533.74it/s]189262it [01:08, 3546.88it/s]162733it [01:04, 3534.42it/s]164312it [01:04, 3538.72it/s]164762it [01:04, 3450.01it/s]189640it [01:08, 3610.49it/s]163088it [01:04, 3362.76it/s]164668it [01:04, 3437.96it/s]165151it [01:04, 3574.91it/s]190003it [01:08, 3507.49it/s]163464it [01:04, 3473.35it/s]165060it [01:04, 3574.59it/s]165510it [01:04, 3484.77it/s]190396it [01:08, 3629.18it/s]163814it [01:04, 3386.43it/s]165420it [01:04, 3437.82it/s]165900it [01:04, 3602.71it/s]190761it [01:08, 3518.71it/s]164195it [01:04, 3505.38it/s]165807it [01:04, 3559.32it/s]166262it [01:04, 3514.25it/s]191141it [01:08, 3598.57it/s]164548it [01:04, 3407.56it/s]166189it [01:04, 3478.42it/s]166652it [01:05, 3623.22it/s]191503it [01:08, 3482.99it/s]164924it [01:04, 3508.46it/s]166563it [01:04, 3552.19it/s]167028it [01:05, 3496.03it/s]191887it [01:08, 3584.12it/s]165305it [01:04, 3594.70it/s]166947it [01:05, 3632.60it/s]167403it [01:05, 3566.04it/s]192247it [01:09, 3438.89it/s]165666it [01:05, 3432.43it/s]167312it [01:05, 3500.90it/s]167768it [01:05, 3589.97it/s]192633it [01:09, 3556.40it/s]166046it [01:05, 3534.89it/s]167692it [01:05, 3585.20it/s]168129it [01:05, 3503.75it/s]193008it [01:09, 3612.27it/s]166402it [01:05, 3441.67it/s]168053it [01:05, 3464.28it/s]168518it [01:05, 3612.83it/s]193371it [01:09, 3505.55it/s]166793it [01:05, 3573.23it/s]168438it [01:05, 3572.46it/s]168881it [01:05, 3512.58it/s]193755it [01:09, 3601.34it/s]167153it [01:05, 3464.11it/s]168798it [01:05, 3489.61it/s]169267it [01:05, 3611.56it/s]194117it [01:09, 3516.38it/s]167536it [01:05, 3566.31it/s]169178it [01:05, 3576.64it/s]169630it [01:05, 3502.10it/s]194507it [01:09, 3625.19it/s]167895it [01:05, 3459.51it/s]169549it [01:05, 3408.40it/s]170001it [01:05, 3560.17it/s]194871it [01:09, 3528.93it/s]168256it [01:05, 3501.35it/s]169923it [01:05, 3499.34it/s]170388it [01:06, 3650.25it/s]195267it [01:09, 3652.35it/s]168637it [01:05, 3589.79it/s]170310it [01:05, 3604.41it/s]170755it [01:06, 3469.90it/s]195634it [01:09, 3472.94it/s]168998it [01:06, 3431.82it/s]170673it [01:06, 3437.52it/s]171135it [01:06, 3562.30it/s]196011it [01:10, 3555.64it/s]169369it [01:06, 3511.00it/s]171037it [01:06, 3493.75it/s]171494it [01:06, 3475.60it/s]196397it [01:10, 3641.25it/s]169722it [01:06, 3417.52it/s]171389it [01:06, 3419.83it/s]171879it [01:06, 3581.43it/s]170107it [01:06, 3531.95it/s]171769it [01:06, 3527.85it/s]172239it [01:06, 3490.47it/s]170462it [01:06, 3435.88it/s]172124it [01:06, 3460.85it/s]172630it [01:06, 3610.84it/s]170846it [01:06, 3551.69it/s]172510it [01:06, 3575.25it/s]172993it [01:06, 3496.24it/s]171206it [01:06, 3563.96it/s]172891it [01:06, 3641.13it/s]173383it [01:06, 3611.04it/s]171564it [01:06, 3364.61it/s]173257it [01:06, 3495.89it/s]173748it [01:07, 3501.13it/s]171939it [01:06, 3473.28it/s]173628it [01:06, 3556.35it/s]174106it [01:07, 3522.59it/s]172289it [01:07, 3333.84it/s]173986it [01:07, 3375.88it/s]174500it [01:07, 3642.60it/s]172677it [01:07, 3486.10it/s]174369it [01:07, 3503.24it/s]174866it [01:07, 3519.49it/s]173029it [01:07, 3409.77it/s]174722it [01:07, 3450.73it/s]175253it [01:07, 3618.99it/s]173407it [01:07, 3514.42it/s]175103it [01:07, 3552.12it/s]175617it [01:07, 3486.06it/s]173761it [01:07, 3395.01it/s]175460it [01:07, 3454.35it/s]175999it [01:07, 3579.61it/s]174145it [01:07, 3520.45it/s]175843it [01:07, 3560.40it/s]176359it [01:07, 3470.71it/s]174521it [01:07, 3588.82it/s]176207it [01:07, 3582.58it/s]176745it [01:07, 3580.27it/s]174882it [01:07, 3459.56it/s]176567it [01:07, 3454.50it/s]177106it [01:07, 3587.84it/s]175261it [01:07, 3553.11it/s]176930it [01:07, 3502.68it/s]177466it [01:08, 3468.69it/s]175619it [01:07, 3433.09it/s]177282it [01:07, 3417.40it/s]177856it [01:08, 3591.51it/s]175996it [01:08, 3529.32it/s]177658it [01:08, 3515.80it/s]178217it [01:08, 3499.72it/s]176351it [01:08, 3416.51it/s]178011it [01:08, 3453.25it/s]178587it [01:08, 3555.95it/s]176723it [01:08, 3500.80it/s]178391it [01:08, 3552.05it/s]178944it [01:08, 3428.80it/s]177101it [01:08, 3580.27it/s]178778it [01:08, 3642.56it/s]179324it [01:08, 3534.87it/s]177461it [01:08, 3414.46it/s]179144it [01:08, 3468.48it/s]179680it [01:08, 3460.43it/s]177841it [01:08, 3522.52it/s]179523it [01:08, 3558.72it/s]180055it [01:08, 3543.32it/s]178196it [01:08, 3421.58it/s]179881it [01:08, 3455.65it/s]180427it [01:08, 3592.61it/s]178566it [01:08, 3499.55it/s]180250it [01:08, 3522.56it/s]180788it [01:09, 3493.96it/s]178918it [01:08, 3417.74it/s]180604it [01:08, 3428.88it/s]181176it [01:09, 3603.28it/s]179280it [01:09, 3474.72it/s]180991it [01:09, 3554.07it/s]181538it [01:09, 3474.97it/s]179629it [01:09, 3394.62it/s]181348it [01:09, 3451.58it/s]181928it [01:09, 3595.11it/s]180004it [01:09, 3496.79it/s]181730it [01:09, 3549.52it/s]182290it [01:09, 3519.41it/s]180393it [01:09, 3609.85it/s]182116it [01:09, 3638.10it/s]182688it [01:09, 3650.40it/s]180756it [01:09, 3377.62it/s]182482it [01:09, 3437.90it/s]183055it [01:09, 3527.68it/s]181139it [01:09, 3503.43it/s]182864it [01:09, 3545.28it/s]183413it [01:09, 3542.20it/s]181493it [01:09, 3348.79it/s]183222it [01:09, 3396.71it/s]183797it [01:09, 3627.87it/s]181874it [01:09, 3477.66it/s]183594it [01:09, 3487.79it/s]184161it [01:09, 3528.26it/s]182225it [01:09, 3392.61it/s]183946it [01:09, 3418.19it/s]184541it [01:10, 3606.13it/s]182612it [01:09, 3526.51it/s]184334it [01:09, 3549.74it/s]184903it [01:10, 3519.44it/s]184691it [01:10, 3473.46it/s]182987it [01:10, 3439.35it/s]185292it [01:10, 3625.13it/s]185080it [01:10, 3591.36it/s]183371it [01:10, 3552.46it/s]185656it [01:10, 3517.39it/s]185445it [01:10, 3606.37it/s]183738it [01:10, 3583.71it/s]186050it [01:10, 3638.66it/s]185807it [01:10, 3522.33it/s]184099it [01:10, 3478.13it/s]186416it [01:10, 3540.31it/s]186191it [01:10, 3614.26it/s]184474it [01:10, 3554.39it/s]186798it [01:10, 3618.72it/s]186554it [01:10, 3449.31it/s]187177it [01:10, 3667.63it/s]184831it [01:10, 3399.70it/s]186961it [01:10, 3626.37it/s]185216it [01:10, 3526.66it/s]187545it [01:10, 3549.81it/s]187326it [01:10, 3518.64it/s]187946it [01:11, 3681.18it/s]185571it [01:10, 3422.65it/s]187714it [01:10, 3621.53it/s]185958it [01:10, 3548.59it/s]188316it [01:11, 3566.77it/s]188079it [01:11, 3537.48it/s]188715it [01:11, 3686.23it/s]186347it [01:11, 3478.47it/s]188453it [01:11, 3593.85it/s]186739it [01:11, 3601.85it/s]189086it [01:11, 3548.49it/s]188835it [01:11, 3659.38it/s]187120it [01:11, 3661.59it/s]189470it [01:11, 3630.13it/s]189203it [01:11, 3514.60it/s]187488it [01:11, 3523.31it/s]189835it [01:11, 3476.14it/s]196764it [01:15, 232.15it/s] 189563it [01:11, 3536.51it/s]187873it [01:11, 3614.35it/s]190221it [01:11, 3582.49it/s]197153it [01:15, 326.54it/s]189919it [01:11, 3463.73it/s]188237it [01:11, 3475.34it/s]190582it [01:11, 3485.31it/s]197487it [01:15, 433.67it/s]190308it [01:11, 3585.72it/s]188622it [01:11, 3580.17it/s]190968it [01:11, 3591.76it/s]197888it [01:15, 606.54it/s]190668it [01:11, 3485.06it/s]191343it [01:11, 3635.46it/s]188983it [01:11, 3464.14it/s]198225it [01:15, 784.22it/s]191044it [01:11, 3562.44it/s]189364it [01:11, 3560.40it/s]191708it [01:12, 3518.93it/s]198616it [01:15, 1047.92it/s]191402it [01:11, 3437.01it/s]192102it [01:12, 3637.49it/s]199009it [01:15, 1357.88it/s]189722it [01:12, 3362.45it/s]191769it [01:12, 3502.93it/s]192468it [01:12, 3525.52it/s]190106it [01:12, 3494.38it/s]199373it [01:16, 1643.88it/s]192160it [01:12, 3614.99it/s]192858it [01:12, 3631.60it/s]190486it [01:12, 3578.96it/s]199745it [01:16, 1971.71it/s]192523it [01:12, 3464.37it/s]200106it [01:16, 2222.41it/s]193223it [01:12, 3437.78it/s]190847it [01:12, 3384.76it/s]192890it [01:12, 3522.11it/s]200489it [01:16, 2548.73it/s]193599it [01:12, 3526.83it/s]191222it [01:12, 3485.31it/s]193244it [01:12, 3392.42it/s]193955it [01:12, 3464.97it/s]200848it [01:16, 2722.03it/s]191574it [01:12, 3382.81it/s]193612it [01:12, 3473.04it/s]194347it [01:12, 3592.84it/s]201232it [01:16, 2989.14it/s]191959it [01:12, 3514.66it/s]193962it [01:12, 3419.16it/s]194733it [01:12, 3667.76it/s]201591it [01:16, 3078.42it/s]192313it [01:12, 3414.68it/s]194348it [01:12, 3544.03it/s]195102it [01:13, 3596.23it/s]201983it [01:16, 3299.71it/s]192699it [01:12, 3539.28it/s]194724it [01:12, 3604.33it/s]195484it [01:13, 3658.48it/s]202372it [01:16, 3459.14it/s]193064it [01:12, 3569.08it/s]195086it [01:13, 3449.46it/s]202743it [01:16, 3450.60it/s]195851it [01:13, 3527.00it/s]193423it [01:13, 3445.54it/s]195461it [01:13, 3534.93it/s]203122it [01:17, 3544.33it/s]196206it [01:13, 3522.52it/s]193795it [01:13, 3522.83it/s]195817it [01:13, 3394.86it/s]203490it [01:17, 3482.73it/s]194149it [01:13, 3344.42it/s]196194it [01:13, 3499.84it/s]203878it [01:17, 3594.82it/s]194538it [01:13, 3489.15it/s]204245it [01:17, 3511.63it/s]194890it [01:13, 3403.83it/s]204636it [01:17, 3623.79it/s]195288it [01:13, 3565.57it/s]205003it [01:17, 3503.05it/s]195647it [01:13, 3465.91it/s]205395it [01:17, 3620.89it/s]196012it [01:13, 3518.14it/s]205761it [01:17, 3521.83it/s]196387it [01:13, 3583.10it/s]206138it [01:17, 3592.77it/s]206525it [01:18, 3672.16it/s]206894it [01:18, 3580.60it/s]207294it [01:18, 3700.09it/s]207666it [01:18, 3584.50it/s]208057it [01:18, 3676.29it/s]208427it [01:18, 3571.14it/s]208821it [01:18, 3676.58it/s]209191it [01:18, 3593.01it/s]209552it [01:18, 3582.41it/s]209935it [01:18, 3653.90it/s]210302it [01:19, 3533.78it/s]210676it [01:19, 3591.56it/s]211037it [01:19, 3489.60it/s]211424it [01:19, 3598.63it/s]211786it [01:19, 3499.86it/s]212170it [01:19, 3596.38it/s]212531it [01:19, 3439.67it/s]212908it [01:19, 3532.35it/s]213282it [01:19, 3591.19it/s]213643it [01:20, 3482.52it/s]214031it [01:20, 3596.48it/s]214393it [01:20, 3488.18it/s]214774it [01:20, 3580.55it/s]215134it [01:20, 3486.84it/s]215522it [01:20, 3599.17it/s]215884it [01:20, 3421.52it/s]216269it [01:20, 3541.46it/s]216659it [01:20, 3485.16it/s]217060it [01:20, 3631.35it/s]217445it [01:21, 3693.66it/s]217817it [01:21, 3622.97it/s]218220it [01:21, 3738.46it/s]218596it [01:21, 3622.22it/s]218965it [01:21, 3640.67it/s]219331it [01:21, 3573.62it/s]219736it [01:21, 3710.29it/s]220109it [01:21, 3628.62it/s]220525it [01:21, 3782.03it/s]220905it [01:22, 3681.35it/s]221305it [01:22, 3773.18it/s]221700it [01:22, 3685.29it/s]222093it [01:22, 3753.22it/s]196560it [01:18, 217.77it/s] 222470it [01:22, 3709.89it/s]196953it [01:18, 310.47it/s]222842it [01:22, 3593.91it/s]197338it [01:18, 430.20it/s]223230it [01:22, 3674.49it/s]197727it [01:18, 591.69it/s]223599it [01:22, 3557.45it/s]198129it [01:19, 805.89it/s]223994it [01:22, 3667.16it/s]198481it [01:19, 1023.17it/s]224363it [01:22, 3532.17it/s]196547it [01:19, 202.50it/s] 198877it [01:19, 1329.61it/s]224750it [01:23, 3626.70it/s]196929it [01:19, 286.64it/s]199238it [01:19, 1607.62it/s]225115it [01:23, 3522.95it/s]197320it [01:19, 403.15it/s]199640it [01:19, 1981.23it/s]225494it [01:23, 3598.84it/s]197639it [01:19, 525.51it/s]200008it [01:19, 2208.20it/s]225856it [01:23, 3589.32it/s]198034it [01:19, 727.63it/s]200382it [01:19, 2513.35it/s]226216it [01:23, 3487.06it/s]198376it [01:19, 934.26it/s]200739it [01:19, 2694.27it/s]226597it [01:23, 3580.03it/s]198766it [01:19, 1229.80it/s]201120it [01:19, 2957.83it/s]226957it [01:23, 3456.69it/s]199120it [01:19, 1506.24it/s]201504it [01:20, 3180.84it/s]227328it [01:23, 3527.26it/s]199506it [01:19, 1859.79it/s]196747it [01:19, 195.12it/s] 201870it [01:20, 3233.18it/s]227683it [01:23, 3431.39it/s]199865it [01:20, 2129.76it/s]197126it [01:20, 275.05it/s]202268it [01:20, 3433.23it/s]228064it [01:24, 3537.36it/s]200237it [01:20, 2444.83it/s]197417it [01:20, 356.13it/s]202637it [01:20, 3431.49it/s]228420it [01:24, 3426.48it/s]200619it [01:20, 2748.87it/s]197809it [01:20, 506.26it/s]203044it [01:20, 3607.91it/s]228778it [01:24, 3467.97it/s]200983it [01:20, 2857.41it/s]198176it [01:20, 679.57it/s]203419it [01:20, 3448.63it/s]229152it [01:24, 3546.06it/s]201359it [01:20, 3081.61it/s]198562it [01:20, 915.98it/s]203804it [01:20, 3559.51it/s]229508it [01:24, 3487.83it/s]201717it [01:20, 3145.88it/s]198947it [01:20, 1197.70it/s]204169it [01:20, 3488.91it/s]229889it [01:24, 3579.86it/s]202110it [01:20, 3355.36it/s]199300it [01:20, 1467.53it/s]204555it [01:20, 3591.61it/s]230248it [01:24, 3465.46it/s]202473it [01:20, 3354.73it/s]199697it [01:20, 1832.64it/s]204919it [01:20, 3504.50it/s]230627it [01:24, 3558.72it/s]202872it [01:20, 3531.49it/s]200059it [01:20, 2087.48it/s]205315it [01:21, 3634.06it/s]230985it [01:24, 3485.30it/s]203240it [01:20, 3493.42it/s]200433it [01:20, 2407.57it/s]205702it [01:21, 3701.28it/s]231373it [01:24, 3599.29it/s]203611it [01:21, 3553.29it/s]200789it [01:21, 2583.69it/s]206075it [01:21, 3593.70it/s]231753it [01:25, 3656.25it/s]203990it [01:21, 3621.31it/s]201164it [01:21, 2851.75it/s]206438it [01:21, 3596.11it/s]232120it [01:25, 3470.47it/s]204358it [01:21, 3480.49it/s]201536it [01:21, 2919.36it/s]206800it [01:21, 3513.38it/s]232494it [01:25, 3545.44it/s]204736it [01:21, 3564.21it/s]201921it [01:21, 3152.25it/s]207198it [01:21, 3647.15it/s]232851it [01:25, 3448.15it/s]205097it [01:21, 3458.27it/s]202318it [01:21, 3366.97it/s]207565it [01:21, 3548.39it/s]233237it [01:25, 3565.90it/s]205482it [01:21, 3569.55it/s]202684it [01:21, 3355.26it/s]207961it [01:21, 3664.44it/s]233596it [01:25, 3468.82it/s]205842it [01:21, 3493.05it/s]203085it [01:21, 3534.71it/s]208329it [01:21, 3582.17it/s]233976it [01:25, 3563.76it/s]206232it [01:21, 3609.86it/s]203455it [01:21, 3455.41it/s]208719it [01:22, 3672.88it/s]234334it [01:25, 3474.89it/s]206595it [01:21, 3432.69it/s]203828it [01:21, 3531.30it/s]209098it [01:22, 3549.20it/s]234705it [01:25, 3540.22it/s]206987it [01:22, 3568.99it/s]204190it [01:22, 3453.23it/s]209472it [01:22, 3595.24it/s]235065it [01:26, 3557.46it/s]207373it [01:22, 3650.57it/s]204563it [01:22, 3530.67it/s]209841it [01:22, 3620.12it/s]235422it [01:26, 3423.57it/s]207741it [01:22, 3510.77it/s]204921it [01:22, 3434.19it/s]210205it [01:22, 3504.09it/s]235795it [01:26, 3511.43it/s]208123it [01:22, 3597.90it/s]205303it [01:22, 3543.75it/s]210584it [01:22, 3583.99it/s]236148it [01:26, 3427.83it/s]208485it [01:22, 3538.12it/s]205683it [01:22, 3617.53it/s]210944it [01:22, 3479.93it/s]236523it [01:26, 3519.83it/s]208875it [01:22, 3640.95it/s]206048it [01:22, 3515.87it/s]211331it [01:22, 3590.14it/s]236877it [01:26, 3428.53it/s]209241it [01:22, 3541.98it/s]206436it [01:22, 3616.89it/s]211692it [01:22, 3480.79it/s]237252it [01:26, 3520.39it/s]209611it [01:22, 3586.78it/s]212070it [01:22, 3564.71it/s]206800it [01:22, 3414.15it/s]237630it [01:26, 3595.80it/s]209971it [01:22, 3463.36it/s]212449it [01:23, 3627.98it/s]207192it [01:22, 3556.50it/s]237991it [01:26, 3454.96it/s]210347it [01:22, 3548.27it/s]207551it [01:23, 3434.80it/s]212813it [01:23, 3449.50it/s]238341it [01:26, 3466.10it/s]210712it [01:23, 3575.60it/s]207935it [01:23, 3547.43it/s]213192it [01:23, 3544.45it/s]238689it [01:27, 3387.94it/s]211071it [01:23, 3422.16it/s]208293it [01:23, 3460.27it/s]213549it [01:23, 3448.06it/s]239065it [01:27, 3493.49it/s]211416it [01:23, 3340.04it/s]208676it [01:23, 3561.05it/s]213932it [01:23, 3556.73it/s]239416it [01:27, 3409.97it/s]211752it [01:23, 3302.78it/s]209063it [01:23, 3647.88it/s]214290it [01:23, 3459.76it/s]239800it [01:27, 3532.44it/s]212130it [01:23, 3437.74it/s]209430it [01:23, 3521.31it/s]214672it [01:23, 3561.80it/s]240178it [01:27, 3604.39it/s]212476it [01:23, 3372.63it/s]209798it [01:23, 3565.73it/s]215030it [01:23, 3444.74it/s]240540it [01:27, 3456.62it/s]212844it [01:23, 3458.78it/s]215416it [01:23, 3561.55it/s]210157it [01:23, 3347.71it/s]240917it [01:27, 3545.63it/s]213221it [01:23, 3548.49it/s]215786it [01:24, 3600.20it/s]210530it [01:23, 3453.95it/s]241274it [01:27, 3412.28it/s]213577it [01:23, 3426.38it/s]216148it [01:24, 3503.86it/s]210879it [01:23, 3287.42it/s]241650it [01:27, 3505.55it/s]213944it [01:24, 3495.45it/s]216538it [01:24, 3615.80it/s]211262it [01:24, 3437.73it/s]242003it [01:28, 3434.31it/s]214295it [01:24, 3412.79it/s]216901it [01:24, 3535.03it/s]211616it [01:24, 3362.24it/s]242383it [01:28, 3538.64it/s]214674it [01:24, 3520.30it/s]217289it [01:24, 3634.41it/s]211997it [01:24, 3487.06it/s]242739it [01:28, 3438.44it/s]215028it [01:24, 3434.01it/s]217654it [01:24, 3545.42it/s]212375it [01:24, 3569.28it/s]243119it [01:28, 3540.82it/s]215414it [01:24, 3557.04it/s]218058it [01:24, 3681.04it/s]212735it [01:24, 3459.31it/s]243490it [01:28, 3589.22it/s]215796it [01:24, 3631.24it/s]218428it [01:24, 3579.76it/s]213093it [01:24, 3493.27it/s]243851it [01:28, 3489.13it/s]216161it [01:24, 3439.44it/s]218828it [01:24, 3699.35it/s]213444it [01:24, 3393.25it/s]244227it [01:28, 3566.54it/s]216542it [01:24, 3543.59it/s]219200it [01:24, 3552.50it/s]213806it [01:24, 3455.79it/s]244585it [01:28, 3390.60it/s]216899it [01:24, 3402.84it/s]219599it [01:25, 3675.27it/s]214153it [01:24, 3361.69it/s]244965it [01:28, 3505.89it/s]217286it [01:24, 3533.59it/s]220005it [01:25, 3784.85it/s]214529it [01:25, 3474.36it/s]245318it [01:28, 3408.90it/s]217642it [01:25, 3475.30it/s]220386it [01:25, 3695.22it/s]214907it [01:25, 3555.55it/s]245702it [01:29, 3529.45it/s]218042it [01:25, 3625.23it/s]220784it [01:25, 3774.90it/s]215264it [01:25, 3452.99it/s]246060it [01:29, 3411.12it/s]218407it [01:25, 3535.22it/s]221163it [01:25, 3664.85it/s]215650it [01:25, 3568.88it/s]246437it [01:29, 3513.25it/s]218811it [01:25, 3678.07it/s]221568it [01:25, 3775.13it/s]216009it [01:25, 3439.10it/s]246820it [01:29, 3602.34it/s]219181it [01:25, 3527.49it/s]221947it [01:25, 3669.70it/s]216377it [01:25, 3504.84it/s]247182it [01:29, 3481.38it/s]219579it [01:25, 3656.36it/s]222320it [01:25, 3684.11it/s]216729it [01:25, 3388.03it/s]247538it [01:29, 3502.92it/s]219949it [01:25, 3667.23it/s]222690it [01:25, 3549.05it/s]217113it [01:25, 3516.27it/s]247890it [01:29, 3411.92it/s]220318it [01:25, 3569.82it/s]223079it [01:26, 3645.28it/s]217496it [01:25, 3605.09it/s]248267it [01:29, 3513.24it/s]220719it [01:25, 3696.55it/s]223446it [01:26, 3543.57it/s]217859it [01:25, 3517.73it/s]248620it [01:29, 3406.67it/s]221091it [01:26, 3599.16it/s]223824it [01:26, 3610.10it/s]218255it [01:26, 3643.56it/s]249000it [01:30, 3514.41it/s]221494it [01:26, 3722.56it/s]224217it [01:26, 3700.64it/s]218621it [01:26, 3532.20it/s]249381it [01:30, 3598.98it/s]221868it [01:26, 3632.65it/s]224589it [01:26, 3560.78it/s]219013it [01:26, 3643.29it/s]249743it [01:30, 3489.23it/s]222243it [01:26, 3665.09it/s]224975it [01:26, 3644.41it/s]219379it [01:26, 3431.18it/s]250127it [01:30, 3588.27it/s]222611it [01:26, 3536.83it/s]225342it [01:26, 3518.48it/s]219775it [01:26, 3578.00it/s]250488it [01:30, 3492.05it/s]222981it [01:26, 3583.28it/s]225702it [01:26, 3539.79it/s]250849it [01:30, 3524.93it/s]220136it [01:26, 3461.00it/s]223358it [01:26, 3636.41it/s]226058it [01:26, 3440.24it/s]220537it [01:26, 3615.40it/s]251203it [01:30, 3424.69it/s]223723it [01:26, 3492.55it/s]226429it [01:26, 3516.63it/s]251581it [01:30, 3526.85it/s]220902it [01:26, 3527.55it/s]224108it [01:26, 3594.15it/s]226782it [01:27, 3427.57it/s]221293it [01:26, 3634.92it/s]251940it [01:30, 3421.12it/s]224470it [01:26, 3490.22it/s]227158it [01:27, 3520.68it/s]252328it [01:30, 3550.49it/s]221697it [01:27, 3598.29it/s]224849it [01:27, 3570.22it/s]227535it [01:27, 3590.91it/s]252706it [01:31, 3615.32it/s]222084it [01:27, 3673.90it/s]225208it [01:27, 3482.38it/s]227896it [01:27, 3485.95it/s]222453it [01:27, 3637.30it/s]253069it [01:31, 3495.66it/s]225580it [01:27, 3549.35it/s]228272it [01:27, 3563.35it/s]253447it [01:31, 3574.78it/s]222818it [01:27, 3518.72it/s]225937it [01:27, 3417.56it/s]228630it [01:27, 3405.09it/s]223192it [01:27, 3580.01it/s]226304it [01:27, 3488.82it/s]229006it [01:27, 3504.89it/s]223552it [01:27, 3423.42it/s]226669it [01:27, 3530.23it/s]229359it [01:27, 3421.93it/s]223937it [01:27, 3540.09it/s]227024it [01:27, 3418.91it/s]229752it [01:27, 3567.57it/s]224293it [01:27, 3451.47it/s]227397it [01:27, 3505.84it/s]230111it [01:28, 3470.40it/s]224675it [01:27, 3554.97it/s]227749it [01:27, 3414.75it/s]230493it [01:28, 3570.13it/s]225057it [01:27, 3456.81it/s]228126it [01:28, 3516.83it/s]230877it [01:28, 3646.83it/s]225431it [01:28, 3536.63it/s]228479it [01:28, 3293.02it/s]231243it [01:28, 3560.84it/s]225787it [01:28, 3539.63it/s]228852it [01:28, 3414.19it/s]231625it [01:28, 3634.87it/s]226143it [01:28, 3411.43it/s]229224it [01:28, 3499.79it/s]231990it [01:28, 3456.57it/s]226510it [01:28, 3484.23it/s]229577it [01:28, 3409.28it/s]232360it [01:28, 3524.52it/s]226860it [01:28, 3368.98it/s]229957it [01:28, 3520.12it/s]232715it [01:28, 3439.92it/s]227229it [01:28, 3458.69it/s]230312it [01:28, 3419.80it/s]233103it [01:28, 3564.05it/s]227577it [01:28, 3362.44it/s]230687it [01:28, 3513.76it/s]233462it [01:28, 3467.61it/s]227953it [01:28, 3475.89it/s]231041it [01:28, 3456.09it/s]233849it [01:29, 3582.56it/s]228330it [01:28, 3559.07it/s]231424it [01:28, 3563.38it/s]234237it [01:29, 3667.52it/s]228688it [01:29, 3306.16it/s]231782it [01:29, 3417.34it/s]234606it [01:29, 3513.61it/s]229058it [01:29, 3416.24it/s]232152it [01:29, 3495.41it/s]234960it [01:29, 3506.65it/s]229404it [01:29, 3317.60it/s]232526it [01:29, 3564.68it/s]235313it [01:29, 3422.91it/s]229789it [01:29, 3466.53it/s]232884it [01:29, 3451.00it/s]235689it [01:29, 3519.14it/s]230139it [01:29, 3380.08it/s]233266it [01:29, 3555.05it/s]236043it [01:29, 3444.58it/s]230515it [01:29, 3486.13it/s]233624it [01:29, 3459.88it/s]236416it [01:29, 3526.83it/s]230893it [01:29, 3569.26it/s]234005it [01:29, 3559.98it/s]236798it [01:29, 3610.97it/s]231252it [01:29, 3485.60it/s]234363it [01:29, 3468.32it/s]237161it [01:30, 3502.92it/s]231603it [01:29, 3488.89it/s]234712it [01:29, 3467.84it/s]237542it [01:30, 3589.70it/s]231953it [01:29, 3401.57it/s]235089it [01:30, 3555.08it/s]237903it [01:30, 3415.29it/s]232323it [01:30, 3485.70it/s]235446it [01:30, 3428.43it/s]238271it [01:30, 3489.60it/s]232673it [01:30, 3347.39it/s]235812it [01:30, 3493.26it/s]238622it [01:30, 3399.88it/s]233051it [01:30, 3469.58it/s]236163it [01:30, 3407.78it/s]239002it [01:30, 3512.33it/s]233432it [01:30, 3568.04it/s]236535it [01:30, 3495.96it/s]239355it [01:30, 3427.95it/s]233791it [01:30, 3464.75it/s]236886it [01:30, 3408.72it/s]239744it [01:30, 3559.01it/s]234170it [01:30, 3557.07it/s]237258it [01:30, 3497.09it/s]240121it [01:30, 3619.33it/s]237612it [01:30, 3507.10it/s]234528it [01:30, 3383.72it/s]240485it [01:30, 3495.06it/s]234895it [01:30, 3464.83it/s]237964it [01:30, 3326.37it/s]240853it [01:31, 3547.70it/s]235244it [01:30, 3372.48it/s]238335it [01:30, 3433.71it/s]241210it [01:31, 3396.99it/s]235610it [01:31, 3453.25it/s]238681it [01:31, 3321.85it/s]241585it [01:31, 3496.03it/s]239056it [01:31, 3443.49it/s]235977it [01:31, 3350.42it/s]241937it [01:31, 3423.18it/s]236353it [01:31, 3463.99it/s]239403it [01:31, 3366.15it/s]242319it [01:31, 3536.87it/s]236727it [01:31, 3542.10it/s]239783it [01:31, 3488.48it/s]242696it [01:31, 3441.71it/s]240159it [01:31, 3567.32it/s]237083it [01:31, 3434.30it/s]243079it [01:31, 3551.33it/s]237455it [01:31, 3515.58it/s]240518it [01:31, 3449.25it/s]243456it [01:31, 3612.94it/s]240876it [01:31, 3485.98it/s]237809it [01:31, 3288.22it/s]243819it [01:31, 3481.01it/s]241226it [01:31, 3408.49it/s]238186it [01:31, 3421.95it/s]244181it [01:32, 3520.36it/s]241595it [01:31, 3487.60it/s]238532it [01:31, 3281.79it/s]244535it [01:32, 3398.56it/s]241945it [01:32, 3411.01it/s]238907it [01:32, 3411.76it/s]244916it [01:32, 3514.35it/s]242322it [01:32, 3514.20it/s]239281it [01:32, 3503.02it/s]245270it [01:32, 3430.32it/s]242698it [01:32, 3583.84it/s]239634it [01:32, 3407.60it/s]245653it [01:32, 3543.67it/s]243058it [01:32, 3460.55it/s]240012it [01:32, 3511.99it/s]246036it [01:32, 3626.47it/s]243437it [01:32, 3552.97it/s]240366it [01:32, 3404.04it/s]246400it [01:32, 3486.38it/s]243794it [01:32, 3393.44it/s]240729it [01:32, 3466.92it/s]246782it [01:32, 3581.82it/s]244166it [01:32, 3483.90it/s]241078it [01:32, 3331.49it/s]247142it [01:32, 3473.69it/s]244517it [01:32, 3373.85it/s]241446it [01:32, 3429.90it/s]247499it [01:32, 3498.97it/s]244888it [01:32, 3468.97it/s]241822it [01:32, 3523.77it/s]247851it [01:33, 3397.42it/s]245237it [01:32, 3386.36it/s]242177it [01:32, 3415.40it/s]248226it [01:33, 3493.61it/s]245617it [01:33, 3504.78it/s]242553it [01:33, 3513.58it/s]248577it [01:33, 3414.46it/s]245991it [01:33, 3571.52it/s]242906it [01:33, 3404.41it/s]248962it [01:33, 3539.71it/s]246350it [01:33, 3459.83it/s]243282it [01:33, 3504.25it/s]249337it [01:33, 3598.55it/s]246730it [01:33, 3555.52it/s]243634it [01:33, 3399.19it/s]249698it [01:33, 3478.05it/s]247087it [01:33, 3328.84it/s]243989it [01:33, 3440.44it/s]250084it [01:33, 3586.61it/s]247462it [01:33, 3445.81it/s]244362it [01:33, 3522.17it/s]250445it [01:33, 3450.07it/s]247810it [01:33, 3320.31it/s]244716it [01:33, 3366.01it/s]250822it [01:33, 3539.04it/s]248181it [01:33, 3428.76it/s]245089it [01:33, 3469.22it/s]251178it [01:34, 3445.19it/s]248558it [01:33, 3525.82it/s]245438it [01:33, 3374.58it/s]251560it [01:34, 3552.67it/s]248913it [01:34, 3435.96it/s]245817it [01:34, 3491.65it/s]251936it [01:34, 3432.99it/s]249287it [01:34, 3521.95it/s]253806it [01:38, 175.06it/s] 246168it [01:34, 3393.15it/s]252326it [01:34, 3564.55it/s]254184it [01:38, 246.96it/s]249641it [01:34, 3418.86it/s]246543it [01:34, 3494.60it/s]252704it [01:34, 3624.13it/s]254529it [01:38, 335.15it/s]250002it [01:34, 3471.62it/s]246897it [01:34, 3273.78it/s]253069it [01:34, 3508.98it/s]254896it [01:38, 461.89it/s]250351it [01:34, 3383.66it/s]247275it [01:34, 3413.22it/s]253448it [01:34, 3588.38it/s]255253it [01:38, 621.94it/s]250733it [01:34, 3508.68it/s]247644it [01:34, 3489.62it/s]255585it [01:38, 803.94it/s]251099it [01:34, 3368.51it/s]247996it [01:34, 3344.31it/s]255964it [01:38, 1069.28it/s]251476it [01:34, 3479.86it/s]248368it [01:34, 3449.27it/s]256307it [01:38, 1328.16it/s]251851it [01:34, 3557.16it/s]248716it [01:34, 3378.42it/s]256692it [01:38, 1675.74it/s]252209it [01:34, 3468.08it/s]249091it [01:34, 3482.55it/s]257049it [01:38, 1959.69it/s]252581it [01:35, 3539.24it/s]249442it [01:35, 3365.89it/s]257431it [01:39, 2300.36it/s]252937it [01:35, 3442.03it/s]249814it [01:35, 3466.00it/s]257819it [01:39, 2629.77it/s]253289it [01:35, 3463.79it/s]250187it [01:35, 3533.97it/s]258182it [01:39, 2790.86it/s]253637it [01:35, 3381.88it/s]250542it [01:35, 3444.79it/s]258545it [01:39, 2993.98it/s]250912it [01:35, 3518.24it/s]258901it [01:39, 3063.89it/s]251266it [01:35, 3411.55it/s]259288it [01:39, 3277.08it/s]251642it [01:35, 3511.00it/s]259647it [01:39, 3275.85it/s]251995it [01:35, 3396.15it/s]260038it [01:39, 3450.00it/s]252364it [01:35, 3479.38it/s]260410it [01:39, 3372.43it/s]252740it [01:36, 3559.94it/s]260801it [01:40, 3522.06it/s]253098it [01:36, 3381.69it/s]261186it [01:40, 3615.29it/s]253477it [01:36, 3489.20it/s]261555it [01:40, 3471.72it/s]261936it [01:40, 3566.84it/s]262298it [01:40, 3474.12it/s]262684it [01:40, 3583.20it/s]263046it [01:40, 3477.87it/s]263434it [01:40, 3590.94it/s]263796it [01:40, 3503.95it/s]264188it [01:40, 3623.19it/s]264566it [01:41, 3666.58it/s]264935it [01:41, 3468.25it/s]265311it [01:41, 3550.42it/s]265669it [01:41, 3442.73it/s]266058it [01:41, 3568.16it/s]266417it [01:41, 3490.55it/s]266808it [01:41, 3609.16it/s]267171it [01:41, 3521.46it/s]267558it [01:41, 3621.71it/s]267942it [01:42, 3663.77it/s]268310it [01:42, 3519.54it/s]268681it [01:42, 3572.91it/s]269040it [01:42, 3464.23it/s]269425it [01:42, 3572.80it/s]269784it [01:42, 3473.29it/s]270172it [01:42, 3589.66it/s]270533it [01:42, 3486.15it/s]270911it [01:42, 3570.12it/s]271270it [01:42, 3547.18it/s]271626it [01:43, 3436.01it/s]272011it [01:43, 3552.96it/s]272368it [01:43, 3449.60it/s]272746it [01:43, 3543.20it/s]273102it [01:43, 3451.25it/s]273490it [01:43, 3573.67it/s]273850it [01:43, 3445.57it/s]274215it [01:43, 3502.37it/s]274589it [01:43, 3569.95it/s]274948it [01:44, 3457.85it/s]275339it [01:44, 3585.69it/s]275700it [01:44, 3486.78it/s]276089it [01:44, 3602.33it/s]276451it [01:44, 3476.84it/s]276834it [01:44, 3575.43it/s]277210it [01:44, 3479.28it/s]277567it [01:44, 3504.73it/s]277944it [01:44, 3579.07it/s]278304it [01:45, 3459.55it/s]278687it [01:45, 3563.70it/s]253809it [01:41, 176.89it/s] 279045it [01:45, 3474.59it/s]254185it [01:41, 248.61it/s]279416it [01:45, 3541.09it/s]254524it [01:41, 335.39it/s]279772it [01:45, 3446.58it/s]254895it [01:41, 464.04it/s]280148it [01:45, 3535.88it/s]255270it [01:41, 633.71it/s]280521it [01:45, 3592.18it/s]255607it [01:41, 815.46it/s]280882it [01:45, 3406.19it/s]255983it [01:42, 1076.62it/s]281256it [01:45, 3499.36it/s]256325it [01:42, 1332.69it/s]281609it [01:45, 3419.65it/s]256703it [01:42, 1669.54it/s]281977it [01:46, 3493.43it/s]257052it [01:42, 1947.41it/s]282328it [01:46, 3413.42it/s]257425it [01:42, 2282.72it/s]282707it [01:46, 3519.71it/s]257811it [01:42, 2616.37it/s]283087it [01:46, 3601.05it/s]258173it [01:42, 2769.98it/s]283449it [01:46, 3462.19it/s]253977it [01:42, 158.54it/s] 258554it [01:42, 3023.18it/s]283804it [01:46, 3484.95it/s]254339it [01:42, 224.10it/s]258913it [01:42, 3043.14it/s]284154it [01:46, 3403.72it/s]254622it [01:42, 292.75it/s]259297it [01:42, 3249.72it/s]284526it [01:46, 3494.86it/s]255004it [01:42, 420.66it/s]259653it [01:43, 3252.77it/s]284877it [01:46, 3421.05it/s]255367it [01:42, 574.84it/s]260043it [01:43, 3430.11it/s]285254it [01:46, 3521.68it/s]255751it [01:43, 788.07it/s]260404it [01:43, 3349.96it/s]285610it [01:47, 3427.78it/s]256134it [01:43, 1047.54it/s]260793it [01:43, 3500.39it/s]285992it [01:47, 3538.62it/s]256483it [01:43, 1300.44it/s]261178it [01:43, 3599.55it/s]286370it [01:47, 3608.56it/s]256854it [01:43, 1621.50it/s]261546it [01:43, 3497.94it/s]286732it [01:47, 3439.93it/s]257204it [01:43, 1893.71it/s]261906it [01:43, 3526.67it/s]287111it [01:47, 3537.71it/s]287112it [01:47, 2670.35it/s]
257561it [01:43, 2201.69it/s]262263it [01:43, 3417.32it/s]257907it [01:43, 2426.91it/s]262648it [01:43, 3538.61it/s]258292it [01:43, 2748.14it/s]263005it [01:44, 3451.18it/s]253829it [01:43, 154.53it/s] 258673it [01:43, 3006.98it/s]263384it [01:44, 3547.23it/s]254205it [01:43, 218.96it/s]259034it [01:44, 3092.92it/s]254525it [01:44, 292.87it/s]263764it [01:44, 3472.98it/s]259415it [01:44, 3281.76it/s]254895it [01:44, 409.75it/s]264155it [01:44, 3596.94it/s]259776it [01:44, 3195.55it/s]255264it [01:44, 562.97it/s]264536it [01:44, 3656.34it/s]260157it [01:44, 3361.22it/s]255596it [01:44, 733.34it/s]264904it [01:44, 3478.61it/s]260512it [01:44, 3259.81it/s]255964it [01:44, 974.29it/s]265282it [01:44, 3563.23it/s]260896it [01:44, 3418.89it/s]256304it [01:44, 1219.45it/s]265641it [01:44, 3465.31it/s]261249it [01:44, 3381.07it/s]256681it [01:44, 1549.03it/s]266017it [01:44, 3547.82it/s]261635it [01:44, 3515.63it/s]257045it [01:44, 1833.34it/s]266374it [01:44, 3469.69it/s]262018it [01:44, 3598.76it/s]257421it [01:44, 2177.26it/s]266767it [01:45, 3601.94it/s]262383it [01:44, 3494.93it/s]257805it [01:44, 2514.32it/s]267129it [01:45, 3506.51it/s]262762it [01:45, 3579.24it/s]258165it [01:45, 2640.35it/s]267516it [01:45, 3609.50it/s]263123it [01:45, 3466.76it/s]258547it [01:45, 2916.44it/s]267896it [01:45, 3664.36it/s]263486it [01:45, 3510.92it/s]258901it [01:45, 2973.17it/s]268264it [01:45, 3464.33it/s]263840it [01:45, 3389.60it/s]259280it [01:45, 3182.93it/s]268641it [01:45, 3549.75it/s]264225it [01:45, 3519.46it/s]259633it [01:45, 3194.47it/s]268999it [01:45, 3415.40it/s]264604it [01:45, 3597.20it/s]260008it [01:45, 3344.16it/s]269378it [01:45, 3519.34it/s]264966it [01:45, 3436.05it/s]260361it [01:45, 3381.76it/s]269733it [01:45, 3423.97it/s]265318it [01:45, 3457.86it/s]260713it [01:45, 3270.74it/s]270120it [01:46, 3550.68it/s]265666it [01:45, 3361.09it/s]261085it [01:45, 3396.12it/s]270484it [01:46, 3435.59it/s]266037it [01:46, 3460.03it/s]261433it [01:46, 3345.00it/s]270867it [01:46, 3545.13it/s]266385it [01:46, 3369.47it/s]261806it [01:46, 3451.75it/s]271226it [01:46, 3556.38it/s]266764it [01:46, 3489.06it/s]262156it [01:46, 3333.66it/s]271584it [01:46, 3453.17it/s]267128it [01:46, 3417.65it/s]262529it [01:46, 3444.42it/s]271959it [01:46, 3536.78it/s]267515it [01:46, 3545.71it/s]262911it [01:46, 3550.94it/s]272315it [01:46, 3447.72it/s]267898it [01:46, 3627.00it/s]263269it [01:46, 3448.51it/s]272698it [01:46, 3557.30it/s]268263it [01:46, 3520.91it/s]263647it [01:46, 3543.50it/s]273056it [01:46, 3469.52it/s]268645it [01:46, 3606.17it/s]264004it [01:46, 3450.23it/s]273440it [01:46, 3574.91it/s]269007it [01:46, 3464.12it/s]264379it [01:46, 3535.96it/s]273833it [01:47, 3677.23it/s]269366it [01:46, 3499.41it/s]264735it [01:46, 3428.65it/s]274202it [01:47, 3542.22it/s]269718it [01:47, 3378.79it/s]265103it [01:47, 3500.18it/s]274558it [01:47, 3528.51it/s]270099it [01:47, 3499.13it/s]265455it [01:47, 3370.39it/s]274912it [01:47, 3432.83it/s]270477it [01:47, 3578.85it/s]265841it [01:47, 3509.16it/s]275304it [01:47, 3572.17it/s]270837it [01:47, 3475.68it/s]266220it [01:47, 3588.27it/s]275663it [01:47, 3473.62it/s]271211it [01:47, 3551.33it/s]266581it [01:47, 3488.47it/s]276044it [01:47, 3569.15it/s]271568it [01:47, 3444.30it/s]266965it [01:47, 3589.67it/s]276403it [01:47, 3471.27it/s]271948it [01:47, 3544.52it/s]276785it [01:47, 3562.32it/s]267326it [01:47, 3384.65it/s]272304it [01:47, 3377.47it/s]277170it [01:48, 3644.51it/s]267708it [01:47, 3505.58it/s]272674it [01:47, 3466.02it/s]268062it [01:47, 3343.97it/s]277536it [01:48, 3418.06it/s]273023it [01:48, 3331.14it/s]268435it [01:48, 3450.55it/s]277910it [01:48, 3507.64it/s]273399it [01:48, 3451.42it/s]278264it [01:48, 3413.92it/s]268806it [01:48, 3373.47it/s]273780it [01:48, 3552.98it/s]278649it [01:48, 3538.03it/s]269180it [01:48, 3474.58it/s]274138it [01:48, 3457.44it/s]269554it [01:48, 3548.58it/s]279006it [01:48, 3458.01it/s]274516it [01:48, 3547.51it/s]279384it [01:48, 3548.15it/s]269911it [01:48, 3442.78it/s]274873it [01:48, 3417.42it/s]270282it [01:48, 3516.90it/s]279741it [01:48, 3457.17it/s]275247it [01:48, 3509.14it/s]280117it [01:48, 3542.87it/s]270636it [01:48, 3358.76it/s]275600it [01:48, 3423.72it/s]280473it [01:48, 3535.57it/s]271011it [01:48, 3468.16it/s]275973it [01:48, 3510.45it/s]280828it [01:49, 3420.99it/s]271361it [01:48, 3332.51it/s]276346it [01:48, 3573.45it/s]281201it [01:49, 3509.37it/s]271739it [01:49, 3458.05it/s]276705it [01:49, 3459.81it/s]281554it [01:49, 3430.56it/s]272115it [01:49, 3543.05it/s]277084it [01:49, 3553.02it/s]281937it [01:49, 3544.21it/s]272472it [01:49, 3430.26it/s]277441it [01:49, 3435.39it/s]282293it [01:49, 3458.10it/s]272847it [01:49, 3519.51it/s]277808it [01:49, 3500.52it/s]282675it [01:49, 3561.78it/s]273201it [01:49, 3417.03it/s]278160it [01:49, 3399.18it/s]283059it [01:49, 3641.77it/s]273556it [01:49, 3454.82it/s]278531it [01:49, 3487.52it/s]283425it [01:49, 3501.26it/s]273903it [01:49, 3378.96it/s]278888it [01:49, 3361.80it/s]283782it [01:49, 3520.05it/s]274268it [01:49, 3456.87it/s]279258it [01:49, 3456.10it/s]284136it [01:50, 3414.19it/s]274642it [01:49, 3538.70it/s]279635it [01:49, 3544.90it/s]284518it [01:50, 3528.45it/s]274997it [01:49, 3443.14it/s]279992it [01:50, 3434.07it/s]284873it [01:50, 3431.49it/s]275381it [01:50, 3555.54it/s]280363it [01:50, 3511.11it/s]285255it [01:50, 3536.95it/s]275738it [01:50, 3431.18it/s]280716it [01:50, 3400.13it/s]285611it [01:50, 3457.39it/s]276114it [01:50, 3524.83it/s]281094it [01:50, 3508.73it/s]285998it [01:50, 3575.86it/s]276468it [01:50, 3288.39it/s]281447it [01:50, 3391.61it/s]286377it [01:50, 3637.67it/s]276842it [01:50, 3413.68it/s]281823it [01:50, 3495.66it/s]286742it [01:50, 3455.72it/s]277206it [01:50, 3293.69it/s]282189it [01:50, 3541.18it/s]287112it [01:50, 2589.31it/s]
277573it [01:50, 3397.15it/s]282545it [01:50, 3401.00it/s]277950it [01:50, 3502.81it/s]282922it [01:50, 3504.44it/s]278304it [01:50, 3392.35it/s]283275it [01:50, 3412.45it/s]278680it [01:51, 3494.98it/s]283639it [01:51, 3477.13it/s]279032it [01:51, 3371.15it/s]283989it [01:51, 3395.64it/s]279396it [01:51, 3446.17it/s]284357it [01:51, 3475.44it/s]279743it [01:51, 3342.51it/s]284730it [01:51, 3549.13it/s]280114it [01:51, 3446.31it/s]285086it [01:51, 3434.94it/s]280483it [01:51, 3515.13it/s]285463it [01:51, 3529.91it/s]280836it [01:51, 3381.60it/s]285818it [01:51, 3429.82it/s]281209it [01:51, 3479.20it/s]286198it [01:51, 3534.02it/s]281559it [01:51, 3356.73it/s]286553it [01:51, 3417.64it/s]281935it [01:51, 3471.17it/s]286935it [01:52, 3531.07it/s]287112it [01:52, 2561.80it/s]
282284it [01:52, 3374.15it/s]282654it [01:52, 3465.25it/s]283027it [01:52, 3540.12it/s]283383it [01:52, 3409.50it/s]283756it [01:52, 3500.66it/s]284108it [01:52, 3416.50it/s]284479it [01:52, 3498.98it/s]284831it [01:52, 3411.94it/s]285206it [01:52, 3507.68it/s]285587it [01:53, 3594.66it/s]285948it [01:53, 3454.33it/s]286323it [01:53, 3539.07it/s]286679it [01:53, 3399.45it/s]287045it [01:53, 3473.34it/s]287112it [01:53, 2530.16it/s]
2022-07-18 12:30:38 | INFO | root | success load 287112 data
2022-07-18 12:30:38 | INFO | transformer.tokenization_utils | Model name '/data/yukangliang/预训练模型/bert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming '/data/yukangliang/预训练模型/bert-base-cased' is a path or url to a directory containing tokenizer files.
2022-07-18 12:30:38 | INFO | transformer.tokenization_utils | Didn't find file /data/yukangliang/预训练模型/bert-base-cased/added_tokens.json. We won't load it.
2022-07-18 12:30:38 | INFO | transformer.tokenization_utils | Didn't find file /data/yukangliang/预训练模型/bert-base-cased/special_tokens_map.json. We won't load it.
2022-07-18 12:30:38 | INFO | transformer.tokenization_utils | loading file /data/yukangliang/预训练模型/bert-base-cased/vocab.txt
2022-07-18 12:30:38 | INFO | transformer.tokenization_utils | loading file None
2022-07-18 12:30:38 | INFO | transformer.tokenization_utils | loading file None
2022-07-18 12:30:38 | INFO | transformer.tokenization_utils | loading file /data/yukangliang/预训练模型/bert-base-cased/tokenizer_config.json
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
2022-07-18 12:32:20 | INFO | train_inner | epoch 004:     34 / 1122 loss=8.639, nll_loss=3.787, mask_ins=1.299, word_ins_ml=5.336, word_reposition=0.997, kpe=1.008, ppl=398.77, wps=4081.9, ups=0.21, wpb=19872.6, bsz=253.8, num_updates=3400, lr=0.000340032, gnorm=2.516, clip=0, loss_scale=8192, train_wall=252, wall=0
2022-07-18 12:37:15 | INFO | train_inner | epoch 004:    134 / 1122 loss=8.522, nll_loss=3.709, mask_ins=1.288, word_ins_ml=5.265, word_reposition=0.967, kpe=1.002, ppl=367.65, wps=6763.7, ups=0.34, wpb=19950.2, bsz=256, num_updates=3500, lr=0.00035003, gnorm=2.403, clip=0, loss_scale=8192, train_wall=252, wall=0
2022-07-18 12:39:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2022-07-18 12:42:06 | INFO | train_inner | epoch 004:    235 / 1122 loss=8.462, nll_loss=3.67, mask_ins=1.256, word_ins_ml=5.229, word_reposition=0.966, kpe=1.011, ppl=352.6, wps=6920.4, ups=0.34, wpb=20148.8, bsz=256, num_updates=3600, lr=0.000360028, gnorm=2.374, clip=0, loss_scale=5799, train_wall=252, wall=0
2022-07-18 12:44:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-07-18 12:46:56 | INFO | train_inner | epoch 004:    336 / 1122 loss=8.364, nll_loss=3.59, mask_ins=1.246, word_ins_ml=5.157, word_reposition=0.951, kpe=1.009, ppl=329.51, wps=6857.3, ups=0.34, wpb=19891.7, bsz=256, num_updates=3700, lr=0.000370026, gnorm=2.383, clip=0, loss_scale=3204, train_wall=251, wall=0
2022-07-18 12:51:44 | INFO | train_inner | epoch 004:    436 / 1122 loss=8.358, nll_loss=3.584, mask_ins=1.23, word_ins_ml=5.15, word_reposition=0.944, kpe=1.034, ppl=328.06, wps=6995.2, ups=0.35, wpb=20112, bsz=256, num_updates=3800, lr=0.000380024, gnorm=2.476, clip=0, loss_scale=2048, train_wall=249, wall=0
2022-07-18 12:56:32 | INFO | train_inner | epoch 004:    536 / 1122 loss=8.23, nll_loss=3.505, mask_ins=1.203, word_ins_ml=5.08, word_reposition=0.931, kpe=1.016, ppl=300.24, wps=6922.2, ups=0.35, wpb=19932.1, bsz=256, num_updates=3900, lr=0.000390022, gnorm=2.324, clip=0, loss_scale=2048, train_wall=250, wall=0
2022-07-18 13:01:57 | INFO | train_inner | epoch 004:    636 / 1122 loss=8.218, nll_loss=3.503, mask_ins=1.194, word_ins_ml=5.076, word_reposition=0.934, kpe=1.014, ppl=297.78, wps=6141.6, ups=0.31, wpb=19995.9, bsz=256, num_updates=4000, lr=0.00040002, gnorm=2.305, clip=0, loss_scale=2048, train_wall=287, wall=0
2022-07-18 13:06:49 | INFO | train_inner | epoch 004:    736 / 1122 loss=8.161, nll_loss=3.462, mask_ins=1.173, word_ins_ml=5.038, word_reposition=0.926, kpe=1.022, ppl=286.15, wps=6901.7, ups=0.34, wpb=20166.1, bsz=256, num_updates=4100, lr=0.000410018, gnorm=2.372, clip=0, loss_scale=2048, train_wall=253, wall=0
2022-07-18 13:11:38 | INFO | train_inner | epoch 004:    836 / 1122 loss=8.093, nll_loss=3.431, mask_ins=1.154, word_ins_ml=5.01, word_reposition=0.914, kpe=1.014, ppl=273.04, wps=6905.8, ups=0.35, wpb=19921, bsz=256, num_updates=4200, lr=0.000420016, gnorm=2.228, clip=0, loss_scale=2703, train_wall=250, wall=0
2022-07-18 13:16:28 | INFO | train_inner | epoch 004:    936 / 1122 loss=8.063, nll_loss=3.415, mask_ins=1.147, word_ins_ml=4.995, word_reposition=0.914, kpe=1.009, ppl=267.48, wps=6936.4, ups=0.34, wpb=20114.6, bsz=256, num_updates=4300, lr=0.000430014, gnorm=2.205, clip=0, loss_scale=4096, train_wall=251, wall=0
2022-07-18 13:21:17 | INFO | train_inner | epoch 004:   1036 / 1122 loss=7.988, nll_loss=3.357, mask_ins=1.135, word_ins_ml=4.943, word_reposition=0.908, kpe=1.002, ppl=253.92, wps=6889.3, ups=0.35, wpb=19945.3, bsz=256, num_updates=4400, lr=0.000440012, gnorm=2.098, clip=0, loss_scale=4096, train_wall=251, wall=0
2022-07-18 13:25:24 | INFO | train | epoch 004 | loss 8.239 | nll_loss 3.52 | mask_ins 1.198 | word_ins_ml 5.091 | word_reposition 0.936 | kpe 1.013 | ppl 302.04 | wps 6439.6 | ups 0.32 | wpb 20005.9 | bsz 255.8 | num_updates 4486 | lr 0.00044861 | gnorm 2.306 | clip 0 | loss_scale 3804 | train_wall 2845 | wall 0
2022-07-18 13:26:43 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 12.528 | nll_loss 6.334 | mask_ins 1.814 | word_ins_ml 7.704 | word_reposition 1.497 | kpe 1.513 | ppl 5904.76 | wps 12266.9 | wpb 2325.1 | bsz 32 | num_updates 4486 | best_loss 12.528
2022-07-18 13:26:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_bert12_adaptor_kpe_target_ACL_cased/checkpoint_best.pt (epoch 4 @ 4486 updates, score 12.528) (writing took 6.250036024488509 seconds)
2022-07-18 13:27:30 | INFO | train_inner | epoch 005:     14 / 1122 loss=7.976, nll_loss=3.357, mask_ins=1.109, word_ins_ml=4.942, word_reposition=0.911, kpe=1.015, ppl=251.75, wps=5336.2, ups=0.27, wpb=19859.5, bsz=253.8, num_updates=4500, lr=0.00045001, gnorm=2.138, clip=0, loss_scale=4096, train_wall=248, wall=0
2022-07-18 13:32:18 | INFO | train_inner | epoch 005:    114 / 1122 loss=7.94, nll_loss=3.335, mask_ins=1.107, word_ins_ml=4.921, word_reposition=0.909, kpe=1.002, ppl=245.51, wps=6978.1, ups=0.35, wpb=20097.9, bsz=256, num_updates=4600, lr=0.000460008, gnorm=2.087, clip=0, loss_scale=4096, train_wall=250, wall=0
2022-07-18 13:37:08 | INFO | train_inner | epoch 005:    214 / 1122 loss=7.891, nll_loss=3.309, mask_ins=1.093, word_ins_ml=4.897, word_reposition=0.895, kpe=1.006, ppl=237.34, wps=6885.3, ups=0.34, wpb=20008, bsz=256, num_updates=4700, lr=0.000470006, gnorm=2.085, clip=0, loss_scale=4915, train_wall=252, wall=0
2022-07-18 13:41:57 | INFO | train_inner | epoch 005:    314 / 1122 loss=7.843, nll_loss=3.253, mask_ins=1.1, word_ins_ml=4.847, word_reposition=0.893, kpe=1.003, ppl=229.64, wps=6977.3, ups=0.35, wpb=20126.3, bsz=256, num_updates=4800, lr=0.000480004, gnorm=2.033, clip=0, loss_scale=8192, train_wall=250, wall=0
2022-07-18 13:42:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
Traceback (most recent call last):
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq_cli/train.py", line 369, in cli_main
    torch.multiprocessing.spawn(
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 130, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGTERM
/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 4 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
