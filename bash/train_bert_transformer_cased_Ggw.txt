nohup: ignoring input
2022-08-01 15:02:20 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:13803
2022-08-01 15:02:20 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:13803
2022-08-01 15:02:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2022-08-01 15:02:20 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:13803
2022-08-01 15:02:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2022-08-01 15:02:20 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:13803
2022-08-01 15:02:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2022-08-01 15:02:20 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2022-08-01 15:02:20 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-08-01 15:02:20 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 0
2022-08-01 15:02:20 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-08-01 15:02:20 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 1
2022-08-01 15:02:20 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-08-01 15:02:20 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 3
2022-08-01 15:02:20 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-08-01 15:02:20 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 2
2022-08-01 15:02:23 | INFO | fairseq_cli.train | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir='', seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, criterion='nat_loss', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', task='translation_lev', num_workers=0, skip_invalid_size_inputs_valid_test=True, max_tokens=None, max_sentences=32, required_batch_size_multiple=8, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, fixed_validation_seed=7, disable_validation=False, max_tokens_valid=None, max_sentences_valid=32, curriculum=0, distributed_world_size=4, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:13803', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, arch='kpe_editor_transformer_with_adapter', max_epoch=0, max_update=100000, clip_norm=25, sentence_avg=False, update_freq=[8], lr=[0.0005], min_lr=1e-09, use_bmuf=False, save_dir='../checkpoints_bert_transformer_cased_Ggw', restore_file='checkpoint_last.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, no_token_positional_embeddings=False, no_cross_attention=False, cross_self_attention=False, encoder_layerdrop=0, decoder_layerdrop=0, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, early_exit='6,6,6', layers_num='6,6,6', finetune_embeddings=False, finetune_whole_encoder=False, decoder_adapter_dimention=2048, finetune_position_embeddings=False, use_adapter_bert=False, keywords_num=40, constraint=False, label_smoothing=0.1, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, warmup_updates=5000, warmup_init_lr=1e-07, data='../data-bin-bert-cased-Ggw', source_lang=None, target_lang=None, load_alignments=False, left_pad_source='False', left_pad_target='False', max_source_positions=512, max_target_positions=512, upsample_primary=1, truncate_source=False, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, noise='random_delete_shuffle', random_seed=1, cached_features_dir='../cached_examples_bert_cased_510_Ggw', tokenizer_dir='/data/yukangliang/预训练模型/bert-base-cased', encoder_adapter_dimention=2048, decoder_input='target', kpe=False, share_all_embeddings=True, no_share_discriminator=True, dropout=0.3, decoder_learned_pos=True, encoder_learned_pos=True, apply_bert_init=True, cache_dir='/data/yukangliang/预训练模型/bert-base-cased', decoder_cache_dir='/data/yukangliang/预训练模型/bert-base-cased-decoder', share_decoder_input_output_embed=False, encoder='bert', decoder='transformer', keywords_gran='token', encoder_embed_path=None, encoder_embed_dim=768, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_attention_heads=8, encoder_normalize_before=False, decoder_embed_path=None, decoder_embed_dim=768, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_input=False, decoder_output_dim=768, decoder_input_dim=768, no_share_maskpredictor=False, share_discriminator_maskpredictor=False, no_share_last_layer=False, cached_dir='/data/yukangliang/预训练模型/bert-base-cased')
2022-08-01 15:02:23 | INFO | fairseq.tasks.translation | [source] dictionary: 28996 types
2022-08-01 15:02:23 | INFO | fairseq.tasks.translation | [target] dictionary: 28996 types
2022-08-01 15:02:23 | INFO | fairseq.data.data_utils | loaded 189612 examples from: ../data-bin-bert-cased-Ggw/valid.source-target.source
2022-08-01 15:02:23 | INFO | fairseq.data.data_utils | loaded 189612 examples from: ../data-bin-bert-cased-Ggw/valid.source-target.target
2022-08-01 15:02:23 | INFO | fairseq.tasks.translation | ../data-bin-bert-cased-Ggw valid source-target 189612 examples
2022-08-01 15:02:24 | INFO | transformer.configuration_utils | loading configuration file /data/yukangliang/预训练模型/bert-base-cased/config.json
2022-08-01 15:02:24 | INFO | transformer.configuration_utils | Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "pruned_heads": {},
  "torchscript": false,
  "transformers_version": "4.6.0.dev0",
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "use_cache": true,
  "vocab_size": 28996
}

2022-08-01 15:02:24 | INFO | transformer.modeling_utils | loading weights file /data/yukangliang/预训练模型/bert-base-cased/pytorch_model.bin
2022-08-01 15:02:25 | INFO | transformer.modeling_utils | Weights from pretrained model not used in BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
Trained parameters: len 514
Trained parameters: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.encoder_attn.k_proj.weight', 'decoder.layers_reposition.0.encoder_attn.k_proj.bias', 'decoder.layers_reposition.0.encoder_attn.v_proj.weight', 'decoder.layers_reposition.0.encoder_attn.v_proj.bias', 'decoder.layers_reposition.0.encoder_attn.q_proj.weight', 'decoder.layers_reposition.0.encoder_attn.q_proj.bias', 'decoder.layers_reposition.0.encoder_attn.out_proj.weight', 'decoder.layers_reposition.0.encoder_attn.out_proj.bias', 'decoder.layers_reposition.0.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.0.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.encoder_attn.k_proj.weight', 'decoder.layers_reposition.1.encoder_attn.k_proj.bias', 'decoder.layers_reposition.1.encoder_attn.v_proj.weight', 'decoder.layers_reposition.1.encoder_attn.v_proj.bias', 'decoder.layers_reposition.1.encoder_attn.q_proj.weight', 'decoder.layers_reposition.1.encoder_attn.q_proj.bias', 'decoder.layers_reposition.1.encoder_attn.out_proj.weight', 'decoder.layers_reposition.1.encoder_attn.out_proj.bias', 'decoder.layers_reposition.1.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.1.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.encoder_attn.k_proj.weight', 'decoder.layers_reposition.2.encoder_attn.k_proj.bias', 'decoder.layers_reposition.2.encoder_attn.v_proj.weight', 'decoder.layers_reposition.2.encoder_attn.v_proj.bias', 'decoder.layers_reposition.2.encoder_attn.q_proj.weight', 'decoder.layers_reposition.2.encoder_attn.q_proj.bias', 'decoder.layers_reposition.2.encoder_attn.out_proj.weight', 'decoder.layers_reposition.2.encoder_attn.out_proj.bias', 'decoder.layers_reposition.2.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.2.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.encoder_attn.k_proj.weight', 'decoder.layers_reposition.3.encoder_attn.k_proj.bias', 'decoder.layers_reposition.3.encoder_attn.v_proj.weight', 'decoder.layers_reposition.3.encoder_attn.v_proj.bias', 'decoder.layers_reposition.3.encoder_attn.q_proj.weight', 'decoder.layers_reposition.3.encoder_attn.q_proj.bias', 'decoder.layers_reposition.3.encoder_attn.out_proj.weight', 'decoder.layers_reposition.3.encoder_attn.out_proj.bias', 'decoder.layers_reposition.3.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.3.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.encoder_attn.k_proj.weight', 'decoder.layers_reposition.4.encoder_attn.k_proj.bias', 'decoder.layers_reposition.4.encoder_attn.v_proj.weight', 'decoder.layers_reposition.4.encoder_attn.v_proj.bias', 'decoder.layers_reposition.4.encoder_attn.q_proj.weight', 'decoder.layers_reposition.4.encoder_attn.q_proj.bias', 'decoder.layers_reposition.4.encoder_attn.out_proj.weight', 'decoder.layers_reposition.4.encoder_attn.out_proj.bias', 'decoder.layers_reposition.4.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.4.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.encoder_attn.k_proj.weight', 'decoder.layers_reposition.5.encoder_attn.k_proj.bias', 'decoder.layers_reposition.5.encoder_attn.v_proj.weight', 'decoder.layers_reposition.5.encoder_attn.v_proj.bias', 'decoder.layers_reposition.5.encoder_attn.q_proj.weight', 'decoder.layers_reposition.5.encoder_attn.q_proj.bias', 'decoder.layers_reposition.5.encoder_attn.out_proj.weight', 'decoder.layers_reposition.5.encoder_attn.out_proj.bias', 'decoder.layers_reposition.5.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.5.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
Trained parameters not adapter: len 394
Trained parameters not adapter: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
2022-08-01 15:02:27 | INFO | fairseq_cli.train | KPEEDITORTransformerModel(
  (encoder): BertEncoder(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(28996, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (decoder): EditorTransformerDecoder(
    (embed_tokens): Embedding(28996, 768, padding_idx=0)
    (embed_positions): LearnedPositionalEmbedding(513, 768, padding_idx=0)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=28996, bias=False)
    (embed_mask_ins): Embedding(256, 1536)
    (layers_reposition): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
2022-08-01 15:02:27 | INFO | fairseq_cli.train | model kpe_editor_transformer_with_adapter, criterion LabelSmoothedDualImitationCriterion
2022-08-01 15:02:27 | INFO | fairseq_cli.train | num. model params: 225901056 (num. trained: 225901056)
2022-08-01 15:02:27 | INFO | fairseq_cli.train | num. Encoder model params: 108310272 (Encoder num. trained: 108310272)
2022-08-01 15:02:27 | INFO | fairseq_cli.train | num. Decoder model params: 117590784 (Decoder num. trained: 117590784)
Trained parameters: len 514
Trained parameters: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.encoder_attn.k_proj.weight', 'decoder.layers_reposition.0.encoder_attn.k_proj.bias', 'decoder.layers_reposition.0.encoder_attn.v_proj.weight', 'decoder.layers_reposition.0.encoder_attn.v_proj.bias', 'decoder.layers_reposition.0.encoder_attn.q_proj.weight', 'decoder.layers_reposition.0.encoder_attn.q_proj.bias', 'decoder.layers_reposition.0.encoder_attn.out_proj.weight', 'decoder.layers_reposition.0.encoder_attn.out_proj.bias', 'decoder.layers_reposition.0.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.0.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.encoder_attn.k_proj.weight', 'decoder.layers_reposition.1.encoder_attn.k_proj.bias', 'decoder.layers_reposition.1.encoder_attn.v_proj.weight', 'decoder.layers_reposition.1.encoder_attn.v_proj.bias', 'decoder.layers_reposition.1.encoder_attn.q_proj.weight', 'decoder.layers_reposition.1.encoder_attn.q_proj.bias', 'decoder.layers_reposition.1.encoder_attn.out_proj.weight', 'decoder.layers_reposition.1.encoder_attn.out_proj.bias', 'decoder.layers_reposition.1.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.1.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.encoder_attn.k_proj.weight', 'decoder.layers_reposition.2.encoder_attn.k_proj.bias', 'decoder.layers_reposition.2.encoder_attn.v_proj.weight', 'decoder.layers_reposition.2.encoder_attn.v_proj.bias', 'decoder.layers_reposition.2.encoder_attn.q_proj.weight', 'decoder.layers_reposition.2.encoder_attn.q_proj.bias', 'decoder.layers_reposition.2.encoder_attn.out_proj.weight', 'decoder.layers_reposition.2.encoder_attn.out_proj.bias', 'decoder.layers_reposition.2.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.2.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.encoder_attn.k_proj.weight', 'decoder.layers_reposition.3.encoder_attn.k_proj.bias', 'decoder.layers_reposition.3.encoder_attn.v_proj.weight', 'decoder.layers_reposition.3.encoder_attn.v_proj.bias', 'decoder.layers_reposition.3.encoder_attn.q_proj.weight', 'decoder.layers_reposition.3.encoder_attn.q_proj.bias', 'decoder.layers_reposition.3.encoder_attn.out_proj.weight', 'decoder.layers_reposition.3.encoder_attn.out_proj.bias', 'decoder.layers_reposition.3.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.3.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.encoder_attn.k_proj.weight', 'decoder.layers_reposition.4.encoder_attn.k_proj.bias', 'decoder.layers_reposition.4.encoder_attn.v_proj.weight', 'decoder.layers_reposition.4.encoder_attn.v_proj.bias', 'decoder.layers_reposition.4.encoder_attn.q_proj.weight', 'decoder.layers_reposition.4.encoder_attn.q_proj.bias', 'decoder.layers_reposition.4.encoder_attn.out_proj.weight', 'decoder.layers_reposition.4.encoder_attn.out_proj.bias', 'decoder.layers_reposition.4.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.4.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.encoder_attn.k_proj.weight', 'decoder.layers_reposition.5.encoder_attn.k_proj.bias', 'decoder.layers_reposition.5.encoder_attn.v_proj.weight', 'decoder.layers_reposition.5.encoder_attn.v_proj.bias', 'decoder.layers_reposition.5.encoder_attn.q_proj.weight', 'decoder.layers_reposition.5.encoder_attn.q_proj.bias', 'decoder.layers_reposition.5.encoder_attn.out_proj.weight', 'decoder.layers_reposition.5.encoder_attn.out_proj.bias', 'decoder.layers_reposition.5.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.5.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
Trained parameters not adapter: len 394
Trained parameters not adapter: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']Trained parameters: len 514
Trained parameters: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.encoder_attn.k_proj.weight', 'decoder.layers_reposition.0.encoder_attn.k_proj.bias', 'decoder.layers_reposition.0.encoder_attn.v_proj.weight', 'decoder.layers_reposition.0.encoder_attn.v_proj.bias', 'decoder.layers_reposition.0.encoder_attn.q_proj.weight', 'decoder.layers_reposition.0.encoder_attn.q_proj.bias', 'decoder.layers_reposition.0.encoder_attn.out_proj.weight', 'decoder.layers_reposition.0.encoder_attn.out_proj.bias', 'decoder.layers_reposition.0.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.0.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.encoder_attn.k_proj.weight', 'decoder.layers_reposition.1.encoder_attn.k_proj.bias', 'decoder.layers_reposition.1.encoder_attn.v_proj.weight', 'decoder.layers_reposition.1.encoder_attn.v_proj.bias', 'decoder.layers_reposition.1.encoder_attn.q_proj.weight', 'decoder.layers_reposition.1.encoder_attn.q_proj.bias', 'decoder.layers_reposition.1.encoder_attn.out_proj.weight', 'decoder.layers_reposition.1.encoder_attn.out_proj.bias', 'decoder.layers_reposition.1.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.1.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.encoder_attn.k_proj.weight', 'decoder.layers_reposition.2.encoder_attn.k_proj.bias', 'decoder.layers_reposition.2.encoder_attn.v_proj.weight', 'decoder.layers_reposition.2.encoder_attn.v_proj.bias', 'decoder.layers_reposition.2.encoder_attn.q_proj.weight', 'decoder.layers_reposition.2.encoder_attn.q_proj.bias', 'decoder.layers_reposition.2.encoder_attn.out_proj.weight', 'decoder.layers_reposition.2.encoder_attn.out_proj.bias', 'decoder.layers_reposition.2.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.2.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.encoder_attn.k_proj.weight', 'decoder.layers_reposition.3.encoder_attn.k_proj.bias', 'decoder.layers_reposition.3.encoder_attn.v_proj.weight', 'decoder.layers_reposition.3.encoder_attn.v_proj.bias', 'decoder.layers_reposition.3.encoder_attn.q_proj.weight', 'decoder.layers_reposition.3.encoder_attn.q_proj.bias', 'decoder.layers_reposition.3.encoder_attn.out_proj.weight', 'decoder.layers_reposition.3.encoder_attn.out_proj.bias', 'decoder.layers_reposition.3.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.3.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.encoder_attn.k_proj.weight', 'decoder.layers_reposition.4.encoder_attn.k_proj.bias', 'decoder.layers_reposition.4.encoder_attn.v_proj.weight', 'decoder.layers_reposition.4.encoder_attn.v_proj.bias', 'decoder.layers_reposition.4.encoder_attn.q_proj.weight', 'decoder.layers_reposition.4.encoder_attn.q_proj.bias', 'decoder.layers_reposition.4.encoder_attn.out_proj.weight', 'decoder.layers_reposition.4.encoder_attn.out_proj.bias', 'decoder.layers_reposition.4.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.4.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.encoder_attn.k_proj.weight', 'decoder.layers_reposition.5.encoder_attn.k_proj.bias', 'decoder.layers_reposition.5.encoder_attn.v_proj.weight', 'decoder.layers_reposition.5.encoder_attn.v_proj.bias', 'decoder.layers_reposition.5.encoder_attn.q_proj.weight', 'decoder.layers_reposition.5.encoder_attn.q_proj.bias', 'decoder.layers_reposition.5.encoder_attn.out_proj.weight', 'decoder.layers_reposition.5.encoder_attn.out_proj.bias', 'decoder.layers_reposition.5.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.5.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
Trained parameters not adapter: len 394
Trained parameters not adapter: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']Trained parameters: len 514
Trained parameters: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.encoder_attn.k_proj.weight', 'decoder.layers_reposition.0.encoder_attn.k_proj.bias', 'decoder.layers_reposition.0.encoder_attn.v_proj.weight', 'decoder.layers_reposition.0.encoder_attn.v_proj.bias', 'decoder.layers_reposition.0.encoder_attn.q_proj.weight', 'decoder.layers_reposition.0.encoder_attn.q_proj.bias', 'decoder.layers_reposition.0.encoder_attn.out_proj.weight', 'decoder.layers_reposition.0.encoder_attn.out_proj.bias', 'decoder.layers_reposition.0.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.0.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.encoder_attn.k_proj.weight', 'decoder.layers_reposition.1.encoder_attn.k_proj.bias', 'decoder.layers_reposition.1.encoder_attn.v_proj.weight', 'decoder.layers_reposition.1.encoder_attn.v_proj.bias', 'decoder.layers_reposition.1.encoder_attn.q_proj.weight', 'decoder.layers_reposition.1.encoder_attn.q_proj.bias', 'decoder.layers_reposition.1.encoder_attn.out_proj.weight', 'decoder.layers_reposition.1.encoder_attn.out_proj.bias', 'decoder.layers_reposition.1.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.1.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.encoder_attn.k_proj.weight', 'decoder.layers_reposition.2.encoder_attn.k_proj.bias', 'decoder.layers_reposition.2.encoder_attn.v_proj.weight', 'decoder.layers_reposition.2.encoder_attn.v_proj.bias', 'decoder.layers_reposition.2.encoder_attn.q_proj.weight', 'decoder.layers_reposition.2.encoder_attn.q_proj.bias', 'decoder.layers_reposition.2.encoder_attn.out_proj.weight', 'decoder.layers_reposition.2.encoder_attn.out_proj.bias', 'decoder.layers_reposition.2.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.2.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.encoder_attn.k_proj.weight', 'decoder.layers_reposition.3.encoder_attn.k_proj.bias', 'decoder.layers_reposition.3.encoder_attn.v_proj.weight', 'decoder.layers_reposition.3.encoder_attn.v_proj.bias', 'decoder.layers_reposition.3.encoder_attn.q_proj.weight', 'decoder.layers_reposition.3.encoder_attn.q_proj.bias', 'decoder.layers_reposition.3.encoder_attn.out_proj.weight', 'decoder.layers_reposition.3.encoder_attn.out_proj.bias', 'decoder.layers_reposition.3.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.3.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.encoder_attn.k_proj.weight', 'decoder.layers_reposition.4.encoder_attn.k_proj.bias', 'decoder.layers_reposition.4.encoder_attn.v_proj.weight', 'decoder.layers_reposition.4.encoder_attn.v_proj.bias', 'decoder.layers_reposition.4.encoder_attn.q_proj.weight', 'decoder.layers_reposition.4.encoder_attn.q_proj.bias', 'decoder.layers_reposition.4.encoder_attn.out_proj.weight', 'decoder.layers_reposition.4.encoder_attn.out_proj.bias', 'decoder.layers_reposition.4.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.4.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.encoder_attn.k_proj.weight', 'decoder.layers_reposition.5.encoder_attn.k_proj.bias', 'decoder.layers_reposition.5.encoder_attn.v_proj.weight', 'decoder.layers_reposition.5.encoder_attn.v_proj.bias', 'decoder.layers_reposition.5.encoder_attn.q_proj.weight', 'decoder.layers_reposition.5.encoder_attn.q_proj.bias', 'decoder.layers_reposition.5.encoder_attn.out_proj.weight', 'decoder.layers_reposition.5.encoder_attn.out_proj.bias', 'decoder.layers_reposition.5.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.5.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
Trained parameters not adapter: len 394
Trained parameters not adapter: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']2022-08-01 15:02:30 | INFO | fairseq_cli.train | training on 4 GPUs
2022-08-01 15:02:30 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 32
2022-08-01 15:02:30 | INFO | fairseq.trainer | no existing checkpoint found ../checkpoints_bert_transformer_cased_Ggw/checkpoint_last.pt
2022-08-01 15:02:30 | INFO | fairseq.trainer | loading train data for epoch 1
2022-08-01 15:02:30 | INFO | fairseq.data.data_utils | loaded 3803212 examples from: ../data-bin-bert-cased-Ggw/train.source-target.source
2022-08-01 15:02:30 | INFO | fairseq.data.data_utils | loaded 3803212 examples from: ../data-bin-bert-cased-Ggw/train.source-target.target
2022-08-01 15:02:30 | INFO | fairseq.tasks.translation | ../data-bin-bert-cased-Ggw train source-target 3803212 examples
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
2022-08-01 15:04:51 | INFO | train_inner | epoch 001:    100 / 3715 loss=23.385, nll_loss=14.333, mask_ins=7.543, word_ins_ml=14.459, word_reposition=1.383, ppl=1.09577e+07, wps=13206.3, ups=0.9, wpb=14605, bsz=1024, num_updates=100, lr=1.0098e-05, gnorm=18.518, clip=0, loss_scale=128, train_wall=111, wall=141
2022-08-01 15:06:39 | INFO | train_inner | epoch 001:    200 / 3715 loss=17.837, nll_loss=12.546, mask_ins=4.343, word_ins_ml=12.86, word_reposition=0.634, ppl=234194, wps=13559.3, ups=0.93, wpb=14603.1, bsz=1024, num_updates=200, lr=2.0096e-05, gnorm=17.738, clip=0, loss_scale=128, train_wall=106, wall=249
2022-08-01 15:08:26 | INFO | train_inner | epoch 001:    300 / 3715 loss=14.609, nll_loss=11.234, mask_ins=2.277, word_ins_ml=11.721, word_reposition=0.611, ppl=24991.5, wps=13823.8, ups=0.94, wpb=14772, bsz=1024, num_updates=300, lr=3.0094e-05, gnorm=3.973, clip=0, loss_scale=128, train_wall=105, wall=356
2022-08-01 15:10:14 | INFO | train_inner | epoch 001:    400 / 3715 loss=13.695, nll_loss=10.408, mask_ins=1.97, word_ins_ml=11.042, word_reposition=0.682, ppl=13260.9, wps=13604.9, ups=0.92, wpb=14728.8, bsz=1024, num_updates=400, lr=4.0092e-05, gnorm=1.696, clip=0, loss_scale=128, train_wall=106, wall=464
2022-08-01 15:12:03 | INFO | train_inner | epoch 001:    500 / 3715 loss=13.334, nll_loss=10.015, mask_ins=1.906, word_ins_ml=10.723, word_reposition=0.706, ppl=10324.2, wps=13369.5, ups=0.92, wpb=14607.3, bsz=1024, num_updates=500, lr=5.009e-05, gnorm=1.851, clip=0, loss_scale=128, train_wall=107, wall=573
2022-08-01 15:13:52 | INFO | train_inner | epoch 001:    600 / 3715 loss=13.079, nll_loss=9.722, mask_ins=1.884, word_ins_ml=10.473, word_reposition=0.722, ppl=8654.38, wps=13448.3, ups=0.92, wpb=14581.3, bsz=1024, num_updates=600, lr=6.0088e-05, gnorm=1.647, clip=0, loss_scale=242, train_wall=107, wall=682
2022-08-01 15:15:46 | INFO | train_inner | epoch 001:    700 / 3715 loss=12.848, nll_loss=9.446, mask_ins=1.883, word_ins_ml=10.232, word_reposition=0.732, ppl=7372.18, wps=12928.1, ups=0.88, wpb=14738.3, bsz=1024, num_updates=700, lr=7.0086e-05, gnorm=1.728, clip=0, loss_scale=256, train_wall=112, wall=796
2022-08-01 15:17:40 | INFO | train_inner | epoch 001:    800 / 3715 loss=12.624, nll_loss=9.21, mask_ins=1.878, word_ins_ml=10.024, word_reposition=0.722, ppl=6312.78, wps=12874.7, ups=0.88, wpb=14637, bsz=1024, num_updates=800, lr=8.0084e-05, gnorm=1.664, clip=0, loss_scale=256, train_wall=112, wall=909
2022-08-01 15:19:28 | INFO | train_inner | epoch 001:    900 / 3715 loss=12.441, nll_loss=9.014, mask_ins=1.875, word_ins_ml=9.851, word_reposition=0.715, ppl=5561.77, wps=13349.4, ups=0.92, wpb=14512.1, bsz=1024, num_updates=900, lr=9.0082e-05, gnorm=1.738, clip=0, loss_scale=256, train_wall=107, wall=1018
2022-08-01 15:21:16 | INFO | train_inner | epoch 001:   1000 / 3715 loss=12.278, nll_loss=8.819, mask_ins=1.877, word_ins_ml=9.679, word_reposition=0.722, ppl=4968.04, wps=13523.6, ups=0.93, wpb=14576.3, bsz=1024, num_updates=1000, lr=0.00010008, gnorm=1.699, clip=0, loss_scale=256, train_wall=106, wall=1126
2022-08-01 15:23:01 | INFO | train_inner | epoch 001:   1100 / 3715 loss=12.117, nll_loss=8.651, mask_ins=1.864, word_ins_ml=9.531, word_reposition=0.722, ppl=4440.99, wps=14011.3, ups=0.96, wpb=14664.5, bsz=1024, num_updates=1100, lr=0.000110078, gnorm=1.494, clip=0, loss_scale=453, train_wall=103, wall=1231
2022-08-01 15:24:43 | INFO | train_inner | epoch 001:   1200 / 3715 loss=12.001, nll_loss=8.511, mask_ins=1.869, word_ins_ml=9.408, word_reposition=0.724, ppl=4099.23, wps=14412, ups=0.98, wpb=14698.2, bsz=1024, num_updates=1200, lr=0.000120076, gnorm=1.613, clip=0, loss_scale=512, train_wall=100, wall=1333
2022-08-01 15:26:26 | INFO | train_inner | epoch 001:   1300 / 3715 loss=11.867, nll_loss=8.377, mask_ins=1.858, word_ins_ml=9.29, word_reposition=0.719, ppl=3734.76, wps=14176.2, ups=0.97, wpb=14674.2, bsz=1024, num_updates=1300, lr=0.000130074, gnorm=1.554, clip=0, loss_scale=512, train_wall=102, wall=1436
2022-08-01 15:28:13 | INFO | train_inner | epoch 001:   1400 / 3715 loss=11.766, nll_loss=8.276, mask_ins=1.853, word_ins_ml=9.201, word_reposition=0.711, ppl=3482.81, wps=13886.6, ups=0.94, wpb=14762.6, bsz=1024, num_updates=1400, lr=0.000140072, gnorm=1.696, clip=0, loss_scale=512, train_wall=104, wall=1542
2022-08-01 15:30:00 | INFO | train_inner | epoch 001:   1500 / 3715 loss=11.634, nll_loss=8.149, mask_ins=1.84, word_ins_ml=9.09, word_reposition=0.705, ppl=3178.86, wps=13673.7, ups=0.93, wpb=14653.9, bsz=1024, num_updates=1500, lr=0.00015007, gnorm=1.51, clip=0, loss_scale=512, train_wall=105, wall=1650
2022-08-01 15:31:46 | INFO | train_inner | epoch 001:   1600 / 3715 loss=11.454, nll_loss=7.931, mask_ins=1.834, word_ins_ml=8.897, word_reposition=0.723, ppl=2805.31, wps=13873.9, ups=0.94, wpb=14712.5, bsz=1024, num_updates=1600, lr=0.000160068, gnorm=1.765, clip=0, loss_scale=845, train_wall=104, wall=1756
2022-08-01 15:33:28 | INFO | train_inner | epoch 001:   1700 / 3715 loss=11.191, nll_loss=7.628, mask_ins=1.825, word_ins_ml=8.628, word_reposition=0.739, ppl=2337.79, wps=14456.9, ups=0.98, wpb=14722.9, bsz=1023.8, num_updates=1700, lr=0.000170066, gnorm=2.132, clip=0, loss_scale=1024, train_wall=100, wall=1857
2022-08-01 15:35:12 | INFO | train_inner | epoch 001:   1800 / 3715 loss=10.98, nll_loss=7.405, mask_ins=1.805, word_ins_ml=8.432, word_reposition=0.743, ppl=2019.6, wps=13952.6, ups=0.95, wpb=14623.7, bsz=1024, num_updates=1800, lr=0.000180064, gnorm=2.396, clip=0, loss_scale=1024, train_wall=103, wall=1962
2022-08-01 15:36:59 | INFO | train_inner | epoch 001:   1900 / 3715 loss=10.807, nll_loss=7.233, mask_ins=1.788, word_ins_ml=8.28, word_reposition=0.74, ppl=1791.85, wps=13772.9, ups=0.94, wpb=14622.6, bsz=1024, num_updates=1900, lr=0.000190062, gnorm=3.134, clip=0, loss_scale=1024, train_wall=104, wall=2068
2022-08-01 15:38:45 | INFO | train_inner | epoch 001:   2000 / 3715 loss=10.665, nll_loss=7.066, mask_ins=1.777, word_ins_ml=8.134, word_reposition=0.755, ppl=1624.03, wps=13820.2, ups=0.94, wpb=14718.6, bsz=1024, num_updates=2000, lr=0.00020006, gnorm=3.143, clip=0, loss_scale=1024, train_wall=105, wall=2175
2022-08-01 15:40:34 | INFO | train_inner | epoch 001:   2100 / 3715 loss=10.527, nll_loss=6.947, mask_ins=1.762, word_ins_ml=8.03, word_reposition=0.735, ppl=1475.57, wps=13488.8, ups=0.92, wpb=14676.5, bsz=1024, num_updates=2100, lr=0.000210058, gnorm=3.43, clip=0, loss_scale=1567, train_wall=107, wall=2284
2022-08-01 15:42:19 | INFO | train_inner | epoch 001:   2200 / 3715 loss=10.385, nll_loss=6.809, mask_ins=1.744, word_ins_ml=7.909, word_reposition=0.731, ppl=1336.77, wps=14038.4, ups=0.95, wpb=14703.8, bsz=1024, num_updates=2200, lr=0.000220056, gnorm=2.883, clip=0, loss_scale=2048, train_wall=103, wall=2389
2022-08-01 15:44:03 | INFO | train_inner | epoch 001:   2300 / 3715 loss=10.239, nll_loss=6.661, mask_ins=1.726, word_ins_ml=7.78, word_reposition=0.733, ppl=1208.8, wps=14230.8, ups=0.96, wpb=14839.5, bsz=1024, num_updates=2300, lr=0.000230054, gnorm=3.171, clip=0, loss_scale=2048, train_wall=102, wall=2493
2022-08-01 15:45:47 | INFO | train_inner | epoch 001:   2400 / 3715 loss=10.096, nll_loss=6.533, mask_ins=1.706, word_ins_ml=7.669, word_reposition=0.72, ppl=1094.24, wps=14071.7, ups=0.96, wpb=14630.8, bsz=1024, num_updates=2400, lr=0.000240052, gnorm=2.793, clip=0, loss_scale=2048, train_wall=102, wall=2597
2022-08-01 15:47:30 | INFO | train_inner | epoch 001:   2500 / 3715 loss=9.934, nll_loss=6.388, mask_ins=1.675, word_ins_ml=7.541, word_reposition=0.718, ppl=978.52, wps=14197, ups=0.97, wpb=14677.7, bsz=1024, num_updates=2500, lr=0.00025005, gnorm=2.831, clip=0, loss_scale=2048, train_wall=102, wall=2700
2022-08-01 15:49:14 | INFO | train_inner | epoch 001:   2600 / 3715 loss=9.773, nll_loss=6.229, mask_ins=1.652, word_ins_ml=7.402, word_reposition=0.719, ppl=874.63, wps=14293, ups=0.97, wpb=14766, bsz=1024, num_updates=2600, lr=0.000260048, gnorm=2.796, clip=0, loss_scale=2888, train_wall=102, wall=2803
2022-08-01 15:50:55 | INFO | train_inner | epoch 001:   2700 / 3715 loss=9.542, nll_loss=6.025, mask_ins=1.613, word_ins_ml=7.224, word_reposition=0.706, ppl=745.66, wps=14505.3, ups=0.98, wpb=14768.3, bsz=1024, num_updates=2700, lr=0.000270046, gnorm=2.582, clip=0, loss_scale=4096, train_wall=100, wall=2905
2022-08-01 15:52:37 | INFO | train_inner | epoch 001:   2800 / 3715 loss=9.341, nll_loss=5.86, mask_ins=1.575, word_ins_ml=7.079, word_reposition=0.687, ppl=648.43, wps=14450.7, ups=0.98, wpb=14687.4, bsz=1024, num_updates=2800, lr=0.000280044, gnorm=2.875, clip=0, loss_scale=4096, train_wall=100, wall=3007
2022-08-01 15:52:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-01 15:54:19 | INFO | train_inner | epoch 001:   2901 / 3715 loss=9.15, nll_loss=5.683, mask_ins=1.554, word_ins_ml=6.924, word_reposition=0.672, ppl=568.13, wps=14225, ups=0.98, wpb=14572.2, bsz=1024, num_updates=2900, lr=0.000290042, gnorm=2.678, clip=0, loss_scale=2048, train_wall=101, wall=3109
2022-08-01 15:56:01 | INFO | train_inner | epoch 001:   3001 / 3715 loss=9.007, nll_loss=5.546, mask_ins=1.533, word_ins_ml=6.804, word_reposition=0.67, ppl=514.61, wps=14477.6, ups=0.99, wpb=14696.4, bsz=1024, num_updates=3000, lr=0.00030004, gnorm=2.449, clip=0, loss_scale=2048, train_wall=100, wall=3211
2022-08-01 15:56:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-01 15:57:44 | INFO | train_inner | epoch 001:   3102 / 3715 loss=8.847, nll_loss=5.409, mask_ins=1.504, word_ins_ml=6.685, word_reposition=0.659, ppl=460.56, wps=14292.2, ups=0.97, wpb=14674.1, bsz=1024, num_updates=3100, lr=0.000310038, gnorm=2.413, clip=0, loss_scale=1085, train_wall=101, wall=3314
2022-08-01 15:59:26 | INFO | train_inner | epoch 001:   3202 / 3715 loss=8.719, nll_loss=5.3, mask_ins=1.483, word_ins_ml=6.589, word_reposition=0.647, ppl=421.5, wps=14147.6, ups=0.97, wpb=14537.9, bsz=1024, num_updates=3200, lr=0.000320036, gnorm=2.299, clip=0, loss_scale=1024, train_wall=101, wall=3416
2022-08-01 16:01:08 | INFO | train_inner | epoch 001:   3302 / 3715 loss=8.587, nll_loss=5.188, mask_ins=1.458, word_ins_ml=6.492, word_reposition=0.637, ppl=384.53, wps=14369.9, ups=0.98, wpb=14672.4, bsz=1024, num_updates=3300, lr=0.000330034, gnorm=2.04, clip=0, loss_scale=1024, train_wall=100, wall=3518
2022-08-01 16:02:51 | INFO | train_inner | epoch 001:   3402 / 3715 loss=8.5, nll_loss=5.102, mask_ins=1.444, word_ins_ml=6.416, word_reposition=0.639, ppl=362.06, wps=14249.9, ups=0.98, wpb=14570.1, bsz=1024, num_updates=3400, lr=0.000340032, gnorm=2.079, clip=0, loss_scale=1024, train_wall=100, wall=3621
2022-08-01 16:04:33 | INFO | train_inner | epoch 001:   3502 / 3715 loss=8.429, nll_loss=5.057, mask_ins=1.428, word_ins_ml=6.377, word_reposition=0.624, ppl=344.57, wps=14401.5, ups=0.98, wpb=14688.2, bsz=1024, num_updates=3500, lr=0.00035003, gnorm=1.878, clip=0, loss_scale=1024, train_wall=100, wall=3723
2022-08-01 16:06:14 | INFO | train_inner | epoch 001:   3602 / 3715 loss=8.366, nll_loss=5.015, mask_ins=1.411, word_ins_ml=6.34, word_reposition=0.615, ppl=329.87, wps=14422.6, ups=0.98, wpb=14646.4, bsz=1024, num_updates=3600, lr=0.000360028, gnorm=1.935, clip=0, loss_scale=1874, train_wall=100, wall=3824
2022-08-01 16:07:56 | INFO | train_inner | epoch 001:   3702 / 3715 loss=8.285, nll_loss=4.943, mask_ins=1.413, word_ins_ml=6.277, word_reposition=0.596, ppl=312.01, wps=14364.2, ups=0.98, wpb=14593, bsz=1024, num_updates=3700, lr=0.000370026, gnorm=1.961, clip=0, loss_scale=2048, train_wall=100, wall=3926
2022-08-01 16:08:08 | INFO | train | epoch 001 | loss 11.297 | nll_loss 7.631 | mask_ins 1.956 | word_ins_ml 8.627 | word_reposition 0.714 | ppl 2515.5 | wps 13932.1 | ups 0.95 | wpb 14661.9 | bsz 1023.7 | num_updates 3713 | lr 0.000371326 | gnorm 3.126 | clip 0 | loss_scale 1176 | train_wall 3843 | wall 3938
2022-08-01 16:09:19 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.15 | nll_loss 4.695 | mask_ins 1.384 | word_ins_ml 6.161 | word_reposition 0.604 | ppl 284.02 | wps 39334.6 | wpb 1849.4 | bsz 127.9 | num_updates 3713
2022-08-01 16:09:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 1 @ 3713 updates, score 8.15) (writing took 4.413241468369961 seconds)
2022-08-01 16:10:52 | INFO | train_inner | epoch 002:     87 / 3715 loss=8.243, nll_loss=4.91, mask_ins=1.404, word_ins_ml=6.248, word_reposition=0.591, ppl=302.96, wps=8188.6, ups=0.57, wpb=14457.3, bsz=1014.7, num_updates=3800, lr=0.000380024, gnorm=1.903, clip=0, loss_scale=2048, train_wall=99, wall=4102
2022-08-01 16:12:35 | INFO | train_inner | epoch 002:    187 / 3715 loss=8.162, nll_loss=4.856, mask_ins=1.385, word_ins_ml=6.201, word_reposition=0.576, ppl=286.51, wps=14384.8, ups=0.98, wpb=14698.6, bsz=1024, num_updates=3900, lr=0.000390022, gnorm=1.766, clip=0, loss_scale=2048, train_wall=100, wall=4205
2022-08-01 16:14:16 | INFO | train_inner | epoch 002:    287 / 3715 loss=8.144, nll_loss=4.839, mask_ins=1.384, word_ins_ml=6.186, word_reposition=0.574, ppl=282.96, wps=14434, ups=0.98, wpb=14660.8, bsz=1024, num_updates=4000, lr=0.00040002, gnorm=1.831, clip=0, loss_scale=2048, train_wall=100, wall=4306
2022-08-01 16:14:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-01 16:15:59 | INFO | train_inner | epoch 002:    388 / 3715 loss=8.153, nll_loss=4.856, mask_ins=1.387, word_ins_ml=6.201, word_reposition=0.565, ppl=284.69, wps=14281.7, ups=0.98, wpb=14624.5, bsz=1024, num_updates=4100, lr=0.000410018, gnorm=2.084, clip=0, loss_scale=1196, train_wall=101, wall=4409
2022-08-01 16:17:40 | INFO | train_inner | epoch 002:    488 / 3715 loss=8.064, nll_loss=4.789, mask_ins=1.365, word_ins_ml=6.142, word_reposition=0.557, ppl=267.58, wps=14433.4, ups=0.99, wpb=14650.3, bsz=1024, num_updates=4200, lr=0.000420016, gnorm=1.915, clip=0, loss_scale=1024, train_wall=100, wall=4510
2022-08-01 16:19:22 | INFO | train_inner | epoch 002:    588 / 3715 loss=8.047, nll_loss=4.77, mask_ins=1.364, word_ins_ml=6.125, word_reposition=0.558, ppl=264.49, wps=14544.9, ups=0.99, wpb=14758.3, bsz=1024, num_updates=4300, lr=0.000430014, gnorm=1.818, clip=0, loss_scale=1024, train_wall=100, wall=4611
2022-08-01 16:21:04 | INFO | train_inner | epoch 002:    688 / 3715 loss=8.004, nll_loss=4.745, mask_ins=1.358, word_ins_ml=6.103, word_reposition=0.543, ppl=256.68, wps=14346.3, ups=0.98, wpb=14640.2, bsz=1024, num_updates=4400, lr=0.000440012, gnorm=1.918, clip=0, loss_scale=1024, train_wall=100, wall=4714
2022-08-01 16:22:46 | INFO | train_inner | epoch 002:    788 / 3715 loss=7.972, nll_loss=4.725, mask_ins=1.351, word_ins_ml=6.086, word_reposition=0.536, ppl=251.1, wps=14262.5, ups=0.97, wpb=14670.4, bsz=1024, num_updates=4500, lr=0.00045001, gnorm=1.774, clip=0, loss_scale=1024, train_wall=101, wall=4816
2022-08-01 16:23:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-01 16:24:29 | INFO | train_inner | epoch 002:    889 / 3715 loss=7.98, nll_loss=4.739, mask_ins=1.348, word_ins_ml=6.098, word_reposition=0.534, ppl=252.46, wps=14255.9, ups=0.98, wpb=14620.9, bsz=1023.8, num_updates=4600, lr=0.000460008, gnorm=2.124, clip=0, loss_scale=1430, train_wall=101, wall=4919
2022-08-01 16:25:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-08-01 16:25:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-01 16:26:13 | INFO | train_inner | epoch 002:    991 / 3715 loss=7.969, nll_loss=4.739, mask_ins=1.344, word_ins_ml=6.098, word_reposition=0.527, ppl=250.57, wps=14136.4, ups=0.97, wpb=14636.3, bsz=1024, num_updates=4700, lr=0.000470006, gnorm=2.263, clip=0, loss_scale=637, train_wall=102, wall=5022
2022-08-01 16:27:54 | INFO | train_inner | epoch 002:   1091 / 3715 loss=8.013, nll_loss=4.767, mask_ins=1.356, word_ins_ml=6.123, word_reposition=0.534, ppl=258.23, wps=14481.8, ups=0.98, wpb=14722.8, bsz=1024, num_updates=4800, lr=0.000480004, gnorm=3.257, clip=2, loss_scale=256, train_wall=100, wall=5124
2022-08-01 16:29:36 | INFO | train_inner | epoch 002:   1191 / 3715 loss=7.954, nll_loss=4.727, mask_ins=1.346, word_ins_ml=6.088, word_reposition=0.521, ppl=248.02, wps=14386.3, ups=0.98, wpb=14605.9, bsz=1024, num_updates=4900, lr=0.000490002, gnorm=2.558, clip=0, loss_scale=256, train_wall=100, wall=5226
2022-08-01 16:31:17 | INFO | train_inner | epoch 002:   1291 / 3715 loss=7.936, nll_loss=4.708, mask_ins=1.338, word_ins_ml=6.071, word_reposition=0.527, ppl=244.91, wps=14507.4, ups=0.99, wpb=14701.5, bsz=1024, num_updates=5000, lr=0.0005, gnorm=2.093, clip=0, loss_scale=256, train_wall=100, wall=5327
2022-08-01 16:33:00 | INFO | train_inner | epoch 002:   1391 / 3715 loss=7.886, nll_loss=4.68, mask_ins=1.33, word_ins_ml=6.046, word_reposition=0.51, ppl=236.51, wps=14381, ups=0.98, wpb=14732.4, bsz=1024, num_updates=5100, lr=0.000495074, gnorm=2.448, clip=0, loss_scale=256, train_wall=101, wall=5429
2022-08-01 16:34:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-01 16:34:42 | INFO | train_inner | epoch 002:   1492 / 3715 loss=7.89, nll_loss=4.684, mask_ins=1.331, word_ins_ml=6.049, word_reposition=0.511, ppl=237.25, wps=14314.4, ups=0.98, wpb=14628.3, bsz=1024, num_updates=5200, lr=0.00049029, gnorm=2.313, clip=0, loss_scale=345, train_wall=100, wall=5532
2022-08-01 16:36:23 | INFO | train_inner | epoch 002:   1592 / 3715 loss=7.857, nll_loss=4.657, mask_ins=1.327, word_ins_ml=6.026, word_reposition=0.505, ppl=231.89, wps=14430.2, ups=0.99, wpb=14589.3, bsz=1024, num_updates=5300, lr=0.000485643, gnorm=1.986, clip=0, loss_scale=256, train_wall=99, wall=5633
2022-08-01 16:38:05 | INFO | train_inner | epoch 002:   1692 / 3715 loss=7.827, nll_loss=4.624, mask_ins=1.324, word_ins_ml=5.995, word_reposition=0.508, ppl=227.11, wps=14332.4, ups=0.98, wpb=14676.1, bsz=1024, num_updates=5400, lr=0.000481125, gnorm=1.99, clip=0, loss_scale=256, train_wall=101, wall=5735
2022-08-01 16:39:49 | INFO | train_inner | epoch 002:   1792 / 3715 loss=7.779, nll_loss=4.593, mask_ins=1.311, word_ins_ml=5.968, word_reposition=0.5, ppl=219.61, wps=14243.5, ups=0.97, wpb=14723.3, bsz=1024, num_updates=5500, lr=0.000476731, gnorm=1.749, clip=0, loss_scale=256, train_wall=102, wall=5839
2022-08-01 16:41:32 | INFO | train_inner | epoch 002:   1892 / 3715 loss=7.737, nll_loss=4.558, mask_ins=1.312, word_ins_ml=5.936, word_reposition=0.489, ppl=213.34, wps=14205.8, ups=0.97, wpb=14675.3, bsz=1024, num_updates=5600, lr=0.000472456, gnorm=1.905, clip=0, loss_scale=256, train_wall=102, wall=5942
2022-08-01 16:43:15 | INFO | train_inner | epoch 002:   1992 / 3715 loss=7.723, nll_loss=4.549, mask_ins=1.303, word_ins_ml=5.928, word_reposition=0.492, ppl=211.27, wps=14177.8, ups=0.97, wpb=14678.5, bsz=1024, num_updates=5700, lr=0.000468293, gnorm=2.423, clip=0, loss_scale=256, train_wall=102, wall=6045
2022-08-01 16:44:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-01 16:44:59 | INFO | train_inner | epoch 002:   2093 / 3715 loss=7.742, nll_loss=4.575, mask_ins=1.304, word_ins_ml=5.95, word_reposition=0.489, ppl=214.15, wps=14180.4, ups=0.97, wpb=14671.6, bsz=1024, num_updates=5800, lr=0.000464238, gnorm=3.093, clip=0, loss_scale=350, train_wall=102, wall=6149
2022-08-01 16:46:40 | INFO | train_inner | epoch 002:   2193 / 3715 loss=7.734, nll_loss=4.564, mask_ins=1.304, word_ins_ml=5.941, word_reposition=0.489, ppl=212.95, wps=14531.4, ups=0.99, wpb=14737.5, bsz=1024, num_updates=5900, lr=0.000460287, gnorm=3.455, clip=3, loss_scale=256, train_wall=100, wall=6250
2022-08-01 16:48:22 | INFO | train_inner | epoch 002:   2293 / 3715 loss=7.635, nll_loss=4.481, mask_ins=1.288, word_ins_ml=5.867, word_reposition=0.48, ppl=198.73, wps=14472.6, ups=0.99, wpb=14678.7, bsz=1024, num_updates=6000, lr=0.000456435, gnorm=2.005, clip=0, loss_scale=256, train_wall=100, wall=6352
2022-08-01 16:50:05 | INFO | train_inner | epoch 002:   2393 / 3715 loss=7.641, nll_loss=4.493, mask_ins=1.291, word_ins_ml=5.877, word_reposition=0.473, ppl=199.55, wps=14240.2, ups=0.97, wpb=14642, bsz=1024, num_updates=6100, lr=0.000452679, gnorm=2.968, clip=1, loss_scale=256, train_wall=101, wall=6454
2022-08-01 16:51:48 | INFO | train_inner | epoch 002:   2493 / 3715 loss=7.642, nll_loss=4.496, mask_ins=1.285, word_ins_ml=5.88, word_reposition=0.477, ppl=199.78, wps=14048.3, ups=0.96, wpb=14599.1, bsz=1024, num_updates=6200, lr=0.000449013, gnorm=2.828, clip=0, loss_scale=256, train_wall=102, wall=6558
2022-08-01 16:53:33 | INFO | train_inner | epoch 002:   2593 / 3715 loss=7.58, nll_loss=4.433, mask_ins=1.283, word_ins_ml=5.823, word_reposition=0.474, ppl=191.4, wps=14019.3, ups=0.96, wpb=14594.7, bsz=1024, num_updates=6300, lr=0.000445435, gnorm=2.069, clip=0, loss_scale=369, train_wall=102, wall=6663
2022-08-01 16:55:16 | INFO | train_inner | epoch 002:   2693 / 3715 loss=7.607, nll_loss=4.459, mask_ins=1.286, word_ins_ml=5.846, word_reposition=0.475, ppl=194.98, wps=14111.4, ups=0.97, wpb=14592, bsz=1024, num_updates=6400, lr=0.000441942, gnorm=2.261, clip=0, loss_scale=512, train_wall=102, wall=6766
2022-08-01 16:56:59 | INFO | train_inner | epoch 002:   2793 / 3715 loss=7.534, nll_loss=4.402, mask_ins=1.273, word_ins_ml=5.795, word_reposition=0.466, ppl=185.33, wps=14315.9, ups=0.97, wpb=14712.3, bsz=1024, num_updates=6500, lr=0.000438529, gnorm=1.676, clip=0, loss_scale=512, train_wall=101, wall=6869
2022-08-01 16:58:41 | INFO | train_inner | epoch 002:   2893 / 3715 loss=7.52, nll_loss=4.382, mask_ins=1.271, word_ins_ml=5.777, word_reposition=0.473, ppl=183.54, wps=14324.2, ups=0.98, wpb=14669.7, bsz=1024, num_updates=6600, lr=0.000435194, gnorm=1.576, clip=0, loss_scale=512, train_wall=101, wall=6971
2022-08-01 16:59:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-01 17:00:25 | INFO | train_inner | epoch 002:   2994 / 3715 loss=7.527, nll_loss=4.391, mask_ins=1.271, word_ins_ml=5.785, word_reposition=0.471, ppl=184.41, wps=13984.9, ups=0.96, wpb=14587.2, bsz=1024, num_updates=6700, lr=0.000431934, gnorm=1.575, clip=0, loss_scale=441, train_wall=103, wall=7075
2022-08-01 17:02:09 | INFO | train_inner | epoch 002:   3094 / 3715 loss=7.501, nll_loss=4.374, mask_ins=1.268, word_ins_ml=5.77, word_reposition=0.463, ppl=181.1, wps=14147, ups=0.97, wpb=14627.5, bsz=1024, num_updates=6800, lr=0.000428746, gnorm=1.501, clip=0, loss_scale=256, train_wall=102, wall=7179
2022-08-01 17:03:52 | INFO | train_inner | epoch 002:   3194 / 3715 loss=7.462, nll_loss=4.327, mask_ins=1.266, word_ins_ml=5.728, word_reposition=0.468, ppl=176.32, wps=14403, ups=0.97, wpb=14809.8, bsz=1024, num_updates=6900, lr=0.000425628, gnorm=1.476, clip=0, loss_scale=256, train_wall=101, wall=7282
2022-08-01 17:05:35 | INFO | train_inner | epoch 002:   3294 / 3715 loss=7.724, nll_loss=4.596, mask_ins=1.287, word_ins_ml=5.964, word_reposition=0.473, ppl=211.42, wps=14147, ups=0.97, wpb=14651, bsz=1024, num_updates=7000, lr=0.000422577, gnorm=5.275, clip=4, loss_scale=256, train_wall=102, wall=7385
2022-08-01 17:07:18 | INFO | train_inner | epoch 002:   3394 / 3715 loss=7.481, nll_loss=4.361, mask_ins=1.258, word_ins_ml=5.758, word_reposition=0.465, ppl=178.68, wps=14274.9, ups=0.97, wpb=14707.4, bsz=1024, num_updates=7100, lr=0.000419591, gnorm=2.195, clip=0, loss_scale=256, train_wall=101, wall=7488
2022-08-01 17:09:02 | INFO | train_inner | epoch 002:   3494 / 3715 loss=7.414, nll_loss=4.301, mask_ins=1.256, word_ins_ml=5.703, word_reposition=0.455, ppl=170.59, wps=14198.7, ups=0.96, wpb=14720.6, bsz=1024, num_updates=7200, lr=0.000416667, gnorm=1.475, clip=0, loss_scale=297, train_wall=102, wall=7592
2022-08-01 17:10:45 | INFO | train_inner | epoch 002:   3594 / 3715 loss=7.414, nll_loss=4.308, mask_ins=1.253, word_ins_ml=5.71, word_reposition=0.452, ppl=170.56, wps=14220, ups=0.97, wpb=14601.9, bsz=1024, num_updates=7300, lr=0.000413803, gnorm=1.704, clip=0, loss_scale=512, train_wall=101, wall=7695
2022-08-01 17:11:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-01 17:12:29 | INFO | train_inner | epoch 002:   3695 / 3715 loss=7.375, nll_loss=4.265, mask_ins=1.249, word_ins_ml=5.671, word_reposition=0.456, ppl=166.04, wps=14159.7, ups=0.96, wpb=14790.6, bsz=1024, num_updates=7400, lr=0.000410997, gnorm=1.668, clip=0, loss_scale=428, train_wall=103, wall=7799
2022-08-01 17:12:49 | INFO | train | epoch 002 | loss 7.777 | nll_loss 4.585 | mask_ins 1.314 | word_ins_ml 5.959 | word_reposition 0.504 | ppl 219.41 | wps 14006.4 | ups 0.96 | wpb 14662.7 | bsz 1023.7 | num_updates 7420 | lr 0.000410443 | gnorm 2.23 | clip 0.3 | loss_scale 591 | train_wall 3740 | wall 7819
2022-08-01 17:13:59 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.276 | nll_loss 4.053 | mask_ins 1.23 | word_ins_ml 5.594 | word_reposition 0.452 | ppl 154.97 | wps 39308 | wpb 1849.4 | bsz 127.9 | num_updates 7420 | best_loss 7.276
2022-08-01 17:14:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 2 @ 7420 updates, score 7.276) (writing took 6.958749735727906 seconds)
2022-08-01 17:15:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-08-01 17:15:29 | INFO | train_inner | epoch 003:     81 / 3715 loss=7.43, nll_loss=4.312, mask_ins=1.258, word_ins_ml=5.713, word_reposition=0.459, ppl=172.41, wps=8134.1, ups=0.56, wpb=14627.7, bsz=1014.7, num_updates=7500, lr=0.000408248, gnorm=4.143, clip=1, loss_scale=222, train_wall=101, wall=7979
2022-08-01 17:17:10 | INFO | train_inner | epoch 003:    181 / 3715 loss=7.318, nll_loss=4.223, mask_ins=1.236, word_ins_ml=5.633, word_reposition=0.449, ppl=159.54, wps=14387.9, ups=0.99, wpb=14589.6, bsz=1024, num_updates=7600, lr=0.000405554, gnorm=1.71, clip=0, loss_scale=128, train_wall=100, wall=8080
2022-08-01 17:18:52 | INFO | train_inner | epoch 003:    281 / 3715 loss=7.317, nll_loss=4.215, mask_ins=1.243, word_ins_ml=5.626, word_reposition=0.447, ppl=159.4, wps=14487.2, ups=0.98, wpb=14718, bsz=1024, num_updates=7700, lr=0.000402911, gnorm=1.468, clip=0, loss_scale=128, train_wall=100, wall=8182
2022-08-01 17:20:34 | INFO | train_inner | epoch 003:    381 / 3715 loss=7.282, nll_loss=4.182, mask_ins=1.236, word_ins_ml=5.597, word_reposition=0.449, ppl=155.61, wps=14468.4, ups=0.98, wpb=14754.1, bsz=1024, num_updates=7800, lr=0.00040032, gnorm=1.389, clip=0, loss_scale=128, train_wall=100, wall=8284
2022-08-01 17:22:16 | INFO | train_inner | epoch 003:    481 / 3715 loss=7.278, nll_loss=4.183, mask_ins=1.234, word_ins_ml=5.598, word_reposition=0.446, ppl=155.16, wps=14375.6, ups=0.98, wpb=14682, bsz=1024, num_updates=7900, lr=0.000397779, gnorm=1.463, clip=0, loss_scale=128, train_wall=100, wall=8386
2022-08-01 17:23:58 | INFO | train_inner | epoch 003:    581 / 3715 loss=7.274, nll_loss=4.18, mask_ins=1.231, word_ins_ml=5.595, word_reposition=0.448, ppl=154.76, wps=14406.9, ups=0.98, wpb=14727, bsz=1024, num_updates=8000, lr=0.000395285, gnorm=1.517, clip=0, loss_scale=147, train_wall=100, wall=8488
2022-08-01 17:25:41 | INFO | train_inner | epoch 003:    681 / 3715 loss=7.281, nll_loss=4.181, mask_ins=1.234, word_ins_ml=5.596, word_reposition=0.452, ppl=155.57, wps=14338.8, ups=0.97, wpb=14708.2, bsz=1024, num_updates=8100, lr=0.000392837, gnorm=1.469, clip=0, loss_scale=256, train_wall=101, wall=8591
2022-08-01 17:27:23 | INFO | train_inner | epoch 003:    781 / 3715 loss=7.234, nll_loss=4.155, mask_ins=1.225, word_ins_ml=5.572, word_reposition=0.437, ppl=150.51, wps=14321.5, ups=0.98, wpb=14639.6, bsz=1024, num_updates=8200, lr=0.000390434, gnorm=1.672, clip=0, loss_scale=256, train_wall=100, wall=8693
2022-08-01 17:29:08 | INFO | train_inner | epoch 003:    881 / 3715 loss=7.221, nll_loss=4.146, mask_ins=1.22, word_ins_ml=5.564, word_reposition=0.438, ppl=149.22, wps=13995.1, ups=0.95, wpb=14706.3, bsz=1024, num_updates=8300, lr=0.000388075, gnorm=1.499, clip=0, loss_scale=256, train_wall=103, wall=8798
2022-08-01 17:30:51 | INFO | train_inner | epoch 003:    981 / 3715 loss=7.223, nll_loss=4.138, mask_ins=1.223, word_ins_ml=5.557, word_reposition=0.443, ppl=149.35, wps=14204.2, ups=0.97, wpb=14603.9, bsz=1024, num_updates=8400, lr=0.000385758, gnorm=1.371, clip=0, loss_scale=256, train_wall=101, wall=8901
2022-08-01 17:32:36 | INFO | train_inner | epoch 003:   1081 / 3715 loss=7.228, nll_loss=4.14, mask_ins=1.228, word_ins_ml=5.559, word_reposition=0.441, ppl=149.88, wps=13906, ups=0.95, wpb=14658.3, bsz=1024, num_updates=8500, lr=0.000383482, gnorm=1.394, clip=0, loss_scale=264, train_wall=104, wall=9006
2022-08-01 17:34:23 | INFO | train_inner | epoch 003:   1181 / 3715 loss=7.242, nll_loss=4.16, mask_ins=1.224, word_ins_ml=5.575, word_reposition=0.442, ppl=151.37, wps=13656.6, ups=0.94, wpb=14593.4, bsz=1024, num_updates=8600, lr=0.000381246, gnorm=2.591, clip=1, loss_scale=512, train_wall=105, wall=9113
2022-08-01 17:36:10 | INFO | train_inner | epoch 003:   1281 / 3715 loss=7.229, nll_loss=4.16, mask_ins=1.222, word_ins_ml=5.575, word_reposition=0.432, ppl=150.01, wps=13641.4, ups=0.94, wpb=14571.9, bsz=1024, num_updates=8700, lr=0.000379049, gnorm=1.458, clip=0, loss_scale=512, train_wall=105, wall=9220
2022-08-01 17:37:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-01 17:37:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-08-01 17:37:56 | INFO | train_inner | epoch 003:   1383 / 3715 loss=7.24, nll_loss=4.16, mask_ins=1.222, word_ins_ml=5.576, word_reposition=0.442, ppl=151.21, wps=13877.6, ups=0.95, wpb=14671, bsz=1024, num_updates=8800, lr=0.000376889, gnorm=3.405, clip=2, loss_scale=418, train_wall=104, wall=9326
2022-08-01 17:39:40 | INFO | train_inner | epoch 003:   1483 / 3715 loss=7.231, nll_loss=4.157, mask_ins=1.217, word_ins_ml=5.572, word_reposition=0.442, ppl=150.27, wps=14102.1, ups=0.96, wpb=14641.7, bsz=1024, num_updates=8900, lr=0.000374766, gnorm=2.285, clip=0, loss_scale=128, train_wall=102, wall=9430
2022-08-01 17:40:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2022-08-01 17:41:25 | INFO | train_inner | epoch 003:   1584 / 3715 loss=7.21, nll_loss=4.137, mask_ins=1.221, word_ins_ml=5.555, word_reposition=0.434, ppl=148.07, wps=13863, ups=0.95, wpb=14606.7, bsz=1024, num_updates=9000, lr=0.000372678, gnorm=3.879, clip=2, loss_scale=89, train_wall=104, wall=9535
2022-08-01 17:43:09 | INFO | train_inner | epoch 003:   1684 / 3715 loss=7.196, nll_loss=4.131, mask_ins=1.219, word_ins_ml=5.549, word_reposition=0.428, ppl=146.66, wps=14067.8, ups=0.96, wpb=14611, bsz=1024, num_updates=9100, lr=0.000370625, gnorm=3.374, clip=1, loss_scale=64, train_wall=102, wall=9639
2022-08-01 17:44:54 | INFO | train_inner | epoch 003:   1784 / 3715 loss=7.188, nll_loss=4.118, mask_ins=1.215, word_ins_ml=5.538, word_reposition=0.434, ppl=145.77, wps=14061.8, ups=0.95, wpb=14745.7, bsz=1024, num_updates=9200, lr=0.000368605, gnorm=1.771, clip=0, loss_scale=64, train_wall=103, wall=9744
2022-08-01 17:46:37 | INFO | train_inner | epoch 003:   1884 / 3715 loss=7.168, nll_loss=4.103, mask_ins=1.215, word_ins_ml=5.524, word_reposition=0.429, ppl=143.85, wps=14131.6, ups=0.97, wpb=14622.4, bsz=1024, num_updates=9300, lr=0.000366618, gnorm=1.449, clip=0, loss_scale=64, train_wall=102, wall=9847
2022-08-01 17:48:21 | INFO | train_inner | epoch 003:   1984 / 3715 loss=7.173, nll_loss=4.107, mask_ins=1.212, word_ins_ml=5.527, word_reposition=0.434, ppl=144.31, wps=14068.6, ups=0.96, wpb=14582.4, bsz=1023.8, num_updates=9400, lr=0.000364662, gnorm=2.403, clip=1, loss_scale=64, train_wall=102, wall=9951
2022-08-01 17:50:04 | INFO | train_inner | epoch 003:   2084 / 3715 loss=7.15, nll_loss=4.088, mask_ins=1.211, word_ins_ml=5.51, word_reposition=0.428, ppl=142, wps=14190.1, ups=0.97, wpb=14616.4, bsz=1024, num_updates=9500, lr=0.000362738, gnorm=3.171, clip=1, loss_scale=95, train_wall=101, wall=10054
2022-08-01 17:51:49 | INFO | train_inner | epoch 003:   2184 / 3715 loss=7.139, nll_loss=4.08, mask_ins=1.207, word_ins_ml=5.503, word_reposition=0.429, ppl=140.92, wps=14051.9, ups=0.95, wpb=14716.8, bsz=1024, num_updates=9600, lr=0.000360844, gnorm=1.797, clip=0, loss_scale=128, train_wall=103, wall=10159
2022-08-01 17:53:32 | INFO | train_inner | epoch 003:   2284 / 3715 loss=7.093, nll_loss=4.038, mask_ins=1.201, word_ins_ml=5.466, word_reposition=0.426, ppl=136.5, wps=14262.8, ups=0.97, wpb=14704.7, bsz=1024, num_updates=9700, lr=0.000358979, gnorm=1.4, clip=0, loss_scale=128, train_wall=101, wall=10262
2022-08-01 17:55:15 | INFO | train_inner | epoch 003:   2384 / 3715 loss=7.091, nll_loss=4.032, mask_ins=1.2, word_ins_ml=5.461, word_reposition=0.431, ppl=136.35, wps=14241.1, ups=0.97, wpb=14667.1, bsz=1024, num_updates=9800, lr=0.000357143, gnorm=1.789, clip=0, loss_scale=128, train_wall=101, wall=10365
2022-08-01 17:56:59 | INFO | train_inner | epoch 003:   2484 / 3715 loss=7.103, nll_loss=4.048, mask_ins=1.204, word_ins_ml=5.474, word_reposition=0.426, ppl=137.5, wps=14204.2, ups=0.96, wpb=14759.7, bsz=1024, num_updates=9900, lr=0.000355335, gnorm=1.6, clip=0, loss_scale=128, train_wall=102, wall=10469
2022-08-01 17:58:42 | INFO | train_inner | epoch 003:   2584 / 3715 loss=7.095, nll_loss=4.042, mask_ins=1.203, word_ins_ml=5.468, word_reposition=0.424, ppl=136.76, wps=14064.2, ups=0.97, wpb=14555.5, bsz=1024, num_updates=10000, lr=0.000353553, gnorm=1.441, clip=0, loss_scale=175, train_wall=102, wall=10572
2022-08-01 18:00:25 | INFO | train_inner | epoch 003:   2684 / 3715 loss=7.09, nll_loss=4.031, mask_ins=1.208, word_ins_ml=5.459, word_reposition=0.423, ppl=136.21, wps=14246.4, ups=0.97, wpb=14724.9, bsz=1024, num_updates=10100, lr=0.000351799, gnorm=1.427, clip=0, loss_scale=256, train_wall=102, wall=10675
2022-08-01 18:02:08 | INFO | train_inner | epoch 003:   2784 / 3715 loss=7.116, nll_loss=4.057, mask_ins=1.202, word_ins_ml=5.482, word_reposition=0.432, ppl=138.74, wps=14179.7, ups=0.97, wpb=14597.2, bsz=1024, num_updates=10200, lr=0.00035007, gnorm=2.553, clip=0, loss_scale=256, train_wall=101, wall=10778
2022-08-01 18:03:52 | INFO | train_inner | epoch 003:   2884 / 3715 loss=7.067, nll_loss=4.022, mask_ins=1.192, word_ins_ml=5.451, word_reposition=0.425, ppl=134.11, wps=14175.7, ups=0.97, wpb=14683.4, bsz=1024, num_updates=10300, lr=0.000348367, gnorm=1.402, clip=0, loss_scale=256, train_wall=102, wall=10882
2022-08-01 18:05:36 | INFO | train_inner | epoch 003:   2984 / 3715 loss=7.059, nll_loss=4.005, mask_ins=1.201, word_ins_ml=5.436, word_reposition=0.423, ppl=133.38, wps=14111.1, ups=0.96, wpb=14723.4, bsz=1024, num_updates=10400, lr=0.000346688, gnorm=1.335, clip=0, loss_scale=256, train_wall=103, wall=10986
2022-08-01 18:07:20 | INFO | train_inner | epoch 003:   3084 / 3715 loss=7.051, nll_loss=3.998, mask_ins=1.196, word_ins_ml=5.428, word_reposition=0.427, ppl=132.65, wps=14224.3, ups=0.96, wpb=14778.6, bsz=1024, num_updates=10500, lr=0.000345033, gnorm=1.314, clip=0, loss_scale=320, train_wall=102, wall=11090
2022-08-01 18:09:04 | INFO | train_inner | epoch 003:   3184 / 3715 loss=7.049, nll_loss=4.011, mask_ins=1.191, word_ins_ml=5.44, word_reposition=0.417, ppl=132.39, wps=14089.6, ups=0.96, wpb=14612.8, bsz=1024, num_updates=10600, lr=0.000343401, gnorm=1.306, clip=0, loss_scale=512, train_wall=102, wall=11194
2022-08-01 18:10:47 | INFO | train_inner | epoch 003:   3284 / 3715 loss=7.05, nll_loss=4.001, mask_ins=1.198, word_ins_ml=5.43, word_reposition=0.421, ppl=132.5, wps=14151.3, ups=0.97, wpb=14648, bsz=1024, num_updates=10700, lr=0.000341793, gnorm=1.365, clip=0, loss_scale=512, train_wall=102, wall=11297
2022-08-01 18:12:30 | INFO | train_inner | epoch 003:   3384 / 3715 loss=7.026, nll_loss=3.99, mask_ins=1.188, word_ins_ml=5.421, word_reposition=0.417, ppl=130.32, wps=14235.4, ups=0.98, wpb=14587.8, bsz=1024, num_updates=10800, lr=0.000340207, gnorm=1.411, clip=0, loss_scale=512, train_wall=101, wall=11400
2022-08-01 18:14:11 | INFO | train_inner | epoch 003:   3484 / 3715 loss=7.016, nll_loss=3.979, mask_ins=1.186, word_ins_ml=5.412, word_reposition=0.419, ppl=129.46, wps=14538.7, ups=0.99, wpb=14732.2, bsz=1024, num_updates=10900, lr=0.000338643, gnorm=1.283, clip=0, loss_scale=512, train_wall=100, wall=11501
2022-08-01 18:15:52 | INFO | train_inner | epoch 003:   3584 / 3715 loss=7.004, nll_loss=3.967, mask_ins=1.188, word_ins_ml=5.4, word_reposition=0.417, ppl=128.39, wps=14594.1, ups=0.99, wpb=14718.1, bsz=1024, num_updates=11000, lr=0.0003371, gnorm=1.262, clip=0, loss_scale=579, train_wall=99, wall=11602
2022-08-01 18:17:33 | INFO | train_inner | epoch 003:   3684 / 3715 loss=6.995, nll_loss=3.963, mask_ins=1.186, word_ins_ml=5.396, word_reposition=0.413, ppl=127.59, wps=14453, ups=0.99, wpb=14591.4, bsz=1024, num_updates=11100, lr=0.000335578, gnorm=1.272, clip=0, loss_scale=1024, train_wall=99, wall=11703
2022-08-01 18:18:04 | INFO | train | epoch 003 | loss 7.163 | nll_loss 4.096 | mask_ins 1.213 | word_ins_ml 5.517 | word_reposition 0.433 | ppl 143.32 | wps 13899.3 | ups 0.95 | wpb 14662.3 | bsz 1023.7 | num_updates 11131 | lr 0.00033511 | gnorm 1.811 | clip 0.2 | loss_scale 273 | train_wall 3772 | wall 11734
2022-08-01 18:19:13 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.926 | nll_loss 3.76 | mask_ins 1.165 | word_ins_ml 5.318 | word_reposition 0.443 | ppl 121.61 | wps 39527.5 | wpb 1849.4 | bsz 127.9 | num_updates 11131 | best_loss 6.926
2022-08-01 18:19:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 3 @ 11131 updates, score 6.926) (writing took 6.688825124874711 seconds)
2022-08-01 18:20:30 | INFO | train_inner | epoch 004:     69 / 3715 loss=6.959, nll_loss=3.936, mask_ins=1.177, word_ins_ml=5.372, word_reposition=0.41, ppl=124.45, wps=8176.6, ups=0.56, wpb=14497.6, bsz=1014.7, num_updates=11200, lr=0.000334077, gnorm=1.276, clip=0, loss_scale=1024, train_wall=100, wall=11880
2022-08-01 18:22:13 | INFO | train_inner | epoch 004:    169 / 3715 loss=6.934, nll_loss=3.91, mask_ins=1.171, word_ins_ml=5.35, word_reposition=0.412, ppl=122.24, wps=14462.7, ups=0.98, wpb=14789.4, bsz=1024, num_updates=11300, lr=0.000332595, gnorm=1.243, clip=0, loss_scale=1024, train_wall=101, wall=11983
2022-08-01 18:23:55 | INFO | train_inner | epoch 004:    269 / 3715 loss=6.963, nll_loss=3.922, mask_ins=1.182, word_ins_ml=5.361, word_reposition=0.421, ppl=124.8, wps=14480.6, ups=0.98, wpb=14758.5, bsz=1024, num_updates=11400, lr=0.000331133, gnorm=1.233, clip=0, loss_scale=1024, train_wall=100, wall=12084
2022-08-01 18:25:37 | INFO | train_inner | epoch 004:    369 / 3715 loss=6.924, nll_loss=3.895, mask_ins=1.179, word_ins_ml=5.337, word_reposition=0.409, ppl=121.46, wps=14344.8, ups=0.98, wpb=14630.6, bsz=1024, num_updates=11500, lr=0.00032969, gnorm=1.272, clip=0, loss_scale=1034, train_wall=100, wall=12186
2022-08-01 18:27:18 | INFO | train_inner | epoch 004:    469 / 3715 loss=6.912, nll_loss=3.883, mask_ins=1.177, word_ins_ml=5.326, word_reposition=0.41, ppl=120.46, wps=14387.4, ups=0.98, wpb=14617.4, bsz=1024, num_updates=11600, lr=0.000328266, gnorm=1.288, clip=0, loss_scale=2048, train_wall=100, wall=12288
2022-08-01 18:28:59 | INFO | train_inner | epoch 004:    569 / 3715 loss=6.948, nll_loss=3.92, mask_ins=1.178, word_ins_ml=5.358, word_reposition=0.412, ppl=123.49, wps=14412.2, ups=0.99, wpb=14591.5, bsz=1024, num_updates=11700, lr=0.00032686, gnorm=1.267, clip=0, loss_scale=2048, train_wall=99, wall=12389
2022-08-01 18:30:41 | INFO | train_inner | epoch 004:    669 / 3715 loss=6.916, nll_loss=3.889, mask_ins=1.172, word_ins_ml=5.331, word_reposition=0.413, ppl=120.74, wps=14476.6, ups=0.98, wpb=14704.8, bsz=1024, num_updates=11800, lr=0.000325472, gnorm=1.249, clip=0, loss_scale=2048, train_wall=100, wall=12491
2022-08-01 18:32:23 | INFO | train_inner | epoch 004:    769 / 3715 loss=6.917, nll_loss=3.885, mask_ins=1.176, word_ins_ml=5.327, word_reposition=0.414, ppl=120.87, wps=14417.2, ups=0.98, wpb=14645, bsz=1024, num_updates=11900, lr=0.000324102, gnorm=1.264, clip=0, loss_scale=2048, train_wall=100, wall=12592
2022-08-01 18:34:05 | INFO | train_inner | epoch 004:    869 / 3715 loss=6.921, nll_loss=3.892, mask_ins=1.174, word_ins_ml=5.333, word_reposition=0.414, ppl=121.22, wps=14344.2, ups=0.97, wpb=14760.5, bsz=1024, num_updates=12000, lr=0.000322749, gnorm=1.287, clip=0, loss_scale=2048, train_wall=101, wall=12695
2022-08-01 18:35:48 | INFO | train_inner | epoch 004:    969 / 3715 loss=6.919, nll_loss=3.901, mask_ins=1.17, word_ins_ml=5.34, word_reposition=0.409, ppl=121.02, wps=14287.9, ups=0.98, wpb=14589.4, bsz=1024, num_updates=12100, lr=0.000321412, gnorm=1.243, clip=0, loss_scale=3871, train_wall=100, wall=12797
2022-08-01 18:37:30 | INFO | train_inner | epoch 004:   1069 / 3715 loss=6.913, nll_loss=3.888, mask_ins=1.176, word_ins_ml=5.329, word_reposition=0.408, ppl=120.54, wps=14314.5, ups=0.98, wpb=14618.5, bsz=1023.8, num_updates=12200, lr=0.000320092, gnorm=1.272, clip=0, loss_scale=4096, train_wall=100, wall=12900
2022-08-01 18:38:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-01 18:39:12 | INFO | train_inner | epoch 004:   1170 / 3715 loss=6.946, nll_loss=3.918, mask_ins=1.177, word_ins_ml=5.356, word_reposition=0.413, ppl=123.33, wps=14286.6, ups=0.97, wpb=14674.8, bsz=1024, num_updates=12300, lr=0.000318788, gnorm=1.262, clip=0, loss_scale=3731, train_wall=101, wall=13002
2022-08-01 18:40:54 | INFO | train_inner | epoch 004:   1270 / 3715 loss=6.884, nll_loss=3.855, mask_ins=1.172, word_ins_ml=5.299, word_reposition=0.413, ppl=118.12, wps=14434, ups=0.98, wpb=14688, bsz=1024, num_updates=12400, lr=0.0003175, gnorm=1.24, clip=0, loss_scale=2048, train_wall=100, wall=13104
2022-08-01 18:41:22 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-01 18:42:37 | INFO | train_inner | epoch 004:   1371 / 3715 loss=6.892, nll_loss=3.872, mask_ins=1.164, word_ins_ml=5.315, word_reposition=0.414, ppl=118.8, wps=14281.6, ups=0.97, wpb=14717.1, bsz=1024, num_updates=12500, lr=0.000316228, gnorm=1.331, clip=0, loss_scale=1288, train_wall=101, wall=13207
2022-08-01 18:44:20 | INFO | train_inner | epoch 004:   1471 / 3715 loss=6.889, nll_loss=3.869, mask_ins=1.171, word_ins_ml=5.312, word_reposition=0.406, ppl=118.51, wps=14198.8, ups=0.97, wpb=14668.6, bsz=1024, num_updates=12600, lr=0.00031497, gnorm=1.326, clip=0, loss_scale=1024, train_wall=102, wall=13310
2022-08-01 18:46:04 | INFO | train_inner | epoch 004:   1571 / 3715 loss=6.862, nll_loss=3.845, mask_ins=1.163, word_ins_ml=5.29, word_reposition=0.409, ppl=116.31, wps=14250.2, ups=0.96, wpb=14773, bsz=1024, num_updates=12700, lr=0.000313728, gnorm=1.341, clip=0, loss_scale=1024, train_wall=102, wall=13414
2022-08-01 18:47:48 | INFO | train_inner | epoch 004:   1671 / 3715 loss=6.883, nll_loss=3.86, mask_ins=1.168, word_ins_ml=5.303, word_reposition=0.412, ppl=118, wps=14100.8, ups=0.96, wpb=14644.8, bsz=1024, num_updates=12800, lr=0.0003125, gnorm=1.353, clip=0, loss_scale=1024, train_wall=102, wall=13518
2022-08-01 18:49:31 | INFO | train_inner | epoch 004:   1771 / 3715 loss=6.879, nll_loss=3.865, mask_ins=1.162, word_ins_ml=5.308, word_reposition=0.408, ppl=117.7, wps=14382.3, ups=0.97, wpb=14757.3, bsz=1024, num_updates=12900, lr=0.000311286, gnorm=1.417, clip=0, loss_scale=1024, train_wall=101, wall=13621
2022-08-01 18:50:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-01 18:51:16 | INFO | train_inner | epoch 004:   1872 / 3715 loss=6.862, nll_loss=3.851, mask_ins=1.165, word_ins_ml=5.295, word_reposition=0.402, ppl=116.3, wps=13906.3, ups=0.95, wpb=14685, bsz=1024, num_updates=13000, lr=0.000310087, gnorm=1.293, clip=0, loss_scale=1389, train_wall=104, wall=13726
2022-08-01 18:52:58 | INFO | train_inner | epoch 004:   1972 / 3715 loss=6.853, nll_loss=3.843, mask_ins=1.158, word_ins_ml=5.288, word_reposition=0.407, ppl=115.6, wps=14319.5, ups=0.98, wpb=14594.5, bsz=1024, num_updates=13100, lr=0.000308901, gnorm=1.263, clip=0, loss_scale=1024, train_wall=100, wall=13828
2022-08-01 18:54:43 | INFO | train_inner | epoch 004:   2072 / 3715 loss=6.858, nll_loss=3.853, mask_ins=1.161, word_ins_ml=5.297, word_reposition=0.4, ppl=115.98, wps=13912, ups=0.95, wpb=14600.8, bsz=1024, num_updates=13200, lr=0.000307729, gnorm=1.236, clip=0, loss_scale=1024, train_wall=103, wall=13933
2022-08-01 18:56:29 | INFO | train_inner | epoch 004:   2172 / 3715 loss=6.882, nll_loss=3.869, mask_ins=1.166, word_ins_ml=5.31, word_reposition=0.405, ppl=117.91, wps=13807.8, ups=0.94, wpb=14632.6, bsz=1024, num_updates=13300, lr=0.00030657, gnorm=1.327, clip=0, loss_scale=1024, train_wall=104, wall=14039
2022-08-01 18:58:12 | INFO | train_inner | epoch 004:   2272 / 3715 loss=6.852, nll_loss=3.833, mask_ins=1.162, word_ins_ml=5.279, word_reposition=0.411, ppl=115.53, wps=14400.3, ups=0.97, wpb=14827.5, bsz=1024, num_updates=13400, lr=0.000305424, gnorm=1.301, clip=0, loss_scale=1024, train_wall=101, wall=14142
2022-08-01 18:59:55 | INFO | train_inner | epoch 004:   2372 / 3715 loss=6.846, nll_loss=3.836, mask_ins=1.157, word_ins_ml=5.282, word_reposition=0.407, ppl=115.03, wps=14309.4, ups=0.97, wpb=14754.5, bsz=1024, num_updates=13500, lr=0.00030429, gnorm=1.295, clip=0, loss_scale=1188, train_wall=101, wall=14245
2022-08-01 19:01:37 | INFO | train_inner | epoch 004:   2472 / 3715 loss=6.857, nll_loss=3.848, mask_ins=1.161, word_ins_ml=5.292, word_reposition=0.405, ppl=115.93, wps=14525.7, ups=0.98, wpb=14748.2, bsz=1024, num_updates=13600, lr=0.00030317, gnorm=1.305, clip=0, loss_scale=2048, train_wall=100, wall=14347
2022-08-01 19:03:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-01 19:03:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-08-01 19:03:20 | INFO | train_inner | epoch 004:   2574 / 3715 loss=6.847, nll_loss=3.84, mask_ins=1.161, word_ins_ml=5.285, word_reposition=0.402, ppl=115.13, wps=14110, ups=0.97, wpb=14573.7, bsz=1024, num_updates=13700, lr=0.000302061, gnorm=1.531, clip=0, loss_scale=1832, train_wall=101, wall=14450
2022-08-01 19:05:01 | INFO | train_inner | epoch 004:   2674 / 3715 loss=6.826, nll_loss=3.821, mask_ins=1.155, word_ins_ml=5.268, word_reposition=0.403, ppl=113.45, wps=14465.6, ups=0.99, wpb=14668, bsz=1024, num_updates=13800, lr=0.000300965, gnorm=1.245, clip=0, loss_scale=512, train_wall=100, wall=14551
2022-08-01 19:06:43 | INFO | train_inner | epoch 004:   2774 / 3715 loss=6.826, nll_loss=3.831, mask_ins=1.153, word_ins_ml=5.277, word_reposition=0.395, ppl=113.42, wps=14353.8, ups=0.99, wpb=14568.5, bsz=1024, num_updates=13900, lr=0.00029988, gnorm=1.354, clip=0, loss_scale=512, train_wall=100, wall=14653
2022-08-01 19:07:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-01 19:08:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-08-01 19:08:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2022-08-01 19:08:27 | INFO | train_inner | epoch 004:   2877 / 3715 loss=7.003, nll_loss=3.996, mask_ins=1.172, word_ins_ml=5.422, word_reposition=0.409, ppl=128.28, wps=13939, ups=0.96, wpb=14562.9, bsz=1024, num_updates=14000, lr=0.000298807, gnorm=3.654, clip=2, loss_scale=359, train_wall=103, wall=14757
2022-08-01 19:10:09 | INFO | train_inner | epoch 004:   2977 / 3715 loss=6.844, nll_loss=3.833, mask_ins=1.162, word_ins_ml=5.278, word_reposition=0.405, ppl=114.91, wps=14325.7, ups=0.98, wpb=14603.4, bsz=1024, num_updates=14100, lr=0.000297746, gnorm=1.556, clip=0, loss_scale=64, train_wall=100, wall=14859
2022-08-01 19:11:51 | INFO | train_inner | epoch 004:   3077 / 3715 loss=6.815, nll_loss=3.817, mask_ins=1.15, word_ins_ml=5.264, word_reposition=0.4, ppl=112.62, wps=14437.6, ups=0.99, wpb=14640.2, bsz=1024, num_updates=14200, lr=0.000296695, gnorm=1.253, clip=0, loss_scale=64, train_wall=100, wall=14961
2022-08-01 19:13:32 | INFO | train_inner | epoch 004:   3177 / 3715 loss=6.823, nll_loss=3.823, mask_ins=1.152, word_ins_ml=5.269, word_reposition=0.403, ppl=113.26, wps=14421.5, ups=0.98, wpb=14646.5, bsz=1024, num_updates=14300, lr=0.000295656, gnorm=1.491, clip=1, loss_scale=64, train_wall=100, wall=15062
2022-08-01 19:15:13 | INFO | train_inner | epoch 004:   3277 / 3715 loss=6.806, nll_loss=3.808, mask_ins=1.155, word_ins_ml=5.256, word_reposition=0.395, ppl=111.89, wps=14326.1, ups=0.99, wpb=14480.2, bsz=1024, num_updates=14400, lr=0.000294628, gnorm=1.253, clip=0, loss_scale=64, train_wall=99, wall=15163
2022-08-01 19:16:54 | INFO | train_inner | epoch 004:   3377 / 3715 loss=6.824, nll_loss=3.823, mask_ins=1.158, word_ins_ml=5.269, word_reposition=0.397, ppl=113.33, wps=14461.7, ups=0.99, wpb=14614.4, bsz=1024, num_updates=14500, lr=0.00029361, gnorm=1.273, clip=0, loss_scale=68, train_wall=99, wall=15264
2022-08-01 19:18:36 | INFO | train_inner | epoch 004:   3477 / 3715 loss=6.809, nll_loss=3.797, mask_ins=1.151, word_ins_ml=5.246, word_reposition=0.412, ppl=112.13, wps=14527.2, ups=0.99, wpb=14734.7, bsz=1024, num_updates=14600, lr=0.000292603, gnorm=1.188, clip=0, loss_scale=128, train_wall=100, wall=15366
2022-08-01 19:20:17 | INFO | train_inner | epoch 004:   3577 / 3715 loss=6.811, nll_loss=3.808, mask_ins=1.157, word_ins_ml=5.256, word_reposition=0.398, ppl=112.25, wps=14553.1, ups=0.99, wpb=14752.7, bsz=1024, num_updates=14700, lr=0.000291606, gnorm=1.316, clip=0, loss_scale=128, train_wall=100, wall=15467
2022-08-01 19:21:59 | INFO | train_inner | epoch 004:   3677 / 3715 loss=6.799, nll_loss=3.803, mask_ins=1.149, word_ins_ml=5.25, word_reposition=0.399, ppl=111.33, wps=14424.3, ups=0.99, wpb=14640.9, bsz=1024, num_updates=14800, lr=0.000290619, gnorm=1.209, clip=0, loss_scale=128, train_wall=100, wall=15569
2022-08-01 19:22:36 | INFO | train | epoch 004 | loss 6.877 | nll_loss 3.862 | mask_ins 1.165 | word_ins_ml 5.305 | word_reposition 0.407 | ppl 117.51 | wps 14034.5 | ups 0.96 | wpb 14662 | bsz 1023.7 | num_updates 14838 | lr 0.000290247 | gnorm 1.364 | clip 0.1 | loss_scale 1237 | train_wall 3731 | wall 15606
2022-08-01 19:23:46 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.723 | nll_loss 3.61 | mask_ins 1.126 | word_ins_ml 5.167 | word_reposition 0.429 | ppl 105.61 | wps 39245.3 | wpb 1849.4 | bsz 127.9 | num_updates 14838 | best_loss 6.723
2022-08-01 19:23:53 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 4 @ 14838 updates, score 6.723) (writing took 6.817782958969474 seconds)
2022-08-01 19:24:56 | INFO | train_inner | epoch 005:     62 / 3715 loss=6.769, nll_loss=3.772, mask_ins=1.149, word_ins_ml=5.224, word_reposition=0.396, ppl=109.06, wps=8177.1, ups=0.56, wpb=14524.8, bsz=1014.7, num_updates=14900, lr=0.000289642, gnorm=1.27, clip=0, loss_scale=128, train_wall=99, wall=15746
2022-08-01 19:26:38 | INFO | train_inner | epoch 005:    162 / 3715 loss=6.756, nll_loss=3.751, mask_ins=1.141, word_ins_ml=5.206, word_reposition=0.41, ppl=108.11, wps=14344.1, ups=0.98, wpb=14617.5, bsz=1024, num_updates=15000, lr=0.000288675, gnorm=1.253, clip=0, loss_scale=128, train_wall=100, wall=15848
2022-08-01 19:28:20 | INFO | train_inner | epoch 005:    262 / 3715 loss=6.725, nll_loss=3.732, mask_ins=1.143, word_ins_ml=5.188, word_reposition=0.394, ppl=105.77, wps=14451.8, ups=0.98, wpb=14677.2, bsz=1024, num_updates=15100, lr=0.000287718, gnorm=1.237, clip=0, loss_scale=250, train_wall=100, wall=15950
2022-08-01 19:30:02 | INFO | train_inner | epoch 005:    362 / 3715 loss=6.752, nll_loss=3.76, mask_ins=1.138, word_ins_ml=5.213, word_reposition=0.401, ppl=107.75, wps=14405, ups=0.98, wpb=14677.5, bsz=1024, num_updates=15200, lr=0.00028677, gnorm=1.467, clip=0, loss_scale=256, train_wall=100, wall=16052
2022-08-01 19:31:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-08-01 19:31:45 | INFO | train_inner | epoch 005:    463 / 3715 loss=6.777, nll_loss=3.776, mask_ins=1.147, word_ins_ml=5.228, word_reposition=0.402, ppl=109.64, wps=14268.5, ups=0.97, wpb=14696.9, bsz=1024, num_updates=15300, lr=0.000285831, gnorm=1.812, clip=0, loss_scale=223, train_wall=101, wall=16155
2022-08-01 19:33:27 | INFO | train_inner | epoch 005:    563 / 3715 loss=6.746, nll_loss=3.741, mask_ins=1.147, word_ins_ml=5.196, word_reposition=0.403, ppl=107.31, wps=14380.3, ups=0.98, wpb=14655.7, bsz=1023.8, num_updates=15400, lr=0.000284901, gnorm=1.813, clip=1, loss_scale=128, train_wall=100, wall=16257
2022-08-01 19:35:08 | INFO | train_inner | epoch 005:    663 / 3715 loss=6.725, nll_loss=3.739, mask_ins=1.137, word_ins_ml=5.194, word_reposition=0.394, ppl=105.75, wps=14486.6, ups=0.98, wpb=14754.2, bsz=1024, num_updates=15500, lr=0.000283981, gnorm=1.202, clip=0, loss_scale=128, train_wall=100, wall=16358
2022-08-01 19:36:50 | INFO | train_inner | epoch 005:    763 / 3715 loss=6.731, nll_loss=3.746, mask_ins=1.143, word_ins_ml=5.2, word_reposition=0.388, ppl=106.24, wps=14410.5, ups=0.98, wpb=14681.1, bsz=1024, num_updates=15600, lr=0.000283069, gnorm=1.34, clip=0, loss_scale=128, train_wall=100, wall=16460
2022-08-01 19:38:32 | INFO | train_inner | epoch 005:    863 / 3715 loss=6.729, nll_loss=3.729, mask_ins=1.141, word_ins_ml=5.185, word_reposition=0.403, ppl=106.07, wps=14590.7, ups=0.98, wpb=14846.3, bsz=1024, num_updates=15700, lr=0.000282166, gnorm=1.426, clip=0, loss_scale=128, train_wall=100, wall=16562
2022-08-01 19:40:14 | INFO | train_inner | epoch 005:    963 / 3715 loss=6.784, nll_loss=3.767, mask_ins=1.155, word_ins_ml=5.219, word_reposition=0.411, ppl=110.22, wps=14490.6, ups=0.98, wpb=14781.8, bsz=1024, num_updates=15800, lr=0.000281272, gnorm=2.786, clip=1, loss_scale=146, train_wall=100, wall=16664
2022-08-01 19:41:55 | INFO | train_inner | epoch 005:   1063 / 3715 loss=6.729, nll_loss=3.738, mask_ins=1.143, word_ins_ml=5.192, word_reposition=0.394, ppl=106.09, wps=14390.9, ups=0.99, wpb=14591.3, bsz=1024, num_updates=15900, lr=0.000280386, gnorm=1.43, clip=0, loss_scale=256, train_wall=100, wall=16765
2022-08-01 19:43:37 | INFO | train_inner | epoch 005:   1163 / 3715 loss=6.714, nll_loss=3.727, mask_ins=1.136, word_ins_ml=5.183, word_reposition=0.395, ppl=104.99, wps=14469, ups=0.99, wpb=14629, bsz=1024, num_updates=16000, lr=0.000279508, gnorm=1.226, clip=0, loss_scale=256, train_wall=99, wall=16867
2022-08-01 19:45:18 | INFO | train_inner | epoch 005:   1263 / 3715 loss=6.739, nll_loss=3.747, mask_ins=1.141, word_ins_ml=5.201, word_reposition=0.397, ppl=106.84, wps=14438.1, ups=0.98, wpb=14696.1, bsz=1024, num_updates=16100, lr=0.000278639, gnorm=1.238, clip=0, loss_scale=256, train_wall=100, wall=16968
2022-08-01 19:47:00 | INFO | train_inner | epoch 005:   1363 / 3715 loss=6.731, nll_loss=3.748, mask_ins=1.143, word_ins_ml=5.201, word_reposition=0.387, ppl=106.21, wps=14410.1, ups=0.98, wpb=14635.5, bsz=1024, num_updates=16200, lr=0.000277778, gnorm=1.762, clip=0, loss_scale=256, train_wall=100, wall=17070
2022-08-01 19:48:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-08-01 19:48:43 | INFO | train_inner | epoch 005:   1464 / 3715 loss=6.71, nll_loss=3.721, mask_ins=1.136, word_ins_ml=5.178, word_reposition=0.396, ppl=104.7, wps=14221.5, ups=0.97, wpb=14645.9, bsz=1024, num_updates=16300, lr=0.000276924, gnorm=1.208, clip=0, loss_scale=236, train_wall=101, wall=17173
2022-08-01 19:50:25 | INFO | train_inner | epoch 005:   1564 / 3715 loss=6.701, nll_loss=3.708, mask_ins=1.135, word_ins_ml=5.166, word_reposition=0.4, ppl=104.04, wps=14299.5, ups=0.98, wpb=14659.7, bsz=1024, num_updates=16400, lr=0.000276079, gnorm=1.208, clip=0, loss_scale=128, train_wall=101, wall=17275
2022-08-01 19:50:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2022-08-01 19:52:10 | INFO | train_inner | epoch 005:   1665 / 3715 loss=6.67, nll_loss=3.695, mask_ins=1.132, word_ins_ml=5.154, word_reposition=0.385, ppl=101.86, wps=14064, ups=0.96, wpb=14681.8, bsz=1024, num_updates=16500, lr=0.000275241, gnorm=1.235, clip=0, loss_scale=83, train_wall=103, wall=17380
2022-08-01 19:53:53 | INFO | train_inner | epoch 005:   1765 / 3715 loss=6.714, nll_loss=3.733, mask_ins=1.137, word_ins_ml=5.188, word_reposition=0.388, ppl=104.95, wps=14173.6, ups=0.97, wpb=14595, bsz=1024, num_updates=16600, lr=0.000274411, gnorm=1.204, clip=0, loss_scale=64, train_wall=101, wall=17483
2022-08-01 19:55:36 | INFO | train_inner | epoch 005:   1865 / 3715 loss=6.711, nll_loss=3.731, mask_ins=1.134, word_ins_ml=5.186, word_reposition=0.391, ppl=104.74, wps=14159.4, ups=0.97, wpb=14634.6, bsz=1024, num_updates=16700, lr=0.000273588, gnorm=1.255, clip=0, loss_scale=64, train_wall=102, wall=17586
2022-08-01 19:57:18 | INFO | train_inner | epoch 005:   1965 / 3715 loss=6.719, nll_loss=3.733, mask_ins=1.14, word_ins_ml=5.188, word_reposition=0.391, ppl=105.31, wps=14444.6, ups=0.98, wpb=14684.3, bsz=1024, num_updates=16800, lr=0.000272772, gnorm=2.112, clip=0, loss_scale=64, train_wall=100, wall=17688
2022-08-01 19:59:00 | INFO | train_inner | epoch 005:   2065 / 3715 loss=6.697, nll_loss=3.721, mask_ins=1.13, word_ins_ml=5.177, word_reposition=0.39, ppl=103.77, wps=14402.4, ups=0.98, wpb=14724.2, bsz=1024, num_updates=16900, lr=0.000271964, gnorm=2.312, clip=1, loss_scale=64, train_wall=100, wall=17790
2022-08-01 20:00:45 | INFO | train_inner | epoch 005:   2165 / 3715 loss=6.709, nll_loss=3.726, mask_ins=1.136, word_ins_ml=5.181, word_reposition=0.391, ppl=104.61, wps=13942.4, ups=0.95, wpb=14621.5, bsz=1024, num_updates=17000, lr=0.000271163, gnorm=1.485, clip=0, loss_scale=102, train_wall=103, wall=17895
2022-08-01 20:02:30 | INFO | train_inner | epoch 005:   2265 / 3715 loss=6.673, nll_loss=3.693, mask_ins=1.134, word_ins_ml=5.153, word_reposition=0.387, ppl=102.06, wps=13836.9, ups=0.95, wpb=14566.9, bsz=1024, num_updates=17100, lr=0.000270369, gnorm=1.197, clip=0, loss_scale=128, train_wall=103, wall=18000
2022-08-01 20:04:12 | INFO | train_inner | epoch 005:   2365 / 3715 loss=6.704, nll_loss=3.72, mask_ins=1.13, word_ins_ml=5.175, word_reposition=0.398, ppl=104.22, wps=14612.7, ups=0.98, wpb=14836.4, bsz=1024, num_updates=17200, lr=0.000269582, gnorm=1.346, clip=0, loss_scale=128, train_wall=100, wall=18102
2022-08-01 20:05:56 | INFO | train_inner | epoch 005:   2465 / 3715 loss=6.689, nll_loss=3.709, mask_ins=1.137, word_ins_ml=5.167, word_reposition=0.385, ppl=103.15, wps=14048.7, ups=0.96, wpb=14645.1, bsz=1024, num_updates=17300, lr=0.000268802, gnorm=1.205, clip=0, loss_scale=128, train_wall=102, wall=18206
2022-08-01 20:07:38 | INFO | train_inner | epoch 005:   2565 / 3715 loss=6.709, nll_loss=3.722, mask_ins=1.138, word_ins_ml=5.178, word_reposition=0.394, ppl=104.65, wps=14378.1, ups=0.98, wpb=14717.4, bsz=1024, num_updates=17400, lr=0.000268028, gnorm=1.254, clip=0, loss_scale=128, train_wall=101, wall=18308
2022-08-01 20:09:20 | INFO | train_inner | epoch 005:   2665 / 3715 loss=6.669, nll_loss=3.698, mask_ins=1.128, word_ins_ml=5.156, word_reposition=0.386, ppl=101.79, wps=14350.1, ups=0.98, wpb=14621.2, bsz=1024, num_updates=17500, lr=0.000267261, gnorm=1.152, clip=0, loss_scale=188, train_wall=100, wall=18410
2022-08-01 20:11:02 | INFO | train_inner | epoch 005:   2765 / 3715 loss=6.713, nll_loss=3.728, mask_ins=1.133, word_ins_ml=5.183, word_reposition=0.397, ppl=104.89, wps=14388, ups=0.98, wpb=14678.1, bsz=1024, num_updates=17600, lr=0.000266501, gnorm=1.368, clip=0, loss_scale=256, train_wall=100, wall=18512
2022-08-01 20:11:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-08-01 20:12:45 | INFO | train_inner | epoch 005:   2866 / 3715 loss=6.7, nll_loss=3.723, mask_ins=1.131, word_ins_ml=5.178, word_reposition=0.391, ppl=103.95, wps=14279.8, ups=0.97, wpb=14672.5, bsz=1024, num_updates=17700, lr=0.000265747, gnorm=2.429, clip=2, loss_scale=153, train_wall=101, wall=18615
2022-08-01 20:14:27 | INFO | train_inner | epoch 005:   2966 / 3715 loss=6.663, nll_loss=3.692, mask_ins=1.124, word_ins_ml=5.151, word_reposition=0.387, ppl=101.31, wps=14441.5, ups=0.98, wpb=14662.5, bsz=1024, num_updates=17800, lr=0.000264999, gnorm=1.282, clip=0, loss_scale=128, train_wall=100, wall=18716
2022-08-01 20:16:08 | INFO | train_inner | epoch 005:   3066 / 3715 loss=6.712, nll_loss=3.727, mask_ins=1.138, word_ins_ml=5.181, word_reposition=0.394, ppl=104.86, wps=14494, ups=0.99, wpb=14712.9, bsz=1024, num_updates=17900, lr=0.000264258, gnorm=2.841, clip=2, loss_scale=128, train_wall=100, wall=18818
2022-08-01 20:17:50 | INFO | train_inner | epoch 005:   3166 / 3715 loss=6.678, nll_loss=3.704, mask_ins=1.134, word_ins_ml=5.161, word_reposition=0.383, ppl=102.43, wps=14275.1, ups=0.98, wpb=14597.3, bsz=1024, num_updates=18000, lr=0.000263523, gnorm=1.975, clip=0, loss_scale=128, train_wall=100, wall=18920
2022-08-01 20:19:32 | INFO | train_inner | epoch 005:   3266 / 3715 loss=6.669, nll_loss=3.692, mask_ins=1.13, word_ins_ml=5.15, word_reposition=0.389, ppl=101.76, wps=14274.7, ups=0.98, wpb=14588.3, bsz=1024, num_updates=18100, lr=0.000262794, gnorm=1.676, clip=0, loss_scale=128, train_wall=100, wall=19022
2022-08-01 20:21:15 | INFO | train_inner | epoch 005:   3366 / 3715 loss=6.676, nll_loss=3.708, mask_ins=1.126, word_ins_ml=5.164, word_reposition=0.385, ppl=102.27, wps=14369.4, ups=0.98, wpb=14663.9, bsz=1024, num_updates=18200, lr=0.000262071, gnorm=1.255, clip=0, loss_scale=216, train_wall=100, wall=19124
2022-08-01 20:22:56 | INFO | train_inner | epoch 005:   3466 / 3715 loss=6.661, nll_loss=3.688, mask_ins=1.129, word_ins_ml=5.146, word_reposition=0.386, ppl=101.21, wps=14494.3, ups=0.99, wpb=14682.1, bsz=1024, num_updates=18300, lr=0.000261354, gnorm=1.193, clip=0, loss_scale=256, train_wall=100, wall=19226
2022-08-01 20:24:37 | INFO | train_inner | epoch 005:   3566 / 3715 loss=6.671, nll_loss=3.696, mask_ins=1.13, word_ins_ml=5.153, word_reposition=0.388, ppl=101.91, wps=14482.6, ups=0.99, wpb=14660.4, bsz=1024, num_updates=18400, lr=0.000260643, gnorm=1.164, clip=0, loss_scale=256, train_wall=99, wall=19327
2022-08-01 20:26:19 | INFO | train_inner | epoch 005:   3666 / 3715 loss=6.631, nll_loss=3.661, mask_ins=1.13, word_ins_ml=5.123, word_reposition=0.378, ppl=99.12, wps=14266.7, ups=0.98, wpb=14580.4, bsz=1024, num_updates=18500, lr=0.000259938, gnorm=1.184, clip=0, loss_scale=256, train_wall=100, wall=19429
2022-08-01 20:27:09 | INFO | train | epoch 005 | loss 6.708 | nll_loss 3.723 | mask_ins 1.136 | word_ins_ml 5.179 | word_reposition 0.393 | ppl 104.56 | wps 14051.8 | ups 0.96 | wpb 14661.7 | bsz 1023.7 | num_updates 18549 | lr 0.000259594 | gnorm 1.507 | clip 0.2 | loss_scale 166 | train_wall 3730 | wall 19478
2022-08-01 20:28:19 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.609 | nll_loss 3.512 | mask_ins 1.121 | word_ins_ml 5.076 | word_reposition 0.412 | ppl 97.59 | wps 39171.2 | wpb 1849.4 | bsz 127.9 | num_updates 18549 | best_loss 6.609
2022-08-01 20:28:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 5 @ 18549 updates, score 6.609) (writing took 6.967630902305245 seconds)
2022-08-01 20:29:18 | INFO | train_inner | epoch 006:     51 / 3715 loss=6.626, nll_loss=3.662, mask_ins=1.122, word_ins_ml=5.124, word_reposition=0.381, ppl=98.76, wps=8064.4, ups=0.56, wpb=14422.2, bsz=1014.7, num_updates=18600, lr=0.000259238, gnorm=1.188, clip=0, loss_scale=256, train_wall=100, wall=19608
2022-08-01 20:31:00 | INFO | train_inner | epoch 006:    151 / 3715 loss=6.588, nll_loss=3.625, mask_ins=1.119, word_ins_ml=5.091, word_reposition=0.378, ppl=96.21, wps=14424.4, ups=0.98, wpb=14727.2, bsz=1024, num_updates=18700, lr=0.000258544, gnorm=1.162, clip=0, loss_scale=402, train_wall=100, wall=19710
2022-08-01 20:32:42 | INFO | train_inner | epoch 006:    251 / 3715 loss=6.578, nll_loss=3.598, mask_ins=1.121, word_ins_ml=5.068, word_reposition=0.39, ppl=95.57, wps=14322.5, ups=0.98, wpb=14590.1, bsz=1023.8, num_updates=18800, lr=0.000257855, gnorm=1.147, clip=0, loss_scale=512, train_wall=100, wall=19812
2022-08-01 20:34:24 | INFO | train_inner | epoch 006:    351 / 3715 loss=6.588, nll_loss=3.627, mask_ins=1.114, word_ins_ml=5.093, word_reposition=0.381, ppl=96.21, wps=14458.9, ups=0.98, wpb=14686.4, bsz=1024, num_updates=18900, lr=0.000257172, gnorm=1.179, clip=0, loss_scale=512, train_wall=100, wall=19914
2022-08-01 20:36:05 | INFO | train_inner | epoch 006:    451 / 3715 loss=6.602, nll_loss=3.628, mask_ins=1.116, word_ins_ml=5.094, word_reposition=0.392, ppl=97.14, wps=14387.2, ups=0.99, wpb=14563.5, bsz=1024, num_updates=19000, lr=0.000256495, gnorm=1.146, clip=0, loss_scale=512, train_wall=99, wall=20015
2022-08-01 20:37:47 | INFO | train_inner | epoch 006:    551 / 3715 loss=6.605, nll_loss=3.64, mask_ins=1.119, word_ins_ml=5.104, word_reposition=0.382, ppl=97.34, wps=14352.1, ups=0.98, wpb=14585.3, bsz=1024, num_updates=19100, lr=0.000255822, gnorm=1.164, clip=0, loss_scale=512, train_wall=100, wall=20116
2022-08-01 20:39:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-08-01 20:39:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-01 20:39:30 | INFO | train_inner | epoch 006:    653 / 3715 loss=6.624, nll_loss=3.65, mask_ins=1.117, word_ins_ml=5.113, word_reposition=0.394, ppl=98.64, wps=14199.8, ups=0.96, wpb=14735.1, bsz=1024, num_updates=19200, lr=0.000255155, gnorm=1.666, clip=0, loss_scale=607, train_wall=102, wall=20220
2022-08-01 20:41:13 | INFO | train_inner | epoch 006:    753 / 3715 loss=6.571, nll_loss=3.603, mask_ins=1.111, word_ins_ml=5.071, word_reposition=0.388, ppl=95.06, wps=14382.6, ups=0.97, wpb=14791.5, bsz=1024, num_updates=19300, lr=0.000254493, gnorm=1.188, clip=0, loss_scale=256, train_wall=101, wall=20323
2022-08-01 20:42:55 | INFO | train_inner | epoch 006:    853 / 3715 loss=6.611, nll_loss=3.64, mask_ins=1.12, word_ins_ml=5.104, word_reposition=0.387, ppl=97.77, wps=14522.7, ups=0.99, wpb=14739.9, bsz=1024, num_updates=19400, lr=0.000253837, gnorm=1.632, clip=0, loss_scale=256, train_wall=100, wall=20425
2022-08-01 20:44:36 | INFO | train_inner | epoch 006:    953 / 3715 loss=6.608, nll_loss=3.64, mask_ins=1.118, word_ins_ml=5.104, word_reposition=0.386, ppl=97.51, wps=14385.4, ups=0.98, wpb=14636.5, bsz=1024, num_updates=19500, lr=0.000253185, gnorm=1.18, clip=0, loss_scale=256, train_wall=100, wall=20526
2022-08-01 20:46:18 | INFO | train_inner | epoch 006:   1053 / 3715 loss=6.593, nll_loss=3.631, mask_ins=1.115, word_ins_ml=5.096, word_reposition=0.381, ppl=96.52, wps=14543.3, ups=0.98, wpb=14769.2, bsz=1024, num_updates=19600, lr=0.000252538, gnorm=1.262, clip=0, loss_scale=256, train_wall=100, wall=20628
2022-08-01 20:48:00 | INFO | train_inner | epoch 006:   1153 / 3715 loss=6.582, nll_loss=3.62, mask_ins=1.114, word_ins_ml=5.085, word_reposition=0.383, ppl=95.79, wps=14493.3, ups=0.98, wpb=14785.9, bsz=1024, num_updates=19700, lr=0.000251896, gnorm=1.307, clip=0, loss_scale=256, train_wall=100, wall=20730
2022-08-01 20:49:42 | INFO | train_inner | epoch 006:   1253 / 3715 loss=6.564, nll_loss=3.605, mask_ins=1.113, word_ins_ml=5.072, word_reposition=0.378, ppl=94.59, wps=14376.2, ups=0.98, wpb=14669.7, bsz=1024, num_updates=19800, lr=0.000251259, gnorm=1.218, clip=0, loss_scale=512, train_wall=100, wall=20832
2022-08-01 20:51:24 | INFO | train_inner | epoch 006:   1353 / 3715 loss=6.586, nll_loss=3.616, mask_ins=1.12, word_ins_ml=5.082, word_reposition=0.384, ppl=96.08, wps=14341.2, ups=0.98, wpb=14625.4, bsz=1024, num_updates=19900, lr=0.000250627, gnorm=1.156, clip=0, loss_scale=512, train_wall=100, wall=20934
2022-08-01 20:53:06 | INFO | train_inner | epoch 006:   1453 / 3715 loss=6.606, nll_loss=3.642, mask_ins=1.121, word_ins_ml=5.105, word_reposition=0.38, ppl=97.4, wps=14298.2, ups=0.98, wpb=14567.2, bsz=1024, num_updates=20000, lr=0.00025, gnorm=1.173, clip=0, loss_scale=512, train_wall=100, wall=21036
2022-08-01 20:54:47 | INFO | train_inner | epoch 006:   1553 / 3715 loss=6.592, nll_loss=3.629, mask_ins=1.112, word_ins_ml=5.093, word_reposition=0.387, ppl=96.48, wps=14565.7, ups=0.99, wpb=14787.1, bsz=1024, num_updates=20100, lr=0.000249377, gnorm=1.179, clip=0, loss_scale=512, train_wall=100, wall=21137
2022-08-01 20:56:29 | INFO | train_inner | epoch 006:   1653 / 3715 loss=6.588, nll_loss=3.614, mask_ins=1.117, word_ins_ml=5.08, word_reposition=0.392, ppl=96.24, wps=14432.8, ups=0.98, wpb=14674.8, bsz=1024, num_updates=20200, lr=0.000248759, gnorm=1.192, clip=0, loss_scale=512, train_wall=100, wall=21239
2022-08-01 20:58:11 | INFO | train_inner | epoch 006:   1753 / 3715 loss=6.581, nll_loss=3.617, mask_ins=1.112, word_ins_ml=5.083, word_reposition=0.386, ppl=95.73, wps=14411.7, ups=0.98, wpb=14698.9, bsz=1024, num_updates=20300, lr=0.000248146, gnorm=1.166, clip=0, loss_scale=963, train_wall=100, wall=21341
2022-08-01 20:59:52 | INFO | train_inner | epoch 006:   1853 / 3715 loss=6.569, nll_loss=3.61, mask_ins=1.113, word_ins_ml=5.077, word_reposition=0.378, ppl=94.95, wps=14411.6, ups=0.99, wpb=14573.8, bsz=1024, num_updates=20400, lr=0.000247537, gnorm=1.155, clip=0, loss_scale=1024, train_wall=99, wall=21442
2022-08-01 21:01:33 | INFO | train_inner | epoch 006:   1953 / 3715 loss=6.594, nll_loss=3.626, mask_ins=1.119, word_ins_ml=5.091, word_reposition=0.384, ppl=96.6, wps=14535.2, ups=0.99, wpb=14692.7, bsz=1024, num_updates=20500, lr=0.000246932, gnorm=1.164, clip=0, loss_scale=1024, train_wall=99, wall=21543
2022-08-01 21:03:15 | INFO | train_inner | epoch 006:   2053 / 3715 loss=6.582, nll_loss=3.618, mask_ins=1.116, word_ins_ml=5.084, word_reposition=0.382, ppl=95.79, wps=14362.8, ups=0.98, wpb=14662.7, bsz=1024, num_updates=20600, lr=0.000246332, gnorm=1.151, clip=0, loss_scale=1024, train_wall=100, wall=21645
2022-08-01 21:04:57 | INFO | train_inner | epoch 006:   2153 / 3715 loss=6.576, nll_loss=3.619, mask_ins=1.115, word_ins_ml=5.085, word_reposition=0.376, ppl=95.39, wps=14404.2, ups=0.99, wpb=14594.7, bsz=1024, num_updates=20700, lr=0.000245737, gnorm=1.277, clip=0, loss_scale=1024, train_wall=100, wall=21747
2022-08-01 21:06:39 | INFO | train_inner | epoch 006:   2253 / 3715 loss=6.583, nll_loss=3.624, mask_ins=1.112, word_ins_ml=5.089, word_reposition=0.382, ppl=95.88, wps=14422.5, ups=0.98, wpb=14717.5, bsz=1024, num_updates=20800, lr=0.000245145, gnorm=1.143, clip=0, loss_scale=1802, train_wall=100, wall=21849
2022-08-01 21:08:20 | INFO | train_inner | epoch 006:   2353 / 3715 loss=6.573, nll_loss=3.616, mask_ins=1.109, word_ins_ml=5.082, word_reposition=0.382, ppl=95.21, wps=14455.1, ups=0.99, wpb=14613.5, bsz=1024, num_updates=20900, lr=0.000244558, gnorm=1.222, clip=0, loss_scale=2048, train_wall=99, wall=21950
2022-08-01 21:10:01 | INFO | train_inner | epoch 006:   2453 / 3715 loss=6.552, nll_loss=3.589, mask_ins=1.112, word_ins_ml=5.058, word_reposition=0.383, ppl=93.86, wps=14608.6, ups=0.99, wpb=14741.7, bsz=1024, num_updates=21000, lr=0.000243975, gnorm=1.147, clip=0, loss_scale=2048, train_wall=99, wall=22051
2022-08-01 21:11:42 | INFO | train_inner | epoch 006:   2553 / 3715 loss=6.564, nll_loss=3.603, mask_ins=1.111, word_ins_ml=5.07, word_reposition=0.383, ppl=94.59, wps=14378.4, ups=0.98, wpb=14634.5, bsz=1024, num_updates=21100, lr=0.000243396, gnorm=1.213, clip=0, loss_scale=2048, train_wall=100, wall=22152
2022-08-01 21:13:26 | INFO | train_inner | epoch 006:   2653 / 3715 loss=6.556, nll_loss=3.605, mask_ins=1.105, word_ins_ml=5.071, word_reposition=0.379, ppl=94.06, wps=14211.6, ups=0.97, wpb=14651.5, bsz=1024, num_updates=21200, lr=0.000242821, gnorm=1.136, clip=0, loss_scale=2048, train_wall=101, wall=22256
2022-08-01 21:14:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-01 21:15:09 | INFO | train_inner | epoch 006:   2754 / 3715 loss=6.537, nll_loss=3.584, mask_ins=1.106, word_ins_ml=5.053, word_reposition=0.377, ppl=92.83, wps=14026.8, ups=0.96, wpb=14573.2, bsz=1024, num_updates=21300, lr=0.000242251, gnorm=1.152, clip=0, loss_scale=2595, train_wall=102, wall=22359
2022-08-01 21:16:52 | INFO | train_inner | epoch 006:   2854 / 3715 loss=6.571, nll_loss=3.612, mask_ins=1.116, word_ins_ml=5.078, word_reposition=0.377, ppl=95.07, wps=14363.1, ups=0.98, wpb=14655, bsz=1024, num_updates=21400, lr=0.000241684, gnorm=1.18, clip=0, loss_scale=2048, train_wall=100, wall=22461
2022-08-01 21:18:33 | INFO | train_inner | epoch 006:   2954 / 3715 loss=6.55, nll_loss=3.603, mask_ins=1.106, word_ins_ml=5.07, word_reposition=0.374, ppl=93.7, wps=14394, ups=0.98, wpb=14648.3, bsz=1024, num_updates=21500, lr=0.000241121, gnorm=1.134, clip=0, loss_scale=2048, train_wall=100, wall=22563
2022-08-01 21:20:15 | INFO | train_inner | epoch 006:   3054 / 3715 loss=6.571, nll_loss=3.606, mask_ins=1.113, word_ins_ml=5.072, word_reposition=0.386, ppl=95.06, wps=14394.1, ups=0.98, wpb=14710.7, bsz=1024, num_updates=21600, lr=0.000240563, gnorm=1.159, clip=0, loss_scale=2048, train_wall=100, wall=22665
2022-08-01 21:21:57 | INFO | train_inner | epoch 006:   3154 / 3715 loss=6.553, nll_loss=3.586, mask_ins=1.115, word_ins_ml=5.054, word_reposition=0.384, ppl=93.92, wps=14351.2, ups=0.98, wpb=14624.5, bsz=1024, num_updates=21700, lr=0.000240008, gnorm=1.153, clip=0, loss_scale=2048, train_wall=100, wall=22767
2022-08-01 21:23:40 | INFO | train_inner | epoch 006:   3254 / 3715 loss=6.563, nll_loss=3.608, mask_ins=1.11, word_ins_ml=5.074, word_reposition=0.378, ppl=94.53, wps=14270.5, ups=0.98, wpb=14610.6, bsz=1024, num_updates=21800, lr=0.000239457, gnorm=1.134, clip=0, loss_scale=2580, train_wall=101, wall=22870
2022-08-01 21:25:22 | INFO | train_inner | epoch 006:   3354 / 3715 loss=6.546, nll_loss=3.595, mask_ins=1.11, word_ins_ml=5.062, word_reposition=0.374, ppl=93.47, wps=14248.9, ups=0.97, wpb=14620.4, bsz=1024, num_updates=21900, lr=0.000238909, gnorm=1.13, clip=0, loss_scale=4096, train_wall=101, wall=22972
2022-08-01 21:27:06 | INFO | train_inner | epoch 006:   3454 / 3715 loss=6.576, nll_loss=3.619, mask_ins=1.111, word_ins_ml=5.083, word_reposition=0.382, ppl=95.41, wps=14123.3, ups=0.96, wpb=14669.4, bsz=1024, num_updates=22000, lr=0.000238366, gnorm=1.17, clip=0, loss_scale=4096, train_wall=102, wall=23076
2022-08-01 21:28:49 | INFO | train_inner | epoch 006:   3554 / 3715 loss=6.538, nll_loss=3.58, mask_ins=1.109, word_ins_ml=5.049, word_reposition=0.38, ppl=92.89, wps=14372.5, ups=0.98, wpb=14720.7, bsz=1024, num_updates=22100, lr=0.000237826, gnorm=1.151, clip=0, loss_scale=4096, train_wall=101, wall=23179
2022-08-01 21:30:30 | INFO | train_inner | epoch 006:   3654 / 3715 loss=6.529, nll_loss=3.578, mask_ins=1.104, word_ins_ml=5.047, word_reposition=0.377, ppl=92.33, wps=14408.7, ups=0.98, wpb=14659.8, bsz=1024, num_updates=22200, lr=0.000237289, gnorm=1.167, clip=0, loss_scale=4096, train_wall=100, wall=23280
2022-08-01 21:31:32 | INFO | train | epoch 006 | loss 6.576 | nll_loss 3.614 | mask_ins 1.114 | word_ins_ml 5.08 | word_reposition 0.382 | ppl 95.41 | wps 14085.8 | ups 0.96 | wpb 14662 | bsz 1023.7 | num_updates 22261 | lr 0.000236964 | gnorm 1.201 | clip 0 | loss_scale 1464 | train_wall 3721 | wall 23342
2022-08-01 21:32:42 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.524 | nll_loss 3.46 | mask_ins 1.107 | word_ins_ml 5.015 | word_reposition 0.402 | ppl 92.03 | wps 39366.1 | wpb 1849.4 | bsz 127.9 | num_updates 22261 | best_loss 6.524
2022-08-01 21:32:49 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 6 @ 22261 updates, score 6.524) (writing took 6.701228655874729 seconds)
2022-08-01 21:33:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-01 21:33:30 | INFO | train_inner | epoch 007:     40 / 3715 loss=6.533, nll_loss=3.583, mask_ins=1.107, word_ins_ml=5.052, word_reposition=0.374, ppl=92.58, wps=8085.5, ups=0.56, wpb=14497.7, bsz=1014.7, num_updates=22300, lr=0.000236757, gnorm=1.222, clip=0, loss_scale=3589, train_wall=101, wall=23460
2022-08-01 21:34:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-01 21:35:14 | INFO | train_inner | epoch 007:    141 / 3715 loss=6.486, nll_loss=3.537, mask_ins=1.104, word_ins_ml=5.011, word_reposition=0.371, ppl=89.62, wps=14017.3, ups=0.96, wpb=14607.3, bsz=1024, num_updates=22400, lr=0.000236228, gnorm=1.238, clip=0, loss_scale=1845, train_wall=102, wall=23564
2022-08-01 21:36:57 | INFO | train_inner | epoch 007:    241 / 3715 loss=6.515, nll_loss=3.555, mask_ins=1.109, word_ins_ml=5.028, word_reposition=0.379, ppl=91.47, wps=14108.5, ups=0.97, wpb=14589.5, bsz=1024, num_updates=22500, lr=0.000235702, gnorm=1.202, clip=0, loss_scale=1024, train_wall=102, wall=23667
2022-08-01 21:38:40 | INFO | train_inner | epoch 007:    341 / 3715 loss=6.473, nll_loss=3.524, mask_ins=1.094, word_ins_ml=5, word_reposition=0.379, ppl=88.83, wps=14352.4, ups=0.97, wpb=14762.7, bsz=1024, num_updates=22600, lr=0.00023518, gnorm=1.122, clip=0, loss_scale=1024, train_wall=101, wall=23770
2022-08-01 21:40:22 | INFO | train_inner | epoch 007:    441 / 3715 loss=6.507, nll_loss=3.551, mask_ins=1.106, word_ins_ml=5.024, word_reposition=0.378, ppl=90.96, wps=14327, ups=0.98, wpb=14647.7, bsz=1024, num_updates=22700, lr=0.000234662, gnorm=1.181, clip=0, loss_scale=1024, train_wall=100, wall=23872
2022-08-01 21:42:01 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-08-01 21:42:06 | INFO | train_inner | epoch 007:    542 / 3715 loss=6.495, nll_loss=3.543, mask_ins=1.1, word_ins_ml=5.016, word_reposition=0.378, ppl=90.18, wps=14196.7, ups=0.97, wpb=14643.8, bsz=1024, num_updates=22800, lr=0.000234146, gnorm=1.144, clip=0, loss_scale=999, train_wall=101, wall=23976
2022-08-01 21:43:48 | INFO | train_inner | epoch 007:    642 / 3715 loss=6.481, nll_loss=3.519, mask_ins=1.104, word_ins_ml=4.995, word_reposition=0.382, ppl=89.32, wps=14357.9, ups=0.98, wpb=14676.6, bsz=1024, num_updates=22900, lr=0.000233635, gnorm=1.143, clip=0, loss_scale=512, train_wall=100, wall=24078
2022-08-01 21:45:30 | INFO | train_inner | epoch 007:    742 / 3715 loss=6.493, nll_loss=3.543, mask_ins=1.1, word_ins_ml=5.016, word_reposition=0.376, ppl=90.07, wps=14315.3, ups=0.98, wpb=14645.9, bsz=1024, num_updates=23000, lr=0.000233126, gnorm=1.127, clip=0, loss_scale=512, train_wall=101, wall=24180
2022-08-01 21:47:12 | INFO | train_inner | epoch 007:    842 / 3715 loss=6.513, nll_loss=3.561, mask_ins=1.103, word_ins_ml=5.032, word_reposition=0.377, ppl=91.3, wps=14457.7, ups=0.99, wpb=14668.8, bsz=1024, num_updates=23100, lr=0.000232621, gnorm=1.372, clip=0, loss_scale=512, train_wall=100, wall=24282
2022-08-01 21:47:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-01 21:48:55 | INFO | train_inner | epoch 007:    943 / 3715 loss=6.489, nll_loss=3.545, mask_ins=1.098, word_ins_ml=5.018, word_reposition=0.373, ppl=89.81, wps=14194.4, ups=0.97, wpb=14658.7, bsz=1024, num_updates=23200, lr=0.000232119, gnorm=1.149, clip=0, loss_scale=345, train_wall=101, wall=24385
2022-08-01 21:50:37 | INFO | train_inner | epoch 007:   1043 / 3715 loss=6.512, nll_loss=3.554, mask_ins=1.104, word_ins_ml=5.025, word_reposition=0.383, ppl=91.29, wps=14423.4, ups=0.98, wpb=14664.2, bsz=1024, num_updates=23300, lr=0.000231621, gnorm=1.132, clip=0, loss_scale=256, train_wall=100, wall=24486
2022-08-01 21:52:19 | INFO | train_inner | epoch 007:   1143 / 3715 loss=6.496, nll_loss=3.546, mask_ins=1.1, word_ins_ml=5.018, word_reposition=0.378, ppl=90.27, wps=14526.4, ups=0.98, wpb=14826.5, bsz=1024, num_updates=23400, lr=0.000231125, gnorm=1.11, clip=0, loss_scale=256, train_wall=100, wall=24589
2022-08-01 21:54:00 | INFO | train_inner | epoch 007:   1243 / 3715 loss=6.493, nll_loss=3.546, mask_ins=1.098, word_ins_ml=5.019, word_reposition=0.376, ppl=90.07, wps=14419.4, ups=0.98, wpb=14673.4, bsz=1024, num_updates=23500, lr=0.000230633, gnorm=1.128, clip=0, loss_scale=256, train_wall=100, wall=24690
2022-08-01 21:55:42 | INFO | train_inner | epoch 007:   1343 / 3715 loss=6.471, nll_loss=3.529, mask_ins=1.093, word_ins_ml=5.004, word_reposition=0.374, ppl=88.72, wps=14493.2, ups=0.99, wpb=14704.6, bsz=1024, num_updates=23600, lr=0.000230144, gnorm=1.142, clip=0, loss_scale=256, train_wall=100, wall=24792
2022-08-01 21:57:23 | INFO | train_inner | epoch 007:   1443 / 3715 loss=6.484, nll_loss=3.537, mask_ins=1.093, word_ins_ml=5.01, word_reposition=0.381, ppl=89.52, wps=14571.1, ups=0.99, wpb=14751.9, bsz=1024, num_updates=23700, lr=0.000229658, gnorm=1.144, clip=0, loss_scale=394, train_wall=99, wall=24893
2022-08-01 21:59:05 | INFO | train_inner | epoch 007:   1543 / 3715 loss=6.467, nll_loss=3.528, mask_ins=1.092, word_ins_ml=5.002, word_reposition=0.373, ppl=88.48, wps=14389.2, ups=0.98, wpb=14647.7, bsz=1024, num_updates=23800, lr=0.000229175, gnorm=1.116, clip=0, loss_scale=512, train_wall=100, wall=24995
2022-08-01 22:00:46 | INFO | train_inner | epoch 007:   1643 / 3715 loss=6.481, nll_loss=3.535, mask_ins=1.094, word_ins_ml=5.009, word_reposition=0.378, ppl=89.34, wps=14469.2, ups=0.99, wpb=14647, bsz=1024, num_updates=23900, lr=0.000228695, gnorm=1.132, clip=0, loss_scale=512, train_wall=99, wall=25096
2022-08-01 22:02:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-01 22:02:29 | INFO | train_inner | epoch 007:   1744 / 3715 loss=6.481, nll_loss=3.54, mask_ins=1.091, word_ins_ml=5.013, word_reposition=0.377, ppl=89.35, wps=14238.3, ups=0.97, wpb=14637.1, bsz=1024, num_updates=24000, lr=0.000228218, gnorm=1.116, clip=0, loss_scale=477, train_wall=101, wall=25199
2022-08-01 22:04:10 | INFO | train_inner | epoch 007:   1844 / 3715 loss=6.49, nll_loss=3.541, mask_ins=1.104, word_ins_ml=5.014, word_reposition=0.371, ppl=89.87, wps=14400.9, ups=0.99, wpb=14586.7, bsz=1024, num_updates=24100, lr=0.000227744, gnorm=1.129, clip=0, loss_scale=256, train_wall=100, wall=25300
2022-08-01 22:05:52 | INFO | train_inner | epoch 007:   1944 / 3715 loss=6.505, nll_loss=3.553, mask_ins=1.101, word_ins_ml=5.024, word_reposition=0.38, ppl=90.83, wps=14329.1, ups=0.98, wpb=14600, bsz=1024, num_updates=24200, lr=0.000227273, gnorm=1.225, clip=0, loss_scale=256, train_wall=100, wall=25402
2022-08-01 22:07:35 | INFO | train_inner | epoch 007:   2044 / 3715 loss=6.479, nll_loss=3.527, mask_ins=1.091, word_ins_ml=5.001, word_reposition=0.387, ppl=89.22, wps=14301.4, ups=0.97, wpb=14686.9, bsz=1024, num_updates=24300, lr=0.000226805, gnorm=1.17, clip=0, loss_scale=256, train_wall=101, wall=25505
2022-08-01 22:09:17 | INFO | train_inner | epoch 007:   2144 / 3715 loss=6.458, nll_loss=3.521, mask_ins=1.091, word_ins_ml=4.996, word_reposition=0.371, ppl=87.93, wps=14219.1, ups=0.98, wpb=14555.8, bsz=1023.8, num_updates=24400, lr=0.000226339, gnorm=1.128, clip=0, loss_scale=256, train_wall=101, wall=25607
2022-08-01 22:11:00 | INFO | train_inner | epoch 007:   2244 / 3715 loss=6.486, nll_loss=3.538, mask_ins=1.101, word_ins_ml=5.011, word_reposition=0.375, ppl=89.65, wps=14285.9, ups=0.97, wpb=14699.2, bsz=1024, num_updates=24500, lr=0.000225877, gnorm=1.128, clip=0, loss_scale=261, train_wall=101, wall=25710
2022-08-01 22:12:43 | INFO | train_inner | epoch 007:   2344 / 3715 loss=6.487, nll_loss=3.539, mask_ins=1.094, word_ins_ml=5.012, word_reposition=0.382, ppl=89.72, wps=14333.2, ups=0.97, wpb=14722, bsz=1024, num_updates=24600, lr=0.000225417, gnorm=1.149, clip=0, loss_scale=512, train_wall=101, wall=25813
2022-08-01 22:14:25 | INFO | train_inner | epoch 007:   2444 / 3715 loss=6.489, nll_loss=3.542, mask_ins=1.096, word_ins_ml=5.015, word_reposition=0.379, ppl=89.84, wps=14344.6, ups=0.98, wpb=14695.4, bsz=1024, num_updates=24700, lr=0.000224961, gnorm=1.128, clip=0, loss_scale=512, train_wall=101, wall=25915
2022-08-01 22:16:08 | INFO | train_inner | epoch 007:   2544 / 3715 loss=6.471, nll_loss=3.526, mask_ins=1.093, word_ins_ml=5, word_reposition=0.377, ppl=88.68, wps=14349.7, ups=0.98, wpb=14701.6, bsz=1024, num_updates=24800, lr=0.000224507, gnorm=1.135, clip=0, loss_scale=512, train_wall=101, wall=26018
2022-08-01 22:17:50 | INFO | train_inner | epoch 007:   2644 / 3715 loss=6.464, nll_loss=3.536, mask_ins=1.091, word_ins_ml=5.009, word_reposition=0.364, ppl=88.29, wps=14220.8, ups=0.98, wpb=14578.2, bsz=1024, num_updates=24900, lr=0.000224055, gnorm=1.153, clip=0, loss_scale=512, train_wall=101, wall=26120
2022-08-01 22:19:33 | INFO | train_inner | epoch 007:   2744 / 3715 loss=6.469, nll_loss=3.524, mask_ins=1.093, word_ins_ml=4.999, word_reposition=0.376, ppl=88.56, wps=14333.9, ups=0.98, wpb=14687.9, bsz=1024, num_updates=25000, lr=0.000223607, gnorm=1.154, clip=0, loss_scale=512, train_wall=101, wall=26223
2022-08-01 22:21:14 | INFO | train_inner | epoch 007:   2844 / 3715 loss=6.451, nll_loss=3.507, mask_ins=1.09, word_ins_ml=4.983, word_reposition=0.378, ppl=87.48, wps=14527.7, ups=0.98, wpb=14767.1, bsz=1024, num_updates=25100, lr=0.000223161, gnorm=1.108, clip=0, loss_scale=973, train_wall=100, wall=26324
2022-08-01 22:22:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-08-01 22:22:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-01 22:22:58 | INFO | train_inner | epoch 007:   2946 / 3715 loss=6.507, nll_loss=3.567, mask_ins=1.104, word_ins_ml=5.037, word_reposition=0.366, ppl=90.93, wps=14134.1, ups=0.96, wpb=14659.6, bsz=1024, num_updates=25200, lr=0.000222718, gnorm=2.039, clip=0, loss_scale=705, train_wall=102, wall=26428
2022-08-01 22:24:39 | INFO | train_inner | epoch 007:   3046 / 3715 loss=6.451, nll_loss=3.51, mask_ins=1.092, word_ins_ml=4.986, word_reposition=0.373, ppl=87.48, wps=14468.3, ups=0.99, wpb=14636.9, bsz=1024, num_updates=25300, lr=0.000222277, gnorm=1.141, clip=0, loss_scale=256, train_wall=99, wall=26529
2022-08-01 22:26:20 | INFO | train_inner | epoch 007:   3146 / 3715 loss=6.464, nll_loss=3.523, mask_ins=1.095, word_ins_ml=4.997, word_reposition=0.372, ppl=88.26, wps=14458, ups=0.99, wpb=14598.2, bsz=1024, num_updates=25400, lr=0.000221839, gnorm=1.92, clip=0, loss_scale=256, train_wall=99, wall=26630
2022-08-01 22:28:01 | INFO | train_inner | epoch 007:   3246 / 3715 loss=6.437, nll_loss=3.509, mask_ins=1.085, word_ins_ml=4.985, word_reposition=0.367, ppl=86.62, wps=14526.2, ups=0.99, wpb=14681.3, bsz=1024, num_updates=25500, lr=0.000221404, gnorm=1.16, clip=0, loss_scale=256, train_wall=99, wall=26731
2022-08-01 22:29:42 | INFO | train_inner | epoch 007:   3346 / 3715 loss=6.434, nll_loss=3.498, mask_ins=1.086, word_ins_ml=4.975, word_reposition=0.373, ppl=86.44, wps=14501.2, ups=0.99, wpb=14652.8, bsz=1024, num_updates=25600, lr=0.000220971, gnorm=1.114, clip=0, loss_scale=256, train_wall=99, wall=26832
2022-08-01 22:31:24 | INFO | train_inner | epoch 007:   3446 / 3715 loss=6.464, nll_loss=3.531, mask_ins=1.09, word_ins_ml=5.004, word_reposition=0.371, ppl=88.3, wps=14475.8, ups=0.98, wpb=14701.9, bsz=1024, num_updates=25700, lr=0.000220541, gnorm=1.491, clip=1, loss_scale=289, train_wall=100, wall=26934
2022-08-01 22:32:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-01 22:33:07 | INFO | train_inner | epoch 007:   3547 / 3715 loss=6.468, nll_loss=3.53, mask_ins=1.094, word_ins_ml=5.003, word_reposition=0.37, ppl=88.49, wps=14235.6, ups=0.97, wpb=14647.7, bsz=1024, num_updates=25800, lr=0.000220113, gnorm=2.002, clip=1, loss_scale=426, train_wall=101, wall=27037
2022-08-01 22:33:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-08-01 22:34:49 | INFO | train_inner | epoch 007:   3648 / 3715 loss=6.519, nll_loss=3.57, mask_ins=1.106, word_ins_ml=5.039, word_reposition=0.374, ppl=91.73, wps=14370.9, ups=0.98, wpb=14704.7, bsz=1024, num_updates=25900, lr=0.000219687, gnorm=1.64, clip=0, loss_scale=138, train_wall=101, wall=27139
2022-08-01 22:35:56 | INFO | train | epoch 007 | loss 6.482 | nll_loss 3.536 | mask_ins 1.097 | word_ins_ml 5.01 | word_reposition 0.375 | ppl 89.38 | wps 14063.5 | ups 0.96 | wpb 14662.2 | bsz 1023.7 | num_updates 25967 | lr 0.000219404 | gnorm 1.25 | clip 0.1 | loss_scale 522 | train_wall 3722 | wall 27206
2022-08-01 22:37:06 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.467 | nll_loss 3.414 | mask_ins 1.094 | word_ins_ml 4.976 | word_reposition 0.397 | ppl 88.44 | wps 39408.7 | wpb 1849.4 | bsz 127.9 | num_updates 25967 | best_loss 6.467
2022-08-01 22:37:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 7 @ 25967 updates, score 6.467) (writing took 7.069457737728953 seconds)
2022-08-01 22:37:46 | INFO | train_inner | epoch 008:     33 / 3715 loss=6.466, nll_loss=3.53, mask_ins=1.094, word_ins_ml=5.003, word_reposition=0.368, ppl=88.4, wps=8161.8, ups=0.56, wpb=14465.6, bsz=1014.7, num_updates=26000, lr=0.000219265, gnorm=1.532, clip=0, loss_scale=128, train_wall=99, wall=27316
2022-08-01 22:39:29 | INFO | train_inner | epoch 008:    133 / 3715 loss=6.411, nll_loss=3.476, mask_ins=1.086, word_ins_ml=4.957, word_reposition=0.369, ppl=85.1, wps=14407.1, ups=0.98, wpb=14750.8, bsz=1024, num_updates=26100, lr=0.000218844, gnorm=2.545, clip=1, loss_scale=128, train_wall=101, wall=27419
2022-08-01 22:41:10 | INFO | train_inner | epoch 008:    233 / 3715 loss=6.393, nll_loss=3.463, mask_ins=1.08, word_ins_ml=4.944, word_reposition=0.368, ppl=84.02, wps=14485.4, ups=0.98, wpb=14754, bsz=1024, num_updates=26200, lr=0.000218426, gnorm=1.195, clip=0, loss_scale=128, train_wall=100, wall=27520
2022-08-01 22:42:00 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2022-08-01 22:42:53 | INFO | train_inner | epoch 008:    334 / 3715 loss=6.479, nll_loss=3.539, mask_ins=1.094, word_ins_ml=5.012, word_reposition=0.373, ppl=89.2, wps=14266.9, ups=0.97, wpb=14647.1, bsz=1024, num_updates=26300, lr=0.00021801, gnorm=3.932, clip=4, loss_scale=94, train_wall=101, wall=27623
2022-08-01 22:44:36 | INFO | train_inner | epoch 008:    434 / 3715 loss=6.412, nll_loss=3.484, mask_ins=1.082, word_ins_ml=4.963, word_reposition=0.367, ppl=85.13, wps=14193.5, ups=0.97, wpb=14658, bsz=1024, num_updates=26400, lr=0.000217597, gnorm=1.466, clip=0, loss_scale=64, train_wall=102, wall=27726
2022-08-01 22:46:19 | INFO | train_inner | epoch 008:    534 / 3715 loss=6.404, nll_loss=3.468, mask_ins=1.087, word_ins_ml=4.949, word_reposition=0.368, ppl=84.66, wps=14265.6, ups=0.97, wpb=14650.6, bsz=1024, num_updates=26500, lr=0.000217186, gnorm=1.338, clip=0, loss_scale=64, train_wall=101, wall=27829
2022-08-01 22:48:02 | INFO | train_inner | epoch 008:    634 / 3715 loss=6.416, nll_loss=3.486, mask_ins=1.086, word_ins_ml=4.964, word_reposition=0.366, ppl=85.4, wps=14184.1, ups=0.97, wpb=14567.4, bsz=1024, num_updates=26600, lr=0.000216777, gnorm=1.183, clip=0, loss_scale=64, train_wall=101, wall=27932
2022-08-01 22:49:44 | INFO | train_inner | epoch 008:    734 / 3715 loss=6.413, nll_loss=3.474, mask_ins=1.088, word_ins_ml=4.954, word_reposition=0.37, ppl=85.18, wps=14285.5, ups=0.98, wpb=14628, bsz=1024, num_updates=26700, lr=0.000216371, gnorm=1.17, clip=0, loss_scale=64, train_wall=101, wall=28034
2022-08-01 22:51:26 | INFO | train_inner | epoch 008:    834 / 3715 loss=6.411, nll_loss=3.472, mask_ins=1.086, word_ins_ml=4.952, word_reposition=0.373, ppl=85.11, wps=14428.4, ups=0.99, wpb=14639.1, bsz=1024, num_updates=26800, lr=0.000215967, gnorm=1.157, clip=0, loss_scale=91, train_wall=100, wall=28136
2022-08-01 22:53:07 | INFO | train_inner | epoch 008:    934 / 3715 loss=6.416, nll_loss=3.474, mask_ins=1.092, word_ins_ml=4.954, word_reposition=0.371, ppl=85.4, wps=14524.2, ups=0.99, wpb=14653.9, bsz=1024, num_updates=26900, lr=0.000215565, gnorm=1.182, clip=0, loss_scale=128, train_wall=99, wall=28237
2022-08-01 22:54:48 | INFO | train_inner | epoch 008:   1034 / 3715 loss=6.415, nll_loss=3.479, mask_ins=1.087, word_ins_ml=4.958, word_reposition=0.37, ppl=85.35, wps=14443.4, ups=0.99, wpb=14647.5, bsz=1024, num_updates=27000, lr=0.000215166, gnorm=1.177, clip=0, loss_scale=128, train_wall=100, wall=28338
2022-08-01 22:56:29 | INFO | train_inner | epoch 008:   1134 / 3715 loss=6.403, nll_loss=3.471, mask_ins=1.084, word_ins_ml=4.951, word_reposition=0.368, ppl=84.63, wps=14406.5, ups=0.99, wpb=14584.7, bsz=1024, num_updates=27100, lr=0.000214768, gnorm=1.183, clip=0, loss_scale=128, train_wall=99, wall=28439
2022-08-01 22:58:10 | INFO | train_inner | epoch 008:   1234 / 3715 loss=6.398, nll_loss=3.469, mask_ins=1.082, word_ins_ml=4.949, word_reposition=0.367, ppl=84.33, wps=14537.2, ups=0.99, wpb=14665.9, bsz=1024, num_updates=27200, lr=0.000214373, gnorm=1.147, clip=0, loss_scale=128, train_wall=99, wall=28540
2022-08-01 22:59:52 | INFO | train_inner | epoch 008:   1334 / 3715 loss=6.413, nll_loss=3.479, mask_ins=1.085, word_ins_ml=4.959, word_reposition=0.369, ppl=85.2, wps=14378.5, ups=0.98, wpb=14629.1, bsz=1024, num_updates=27300, lr=0.00021398, gnorm=1.317, clip=0, loss_scale=166, train_wall=100, wall=28642
2022-08-01 23:01:33 | INFO | train_inner | epoch 008:   1434 / 3715 loss=6.388, nll_loss=3.453, mask_ins=1.082, word_ins_ml=4.935, word_reposition=0.371, ppl=83.78, wps=14519.3, ups=0.99, wpb=14705.2, bsz=1024, num_updates=27400, lr=0.000213589, gnorm=1.208, clip=0, loss_scale=256, train_wall=100, wall=28743
2022-08-01 23:03:15 | INFO | train_inner | epoch 008:   1534 / 3715 loss=6.414, nll_loss=3.471, mask_ins=1.087, word_ins_ml=4.951, word_reposition=0.376, ppl=85.25, wps=14486.3, ups=0.99, wpb=14685.5, bsz=1024, num_updates=27500, lr=0.000213201, gnorm=1.168, clip=0, loss_scale=256, train_wall=100, wall=28844
2022-08-01 23:04:56 | INFO | train_inner | epoch 008:   1634 / 3715 loss=6.413, nll_loss=3.484, mask_ins=1.083, word_ins_ml=4.962, word_reposition=0.368, ppl=85.21, wps=14605.1, ups=0.99, wpb=14752.8, bsz=1024, num_updates=27600, lr=0.000212814, gnorm=1.117, clip=0, loss_scale=256, train_wall=99, wall=28945
2022-08-01 23:06:37 | INFO | train_inner | epoch 008:   1734 / 3715 loss=6.389, nll_loss=3.46, mask_ins=1.077, word_ins_ml=4.941, word_reposition=0.37, ppl=83.78, wps=14498.3, ups=0.98, wpb=14743.6, bsz=1024, num_updates=27700, lr=0.00021243, gnorm=1.125, clip=0, loss_scale=256, train_wall=100, wall=29047
2022-08-01 23:08:19 | INFO | train_inner | epoch 008:   1834 / 3715 loss=6.416, nll_loss=3.482, mask_ins=1.087, word_ins_ml=4.96, word_reposition=0.369, ppl=85.38, wps=14395.7, ups=0.99, wpb=14581.8, bsz=1024, num_updates=27800, lr=0.000212047, gnorm=1.144, clip=0, loss_scale=302, train_wall=100, wall=29148
2022-08-01 23:10:00 | INFO | train_inner | epoch 008:   1934 / 3715 loss=6.398, nll_loss=3.472, mask_ins=1.078, word_ins_ml=4.952, word_reposition=0.369, ppl=84.36, wps=14485, ups=0.99, wpb=14656.8, bsz=1024, num_updates=27900, lr=0.000211667, gnorm=1.113, clip=0, loss_scale=512, train_wall=99, wall=29250
2022-08-01 23:11:43 | INFO | train_inner | epoch 008:   2034 / 3715 loss=6.436, nll_loss=3.498, mask_ins=1.091, word_ins_ml=4.974, word_reposition=0.371, ppl=86.57, wps=14161.2, ups=0.97, wpb=14628.8, bsz=1024, num_updates=28000, lr=0.000211289, gnorm=1.145, clip=0, loss_scale=512, train_wall=102, wall=29353
2022-08-01 23:13:26 | INFO | train_inner | epoch 008:   2134 / 3715 loss=6.4, nll_loss=3.47, mask_ins=1.083, word_ins_ml=4.95, word_reposition=0.367, ppl=84.47, wps=14237.6, ups=0.97, wpb=14635.4, bsz=1024, num_updates=28100, lr=0.000210912, gnorm=1.131, clip=0, loss_scale=512, train_wall=101, wall=29456
2022-08-01 23:15:07 | INFO | train_inner | epoch 008:   2234 / 3715 loss=6.385, nll_loss=3.467, mask_ins=1.077, word_ins_ml=4.947, word_reposition=0.361, ppl=83.59, wps=14469.5, ups=0.99, wpb=14615.8, bsz=1024, num_updates=28200, lr=0.000210538, gnorm=1.14, clip=0, loss_scale=512, train_wall=99, wall=29557
2022-08-01 23:16:48 | INFO | train_inner | epoch 008:   2334 / 3715 loss=6.421, nll_loss=3.486, mask_ins=1.082, word_ins_ml=4.963, word_reposition=0.376, ppl=85.67, wps=14449.2, ups=0.98, wpb=14680.2, bsz=1024, num_updates=28300, lr=0.000210166, gnorm=1.273, clip=0, loss_scale=543, train_wall=100, wall=29658
2022-08-01 23:18:30 | INFO | train_inner | epoch 008:   2434 / 3715 loss=6.371, nll_loss=3.445, mask_ins=1.08, word_ins_ml=4.927, word_reposition=0.363, ppl=82.77, wps=14452.5, ups=0.99, wpb=14660.5, bsz=1024, num_updates=28400, lr=0.000209795, gnorm=1.147, clip=0, loss_scale=1024, train_wall=100, wall=29760
2022-08-01 23:20:11 | INFO | train_inner | epoch 008:   2534 / 3715 loss=6.377, nll_loss=3.452, mask_ins=1.077, word_ins_ml=4.933, word_reposition=0.367, ppl=83.13, wps=14482.9, ups=0.99, wpb=14665.7, bsz=1024, num_updates=28500, lr=0.000209427, gnorm=1.116, clip=0, loss_scale=1024, train_wall=99, wall=29861
2022-08-01 23:21:52 | INFO | train_inner | epoch 008:   2634 / 3715 loss=6.392, nll_loss=3.467, mask_ins=1.077, word_ins_ml=4.947, word_reposition=0.369, ppl=84.01, wps=14528.2, ups=0.99, wpb=14715.5, bsz=1024, num_updates=28600, lr=0.000209061, gnorm=1.192, clip=0, loss_scale=1024, train_wall=100, wall=29962
2022-08-01 23:23:34 | INFO | train_inner | epoch 008:   2734 / 3715 loss=6.396, nll_loss=3.458, mask_ins=1.091, word_ins_ml=4.939, word_reposition=0.367, ppl=84.24, wps=14411, ups=0.98, wpb=14694.5, bsz=1024, num_updates=28700, lr=0.000208696, gnorm=1.155, clip=0, loss_scale=1024, train_wall=100, wall=30064
2022-08-01 23:25:16 | INFO | train_inner | epoch 008:   2834 / 3715 loss=6.393, nll_loss=3.456, mask_ins=1.083, word_ins_ml=4.937, word_reposition=0.373, ppl=84.02, wps=14507.5, ups=0.98, wpb=14796.7, bsz=1024, num_updates=28800, lr=0.000208333, gnorm=1.114, clip=0, loss_scale=1024, train_wall=100, wall=30166
2022-08-01 23:26:58 | INFO | train_inner | epoch 008:   2934 / 3715 loss=6.403, nll_loss=3.47, mask_ins=1.084, word_ins_ml=4.95, word_reposition=0.369, ppl=84.6, wps=14397.4, ups=0.98, wpb=14624.8, bsz=1024, num_updates=28900, lr=0.000207973, gnorm=1.176, clip=0, loss_scale=1987, train_wall=100, wall=30268
2022-08-01 23:27:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-01 23:28:41 | INFO | train_inner | epoch 008:   3035 / 3715 loss=6.415, nll_loss=3.48, mask_ins=1.084, word_ins_ml=4.958, word_reposition=0.373, ppl=85.31, wps=14362.9, ups=0.97, wpb=14799.9, bsz=1024, num_updates=29000, lr=0.000207614, gnorm=1.179, clip=0, loss_scale=1196, train_wall=101, wall=30371
2022-08-01 23:30:22 | INFO | train_inner | epoch 008:   3135 / 3715 loss=6.405, nll_loss=3.478, mask_ins=1.081, word_ins_ml=4.956, word_reposition=0.369, ppl=84.77, wps=14475.6, ups=0.99, wpb=14640.6, bsz=1024, num_updates=29100, lr=0.000207257, gnorm=1.124, clip=0, loss_scale=1024, train_wall=99, wall=30472
2022-08-01 23:30:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-08-01 23:32:05 | INFO | train_inner | epoch 008:   3236 / 3715 loss=6.367, nll_loss=3.447, mask_ins=1.078, word_ins_ml=4.929, word_reposition=0.36, ppl=82.54, wps=14318.7, ups=0.98, wpb=14665.6, bsz=1024, num_updates=29200, lr=0.000206901, gnorm=1.141, clip=0, loss_scale=618, train_wall=101, wall=30575
2022-08-01 23:33:46 | INFO | train_inner | epoch 008:   3336 / 3715 loss=6.397, nll_loss=3.463, mask_ins=1.083, word_ins_ml=4.943, word_reposition=0.371, ppl=84.26, wps=14400.9, ups=0.99, wpb=14595, bsz=1024, num_updates=29300, lr=0.000206548, gnorm=1.113, clip=0, loss_scale=512, train_wall=100, wall=30676
2022-08-01 23:35:27 | INFO | train_inner | epoch 008:   3436 / 3715 loss=6.407, nll_loss=3.485, mask_ins=1.079, word_ins_ml=4.962, word_reposition=0.366, ppl=84.86, wps=14426.1, ups=0.99, wpb=14639.9, bsz=1024, num_updates=29400, lr=0.000206197, gnorm=1.127, clip=0, loss_scale=512, train_wall=100, wall=30777
2022-08-01 23:37:09 | INFO | train_inner | epoch 008:   3536 / 3715 loss=6.403, nll_loss=3.478, mask_ins=1.078, word_ins_ml=4.956, word_reposition=0.368, ppl=84.61, wps=14470.1, ups=0.98, wpb=14714.3, bsz=1024, num_updates=29500, lr=0.000205847, gnorm=1.164, clip=0, loss_scale=512, train_wall=100, wall=30879
2022-08-01 23:38:51 | INFO | train_inner | epoch 008:   3636 / 3715 loss=6.358, nll_loss=3.438, mask_ins=1.074, word_ins_ml=4.921, word_reposition=0.363, ppl=82.02, wps=14324.3, ups=0.98, wpb=14610.9, bsz=1023.8, num_updates=29600, lr=0.000205499, gnorm=1.127, clip=0, loss_scale=512, train_wall=100, wall=30981
2022-08-01 23:40:11 | INFO | train | epoch 008 | loss 6.403 | nll_loss 3.472 | mask_ins 1.083 | word_ins_ml 4.952 | word_reposition 0.369 | ppl 84.65 | wps 14120.6 | ups 0.96 | wpb 14662.8 | bsz 1023.7 | num_updates 29679 | lr 0.000205225 | gnorm 1.289 | clip 0.1 | loss_scale 484 | train_wall 3712 | wall 31061
2022-08-01 23:41:20 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 6.406 | nll_loss 3.374 | mask_ins 1.088 | word_ins_ml 4.937 | word_reposition 0.381 | ppl 84.8 | wps 39290.1 | wpb 1849.4 | bsz 127.9 | num_updates 29679 | best_loss 6.406
2022-08-01 23:41:27 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 8 @ 29679 updates, score 6.406) (writing took 6.8808901235461235 seconds)
2022-08-01 23:41:49 | INFO | train_inner | epoch 009:     21 / 3715 loss=6.378, nll_loss=3.448, mask_ins=1.079, word_ins_ml=4.93, word_reposition=0.369, ppl=83.17, wps=8230.9, ups=0.56, wpb=14622.8, bsz=1014.7, num_updates=29700, lr=0.000205152, gnorm=1.141, clip=0, loss_scale=860, train_wall=99, wall=31159
2022-08-01 23:43:30 | INFO | train_inner | epoch 009:    121 / 3715 loss=6.336, nll_loss=3.408, mask_ins=1.074, word_ins_ml=4.895, word_reposition=0.367, ppl=80.78, wps=14368.4, ups=0.99, wpb=14575.5, bsz=1024, num_updates=29800, lr=0.000204808, gnorm=1.109, clip=0, loss_scale=1024, train_wall=100, wall=31260
2022-08-01 23:45:12 | INFO | train_inner | epoch 009:    221 / 3715 loss=6.33, nll_loss=3.403, mask_ins=1.074, word_ins_ml=4.89, word_reposition=0.367, ppl=80.47, wps=14344.3, ups=0.99, wpb=14544.4, bsz=1023.8, num_updates=29900, lr=0.000204465, gnorm=1.133, clip=0, loss_scale=1024, train_wall=100, wall=31362
2022-08-01 23:46:53 | INFO | train_inner | epoch 009:    321 / 3715 loss=6.322, nll_loss=3.403, mask_ins=1.067, word_ins_ml=4.891, word_reposition=0.364, ppl=80, wps=14451.3, ups=0.99, wpb=14645.6, bsz=1024, num_updates=30000, lr=0.000204124, gnorm=1.123, clip=0, loss_scale=1024, train_wall=100, wall=31463
2022-08-01 23:48:34 | INFO | train_inner | epoch 009:    421 / 3715 loss=6.35, nll_loss=3.424, mask_ins=1.072, word_ins_ml=4.908, word_reposition=0.37, ppl=81.59, wps=14526.6, ups=0.99, wpb=14725.1, bsz=1024, num_updates=30100, lr=0.000203785, gnorm=1.134, clip=0, loss_scale=1024, train_wall=100, wall=31564
2022-08-01 23:50:16 | INFO | train_inner | epoch 009:    521 / 3715 loss=6.339, nll_loss=3.418, mask_ins=1.071, word_ins_ml=4.903, word_reposition=0.364, ppl=80.94, wps=14582, ups=0.98, wpb=14804.3, bsz=1024, num_updates=30200, lr=0.000203447, gnorm=1.12, clip=0, loss_scale=1597, train_wall=100, wall=31666
2022-08-01 23:51:57 | INFO | train_inner | epoch 009:    621 / 3715 loss=6.335, nll_loss=3.41, mask_ins=1.076, word_ins_ml=4.896, word_reposition=0.363, ppl=80.71, wps=14554.3, ups=0.99, wpb=14759, bsz=1024, num_updates=30300, lr=0.000203111, gnorm=1.14, clip=0, loss_scale=2048, train_wall=100, wall=31767
2022-08-01 23:53:38 | INFO | train_inner | epoch 009:    721 / 3715 loss=6.329, nll_loss=3.406, mask_ins=1.072, word_ins_ml=4.892, word_reposition=0.364, ppl=80.41, wps=14323.4, ups=0.99, wpb=14494.1, bsz=1024, num_updates=30400, lr=0.000202777, gnorm=1.182, clip=0, loss_scale=2048, train_wall=99, wall=31868
2022-08-01 23:55:20 | INFO | train_inner | epoch 009:    821 / 3715 loss=6.347, nll_loss=3.416, mask_ins=1.073, word_ins_ml=4.902, word_reposition=0.373, ppl=81.42, wps=14428.5, ups=0.99, wpb=14620.2, bsz=1024, num_updates=30500, lr=0.000202444, gnorm=1.132, clip=0, loss_scale=2048, train_wall=100, wall=31970
2022-08-01 23:57:01 | INFO | train_inner | epoch 009:    921 / 3715 loss=6.317, nll_loss=3.394, mask_ins=1.069, word_ins_ml=4.882, word_reposition=0.366, ppl=79.71, wps=14498.4, ups=0.99, wpb=14651.3, bsz=1024, num_updates=30600, lr=0.000202113, gnorm=1.122, clip=0, loss_scale=2048, train_wall=99, wall=32071
2022-08-01 23:58:42 | INFO | train_inner | epoch 009:   1021 / 3715 loss=6.331, nll_loss=3.414, mask_ins=1.071, word_ins_ml=4.899, word_reposition=0.36, ppl=80.51, wps=14596.8, ups=0.99, wpb=14765.6, bsz=1024, num_updates=30700, lr=0.000201784, gnorm=1.128, clip=0, loss_scale=2949, train_wall=99, wall=32172
2022-08-01 23:59:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-01 23:59:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 00:00:25 | INFO | train_inner | epoch 009:   1123 / 3715 loss=6.334, nll_loss=3.414, mask_ins=1.073, word_ins_ml=4.9, word_reposition=0.361, ppl=80.68, wps=14317.2, ups=0.97, wpb=14749.4, bsz=1024, num_updates=30800, lr=0.000201456, gnorm=1.153, clip=0, loss_scale=2500, train_wall=101, wall=32275
2022-08-02 00:02:07 | INFO | train_inner | epoch 009:   1223 / 3715 loss=6.324, nll_loss=3.406, mask_ins=1.063, word_ins_ml=4.893, word_reposition=0.368, ppl=80.11, wps=14394.2, ups=0.98, wpb=14613.9, bsz=1024, num_updates=30900, lr=0.000201129, gnorm=1.234, clip=0, loss_scale=1024, train_wall=100, wall=32376
2022-08-02 00:03:48 | INFO | train_inner | epoch 009:   1323 / 3715 loss=6.341, nll_loss=3.415, mask_ins=1.069, word_ins_ml=4.9, word_reposition=0.371, ppl=81.05, wps=14471.4, ups=0.98, wpb=14712, bsz=1024, num_updates=31000, lr=0.000200805, gnorm=1.116, clip=0, loss_scale=1024, train_wall=100, wall=32478
2022-08-02 00:05:30 | INFO | train_inner | epoch 009:   1423 / 3715 loss=6.357, nll_loss=3.416, mask_ins=1.076, word_ins_ml=4.901, word_reposition=0.38, ppl=81.98, wps=14296, ups=0.98, wpb=14588.5, bsz=1024, num_updates=31100, lr=0.000200482, gnorm=1.168, clip=0, loss_scale=1024, train_wall=100, wall=32580
2022-08-02 00:07:12 | INFO | train_inner | epoch 009:   1523 / 3715 loss=6.356, nll_loss=3.425, mask_ins=1.073, word_ins_ml=4.909, word_reposition=0.375, ppl=81.92, wps=14372.4, ups=0.98, wpb=14651.7, bsz=1024, num_updates=31200, lr=0.00020016, gnorm=1.135, clip=0, loss_scale=1024, train_wall=100, wall=32682
2022-08-02 00:08:54 | INFO | train_inner | epoch 009:   1623 / 3715 loss=6.352, nll_loss=3.434, mask_ins=1.077, word_ins_ml=4.917, word_reposition=0.359, ppl=81.69, wps=14284, ups=0.98, wpb=14574.9, bsz=1024, num_updates=31300, lr=0.00019984, gnorm=1.116, clip=0, loss_scale=1423, train_wall=100, wall=32784
2022-08-02 00:09:02 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 00:09:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-08-02 00:09:38 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-02 00:10:39 | INFO | train_inner | epoch 009:   1726 / 3715 loss=6.459, nll_loss=3.443, mask_ins=1.074, word_ins_ml=4.925, word_reposition=0.46, ppl=88, wps=14063.8, ups=0.95, wpb=14760.4, bsz=1024, num_updates=31400, lr=0.000199522, gnorm=1.873, clip=0, loss_scale=629, train_wall=103, wall=32889
2022-08-02 00:12:21 | INFO | train_inner | epoch 009:   1826 / 3715 loss=6.338, nll_loss=3.417, mask_ins=1.071, word_ins_ml=4.901, word_reposition=0.366, ppl=80.9, wps=14418, ups=0.98, wpb=14714.4, bsz=1024, num_updates=31500, lr=0.000199205, gnorm=1.223, clip=0, loss_scale=256, train_wall=100, wall=32991
2022-08-02 00:14:03 | INFO | train_inner | epoch 009:   1926 / 3715 loss=6.341, nll_loss=3.416, mask_ins=1.068, word_ins_ml=4.901, word_reposition=0.373, ppl=81.09, wps=14354.6, ups=0.98, wpb=14617.5, bsz=1024, num_updates=31600, lr=0.000198889, gnorm=1.628, clip=1, loss_scale=256, train_wall=100, wall=33093
2022-08-02 00:15:44 | INFO | train_inner | epoch 009:   2026 / 3715 loss=6.343, nll_loss=3.419, mask_ins=1.073, word_ins_ml=4.903, word_reposition=0.367, ppl=81.17, wps=14450.8, ups=0.99, wpb=14629, bsz=1024, num_updates=31700, lr=0.000198575, gnorm=1.126, clip=0, loss_scale=256, train_wall=99, wall=33194
2022-08-02 00:17:25 | INFO | train_inner | epoch 009:   2126 / 3715 loss=6.339, nll_loss=3.422, mask_ins=1.067, word_ins_ml=4.907, word_reposition=0.365, ppl=80.94, wps=14647.6, ups=0.99, wpb=14762.9, bsz=1024, num_updates=31800, lr=0.000198263, gnorm=1.117, clip=0, loss_scale=256, train_wall=99, wall=33295
2022-08-02 00:19:06 | INFO | train_inner | epoch 009:   2226 / 3715 loss=6.321, nll_loss=3.413, mask_ins=1.069, word_ins_ml=4.898, word_reposition=0.354, ppl=79.95, wps=14526.1, ups=0.99, wpb=14726.2, bsz=1024, num_updates=31900, lr=0.000197952, gnorm=1.111, clip=0, loss_scale=381, train_wall=100, wall=33396
2022-08-02 00:20:48 | INFO | train_inner | epoch 009:   2326 / 3715 loss=6.339, nll_loss=3.416, mask_ins=1.069, word_ins_ml=4.901, word_reposition=0.37, ppl=80.97, wps=14450.8, ups=0.99, wpb=14636.4, bsz=1024, num_updates=32000, lr=0.000197642, gnorm=1.135, clip=0, loss_scale=512, train_wall=100, wall=33498
2022-08-02 00:22:29 | INFO | train_inner | epoch 009:   2426 / 3715 loss=6.34, nll_loss=3.424, mask_ins=1.073, word_ins_ml=4.908, word_reposition=0.359, ppl=81.03, wps=14454.6, ups=0.99, wpb=14638.6, bsz=1024, num_updates=32100, lr=0.000197334, gnorm=1.149, clip=0, loss_scale=512, train_wall=100, wall=33599
2022-08-02 00:24:11 | INFO | train_inner | epoch 009:   2526 / 3715 loss=6.333, nll_loss=3.417, mask_ins=1.066, word_ins_ml=4.901, word_reposition=0.366, ppl=80.64, wps=14463, ups=0.98, wpb=14699.6, bsz=1024, num_updates=32200, lr=0.000197028, gnorm=1.177, clip=0, loss_scale=512, train_wall=100, wall=33701
2022-08-02 00:25:52 | INFO | train_inner | epoch 009:   2626 / 3715 loss=6.344, nll_loss=3.425, mask_ins=1.076, word_ins_ml=4.909, word_reposition=0.36, ppl=81.22, wps=14427.8, ups=0.99, wpb=14647, bsz=1024, num_updates=32300, lr=0.000196722, gnorm=1.23, clip=0, loss_scale=512, train_wall=100, wall=33802
2022-08-02 00:27:34 | INFO | train_inner | epoch 009:   2726 / 3715 loss=6.325, nll_loss=3.412, mask_ins=1.063, word_ins_ml=4.897, word_reposition=0.365, ppl=80.19, wps=14530.4, ups=0.99, wpb=14727.3, bsz=1024, num_updates=32400, lr=0.000196419, gnorm=1.138, clip=0, loss_scale=701, train_wall=100, wall=33903
2022-08-02 00:29:16 | INFO | train_inner | epoch 009:   2826 / 3715 loss=6.341, nll_loss=3.421, mask_ins=1.07, word_ins_ml=4.905, word_reposition=0.367, ppl=81.08, wps=14320.1, ups=0.97, wpb=14694, bsz=1024, num_updates=32500, lr=0.000196116, gnorm=1.198, clip=0, loss_scale=1024, train_wall=101, wall=34006
2022-08-02 00:30:59 | INFO | train_inner | epoch 009:   2926 / 3715 loss=6.332, nll_loss=3.412, mask_ins=1.065, word_ins_ml=4.897, word_reposition=0.37, ppl=80.57, wps=14292.9, ups=0.97, wpb=14695.4, bsz=1024, num_updates=32600, lr=0.000195815, gnorm=1.165, clip=0, loss_scale=1024, train_wall=101, wall=34109
2022-08-02 00:32:41 | INFO | train_inner | epoch 009:   3026 / 3715 loss=6.363, nll_loss=3.42, mask_ins=1.071, word_ins_ml=4.904, word_reposition=0.388, ppl=82.3, wps=14350.4, ups=0.98, wpb=14684.1, bsz=1024, num_updates=32700, lr=0.000195515, gnorm=1.734, clip=0, loss_scale=1024, train_wall=101, wall=34211
2022-08-02 00:34:24 | INFO | train_inner | epoch 009:   3126 / 3715 loss=6.344, nll_loss=3.41, mask_ins=1.076, word_ins_ml=4.896, word_reposition=0.372, ppl=81.23, wps=14229.1, ups=0.97, wpb=14606.9, bsz=1024, num_updates=32800, lr=0.000195217, gnorm=1.438, clip=0, loss_scale=1024, train_wall=101, wall=34314
2022-08-02 00:36:06 | INFO | train_inner | epoch 009:   3226 / 3715 loss=6.334, nll_loss=3.418, mask_ins=1.073, word_ins_ml=4.903, word_reposition=0.359, ppl=80.7, wps=14261.5, ups=0.98, wpb=14626.2, bsz=1024, num_updates=32900, lr=0.00019492, gnorm=1.172, clip=0, loss_scale=1280, train_wall=101, wall=34416
2022-08-02 00:37:49 | INFO | train_inner | epoch 009:   3326 / 3715 loss=6.327, nll_loss=3.404, mask_ins=1.07, word_ins_ml=4.89, word_reposition=0.367, ppl=80.29, wps=14388.1, ups=0.98, wpb=14745, bsz=1024, num_updates=33000, lr=0.000194625, gnorm=1.227, clip=0, loss_scale=2048, train_wall=101, wall=34519
2022-08-02 00:38:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 00:39:32 | INFO | train_inner | epoch 009:   3427 / 3715 loss=6.348, nll_loss=3.411, mask_ins=1.075, word_ins_ml=4.896, word_reposition=0.377, ppl=81.48, wps=14138.6, ups=0.97, wpb=14576.9, bsz=1024, num_updates=33100, lr=0.000194331, gnorm=1.583, clip=0, loss_scale=1602, train_wall=101, wall=34622
2022-08-02 00:41:14 | INFO | train_inner | epoch 009:   3527 / 3715 loss=6.327, nll_loss=3.412, mask_ins=1.064, word_ins_ml=4.897, word_reposition=0.366, ppl=80.28, wps=14439.1, ups=0.98, wpb=14738.8, bsz=1024, num_updates=33200, lr=0.000194038, gnorm=1.117, clip=0, loss_scale=1024, train_wall=100, wall=34724
2022-08-02 00:42:57 | INFO | train_inner | epoch 009:   3627 / 3715 loss=6.329, nll_loss=3.419, mask_ins=1.062, word_ins_ml=4.903, word_reposition=0.363, ppl=80.38, wps=14274.1, ups=0.98, wpb=14636.5, bsz=1024, num_updates=33300, lr=0.000193746, gnorm=1.111, clip=0, loss_scale=1024, train_wall=101, wall=34827
2022-08-02 00:44:27 | INFO | train | epoch 009 | loss 6.34 | nll_loss 3.415 | mask_ins 1.071 | word_ins_ml 4.9 | word_reposition 0.369 | ppl 81.01 | wps 14103.4 | ups 0.96 | wpb 14662.2 | bsz 1023.7 | num_updates 33388 | lr 0.000193491 | gnorm 1.217 | clip 0 | loss_scale 1128 | train_wall 3713 | wall 34917
2022-08-02 00:45:36 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 6.386 | nll_loss 3.347 | mask_ins 1.083 | word_ins_ml 4.909 | word_reposition 0.393 | ppl 83.61 | wps 39325.6 | wpb 1849.4 | bsz 127.9 | num_updates 33388 | best_loss 6.386
2022-08-02 00:45:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 9 @ 33388 updates, score 6.386) (writing took 6.86857190169394 seconds)
2022-08-02 00:45:56 | INFO | train_inner | epoch 010:     12 / 3715 loss=6.293, nll_loss=3.387, mask_ins=1.062, word_ins_ml=4.875, word_reposition=0.356, ppl=78.42, wps=8077.2, ups=0.56, wpb=14454.5, bsz=1014.7, num_updates=33400, lr=0.000193456, gnorm=1.148, clip=0, loss_scale=1024, train_wall=101, wall=35006
2022-08-02 00:47:39 | INFO | train_inner | epoch 010:    112 / 3715 loss=6.276, nll_loss=3.359, mask_ins=1.064, word_ins_ml=4.851, word_reposition=0.362, ppl=77.52, wps=14191.4, ups=0.97, wpb=14638.8, bsz=1024, num_updates=33500, lr=0.000193167, gnorm=1.182, clip=0, loss_scale=1024, train_wall=101, wall=35109
2022-08-02 00:49:22 | INFO | train_inner | epoch 010:    212 / 3715 loss=6.287, nll_loss=3.374, mask_ins=1.067, word_ins_ml=4.864, word_reposition=0.357, ppl=78.09, wps=14208.1, ups=0.97, wpb=14614.4, bsz=1024, num_updates=33600, lr=0.000192879, gnorm=1.168, clip=0, loss_scale=1352, train_wall=101, wall=35212
2022-08-02 00:51:04 | INFO | train_inner | epoch 010:    312 / 3715 loss=6.267, nll_loss=3.355, mask_ins=1.058, word_ins_ml=4.847, word_reposition=0.362, ppl=77.01, wps=14312, ups=0.97, wpb=14702.7, bsz=1023.8, num_updates=33700, lr=0.000192593, gnorm=1.125, clip=0, loss_scale=2048, train_wall=101, wall=35314
2022-08-02 00:52:47 | INFO | train_inner | epoch 010:    412 / 3715 loss=6.281, nll_loss=3.366, mask_ins=1.061, word_ins_ml=4.857, word_reposition=0.363, ppl=77.77, wps=14205.5, ups=0.98, wpb=14559, bsz=1024, num_updates=33800, lr=0.000192308, gnorm=1.137, clip=0, loss_scale=2048, train_wall=101, wall=35417
2022-08-02 00:54:30 | INFO | train_inner | epoch 010:    512 / 3715 loss=6.277, nll_loss=3.363, mask_ins=1.061, word_ins_ml=4.853, word_reposition=0.364, ppl=77.57, wps=14119.3, ups=0.97, wpb=14554.9, bsz=1024, num_updates=33900, lr=0.000192024, gnorm=1.151, clip=0, loss_scale=2048, train_wall=101, wall=35520
2022-08-02 00:56:12 | INFO | train_inner | epoch 010:    612 / 3715 loss=6.274, nll_loss=3.355, mask_ins=1.06, word_ins_ml=4.846, word_reposition=0.368, ppl=77.38, wps=14540.7, ups=0.98, wpb=14781.9, bsz=1024, num_updates=34000, lr=0.000191741, gnorm=1.16, clip=0, loss_scale=2048, train_wall=100, wall=35622
2022-08-02 00:57:53 | INFO | train_inner | epoch 010:    712 / 3715 loss=6.275, nll_loss=3.362, mask_ins=1.061, word_ins_ml=4.853, word_reposition=0.361, ppl=77.43, wps=14548.6, ups=0.98, wpb=14795.2, bsz=1024, num_updates=34100, lr=0.00019146, gnorm=1.13, clip=0, loss_scale=2458, train_wall=100, wall=35723
2022-08-02 00:59:35 | INFO | train_inner | epoch 010:    812 / 3715 loss=6.284, nll_loss=3.373, mask_ins=1.061, word_ins_ml=4.862, word_reposition=0.361, ppl=77.94, wps=14468.3, ups=0.98, wpb=14704, bsz=1024, num_updates=34200, lr=0.00019118, gnorm=1.142, clip=0, loss_scale=4096, train_wall=100, wall=35825
2022-08-02 01:00:32 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 01:01:17 | INFO | train_inner | epoch 010:    913 / 3715 loss=6.297, nll_loss=3.369, mask_ins=1.063, word_ins_ml=4.859, word_reposition=0.375, ppl=78.62, wps=14419.9, ups=0.98, wpb=14752.3, bsz=1024, num_updates=34300, lr=0.000190901, gnorm=1.248, clip=0, loss_scale=3163, train_wall=101, wall=35927
2022-08-02 01:02:59 | INFO | train_inner | epoch 010:   1013 / 3715 loss=6.288, nll_loss=3.374, mask_ins=1.061, word_ins_ml=4.864, word_reposition=0.363, ppl=78.12, wps=14441.1, ups=0.99, wpb=14638.4, bsz=1024, num_updates=34400, lr=0.000190623, gnorm=1.191, clip=0, loss_scale=2048, train_wall=100, wall=36029
2022-08-02 01:04:40 | INFO | train_inner | epoch 010:   1113 / 3715 loss=6.266, nll_loss=3.354, mask_ins=1.056, word_ins_ml=4.845, word_reposition=0.365, ppl=76.94, wps=14506.7, ups=0.98, wpb=14754.1, bsz=1024, num_updates=34500, lr=0.000190347, gnorm=1.125, clip=0, loss_scale=2048, train_wall=100, wall=36130
2022-08-02 01:06:22 | INFO | train_inner | epoch 010:   1213 / 3715 loss=6.263, nll_loss=3.356, mask_ins=1.056, word_ins_ml=4.847, word_reposition=0.359, ppl=76.77, wps=14324.4, ups=0.98, wpb=14589.9, bsz=1024, num_updates=34600, lr=0.000190071, gnorm=1.184, clip=0, loss_scale=2048, train_wall=100, wall=36232
2022-08-02 01:08:06 | INFO | train_inner | epoch 010:   1313 / 3715 loss=6.272, nll_loss=3.366, mask_ins=1.06, word_ins_ml=4.856, word_reposition=0.357, ppl=77.3, wps=14141.1, ups=0.96, wpb=14655.2, bsz=1024, num_updates=34700, lr=0.000189797, gnorm=1.114, clip=0, loss_scale=2048, train_wall=102, wall=36336
2022-08-02 01:09:48 | INFO | train_inner | epoch 010:   1413 / 3715 loss=6.293, nll_loss=3.379, mask_ins=1.066, word_ins_ml=4.868, word_reposition=0.36, ppl=78.42, wps=14210.4, ups=0.97, wpb=14587, bsz=1024, num_updates=34800, lr=0.000189525, gnorm=1.134, clip=0, loss_scale=2744, train_wall=101, wall=36438
2022-08-02 01:09:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 01:10:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 01:11:32 | INFO | train_inner | epoch 010:   1515 / 3715 loss=6.31, nll_loss=3.383, mask_ins=1.071, word_ins_ml=4.871, word_reposition=0.369, ppl=79.36, wps=14042.7, ups=0.96, wpb=14579.1, bsz=1024, num_updates=34900, lr=0.000189253, gnorm=1.198, clip=0, loss_scale=1677, train_wall=102, wall=36542
2022-08-02 01:13:14 | INFO | train_inner | epoch 010:   1615 / 3715 loss=6.296, nll_loss=3.384, mask_ins=1.065, word_ins_ml=4.872, word_reposition=0.359, ppl=78.57, wps=14509.5, ups=0.99, wpb=14697.8, bsz=1024, num_updates=35000, lr=0.000188982, gnorm=1.148, clip=0, loss_scale=1024, train_wall=100, wall=36644
2022-08-02 01:14:55 | INFO | train_inner | epoch 010:   1715 / 3715 loss=6.282, nll_loss=3.362, mask_ins=1.065, word_ins_ml=4.852, word_reposition=0.364, ppl=77.82, wps=14432, ups=0.98, wpb=14679.6, bsz=1024, num_updates=35100, lr=0.000188713, gnorm=1.171, clip=0, loss_scale=1024, train_wall=100, wall=36745
2022-08-02 01:16:37 | INFO | train_inner | epoch 010:   1815 / 3715 loss=6.276, nll_loss=3.365, mask_ins=1.062, word_ins_ml=4.855, word_reposition=0.359, ppl=77.49, wps=14446.7, ups=0.99, wpb=14658.3, bsz=1024, num_updates=35200, lr=0.000188445, gnorm=1.154, clip=0, loss_scale=1024, train_wall=100, wall=36847
2022-08-02 01:18:18 | INFO | train_inner | epoch 010:   1915 / 3715 loss=6.284, nll_loss=3.37, mask_ins=1.064, word_ins_ml=4.859, word_reposition=0.36, ppl=77.9, wps=14479.5, ups=0.99, wpb=14653.6, bsz=1024, num_updates=35300, lr=0.000188177, gnorm=1.126, clip=0, loss_scale=1024, train_wall=99, wall=36948
2022-08-02 01:20:00 | INFO | train_inner | epoch 010:   2015 / 3715 loss=6.293, nll_loss=3.377, mask_ins=1.061, word_ins_ml=4.866, word_reposition=0.366, ppl=78.42, wps=14482.7, ups=0.98, wpb=14743, bsz=1024, num_updates=35400, lr=0.000187912, gnorm=1.216, clip=0, loss_scale=1403, train_wall=100, wall=37050
2022-08-02 01:21:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 01:21:42 | INFO | train_inner | epoch 010:   2116 / 3715 loss=6.3, nll_loss=3.375, mask_ins=1.063, word_ins_ml=4.864, word_reposition=0.373, ppl=78.8, wps=14387.7, ups=0.98, wpb=14750.1, bsz=1024, num_updates=35500, lr=0.000187647, gnorm=1.231, clip=0, loss_scale=1876, train_wall=101, wall=37152
2022-08-02 01:23:24 | INFO | train_inner | epoch 010:   2216 / 3715 loss=6.262, nll_loss=3.356, mask_ins=1.056, word_ins_ml=4.847, word_reposition=0.359, ppl=76.76, wps=14315.8, ups=0.98, wpb=14549.2, bsz=1024, num_updates=35600, lr=0.000187383, gnorm=1.137, clip=0, loss_scale=1024, train_wall=100, wall=37254
2022-08-02 01:25:05 | INFO | train_inner | epoch 010:   2316 / 3715 loss=6.281, nll_loss=3.377, mask_ins=1.061, word_ins_ml=4.865, word_reposition=0.354, ppl=77.76, wps=14398, ups=0.99, wpb=14591.5, bsz=1024, num_updates=35700, lr=0.00018712, gnorm=1.171, clip=0, loss_scale=1024, train_wall=100, wall=37355
2022-08-02 01:26:47 | INFO | train_inner | epoch 010:   2416 / 3715 loss=6.263, nll_loss=3.356, mask_ins=1.062, word_ins_ml=4.847, word_reposition=0.355, ppl=76.8, wps=14275.8, ups=0.99, wpb=14489.1, bsz=1024, num_updates=35800, lr=0.000186859, gnorm=1.149, clip=0, loss_scale=1024, train_wall=100, wall=37457
2022-08-02 01:28:28 | INFO | train_inner | epoch 010:   2516 / 3715 loss=6.297, nll_loss=3.378, mask_ins=1.065, word_ins_ml=4.866, word_reposition=0.365, ppl=78.65, wps=14476.7, ups=0.99, wpb=14692.7, bsz=1024, num_updates=35900, lr=0.000186598, gnorm=1.435, clip=0, loss_scale=1024, train_wall=100, wall=37558
2022-08-02 01:30:10 | INFO | train_inner | epoch 010:   2616 / 3715 loss=6.28, nll_loss=3.368, mask_ins=1.06, word_ins_ml=4.857, word_reposition=0.362, ppl=77.69, wps=14418.5, ups=0.99, wpb=14606.5, bsz=1024, num_updates=36000, lr=0.000186339, gnorm=1.131, clip=0, loss_scale=1075, train_wall=100, wall=37659
2022-08-02 01:31:52 | INFO | train_inner | epoch 010:   2716 / 3715 loss=6.258, nll_loss=3.35, mask_ins=1.056, word_ins_ml=4.841, word_reposition=0.36, ppl=76.51, wps=14488.6, ups=0.98, wpb=14794.3, bsz=1024, num_updates=36100, lr=0.000186081, gnorm=1.131, clip=0, loss_scale=2048, train_wall=100, wall=37762
2022-08-02 01:33:34 | INFO | train_inner | epoch 010:   2816 / 3715 loss=6.264, nll_loss=3.354, mask_ins=1.056, word_ins_ml=4.845, word_reposition=0.363, ppl=76.83, wps=14433.2, ups=0.98, wpb=14767.8, bsz=1024, num_updates=36200, lr=0.000185824, gnorm=1.146, clip=0, loss_scale=2048, train_wall=101, wall=37864
2022-08-02 01:35:16 | INFO | train_inner | epoch 010:   2916 / 3715 loss=6.296, nll_loss=3.389, mask_ins=1.064, word_ins_ml=4.875, word_reposition=0.358, ppl=78.6, wps=14451, ups=0.98, wpb=14794.3, bsz=1024, num_updates=36300, lr=0.000185567, gnorm=1.114, clip=0, loss_scale=2048, train_wall=101, wall=37966
2022-08-02 01:36:59 | INFO | train_inner | epoch 010:   3016 / 3715 loss=6.291, nll_loss=3.373, mask_ins=1.064, word_ins_ml=4.862, word_reposition=0.365, ppl=78.29, wps=14415.3, ups=0.98, wpb=14740.8, bsz=1024, num_updates=36400, lr=0.000185312, gnorm=1.156, clip=0, loss_scale=2048, train_wall=100, wall=38069
2022-08-02 01:38:41 | INFO | train_inner | epoch 010:   3116 / 3715 loss=6.287, nll_loss=3.375, mask_ins=1.065, word_ins_ml=4.864, word_reposition=0.358, ppl=78.1, wps=14434.6, ups=0.98, wpb=14762.4, bsz=1024, num_updates=36500, lr=0.000185058, gnorm=1.155, clip=0, loss_scale=2048, train_wall=100, wall=38171
2022-08-02 01:40:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 01:40:24 | INFO | train_inner | epoch 010:   3217 / 3715 loss=6.303, nll_loss=3.381, mask_ins=1.06, word_ins_ml=4.868, word_reposition=0.375, ppl=78.98, wps=14210.8, ups=0.97, wpb=14629.3, bsz=1024, num_updates=36600, lr=0.000184805, gnorm=1.213, clip=0, loss_scale=3528, train_wall=101, wall=38274
2022-08-02 01:40:39 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 01:42:07 | INFO | train_inner | epoch 010:   3318 / 3715 loss=6.295, nll_loss=3.384, mask_ins=1.057, word_ins_ml=4.871, word_reposition=0.367, ppl=78.53, wps=14188.1, ups=0.97, wpb=14687.5, bsz=1024, num_updates=36700, lr=0.000184553, gnorm=1.135, clip=0, loss_scale=1166, train_wall=102, wall=38377
2022-08-02 01:43:50 | INFO | train_inner | epoch 010:   3418 / 3715 loss=6.257, nll_loss=3.354, mask_ins=1.057, word_ins_ml=4.845, word_reposition=0.355, ppl=76.46, wps=14407.7, ups=0.98, wpb=14776, bsz=1024, num_updates=36800, lr=0.000184302, gnorm=1.18, clip=0, loss_scale=1024, train_wall=101, wall=38480
2022-08-02 01:45:32 | INFO | train_inner | epoch 010:   3518 / 3715 loss=6.252, nll_loss=3.348, mask_ins=1.056, word_ins_ml=4.839, word_reposition=0.358, ppl=76.22, wps=14236.9, ups=0.98, wpb=14560.4, bsz=1024, num_updates=36900, lr=0.000184053, gnorm=1.18, clip=0, loss_scale=1024, train_wall=100, wall=38582
2022-08-02 01:47:15 | INFO | train_inner | epoch 010:   3618 / 3715 loss=6.275, nll_loss=3.372, mask_ins=1.06, word_ins_ml=4.861, word_reposition=0.355, ppl=77.46, wps=14134.2, ups=0.97, wpb=14503.1, bsz=1024, num_updates=37000, lr=0.000183804, gnorm=1.15, clip=0, loss_scale=1024, train_wall=101, wall=38685
2022-08-02 01:48:53 | INFO | train | epoch 010 | loss 6.28 | nll_loss 3.367 | mask_ins 1.061 | word_ins_ml 4.857 | word_reposition 0.362 | ppl 77.72 | wps 14066.1 | ups 0.96 | wpb 14661.8 | bsz 1023.7 | num_updates 37097 | lr 0.000183563 | gnorm 1.167 | clip 0 | loss_scale 1741 | train_wall 3724 | wall 38783
2022-08-02 01:50:03 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 6.326 | nll_loss 3.293 | mask_ins 1.073 | word_ins_ml 4.867 | word_reposition 0.387 | ppl 80.25 | wps 39246.3 | wpb 1849.4 | bsz 127.9 | num_updates 37097 | best_loss 6.326
2022-08-02 01:50:09 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 10 @ 37097 updates, score 6.326) (writing took 6.825916280969977 seconds)
2022-08-02 01:50:12 | INFO | train_inner | epoch 011:      3 / 3715 loss=6.272, nll_loss=3.359, mask_ins=1.058, word_ins_ml=4.849, word_reposition=0.364, ppl=77.25, wps=8125.1, ups=0.56, wpb=14434.5, bsz=1014.7, num_updates=37100, lr=0.000183556, gnorm=1.155, clip=0, loss_scale=1024, train_wall=99, wall=38862
2022-08-02 01:51:54 | INFO | train_inner | epoch 011:    103 / 3715 loss=6.223, nll_loss=3.319, mask_ins=1.052, word_ins_ml=4.814, word_reposition=0.357, ppl=74.69, wps=14387.9, ups=0.98, wpb=14664.5, bsz=1024, num_updates=37200, lr=0.000183309, gnorm=1.143, clip=0, loss_scale=1792, train_wall=100, wall=38964
2022-08-02 01:53:37 | INFO | train_inner | epoch 011:    203 / 3715 loss=6.204, nll_loss=3.304, mask_ins=1.047, word_ins_ml=4.801, word_reposition=0.357, ppl=73.73, wps=14365.7, ups=0.98, wpb=14712.5, bsz=1024, num_updates=37300, lr=0.000183063, gnorm=1.16, clip=0, loss_scale=2048, train_wall=101, wall=39067
2022-08-02 01:55:19 | INFO | train_inner | epoch 011:    303 / 3715 loss=6.222, nll_loss=3.318, mask_ins=1.054, word_ins_ml=4.813, word_reposition=0.355, ppl=74.66, wps=14283.2, ups=0.97, wpb=14663.7, bsz=1024, num_updates=37400, lr=0.000182818, gnorm=1.139, clip=0, loss_scale=2048, train_wall=101, wall=39169
2022-08-02 01:57:02 | INFO | train_inner | epoch 011:    403 / 3715 loss=6.229, nll_loss=3.323, mask_ins=1.056, word_ins_ml=4.817, word_reposition=0.355, ppl=74.99, wps=14322.4, ups=0.98, wpb=14629.2, bsz=1024, num_updates=37500, lr=0.000182574, gnorm=1.137, clip=0, loss_scale=2048, train_wall=100, wall=39272
2022-08-02 01:58:43 | INFO | train_inner | epoch 011:    503 / 3715 loss=6.231, nll_loss=3.32, mask_ins=1.058, word_ins_ml=4.815, word_reposition=0.358, ppl=75.11, wps=14267.6, ups=0.98, wpb=14530.4, bsz=1024, num_updates=37600, lr=0.000182331, gnorm=1.137, clip=0, loss_scale=2048, train_wall=100, wall=39373
2022-08-02 02:00:25 | INFO | train_inner | epoch 011:    603 / 3715 loss=6.228, nll_loss=3.329, mask_ins=1.052, word_ins_ml=4.823, word_reposition=0.353, ppl=74.96, wps=14499.9, ups=0.99, wpb=14669.1, bsz=1024, num_updates=37700, lr=0.000182089, gnorm=1.132, clip=0, loss_scale=3338, train_wall=99, wall=39475
2022-08-02 02:00:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 02:02:07 | INFO | train_inner | epoch 011:    704 / 3715 loss=6.229, nll_loss=3.317, mask_ins=1.055, word_ins_ml=4.813, word_reposition=0.362, ppl=75.03, wps=14425.7, ups=0.98, wpb=14739.5, bsz=1024, num_updates=37800, lr=0.000181848, gnorm=1.186, clip=0, loss_scale=2413, train_wall=100, wall=39577
2022-08-02 02:02:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 02:03:49 | INFO | train_inner | epoch 011:    805 / 3715 loss=6.242, nll_loss=3.334, mask_ins=1.055, word_ins_ml=4.827, word_reposition=0.36, ppl=75.69, wps=14422.9, ups=0.98, wpb=14733, bsz=1024, num_updates=37900, lr=0.000181608, gnorm=1.153, clip=0, loss_scale=1146, train_wall=100, wall=39679
2022-08-02 02:05:31 | INFO | train_inner | epoch 011:    905 / 3715 loss=6.204, nll_loss=3.303, mask_ins=1.052, word_ins_ml=4.799, word_reposition=0.353, ppl=73.75, wps=14350.1, ups=0.98, wpb=14712.7, bsz=1024, num_updates=38000, lr=0.000181369, gnorm=1.144, clip=0, loss_scale=1024, train_wall=101, wall=39781
2022-08-02 02:07:13 | INFO | train_inner | epoch 011:   1005 / 3715 loss=6.233, nll_loss=3.325, mask_ins=1.058, word_ins_ml=4.819, word_reposition=0.355, ppl=75.19, wps=14420.7, ups=0.98, wpb=14690.9, bsz=1024, num_updates=38100, lr=0.000181131, gnorm=1.154, clip=0, loss_scale=1024, train_wall=100, wall=39883
2022-08-02 02:08:55 | INFO | train_inner | epoch 011:   1105 / 3715 loss=6.223, nll_loss=3.315, mask_ins=1.057, word_ins_ml=4.81, word_reposition=0.355, ppl=74.71, wps=14401.7, ups=0.98, wpb=14639.2, bsz=1024, num_updates=38200, lr=0.000180894, gnorm=1.139, clip=0, loss_scale=1024, train_wall=100, wall=39985
2022-08-02 02:10:37 | INFO | train_inner | epoch 011:   1205 / 3715 loss=6.238, nll_loss=3.333, mask_ins=1.053, word_ins_ml=4.826, word_reposition=0.359, ppl=75.47, wps=14441, ups=0.98, wpb=14690, bsz=1024, num_updates=38300, lr=0.000180657, gnorm=1.128, clip=0, loss_scale=1024, train_wall=100, wall=40087
2022-08-02 02:12:19 | INFO | train_inner | epoch 011:   1305 / 3715 loss=6.24, nll_loss=3.336, mask_ins=1.056, word_ins_ml=4.829, word_reposition=0.355, ppl=75.58, wps=14245.2, ups=0.98, wpb=14517.5, bsz=1024, num_updates=38400, lr=0.000180422, gnorm=1.134, clip=0, loss_scale=1812, train_wall=100, wall=40189
2022-08-02 02:14:02 | INFO | train_inner | epoch 011:   1405 / 3715 loss=6.234, nll_loss=3.328, mask_ins=1.055, word_ins_ml=4.822, word_reposition=0.358, ppl=75.28, wps=14314.6, ups=0.97, wpb=14793.8, bsz=1024, num_updates=38500, lr=0.000180187, gnorm=1.128, clip=0, loss_scale=2048, train_wall=102, wall=40292
2022-08-02 02:15:45 | INFO | train_inner | epoch 011:   1505 / 3715 loss=6.242, nll_loss=3.335, mask_ins=1.054, word_ins_ml=4.828, word_reposition=0.36, ppl=75.69, wps=14252.6, ups=0.97, wpb=14717.3, bsz=1024, num_updates=38600, lr=0.000179954, gnorm=1.13, clip=0, loss_scale=2048, train_wall=101, wall=40395
2022-08-02 02:17:28 | INFO | train_inner | epoch 011:   1605 / 3715 loss=6.225, nll_loss=3.325, mask_ins=1.051, word_ins_ml=4.819, word_reposition=0.356, ppl=74.82, wps=14320.7, ups=0.97, wpb=14748, bsz=1024, num_updates=38700, lr=0.000179721, gnorm=1.124, clip=0, loss_scale=2048, train_wall=101, wall=40498
2022-08-02 02:19:10 | INFO | train_inner | epoch 011:   1705 / 3715 loss=6.236, nll_loss=3.333, mask_ins=1.055, word_ins_ml=4.826, word_reposition=0.355, ppl=75.36, wps=14462.2, ups=0.99, wpb=14673.9, bsz=1024, num_updates=38800, lr=0.00017949, gnorm=1.138, clip=0, loss_scale=2048, train_wall=100, wall=40600
2022-08-02 02:20:52 | INFO | train_inner | epoch 011:   1805 / 3715 loss=6.214, nll_loss=3.317, mask_ins=1.05, word_ins_ml=4.811, word_reposition=0.353, ppl=74.24, wps=14258.4, ups=0.97, wpb=14639.6, bsz=1024, num_updates=38900, lr=0.000179259, gnorm=1.16, clip=0, loss_scale=3379, train_wall=101, wall=40702
2022-08-02 02:22:35 | INFO | train_inner | epoch 011:   1905 / 3715 loss=6.233, nll_loss=3.331, mask_ins=1.057, word_ins_ml=4.824, word_reposition=0.352, ppl=75.2, wps=14177, ups=0.97, wpb=14610.7, bsz=1024, num_updates=39000, lr=0.000179029, gnorm=1.145, clip=0, loss_scale=4096, train_wall=101, wall=40805
2022-08-02 02:24:20 | INFO | train_inner | epoch 011:   2005 / 3715 loss=6.212, nll_loss=3.311, mask_ins=1.05, word_ins_ml=4.807, word_reposition=0.355, ppl=74.13, wps=13978.5, ups=0.96, wpb=14631.1, bsz=1023.8, num_updates=39100, lr=0.0001788, gnorm=1.132, clip=0, loss_scale=4096, train_wall=103, wall=40910
2022-08-02 02:26:03 | INFO | train_inner | epoch 011:   2105 / 3715 loss=6.206, nll_loss=3.316, mask_ins=1.045, word_ins_ml=4.811, word_reposition=0.35, ppl=73.84, wps=14218.8, ups=0.98, wpb=14576.5, bsz=1024, num_updates=39200, lr=0.000178571, gnorm=1.141, clip=0, loss_scale=4096, train_wall=101, wall=41013
2022-08-02 02:27:45 | INFO | train_inner | epoch 011:   2205 / 3715 loss=6.23, nll_loss=3.334, mask_ins=1.054, word_ins_ml=4.826, word_reposition=0.349, ppl=75.05, wps=14294.8, ups=0.97, wpb=14661.7, bsz=1024, num_updates=39300, lr=0.000178344, gnorm=1.125, clip=0, loss_scale=4096, train_wall=101, wall=41115
2022-08-02 02:29:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2022-08-02 02:29:28 | INFO | train_inner | epoch 011:   2306 / 3715 loss=6.22, nll_loss=3.318, mask_ins=1.05, word_ins_ml=4.812, word_reposition=0.358, ppl=74.52, wps=14293.3, ups=0.98, wpb=14639.8, bsz=1024, num_updates=39400, lr=0.000178118, gnorm=1.158, clip=0, loss_scale=5880, train_wall=101, wall=41218
2022-08-02 02:31:09 | INFO | train_inner | epoch 011:   2406 / 3715 loss=6.23, nll_loss=3.332, mask_ins=1.055, word_ins_ml=4.824, word_reposition=0.351, ppl=75.06, wps=14398.8, ups=0.99, wpb=14594.3, bsz=1024, num_updates=39500, lr=0.000177892, gnorm=1.174, clip=0, loss_scale=4096, train_wall=100, wall=41319
2022-08-02 02:32:50 | INFO | train_inner | epoch 011:   2506 / 3715 loss=6.226, nll_loss=3.314, mask_ins=1.058, word_ins_ml=4.809, word_reposition=0.36, ppl=74.85, wps=14618, ups=0.99, wpb=14772.3, bsz=1024, num_updates=39600, lr=0.000177667, gnorm=1.132, clip=0, loss_scale=4096, train_wall=99, wall=41420
2022-08-02 02:34:34 | INFO | train_inner | epoch 011:   2606 / 3715 loss=6.225, nll_loss=3.32, mask_ins=1.055, word_ins_ml=4.814, word_reposition=0.356, ppl=74.82, wps=14177.8, ups=0.97, wpb=14676.5, bsz=1024, num_updates=39700, lr=0.000177443, gnorm=1.181, clip=0, loss_scale=4096, train_wall=102, wall=41523
2022-08-02 02:36:16 | INFO | train_inner | epoch 011:   2706 / 3715 loss=6.228, nll_loss=3.338, mask_ins=1.049, word_ins_ml=4.83, word_reposition=0.349, ppl=74.94, wps=14306.5, ups=0.97, wpb=14676.3, bsz=1024, num_updates=39800, lr=0.00017722, gnorm=1.132, clip=0, loss_scale=4096, train_wall=101, wall=41626
2022-08-02 02:37:59 | INFO | train_inner | epoch 011:   2806 / 3715 loss=6.244, nll_loss=3.335, mask_ins=1.053, word_ins_ml=4.827, word_reposition=0.364, ppl=75.82, wps=14354.7, ups=0.97, wpb=14727.4, bsz=1024, num_updates=39900, lr=0.000176998, gnorm=1.125, clip=0, loss_scale=4096, train_wall=101, wall=41729
2022-08-02 02:39:43 | INFO | train_inner | epoch 011:   2906 / 3715 loss=6.211, nll_loss=3.313, mask_ins=1.05, word_ins_ml=4.808, word_reposition=0.353, ppl=74.06, wps=14060.5, ups=0.96, wpb=14618.6, bsz=1024, num_updates=40000, lr=0.000176777, gnorm=1.128, clip=0, loss_scale=8110, train_wall=102, wall=41833
2022-08-02 02:41:26 | INFO | train_inner | epoch 011:   3006 / 3715 loss=6.232, nll_loss=3.331, mask_ins=1.052, word_ins_ml=4.824, word_reposition=0.356, ppl=75.17, wps=14173.3, ups=0.97, wpb=14642.8, bsz=1024, num_updates=40100, lr=0.000176556, gnorm=1.13, clip=0, loss_scale=8192, train_wall=102, wall=41936
2022-08-02 02:43:10 | INFO | train_inner | epoch 011:   3106 / 3715 loss=6.218, nll_loss=3.316, mask_ins=1.052, word_ins_ml=4.81, word_reposition=0.355, ppl=74.42, wps=14130.9, ups=0.96, wpb=14650.5, bsz=1024, num_updates=40200, lr=0.000176336, gnorm=1.124, clip=0, loss_scale=8192, train_wall=102, wall=42040
2022-08-02 02:44:52 | INFO | train_inner | epoch 011:   3206 / 3715 loss=6.232, nll_loss=3.328, mask_ins=1.053, word_ins_ml=4.821, word_reposition=0.358, ppl=75.16, wps=14336.6, ups=0.98, wpb=14654.3, bsz=1024, num_updates=40300, lr=0.000176117, gnorm=1.141, clip=0, loss_scale=8192, train_wall=100, wall=42142
2022-08-02 02:46:34 | INFO | train_inner | epoch 011:   3306 / 3715 loss=6.23, nll_loss=3.335, mask_ins=1.051, word_ins_ml=4.827, word_reposition=0.352, ppl=75.08, wps=14383.4, ups=0.98, wpb=14679.6, bsz=1024, num_updates=40400, lr=0.000175899, gnorm=1.129, clip=0, loss_scale=8192, train_wall=100, wall=42244
2022-08-02 02:46:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2022-08-02 02:48:16 | INFO | train_inner | epoch 011:   3407 / 3715 loss=6.23, nll_loss=3.334, mask_ins=1.051, word_ins_ml=4.826, word_reposition=0.353, ppl=75.07, wps=14235.2, ups=0.98, wpb=14573.2, bsz=1024, num_updates=40500, lr=0.000175682, gnorm=1.153, clip=0, loss_scale=8841, train_wall=101, wall=42346
2022-08-02 02:48:44 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2022-08-02 02:49:59 | INFO | train_inner | epoch 011:   3508 / 3715 loss=6.213, nll_loss=3.312, mask_ins=1.047, word_ins_ml=4.807, word_reposition=0.359, ppl=74.18, wps=14234.2, ups=0.97, wpb=14642.8, bsz=1024, num_updates=40600, lr=0.000175466, gnorm=1.141, clip=0, loss_scale=5150, train_wall=101, wall=42449
2022-08-02 02:51:41 | INFO | train_inner | epoch 011:   3608 / 3715 loss=6.227, nll_loss=3.328, mask_ins=1.051, word_ins_ml=4.821, word_reposition=0.355, ppl=74.91, wps=14363.7, ups=0.98, wpb=14680.8, bsz=1024, num_updates=40700, lr=0.00017525, gnorm=1.116, clip=0, loss_scale=4096, train_wall=100, wall=42551
2022-08-02 02:53:24 | INFO | train_inner | epoch 011:   3708 / 3715 loss=6.26, nll_loss=3.35, mask_ins=1.055, word_ins_ml=4.84, word_reposition=0.365, ppl=76.61, wps=14383.2, ups=0.98, wpb=14707.8, bsz=1024, num_updates=40800, lr=0.000175035, gnorm=1.174, clip=0, loss_scale=4096, train_wall=100, wall=42654
2022-08-02 02:53:30 | INFO | train | epoch 011 | loss 6.227 | nll_loss 3.325 | mask_ins 1.053 | word_ins_ml 4.818 | word_reposition 0.356 | ppl 74.91 | wps 14028.4 | ups 0.96 | wpb 14661.4 | bsz 1023.7 | num_updates 40807 | lr 0.00017502 | gnorm 1.142 | clip 0 | loss_scale 3788 | train_wall 3735 | wall 42660
2022-08-02 02:54:40 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 6.325 | nll_loss 3.297 | mask_ins 1.067 | word_ins_ml 4.864 | word_reposition 0.393 | ppl 80.15 | wps 39050 | wpb 1849.4 | bsz 127.9 | num_updates 40807 | best_loss 6.325
2022-08-02 02:54:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 11 @ 40807 updates, score 6.325) (writing took 6.864066107198596 seconds)
2022-08-02 02:55:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 02:56:23 | INFO | train_inner | epoch 012:     94 / 3715 loss=6.188, nll_loss=3.279, mask_ins=1.048, word_ins_ml=4.778, word_reposition=0.362, ppl=72.89, wps=8087.7, ups=0.56, wpb=14493.4, bsz=1014.7, num_updates=40900, lr=0.000174821, gnorm=1.162, clip=0, loss_scale=3021, train_wall=100, wall=42833
2022-08-02 02:58:05 | INFO | train_inner | epoch 012:    194 / 3715 loss=6.175, nll_loss=3.28, mask_ins=1.048, word_ins_ml=4.779, word_reposition=0.348, ppl=72.24, wps=14414.7, ups=0.98, wpb=14730.8, bsz=1024, num_updates=41000, lr=0.000174608, gnorm=1.142, clip=0, loss_scale=2048, train_wall=100, wall=42935
2022-08-02 02:59:49 | INFO | train_inner | epoch 012:    294 / 3715 loss=6.179, nll_loss=3.279, mask_ins=1.048, word_ins_ml=4.778, word_reposition=0.352, ppl=72.46, wps=14120.7, ups=0.96, wpb=14653.4, bsz=1024, num_updates=41100, lr=0.000174395, gnorm=1.154, clip=0, loss_scale=2048, train_wall=102, wall=43039
2022-08-02 03:01:33 | INFO | train_inner | epoch 012:    394 / 3715 loss=6.182, nll_loss=3.291, mask_ins=1.038, word_ins_ml=4.789, word_reposition=0.355, ppl=72.58, wps=14110.3, ups=0.96, wpb=14724, bsz=1024, num_updates=41200, lr=0.000174183, gnorm=1.164, clip=0, loss_scale=2048, train_wall=103, wall=43143
2022-08-02 03:03:18 | INFO | train_inner | epoch 012:    494 / 3715 loss=6.175, nll_loss=3.279, mask_ins=1.044, word_ins_ml=4.778, word_reposition=0.353, ppl=72.25, wps=14122.9, ups=0.96, wpb=14786.4, bsz=1024, num_updates=41300, lr=0.000173972, gnorm=1.146, clip=0, loss_scale=2048, train_wall=103, wall=43248
2022-08-02 03:05:03 | INFO | train_inner | epoch 012:    594 / 3715 loss=6.171, nll_loss=3.279, mask_ins=1.046, word_ins_ml=4.778, word_reposition=0.348, ppl=72.07, wps=13921.5, ups=0.95, wpb=14638, bsz=1024, num_updates=41400, lr=0.000173762, gnorm=1.191, clip=0, loss_scale=2888, train_wall=103, wall=43353
2022-08-02 03:06:48 | INFO | train_inner | epoch 012:    694 / 3715 loss=6.159, nll_loss=3.271, mask_ins=1.042, word_ins_ml=4.771, word_reposition=0.346, ppl=71.45, wps=13980.4, ups=0.95, wpb=14720.3, bsz=1024, num_updates=41500, lr=0.000173553, gnorm=1.156, clip=0, loss_scale=4096, train_wall=103, wall=43458
2022-08-02 03:07:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 03:08:36 | INFO | train_inner | epoch 012:    795 / 3715 loss=6.169, nll_loss=3.261, mask_ins=1.048, word_ins_ml=4.761, word_reposition=0.36, ppl=71.95, wps=13755.4, ups=0.93, wpb=14836.9, bsz=1024, num_updates=41600, lr=0.000173344, gnorm=1.17, clip=0, loss_scale=2312, train_wall=106, wall=43566
2022-08-02 03:08:43 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 03:10:22 | INFO | train_inner | epoch 012:    896 / 3715 loss=6.177, nll_loss=3.28, mask_ins=1.044, word_ins_ml=4.779, word_reposition=0.354, ppl=72.35, wps=13751.2, ups=0.94, wpb=14601.1, bsz=1024, num_updates=41700, lr=0.000173136, gnorm=1.147, clip=0, loss_scale=1085, train_wall=104, wall=43672
2022-08-02 03:12:07 | INFO | train_inner | epoch 012:    996 / 3715 loss=6.176, nll_loss=3.282, mask_ins=1.045, word_ins_ml=4.781, word_reposition=0.35, ppl=72.28, wps=14069.5, ups=0.96, wpb=14726.5, bsz=1024, num_updates=41800, lr=0.000172929, gnorm=1.182, clip=0, loss_scale=1024, train_wall=103, wall=43777
2022-08-02 03:13:51 | INFO | train_inner | epoch 012:   1096 / 3715 loss=6.157, nll_loss=3.263, mask_ins=1.04, word_ins_ml=4.763, word_reposition=0.353, ppl=71.34, wps=14179.1, ups=0.97, wpb=14684.5, bsz=1024, num_updates=41900, lr=0.000172722, gnorm=1.225, clip=0, loss_scale=1024, train_wall=102, wall=43881
2022-08-02 03:13:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-08-02 03:15:34 | INFO | train_inner | epoch 012:   1197 / 3715 loss=6.183, nll_loss=3.285, mask_ins=1.044, word_ins_ml=4.784, word_reposition=0.355, ppl=72.66, wps=14225, ups=0.97, wpb=14645.2, bsz=1024, num_updates=42000, lr=0.000172516, gnorm=1.347, clip=0, loss_scale=537, train_wall=101, wall=43983
2022-08-02 03:17:16 | INFO | train_inner | epoch 012:   1297 / 3715 loss=6.189, nll_loss=3.294, mask_ins=1.048, word_ins_ml=4.792, word_reposition=0.349, ppl=72.96, wps=14368.3, ups=0.98, wpb=14695, bsz=1024, num_updates=42100, lr=0.000172311, gnorm=1.153, clip=0, loss_scale=512, train_wall=101, wall=44086
2022-08-02 03:18:58 | INFO | train_inner | epoch 012:   1397 / 3715 loss=6.22, nll_loss=3.295, mask_ins=1.046, word_ins_ml=4.792, word_reposition=0.383, ppl=74.53, wps=14375.7, ups=0.98, wpb=14647.7, bsz=1024, num_updates=42200, lr=0.000172107, gnorm=1.532, clip=0, loss_scale=512, train_wall=100, wall=44188
2022-08-02 03:20:39 | INFO | train_inner | epoch 012:   1497 / 3715 loss=6.183, nll_loss=3.285, mask_ins=1.047, word_ins_ml=4.783, word_reposition=0.353, ppl=72.67, wps=14493.8, ups=0.99, wpb=14675.7, bsz=1024, num_updates=42300, lr=0.000171904, gnorm=1.151, clip=0, loss_scale=512, train_wall=99, wall=44289
2022-08-02 03:22:20 | INFO | train_inner | epoch 012:   1597 / 3715 loss=6.197, nll_loss=3.3, mask_ins=1.046, word_ins_ml=4.796, word_reposition=0.355, ppl=73.35, wps=14438.6, ups=0.99, wpb=14648.2, bsz=1024, num_updates=42400, lr=0.000171701, gnorm=1.184, clip=0, loss_scale=512, train_wall=100, wall=44390
2022-08-02 03:24:05 | INFO | train_inner | epoch 012:   1697 / 3715 loss=6.177, nll_loss=3.289, mask_ins=1.041, word_ins_ml=4.787, word_reposition=0.349, ppl=72.36, wps=14148.2, ups=0.96, wpb=14729.1, bsz=1024, num_updates=42500, lr=0.000171499, gnorm=1.161, clip=0, loss_scale=942, train_wall=102, wall=44494
2022-08-02 03:25:48 | INFO | train_inner | epoch 012:   1797 / 3715 loss=6.161, nll_loss=3.272, mask_ins=1.042, word_ins_ml=4.771, word_reposition=0.348, ppl=71.58, wps=14107.6, ups=0.97, wpb=14565.5, bsz=1024, num_updates=42600, lr=0.000171297, gnorm=1.144, clip=0, loss_scale=1024, train_wall=101, wall=44598
2022-08-02 03:27:31 | INFO | train_inner | epoch 012:   1897 / 3715 loss=6.171, nll_loss=3.27, mask_ins=1.046, word_ins_ml=4.77, word_reposition=0.356, ppl=72.05, wps=14361.2, ups=0.97, wpb=14855.9, bsz=1024, num_updates=42700, lr=0.000171096, gnorm=1.161, clip=0, loss_scale=1024, train_wall=102, wall=44701
2022-08-02 03:29:14 | INFO | train_inner | epoch 012:   1997 / 3715 loss=6.186, nll_loss=3.289, mask_ins=1.045, word_ins_ml=4.786, word_reposition=0.354, ppl=72.8, wps=14412.6, ups=0.98, wpb=14757.4, bsz=1024, num_updates=42800, lr=0.000170896, gnorm=1.143, clip=0, loss_scale=1024, train_wall=101, wall=44804
2022-08-02 03:30:55 | INFO | train_inner | epoch 012:   2097 / 3715 loss=6.193, nll_loss=3.295, mask_ins=1.046, word_ins_ml=4.791, word_reposition=0.355, ppl=73.14, wps=14381.1, ups=0.98, wpb=14651.8, bsz=1024, num_updates=42900, lr=0.000170697, gnorm=1.138, clip=0, loss_scale=1024, train_wall=100, wall=44905
2022-08-02 03:32:38 | INFO | train_inner | epoch 012:   2197 / 3715 loss=6.17, nll_loss=3.276, mask_ins=1.042, word_ins_ml=4.775, word_reposition=0.353, ppl=72.02, wps=14414.6, ups=0.98, wpb=14725.8, bsz=1024, num_updates=43000, lr=0.000170499, gnorm=1.134, clip=0, loss_scale=1761, train_wall=100, wall=45008
2022-08-02 03:34:20 | INFO | train_inner | epoch 012:   2297 / 3715 loss=6.187, nll_loss=3.294, mask_ins=1.045, word_ins_ml=4.791, word_reposition=0.351, ppl=72.87, wps=14263, ups=0.98, wpb=14567.8, bsz=1024, num_updates=43100, lr=0.000170301, gnorm=1.166, clip=0, loss_scale=2048, train_wall=100, wall=45110
2022-08-02 03:35:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 03:36:03 | INFO | train_inner | epoch 012:   2398 / 3715 loss=6.189, nll_loss=3.295, mask_ins=1.047, word_ins_ml=4.792, word_reposition=0.35, ppl=72.93, wps=14120.9, ups=0.97, wpb=14585.8, bsz=1024, num_updates=43200, lr=0.000170103, gnorm=1.139, clip=0, loss_scale=1653, train_wall=101, wall=45213
2022-08-02 03:37:46 | INFO | train_inner | epoch 012:   2498 / 3715 loss=6.199, nll_loss=3.302, mask_ins=1.046, word_ins_ml=4.797, word_reposition=0.355, ppl=73.45, wps=14244.8, ups=0.98, wpb=14593.5, bsz=1024, num_updates=43300, lr=0.000169907, gnorm=1.149, clip=0, loss_scale=1024, train_wall=101, wall=45315
2022-08-02 03:39:27 | INFO | train_inner | epoch 012:   2598 / 3715 loss=6.186, nll_loss=3.293, mask_ins=1.044, word_ins_ml=4.789, word_reposition=0.352, ppl=72.78, wps=14428.4, ups=0.98, wpb=14669.2, bsz=1024, num_updates=43400, lr=0.000169711, gnorm=1.172, clip=0, loss_scale=1024, train_wall=100, wall=45417
2022-08-02 03:41:09 | INFO | train_inner | epoch 012:   2698 / 3715 loss=6.179, nll_loss=3.284, mask_ins=1.045, word_ins_ml=4.781, word_reposition=0.353, ppl=72.47, wps=14400.8, ups=0.98, wpb=14651.6, bsz=1024, num_updates=43500, lr=0.000169516, gnorm=1.145, clip=0, loss_scale=1024, train_wall=100, wall=45519
2022-08-02 03:42:51 | INFO | train_inner | epoch 012:   2798 / 3715 loss=6.209, nll_loss=3.308, mask_ins=1.046, word_ins_ml=4.803, word_reposition=0.361, ppl=73.98, wps=14310.9, ups=0.98, wpb=14544.6, bsz=1024, num_updates=43600, lr=0.000169321, gnorm=1.19, clip=0, loss_scale=1024, train_wall=100, wall=45621
2022-08-02 03:44:32 | INFO | train_inner | epoch 012:   2898 / 3715 loss=6.17, nll_loss=3.276, mask_ins=1.046, word_ins_ml=4.774, word_reposition=0.35, ppl=72.03, wps=14405.4, ups=0.99, wpb=14578.4, bsz=1024, num_updates=43700, lr=0.000169128, gnorm=1.132, clip=0, loss_scale=1300, train_wall=99, wall=45722
2022-08-02 03:46:15 | INFO | train_inner | epoch 012:   2998 / 3715 loss=6.176, nll_loss=3.292, mask_ins=1.038, word_ins_ml=4.789, word_reposition=0.349, ppl=72.32, wps=14219.1, ups=0.97, wpb=14621.8, bsz=1024, num_updates=43800, lr=0.000168934, gnorm=1.148, clip=0, loss_scale=2048, train_wall=101, wall=45825
2022-08-02 03:47:57 | INFO | train_inner | epoch 012:   3098 / 3715 loss=6.185, nll_loss=3.295, mask_ins=1.044, word_ins_ml=4.791, word_reposition=0.349, ppl=72.76, wps=14279.5, ups=0.98, wpb=14601.3, bsz=1024, num_updates=43900, lr=0.000168742, gnorm=1.137, clip=0, loss_scale=2048, train_wall=101, wall=45927
2022-08-02 03:49:39 | INFO | train_inner | epoch 012:   3198 / 3715 loss=6.188, nll_loss=3.302, mask_ins=1.038, word_ins_ml=4.797, word_reposition=0.353, ppl=72.91, wps=14359.8, ups=0.98, wpb=14621.1, bsz=1024, num_updates=44000, lr=0.00016855, gnorm=1.154, clip=0, loss_scale=2048, train_wall=100, wall=46029
2022-08-02 03:49:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 03:51:22 | INFO | train_inner | epoch 012:   3299 / 3715 loss=6.183, nll_loss=3.289, mask_ins=1.04, word_ins_ml=4.786, word_reposition=0.357, ppl=72.67, wps=14200.1, ups=0.96, wpb=14725.6, bsz=1024, num_updates=44100, lr=0.000168359, gnorm=1.227, clip=0, loss_scale=1115, train_wall=102, wall=46132
2022-08-02 03:53:05 | INFO | train_inner | epoch 012:   3399 / 3715 loss=6.172, nll_loss=3.291, mask_ins=1.036, word_ins_ml=4.788, word_reposition=0.348, ppl=72.11, wps=14263.9, ups=0.97, wpb=14690, bsz=1024, num_updates=44200, lr=0.000168168, gnorm=1.138, clip=0, loss_scale=1024, train_wall=101, wall=46235
2022-08-02 03:54:49 | INFO | train_inner | epoch 012:   3499 / 3715 loss=6.183, nll_loss=3.293, mask_ins=1.043, word_ins_ml=4.79, word_reposition=0.35, ppl=72.64, wps=14099.1, ups=0.97, wpb=14560.6, bsz=1024, num_updates=44300, lr=0.000167978, gnorm=1.174, clip=0, loss_scale=1024, train_wall=102, wall=46339
2022-08-02 03:56:33 | INFO | train_inner | epoch 012:   3599 / 3715 loss=6.205, nll_loss=3.298, mask_ins=1.048, word_ins_ml=4.794, word_reposition=0.363, ppl=73.77, wps=14031.9, ups=0.96, wpb=14666.9, bsz=1024, num_updates=44400, lr=0.000167789, gnorm=1.159, clip=0, loss_scale=1024, train_wall=103, wall=46443
2022-08-02 03:56:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-08-02 03:58:19 | INFO | train_inner | epoch 012:   3700 / 3715 loss=6.226, nll_loss=3.292, mask_ins=1.044, word_ins_ml=4.789, word_reposition=0.393, ppl=74.86, wps=13893.4, ups=0.95, wpb=14634.1, bsz=1023.8, num_updates=44500, lr=0.0001676, gnorm=2.385, clip=1, loss_scale=563, train_wall=104, wall=46548
2022-08-02 03:58:33 | INFO | train | epoch 012 | loss 6.183 | nll_loss 3.286 | mask_ins 1.044 | word_ins_ml 4.784 | word_reposition 0.355 | ppl 72.66 | wps 13929.4 | ups 0.95 | wpb 14662 | bsz 1023.7 | num_updates 44515 | lr 0.000167572 | gnorm 1.208 | clip 0 | loss_scale 1424 | train_wall 3760 | wall 46563
2022-08-02 03:59:43 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 6.279 | nll_loss 3.262 | mask_ins 1.068 | word_ins_ml 4.838 | word_reposition 0.373 | ppl 77.67 | wps 39277.5 | wpb 1849.4 | bsz 127.9 | num_updates 44515 | best_loss 6.279
2022-08-02 03:59:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 12 @ 44515 updates, score 6.279) (writing took 7.169565413147211 seconds)
2022-08-02 04:01:17 | INFO | train_inner | epoch 013:     85 / 3715 loss=6.13, nll_loss=3.239, mask_ins=1.038, word_ins_ml=4.742, word_reposition=0.35, ppl=70.02, wps=8180.2, ups=0.56, wpb=14590.3, bsz=1014.7, num_updates=44600, lr=0.000167412, gnorm=1.187, clip=0, loss_scale=512, train_wall=100, wall=46727
2022-08-02 04:02:59 | INFO | train_inner | epoch 013:    185 / 3715 loss=6.136, nll_loss=3.247, mask_ins=1.043, word_ins_ml=4.749, word_reposition=0.344, ppl=70.34, wps=14234.9, ups=0.98, wpb=14574.4, bsz=1024, num_updates=44700, lr=0.000167225, gnorm=1.191, clip=0, loss_scale=512, train_wall=101, wall=46829
2022-08-02 04:04:41 | INFO | train_inner | epoch 013:    285 / 3715 loss=6.123, nll_loss=3.235, mask_ins=1.039, word_ins_ml=4.738, word_reposition=0.347, ppl=69.71, wps=14468.6, ups=0.98, wpb=14754.1, bsz=1024, num_updates=44800, lr=0.000167038, gnorm=1.172, clip=0, loss_scale=512, train_wall=100, wall=46931
2022-08-02 04:06:24 | INFO | train_inner | epoch 013:    385 / 3715 loss=6.137, nll_loss=3.246, mask_ins=1.04, word_ins_ml=4.749, word_reposition=0.349, ppl=70.37, wps=14155.4, ups=0.97, wpb=14601.6, bsz=1024, num_updates=44900, lr=0.000166852, gnorm=1.155, clip=0, loss_scale=512, train_wall=101, wall=47034
2022-08-02 04:08:07 | INFO | train_inner | epoch 013:    485 / 3715 loss=6.145, nll_loss=3.251, mask_ins=1.039, word_ins_ml=4.753, word_reposition=0.353, ppl=70.75, wps=14249.9, ups=0.98, wpb=14600.8, bsz=1024, num_updates=45000, lr=0.000166667, gnorm=1.289, clip=0, loss_scale=916, train_wall=101, wall=47137
2022-08-02 04:09:49 | INFO | train_inner | epoch 013:    585 / 3715 loss=6.155, nll_loss=3.255, mask_ins=1.04, word_ins_ml=4.756, word_reposition=0.36, ppl=71.27, wps=14285.7, ups=0.98, wpb=14625.4, bsz=1024, num_updates=45100, lr=0.000166482, gnorm=1.218, clip=0, loss_scale=1024, train_wall=101, wall=47239
2022-08-02 04:11:32 | INFO | train_inner | epoch 013:    685 / 3715 loss=6.146, nll_loss=3.252, mask_ins=1.041, word_ins_ml=4.753, word_reposition=0.351, ppl=70.79, wps=14393.8, ups=0.98, wpb=14728.8, bsz=1024, num_updates=45200, lr=0.000166298, gnorm=1.18, clip=0, loss_scale=1024, train_wall=101, wall=47341
2022-08-02 04:13:14 | INFO | train_inner | epoch 013:    785 / 3715 loss=6.124, nll_loss=3.244, mask_ins=1.035, word_ins_ml=4.747, word_reposition=0.342, ppl=69.73, wps=14247.3, ups=0.97, wpb=14632.2, bsz=1024, num_updates=45300, lr=0.000166114, gnorm=1.219, clip=0, loss_scale=1024, train_wall=101, wall=47444
2022-08-02 04:14:56 | INFO | train_inner | epoch 013:    885 / 3715 loss=6.131, nll_loss=3.25, mask_ins=1.035, word_ins_ml=4.752, word_reposition=0.345, ppl=70.1, wps=14479.5, ups=0.99, wpb=14680.9, bsz=1024, num_updates=45400, lr=0.000165931, gnorm=1.153, clip=0, loss_scale=1024, train_wall=100, wall=47546
2022-08-02 04:16:37 | INFO | train_inner | epoch 013:    985 / 3715 loss=6.14, nll_loss=3.249, mask_ins=1.037, word_ins_ml=4.75, word_reposition=0.353, ppl=70.53, wps=14519.3, ups=0.99, wpb=14727.9, bsz=1024, num_updates=45500, lr=0.000165748, gnorm=1.176, clip=0, loss_scale=1710, train_wall=100, wall=47647
2022-08-02 04:18:18 | INFO | train_inner | epoch 013:   1085 / 3715 loss=6.132, nll_loss=3.231, mask_ins=1.041, word_ins_ml=4.735, word_reposition=0.356, ppl=70.14, wps=14523.9, ups=0.99, wpb=14717.8, bsz=1024, num_updates=45600, lr=0.000165567, gnorm=1.154, clip=0, loss_scale=2048, train_wall=100, wall=47748
2022-08-02 04:20:00 | INFO | train_inner | epoch 013:   1185 / 3715 loss=6.14, nll_loss=3.253, mask_ins=1.04, word_ins_ml=4.754, word_reposition=0.346, ppl=70.51, wps=14471.1, ups=0.99, wpb=14689.7, bsz=1024, num_updates=45700, lr=0.000165385, gnorm=1.148, clip=0, loss_scale=2048, train_wall=100, wall=47850
2022-08-02 04:21:42 | INFO | train_inner | epoch 013:   1285 / 3715 loss=6.144, nll_loss=3.257, mask_ins=1.04, word_ins_ml=4.758, word_reposition=0.346, ppl=70.71, wps=14447.7, ups=0.98, wpb=14704.4, bsz=1024, num_updates=45800, lr=0.000165205, gnorm=1.15, clip=0, loss_scale=2048, train_wall=100, wall=47952
2022-08-02 04:23:23 | INFO | train_inner | epoch 013:   1385 / 3715 loss=6.13, nll_loss=3.236, mask_ins=1.042, word_ins_ml=4.739, word_reposition=0.349, ppl=70.05, wps=14693.2, ups=0.98, wpb=14921.1, bsz=1024, num_updates=45900, lr=0.000165025, gnorm=1.146, clip=0, loss_scale=2048, train_wall=100, wall=48053
2022-08-02 04:25:04 | INFO | train_inner | epoch 013:   1485 / 3715 loss=6.15, nll_loss=3.254, mask_ins=1.044, word_ins_ml=4.755, word_reposition=0.351, ppl=70.99, wps=14520.3, ups=0.99, wpb=14680.2, bsz=1024, num_updates=46000, lr=0.000164845, gnorm=1.163, clip=0, loss_scale=3174, train_wall=99, wall=48154
2022-08-02 04:26:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 04:26:48 | INFO | train_inner | epoch 013:   1586 / 3715 loss=6.139, nll_loss=3.249, mask_ins=1.038, word_ins_ml=4.751, word_reposition=0.351, ppl=70.49, wps=14100.5, ups=0.96, wpb=14649.1, bsz=1024, num_updates=46100, lr=0.000164666, gnorm=1.173, clip=0, loss_scale=3366, train_wall=102, wall=48258
2022-08-02 04:26:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 04:28:32 | INFO | train_inner | epoch 013:   1687 / 3715 loss=6.148, nll_loss=3.262, mask_ins=1.037, word_ins_ml=4.762, word_reposition=0.349, ppl=70.92, wps=14037.3, ups=0.96, wpb=14580.8, bsz=1024, num_updates=46200, lr=0.000164488, gnorm=1.214, clip=0, loss_scale=1034, train_wall=102, wall=48362
2022-08-02 04:30:15 | INFO | train_inner | epoch 013:   1787 / 3715 loss=6.153, nll_loss=3.259, mask_ins=1.036, word_ins_ml=4.76, word_reposition=0.357, ppl=71.14, wps=14251.8, ups=0.97, wpb=14678.9, bsz=1024, num_updates=46300, lr=0.00016431, gnorm=1.177, clip=0, loss_scale=1024, train_wall=101, wall=48465
2022-08-02 04:31:58 | INFO | train_inner | epoch 013:   1887 / 3715 loss=6.138, nll_loss=3.248, mask_ins=1.035, word_ins_ml=4.75, word_reposition=0.353, ppl=70.41, wps=14254.5, ups=0.97, wpb=14685, bsz=1024, num_updates=46400, lr=0.000164133, gnorm=1.219, clip=0, loss_scale=1024, train_wall=101, wall=48568
2022-08-02 04:33:41 | INFO | train_inner | epoch 013:   1987 / 3715 loss=6.159, nll_loss=3.27, mask_ins=1.037, word_ins_ml=4.77, word_reposition=0.352, ppl=71.44, wps=14310.7, ups=0.98, wpb=14666.7, bsz=1024, num_updates=46500, lr=0.000163956, gnorm=1.176, clip=0, loss_scale=1024, train_wall=101, wall=48671
2022-08-02 04:35:23 | INFO | train_inner | epoch 013:   2087 / 3715 loss=6.166, nll_loss=3.274, mask_ins=1.043, word_ins_ml=4.772, word_reposition=0.352, ppl=71.82, wps=14278.1, ups=0.98, wpb=14620.1, bsz=1024, num_updates=46600, lr=0.00016378, gnorm=1.143, clip=0, loss_scale=1024, train_wall=101, wall=48773
2022-08-02 04:37:06 | INFO | train_inner | epoch 013:   2187 / 3715 loss=6.153, nll_loss=3.268, mask_ins=1.036, word_ins_ml=4.767, word_reposition=0.35, ppl=71.18, wps=14237.1, ups=0.97, wpb=14690.4, bsz=1024, num_updates=46700, lr=0.000163605, gnorm=1.162, clip=0, loss_scale=1925, train_wall=101, wall=48876
2022-08-02 04:38:48 | INFO | train_inner | epoch 013:   2287 / 3715 loss=6.152, nll_loss=3.271, mask_ins=1.037, word_ins_ml=4.77, word_reposition=0.345, ppl=71.09, wps=14404.3, ups=0.98, wpb=14672.5, bsz=1024, num_updates=46800, lr=0.00016343, gnorm=1.165, clip=0, loss_scale=2048, train_wall=100, wall=48978
2022-08-02 04:40:29 | INFO | train_inner | epoch 013:   2387 / 3715 loss=6.139, nll_loss=3.258, mask_ins=1.036, word_ins_ml=4.758, word_reposition=0.345, ppl=70.5, wps=14428.2, ups=0.99, wpb=14623.1, bsz=1024, num_updates=46900, lr=0.000163256, gnorm=1.174, clip=0, loss_scale=2048, train_wall=100, wall=49079
2022-08-02 04:42:11 | INFO | train_inner | epoch 013:   2487 / 3715 loss=6.145, nll_loss=3.253, mask_ins=1.041, word_ins_ml=4.754, word_reposition=0.35, ppl=70.79, wps=14286.8, ups=0.98, wpb=14574.6, bsz=1024, num_updates=47000, lr=0.000163082, gnorm=1.148, clip=0, loss_scale=2048, train_wall=100, wall=49181
2022-08-02 04:43:53 | INFO | train_inner | epoch 013:   2587 / 3715 loss=6.149, nll_loss=3.261, mask_ins=1.04, word_ins_ml=4.76, word_reposition=0.348, ppl=70.95, wps=14499.8, ups=0.98, wpb=14746.3, bsz=1024, num_updates=47100, lr=0.000162909, gnorm=1.161, clip=0, loss_scale=2048, train_wall=100, wall=49283
2022-08-02 04:44:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 04:45:36 | INFO | train_inner | epoch 013:   2688 / 3715 loss=6.136, nll_loss=3.26, mask_ins=1.033, word_ins_ml=4.76, word_reposition=0.343, ppl=70.34, wps=14307.3, ups=0.97, wpb=14706, bsz=1024, num_updates=47200, lr=0.000162736, gnorm=1.153, clip=0, loss_scale=2595, train_wall=101, wall=49386
2022-08-02 04:47:18 | INFO | train_inner | epoch 013:   2788 / 3715 loss=6.164, nll_loss=3.274, mask_ins=1.041, word_ins_ml=4.772, word_reposition=0.351, ppl=71.69, wps=14235.5, ups=0.98, wpb=14596.4, bsz=1024, num_updates=47300, lr=0.000162564, gnorm=1.198, clip=0, loss_scale=2048, train_wall=101, wall=49488
2022-08-02 04:48:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 04:49:01 | INFO | train_inner | epoch 013:   2889 / 3715 loss=6.157, nll_loss=3.266, mask_ins=1.04, word_ins_ml=4.765, word_reposition=0.352, ppl=71.35, wps=14285.4, ups=0.98, wpb=14599.2, bsz=1024, num_updates=47400, lr=0.000162392, gnorm=1.192, clip=0, loss_scale=1501, train_wall=100, wall=49591
2022-08-02 04:50:42 | INFO | train_inner | epoch 013:   2989 / 3715 loss=6.134, nll_loss=3.25, mask_ins=1.035, word_ins_ml=4.751, word_reposition=0.347, ppl=70.23, wps=14374.1, ups=0.99, wpb=14589.9, bsz=1024, num_updates=47500, lr=0.000162221, gnorm=1.144, clip=0, loss_scale=1024, train_wall=100, wall=49692
2022-08-02 04:52:24 | INFO | train_inner | epoch 013:   3089 / 3715 loss=6.165, nll_loss=3.271, mask_ins=1.039, word_ins_ml=4.77, word_reposition=0.356, ppl=71.75, wps=14395.4, ups=0.98, wpb=14622.3, bsz=1024, num_updates=47600, lr=0.000162051, gnorm=1.151, clip=0, loss_scale=1024, train_wall=100, wall=49794
2022-08-02 04:54:05 | INFO | train_inner | epoch 013:   3189 / 3715 loss=6.126, nll_loss=3.243, mask_ins=1.03, word_ins_ml=4.745, word_reposition=0.352, ppl=69.86, wps=14454.4, ups=0.98, wpb=14682, bsz=1024, num_updates=47700, lr=0.000161881, gnorm=1.207, clip=0, loss_scale=1024, train_wall=100, wall=49895
2022-08-02 04:55:47 | INFO | train_inner | epoch 013:   3289 / 3715 loss=6.149, nll_loss=3.254, mask_ins=1.039, word_ins_ml=4.755, word_reposition=0.356, ppl=70.98, wps=14490.6, ups=0.99, wpb=14670.7, bsz=1023.8, num_updates=47800, lr=0.000161712, gnorm=1.157, clip=0, loss_scale=1024, train_wall=99, wall=49996
2022-08-02 04:57:28 | INFO | train_inner | epoch 013:   3389 / 3715 loss=6.149, nll_loss=3.263, mask_ins=1.033, word_ins_ml=4.763, word_reposition=0.353, ppl=70.95, wps=14402.7, ups=0.99, wpb=14562.3, bsz=1024, num_updates=47900, lr=0.000161543, gnorm=1.475, clip=0, loss_scale=1454, train_wall=99, wall=50098
2022-08-02 04:59:09 | INFO | train_inner | epoch 013:   3489 / 3715 loss=6.145, nll_loss=3.266, mask_ins=1.034, word_ins_ml=4.765, word_reposition=0.347, ppl=70.78, wps=14471.1, ups=0.99, wpb=14615.3, bsz=1024, num_updates=48000, lr=0.000161374, gnorm=1.169, clip=0, loss_scale=2048, train_wall=99, wall=50199
2022-08-02 05:00:50 | INFO | train_inner | epoch 013:   3589 / 3715 loss=6.165, nll_loss=3.272, mask_ins=1.043, word_ins_ml=4.77, word_reposition=0.352, ppl=71.76, wps=14557.6, ups=0.99, wpb=14720.4, bsz=1024, num_updates=48100, lr=0.000161206, gnorm=1.176, clip=0, loss_scale=2048, train_wall=99, wall=50300
2022-08-02 05:02:31 | INFO | train_inner | epoch 013:   3689 / 3715 loss=6.146, nll_loss=3.261, mask_ins=1.035, word_ins_ml=4.76, word_reposition=0.351, ppl=70.82, wps=14466.6, ups=0.99, wpb=14685.6, bsz=1024, num_updates=48200, lr=0.000161039, gnorm=1.146, clip=0, loss_scale=2048, train_wall=100, wall=50401
2022-08-02 05:02:57 | INFO | train | epoch 013 | loss 6.144 | nll_loss 3.255 | mask_ins 1.038 | word_ins_ml 4.756 | word_reposition 0.35 | ppl 70.72 | wps 14082 | ups 0.96 | wpb 14661.6 | bsz 1023.7 | num_updates 48226 | lr 0.000160996 | gnorm 1.183 | clip 0 | loss_scale 1538 | train_wall 3721 | wall 50427
2022-08-02 05:04:06 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 6.259 | nll_loss 3.252 | mask_ins 1.052 | word_ins_ml 4.824 | word_reposition 0.383 | ppl 76.59 | wps 39453.1 | wpb 1849.4 | bsz 127.9 | num_updates 48226 | best_loss 6.259
2022-08-02 05:04:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 13 @ 48226 updates, score 6.259) (writing took 6.9793042447417974 seconds)
2022-08-02 05:04:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 05:05:30 | INFO | train_inner | epoch 014:     75 / 3715 loss=6.106, nll_loss=3.227, mask_ins=1.034, word_ins_ml=4.731, word_reposition=0.342, ppl=68.88, wps=8145.2, ups=0.56, wpb=14554, bsz=1014.7, num_updates=48300, lr=0.000160872, gnorm=1.19, clip=0, loss_scale=1440, train_wall=100, wall=50580
2022-08-02 05:07:13 | INFO | train_inner | epoch 014:    175 / 3715 loss=6.107, nll_loss=3.218, mask_ins=1.035, word_ins_ml=4.724, word_reposition=0.348, ppl=68.95, wps=14296.4, ups=0.97, wpb=14703.3, bsz=1024, num_updates=48400, lr=0.000160706, gnorm=1.189, clip=0, loss_scale=1024, train_wall=101, wall=50683
2022-08-02 05:08:55 | INFO | train_inner | epoch 014:    275 / 3715 loss=6.1, nll_loss=3.211, mask_ins=1.034, word_ins_ml=4.716, word_reposition=0.35, ppl=68.6, wps=14299, ups=0.98, wpb=14639.7, bsz=1024, num_updates=48500, lr=0.00016054, gnorm=1.204, clip=0, loss_scale=1024, train_wall=101, wall=50785
2022-08-02 05:10:38 | INFO | train_inner | epoch 014:    375 / 3715 loss=6.101, nll_loss=3.217, mask_ins=1.033, word_ins_ml=4.722, word_reposition=0.345, ppl=68.62, wps=14215.3, ups=0.97, wpb=14633.1, bsz=1024, num_updates=48600, lr=0.000160375, gnorm=1.182, clip=0, loss_scale=1024, train_wall=101, wall=50888
2022-08-02 05:12:21 | INFO | train_inner | epoch 014:    475 / 3715 loss=6.078, nll_loss=3.198, mask_ins=1.027, word_ins_ml=4.705, word_reposition=0.345, ppl=67.54, wps=14192.2, ups=0.97, wpb=14607.1, bsz=1024, num_updates=48700, lr=0.00016021, gnorm=1.196, clip=0, loss_scale=1024, train_wall=101, wall=50991
2022-08-02 05:14:04 | INFO | train_inner | epoch 014:    575 / 3715 loss=6.088, nll_loss=3.207, mask_ins=1.027, word_ins_ml=4.714, word_reposition=0.347, ppl=68.03, wps=14246.8, ups=0.97, wpb=14627.4, bsz=1024, num_updates=48800, lr=0.000160046, gnorm=1.174, clip=0, loss_scale=1516, train_wall=101, wall=51094
2022-08-02 05:15:47 | INFO | train_inner | epoch 014:    675 / 3715 loss=6.093, nll_loss=3.207, mask_ins=1.033, word_ins_ml=4.714, word_reposition=0.346, ppl=68.27, wps=14159.9, ups=0.97, wpb=14581, bsz=1024, num_updates=48900, lr=0.000159882, gnorm=1.186, clip=0, loss_scale=2048, train_wall=101, wall=51197
2022-08-02 05:17:30 | INFO | train_inner | epoch 014:    775 / 3715 loss=6.076, nll_loss=3.196, mask_ins=1.026, word_ins_ml=4.703, word_reposition=0.346, ppl=67.47, wps=14136.6, ups=0.97, wpb=14599.4, bsz=1024, num_updates=49000, lr=0.000159719, gnorm=1.158, clip=0, loss_scale=2048, train_wall=102, wall=51300
2022-08-02 05:19:13 | INFO | train_inner | epoch 014:    875 / 3715 loss=6.122, nll_loss=3.242, mask_ins=1.032, word_ins_ml=4.745, word_reposition=0.345, ppl=69.64, wps=14228.1, ups=0.97, wpb=14686.9, bsz=1024, num_updates=49100, lr=0.000159556, gnorm=1.18, clip=0, loss_scale=2048, train_wall=101, wall=51403
2022-08-02 05:20:56 | INFO | train_inner | epoch 014:    975 / 3715 loss=6.097, nll_loss=3.218, mask_ins=1.028, word_ins_ml=4.723, word_reposition=0.346, ppl=68.45, wps=14284.5, ups=0.97, wpb=14728.9, bsz=1024, num_updates=49200, lr=0.000159394, gnorm=1.165, clip=0, loss_scale=2048, train_wall=101, wall=51506
2022-08-02 05:22:40 | INFO | train_inner | epoch 014:   1075 / 3715 loss=6.093, nll_loss=3.214, mask_ins=1.028, word_ins_ml=4.719, word_reposition=0.345, ppl=68.25, wps=14195.8, ups=0.97, wpb=14660.9, bsz=1024, num_updates=49300, lr=0.000159232, gnorm=1.168, clip=0, loss_scale=2785, train_wall=102, wall=51610
2022-08-02 05:24:22 | INFO | train_inner | epoch 014:   1175 / 3715 loss=6.111, nll_loss=3.223, mask_ins=1.032, word_ins_ml=4.727, word_reposition=0.352, ppl=69.12, wps=14391.9, ups=0.98, wpb=14729.5, bsz=1024, num_updates=49400, lr=0.000159071, gnorm=1.18, clip=0, loss_scale=4096, train_wall=101, wall=51712
2022-08-02 05:26:04 | INFO | train_inner | epoch 014:   1275 / 3715 loss=6.07, nll_loss=3.186, mask_ins=1.031, word_ins_ml=4.694, word_reposition=0.344, ppl=67.18, wps=14473.7, ups=0.98, wpb=14700.8, bsz=1024, num_updates=49500, lr=0.00015891, gnorm=1.181, clip=0, loss_scale=4096, train_wall=100, wall=51813
2022-08-02 05:27:45 | INFO | train_inner | epoch 014:   1375 / 3715 loss=6.122, nll_loss=3.238, mask_ins=1.03, word_ins_ml=4.741, word_reposition=0.352, ppl=69.63, wps=14327.7, ups=0.98, wpb=14596, bsz=1024, num_updates=49600, lr=0.00015875, gnorm=1.171, clip=0, loss_scale=4096, train_wall=100, wall=51915
2022-08-02 05:28:17 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 05:29:28 | INFO | train_inner | epoch 014:   1476 / 3715 loss=6.112, nll_loss=3.228, mask_ins=1.033, word_ins_ml=4.731, word_reposition=0.348, ppl=69.18, wps=14360.8, ups=0.97, wpb=14765.9, bsz=1024, num_updates=49700, lr=0.00015859, gnorm=1.203, clip=0, loss_scale=2656, train_wall=101, wall=52018
2022-08-02 05:31:10 | INFO | train_inner | epoch 014:   1576 / 3715 loss=6.117, nll_loss=3.229, mask_ins=1.035, word_ins_ml=4.732, word_reposition=0.351, ppl=69.43, wps=14359.6, ups=0.98, wpb=14627, bsz=1024, num_updates=49800, lr=0.000158431, gnorm=1.189, clip=0, loss_scale=2048, train_wall=100, wall=52120
2022-08-02 05:32:52 | INFO | train_inner | epoch 014:   1676 / 3715 loss=6.11, nll_loss=3.225, mask_ins=1.035, word_ins_ml=4.729, word_reposition=0.347, ppl=69.06, wps=14381.2, ups=0.98, wpb=14623.2, bsz=1024, num_updates=49900, lr=0.000158272, gnorm=1.19, clip=0, loss_scale=2048, train_wall=100, wall=52222
2022-08-02 05:34:33 | INFO | train_inner | epoch 014:   1776 / 3715 loss=6.097, nll_loss=3.219, mask_ins=1.026, word_ins_ml=4.723, word_reposition=0.347, ppl=68.43, wps=14576.9, ups=0.99, wpb=14782.1, bsz=1024, num_updates=50000, lr=0.000158114, gnorm=1.197, clip=0, loss_scale=2048, train_wall=100, wall=52323
2022-08-02 05:36:14 | INFO | train_inner | epoch 014:   1876 / 3715 loss=6.089, nll_loss=3.211, mask_ins=1.025, word_ins_ml=4.716, word_reposition=0.347, ppl=68.07, wps=14545.1, ups=0.99, wpb=14708, bsz=1024, num_updates=50100, lr=0.000157956, gnorm=1.231, clip=0, loss_scale=2048, train_wall=99, wall=52424
2022-08-02 05:37:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 05:37:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 05:37:57 | INFO | train_inner | epoch 014:   1978 / 3715 loss=6.119, nll_loss=3.234, mask_ins=1.033, word_ins_ml=4.737, word_reposition=0.349, ppl=69.52, wps=14213.7, ups=0.97, wpb=14668.4, bsz=1024, num_updates=50200, lr=0.000157799, gnorm=1.371, clip=0, loss_scale=2409, train_wall=101, wall=52527
2022-08-02 05:39:39 | INFO | train_inner | epoch 014:   2078 / 3715 loss=6.127, nll_loss=3.245, mask_ins=1.034, word_ins_ml=4.746, word_reposition=0.347, ppl=69.89, wps=14396.8, ups=0.98, wpb=14620.1, bsz=1024, num_updates=50300, lr=0.000157642, gnorm=1.306, clip=0, loss_scale=1024, train_wall=100, wall=52629
2022-08-02 05:41:22 | INFO | train_inner | epoch 014:   2178 / 3715 loss=6.115, nll_loss=3.235, mask_ins=1.033, word_ins_ml=4.737, word_reposition=0.345, ppl=69.33, wps=14412.3, ups=0.98, wpb=14770.5, bsz=1024, num_updates=50400, lr=0.000157485, gnorm=1.228, clip=0, loss_scale=1024, train_wall=101, wall=52731
2022-08-02 05:42:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-08-02 05:43:05 | INFO | train_inner | epoch 014:   2279 / 3715 loss=6.113, nll_loss=3.231, mask_ins=1.031, word_ins_ml=4.735, word_reposition=0.348, ppl=69.23, wps=14135.2, ups=0.97, wpb=14607.2, bsz=1024, num_updates=50500, lr=0.000157329, gnorm=1.249, clip=0, loss_scale=882, train_wall=102, wall=52835
2022-08-02 05:44:47 | INFO | train_inner | epoch 014:   2379 / 3715 loss=6.101, nll_loss=3.226, mask_ins=1.029, word_ins_ml=4.73, word_reposition=0.342, ppl=68.65, wps=14401.8, ups=0.98, wpb=14672.4, bsz=1024, num_updates=50600, lr=0.000157174, gnorm=1.288, clip=0, loss_scale=512, train_wall=100, wall=52937
2022-08-02 05:46:29 | INFO | train_inner | epoch 014:   2479 / 3715 loss=6.095, nll_loss=3.215, mask_ins=1.026, word_ins_ml=4.72, word_reposition=0.349, ppl=68.36, wps=14329.2, ups=0.98, wpb=14694, bsz=1024, num_updates=50700, lr=0.000157019, gnorm=1.185, clip=0, loss_scale=512, train_wall=101, wall=53039
2022-08-02 05:48:12 | INFO | train_inner | epoch 014:   2579 / 3715 loss=6.113, nll_loss=3.234, mask_ins=1.031, word_ins_ml=4.736, word_reposition=0.346, ppl=69.21, wps=14089.7, ups=0.97, wpb=14498.8, bsz=1024, num_updates=50800, lr=0.000156864, gnorm=1.283, clip=0, loss_scale=512, train_wall=101, wall=53142
2022-08-02 05:49:55 | INFO | train_inner | epoch 014:   2679 / 3715 loss=6.096, nll_loss=3.216, mask_ins=1.029, word_ins_ml=4.721, word_reposition=0.346, ppl=68.39, wps=14136.6, ups=0.97, wpb=14559.5, bsz=1024, num_updates=50900, lr=0.00015671, gnorm=1.187, clip=0, loss_scale=512, train_wall=101, wall=53245
2022-08-02 05:51:36 | INFO | train_inner | epoch 014:   2779 / 3715 loss=6.124, nll_loss=3.239, mask_ins=1.033, word_ins_ml=4.741, word_reposition=0.35, ppl=69.74, wps=14487, ups=0.99, wpb=14671.4, bsz=1024, num_updates=51000, lr=0.000156556, gnorm=1.176, clip=0, loss_scale=594, train_wall=100, wall=53346
2022-08-02 05:53:18 | INFO | train_inner | epoch 014:   2879 / 3715 loss=6.115, nll_loss=3.229, mask_ins=1.034, word_ins_ml=4.732, word_reposition=0.349, ppl=69.33, wps=14470.9, ups=0.99, wpb=14635.4, bsz=1024, num_updates=51100, lr=0.000156403, gnorm=1.172, clip=0, loss_scale=1024, train_wall=99, wall=53448
2022-08-02 05:54:59 | INFO | train_inner | epoch 014:   2979 / 3715 loss=6.102, nll_loss=3.227, mask_ins=1.032, word_ins_ml=4.73, word_reposition=0.34, ppl=68.71, wps=14517.4, ups=0.99, wpb=14679.6, bsz=1023.8, num_updates=51200, lr=0.00015625, gnorm=1.163, clip=0, loss_scale=1024, train_wall=99, wall=53549
2022-08-02 05:56:40 | INFO | train_inner | epoch 014:   3079 / 3715 loss=6.115, nll_loss=3.236, mask_ins=1.034, word_ins_ml=4.738, word_reposition=0.343, ppl=69.33, wps=14541, ups=0.99, wpb=14697.9, bsz=1024, num_updates=51300, lr=0.000156098, gnorm=1.156, clip=0, loss_scale=1024, train_wall=99, wall=53650
2022-08-02 05:58:21 | INFO | train_inner | epoch 014:   3179 / 3715 loss=6.096, nll_loss=3.221, mask_ins=1.025, word_ins_ml=4.725, word_reposition=0.346, ppl=68.4, wps=14499.5, ups=0.99, wpb=14627.7, bsz=1024, num_updates=51400, lr=0.000155946, gnorm=1.183, clip=0, loss_scale=1024, train_wall=99, wall=53751
2022-08-02 06:00:02 | INFO | train_inner | epoch 014:   3279 / 3715 loss=6.128, nll_loss=3.245, mask_ins=1.035, word_ins_ml=4.746, word_reposition=0.347, ppl=69.94, wps=14484.8, ups=0.99, wpb=14660, bsz=1024, num_updates=51500, lr=0.000155794, gnorm=1.175, clip=0, loss_scale=1065, train_wall=99, wall=53852
2022-08-02 06:01:43 | INFO | train_inner | epoch 014:   3379 / 3715 loss=6.095, nll_loss=3.215, mask_ins=1.03, word_ins_ml=4.72, word_reposition=0.345, ppl=68.34, wps=14434.5, ups=0.99, wpb=14633.7, bsz=1024, num_updates=51600, lr=0.000155643, gnorm=1.186, clip=0, loss_scale=2048, train_wall=100, wall=53953
2022-08-02 06:03:25 | INFO | train_inner | epoch 014:   3479 / 3715 loss=6.097, nll_loss=3.208, mask_ins=1.034, word_ins_ml=4.714, word_reposition=0.349, ppl=68.46, wps=14455.4, ups=0.98, wpb=14728.3, bsz=1024, num_updates=51700, lr=0.000155493, gnorm=1.158, clip=0, loss_scale=2048, train_wall=100, wall=54055
2022-08-02 06:05:07 | INFO | train_inner | epoch 014:   3579 / 3715 loss=6.092, nll_loss=3.217, mask_ins=1.029, word_ins_ml=4.721, word_reposition=0.342, ppl=68.2, wps=14456.3, ups=0.98, wpb=14714, bsz=1024, num_updates=51800, lr=0.000155342, gnorm=1.162, clip=0, loss_scale=2048, train_wall=100, wall=54157
2022-08-02 06:06:49 | INFO | train_inner | epoch 014:   3679 / 3715 loss=6.101, nll_loss=3.221, mask_ins=1.027, word_ins_ml=4.725, word_reposition=0.349, ppl=68.66, wps=14540, ups=0.98, wpb=14783.1, bsz=1024, num_updates=51900, lr=0.000155193, gnorm=1.162, clip=0, loss_scale=2048, train_wall=100, wall=54259
2022-08-02 06:07:25 | INFO | train | epoch 014 | loss 6.104 | nll_loss 3.222 | mask_ins 1.031 | word_ins_ml 4.726 | word_reposition 0.347 | ppl 68.78 | wps 14065 | ups 0.96 | wpb 14662.7 | bsz 1023.7 | num_updates 51936 | lr 0.000155139 | gnorm 1.198 | clip 0 | loss_scale 1690 | train_wall 3726 | wall 54294
2022-08-02 06:08:34 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 6.238 | nll_loss 3.237 | mask_ins 1.049 | word_ins_ml 4.81 | word_reposition 0.379 | ppl 75.48 | wps 39325.8 | wpb 1849.4 | bsz 127.9 | num_updates 51936 | best_loss 6.238
2022-08-02 06:08:42 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 14 @ 51936 updates, score 6.238) (writing took 7.277477588504553 seconds)
2022-08-02 06:09:47 | INFO | train_inner | epoch 015:     64 / 3715 loss=6.09, nll_loss=3.204, mask_ins=1.027, word_ins_ml=4.711, word_reposition=0.352, ppl=68.11, wps=8192.5, ups=0.56, wpb=14601.3, bsz=1014.7, num_updates=52000, lr=0.000155043, gnorm=1.208, clip=0, loss_scale=2048, train_wall=99, wall=54437
2022-08-02 06:11:29 | INFO | train_inner | epoch 015:    164 / 3715 loss=6.061, nll_loss=3.177, mask_ins=1.032, word_ins_ml=4.686, word_reposition=0.343, ppl=66.79, wps=14507.2, ups=0.98, wpb=14768.6, bsz=1024, num_updates=52100, lr=0.000154895, gnorm=1.22, clip=0, loss_scale=3932, train_wall=100, wall=54539
2022-08-02 06:13:10 | INFO | train_inner | epoch 015:    264 / 3715 loss=6.06, nll_loss=3.183, mask_ins=1.026, word_ins_ml=4.691, word_reposition=0.343, ppl=66.7, wps=14348, ups=0.98, wpb=14603.5, bsz=1024, num_updates=52200, lr=0.000154746, gnorm=1.17, clip=0, loss_scale=4096, train_wall=100, wall=54640
2022-08-02 06:14:52 | INFO | train_inner | epoch 015:    364 / 3715 loss=6.059, nll_loss=3.187, mask_ins=1.018, word_ins_ml=4.695, word_reposition=0.345, ppl=66.67, wps=14411.9, ups=0.98, wpb=14702.2, bsz=1024, num_updates=52300, lr=0.000154598, gnorm=1.189, clip=0, loss_scale=4096, train_wall=100, wall=54742
2022-08-02 06:16:34 | INFO | train_inner | epoch 015:    464 / 3715 loss=6.046, nll_loss=3.169, mask_ins=1.023, word_ins_ml=4.679, word_reposition=0.344, ppl=66.06, wps=14492.3, ups=0.98, wpb=14740, bsz=1024, num_updates=52400, lr=0.000154451, gnorm=1.188, clip=0, loss_scale=4096, train_wall=100, wall=54844
2022-08-02 06:18:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 06:18:17 | INFO | train_inner | epoch 015:    565 / 3715 loss=6.065, nll_loss=3.194, mask_ins=1.023, word_ins_ml=4.701, word_reposition=0.341, ppl=66.96, wps=14237.8, ups=0.97, wpb=14604.5, bsz=1024, num_updates=52500, lr=0.000154303, gnorm=1.183, clip=0, loss_scale=4035, train_wall=101, wall=54947
2022-08-02 06:19:58 | INFO | train_inner | epoch 015:    665 / 3715 loss=6.041, nll_loss=3.161, mask_ins=1.023, word_ins_ml=4.672, word_reposition=0.346, ppl=65.86, wps=14395.6, ups=0.98, wpb=14635.4, bsz=1024, num_updates=52600, lr=0.000154157, gnorm=1.172, clip=0, loss_scale=2048, train_wall=100, wall=55048
2022-08-02 06:21:41 | INFO | train_inner | epoch 015:    765 / 3715 loss=6.06, nll_loss=3.178, mask_ins=1.026, word_ins_ml=4.688, word_reposition=0.347, ppl=66.7, wps=14407.1, ups=0.97, wpb=14796.4, bsz=1024, num_updates=52700, lr=0.00015401, gnorm=1.184, clip=0, loss_scale=2048, train_wall=101, wall=55151
2022-08-02 06:23:26 | INFO | train_inner | epoch 015:    865 / 3715 loss=6.065, nll_loss=3.184, mask_ins=1.024, word_ins_ml=4.693, word_reposition=0.349, ppl=66.94, wps=13916.4, ups=0.95, wpb=14628.6, bsz=1024, num_updates=52800, lr=0.000153864, gnorm=1.187, clip=0, loss_scale=2048, train_wall=103, wall=55256
2022-08-02 06:25:11 | INFO | train_inner | epoch 015:    965 / 3715 loss=6.072, nll_loss=3.189, mask_ins=1.024, word_ins_ml=4.696, word_reposition=0.351, ppl=67.29, wps=14043.8, ups=0.95, wpb=14728.7, bsz=1024, num_updates=52900, lr=0.000153719, gnorm=1.186, clip=0, loss_scale=2048, train_wall=103, wall=55361
2022-08-02 06:26:54 | INFO | train_inner | epoch 015:   1065 / 3715 loss=6.067, nll_loss=3.191, mask_ins=1.025, word_ins_ml=4.699, word_reposition=0.342, ppl=67.03, wps=14154.6, ups=0.98, wpb=14508.9, bsz=1024, num_updates=53000, lr=0.000153574, gnorm=1.184, clip=0, loss_scale=2048, train_wall=101, wall=55464
2022-08-02 06:28:36 | INFO | train_inner | epoch 015:   1165 / 3715 loss=6.061, nll_loss=3.184, mask_ins=1.019, word_ins_ml=4.692, word_reposition=0.349, ppl=66.74, wps=14384.8, ups=0.98, wpb=14712.8, bsz=1023.8, num_updates=53100, lr=0.000153429, gnorm=1.206, clip=0, loss_scale=3912, train_wall=101, wall=55566
2022-08-02 06:30:18 | INFO | train_inner | epoch 015:   1265 / 3715 loss=6.074, nll_loss=3.191, mask_ins=1.027, word_ins_ml=4.699, word_reposition=0.349, ppl=67.38, wps=14368.6, ups=0.98, wpb=14694.4, bsz=1024, num_updates=53200, lr=0.000153285, gnorm=1.169, clip=0, loss_scale=4096, train_wall=101, wall=55668
2022-08-02 06:32:00 | INFO | train_inner | epoch 015:   1365 / 3715 loss=6.062, nll_loss=3.185, mask_ins=1.028, word_ins_ml=4.693, word_reposition=0.341, ppl=66.8, wps=14528.7, ups=0.98, wpb=14789.9, bsz=1024, num_updates=53300, lr=0.000153141, gnorm=1.17, clip=0, loss_scale=4096, train_wall=100, wall=55770
2022-08-02 06:32:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 06:33:43 | INFO | train_inner | epoch 015:   1466 / 3715 loss=6.09, nll_loss=3.209, mask_ins=1.025, word_ins_ml=4.715, word_reposition=0.35, ppl=68.1, wps=14148.6, ups=0.97, wpb=14588.7, bsz=1024, num_updates=53400, lr=0.000152998, gnorm=1.202, clip=0, loss_scale=2312, train_wall=101, wall=55873
2022-08-02 06:35:24 | INFO | train_inner | epoch 015:   1566 / 3715 loss=6.058, nll_loss=3.184, mask_ins=1.025, word_ins_ml=4.692, word_reposition=0.341, ppl=66.64, wps=14393.7, ups=0.99, wpb=14598.7, bsz=1024, num_updates=53500, lr=0.000152854, gnorm=1.2, clip=0, loss_scale=2048, train_wall=100, wall=55974
2022-08-02 06:37:06 | INFO | train_inner | epoch 015:   1666 / 3715 loss=6.071, nll_loss=3.19, mask_ins=1.023, word_ins_ml=4.698, word_reposition=0.349, ppl=67.21, wps=14478.9, ups=0.99, wpb=14676.4, bsz=1024, num_updates=53600, lr=0.000152712, gnorm=1.183, clip=0, loss_scale=2048, train_wall=100, wall=56076
2022-08-02 06:38:48 | INFO | train_inner | epoch 015:   1766 / 3715 loss=6.06, nll_loss=3.182, mask_ins=1.031, word_ins_ml=4.691, word_reposition=0.338, ppl=66.72, wps=14456.5, ups=0.98, wpb=14708.9, bsz=1024, num_updates=53700, lr=0.00015257, gnorm=1.181, clip=0, loss_scale=2048, train_wall=100, wall=56178
2022-08-02 06:40:29 | INFO | train_inner | epoch 015:   1866 / 3715 loss=6.06, nll_loss=3.189, mask_ins=1.021, word_ins_ml=4.697, word_reposition=0.343, ppl=66.74, wps=14420.9, ups=0.98, wpb=14651, bsz=1024, num_updates=53800, lr=0.000152428, gnorm=1.173, clip=0, loss_scale=2048, train_wall=100, wall=56279
2022-08-02 06:42:10 | INFO | train_inner | epoch 015:   1966 / 3715 loss=6.095, nll_loss=3.222, mask_ins=1.03, word_ins_ml=4.726, word_reposition=0.339, ppl=68.35, wps=14385.3, ups=0.99, wpb=14570, bsz=1024, num_updates=53900, lr=0.000152286, gnorm=1.181, clip=0, loss_scale=3604, train_wall=100, wall=56380
2022-08-02 06:43:52 | INFO | train_inner | epoch 015:   2066 / 3715 loss=6.077, nll_loss=3.201, mask_ins=1.026, word_ins_ml=4.708, word_reposition=0.343, ppl=67.51, wps=14425, ups=0.98, wpb=14661.4, bsz=1024, num_updates=54000, lr=0.000152145, gnorm=1.197, clip=0, loss_scale=4096, train_wall=100, wall=56482
2022-08-02 06:45:34 | INFO | train_inner | epoch 015:   2166 / 3715 loss=6.072, nll_loss=3.197, mask_ins=1.03, word_ins_ml=4.703, word_reposition=0.339, ppl=67.26, wps=14339.3, ups=0.98, wpb=14605.4, bsz=1024, num_updates=54100, lr=0.000152004, gnorm=1.18, clip=0, loss_scale=4096, train_wall=100, wall=56584
2022-08-02 06:47:15 | INFO | train_inner | epoch 015:   2266 / 3715 loss=6.052, nll_loss=3.177, mask_ins=1.02, word_ins_ml=4.686, word_reposition=0.346, ppl=66.33, wps=14438.2, ups=0.99, wpb=14649.2, bsz=1024, num_updates=54200, lr=0.000151864, gnorm=1.206, clip=0, loss_scale=4096, train_wall=100, wall=56685
2022-08-02 06:48:58 | INFO | train_inner | epoch 015:   2366 / 3715 loss=6.08, nll_loss=3.206, mask_ins=1.023, word_ins_ml=4.712, word_reposition=0.345, ppl=67.65, wps=14468.5, ups=0.98, wpb=14780.9, bsz=1024, num_updates=54300, lr=0.000151724, gnorm=1.173, clip=0, loss_scale=4096, train_wall=100, wall=56788
2022-08-02 06:50:40 | INFO | train_inner | epoch 015:   2466 / 3715 loss=6.072, nll_loss=3.198, mask_ins=1.027, word_ins_ml=4.705, word_reposition=0.341, ppl=67.3, wps=14439, ups=0.98, wpb=14734.4, bsz=1024, num_updates=54400, lr=0.000151585, gnorm=1.18, clip=0, loss_scale=6717, train_wall=100, wall=56890
2022-08-02 06:52:22 | INFO | train_inner | epoch 015:   2566 / 3715 loss=6.069, nll_loss=3.204, mask_ins=1.017, word_ins_ml=4.71, word_reposition=0.341, ppl=67.11, wps=14331.3, ups=0.98, wpb=14611.4, bsz=1024, num_updates=54500, lr=0.000151446, gnorm=1.171, clip=0, loss_scale=8192, train_wall=100, wall=56992
2022-08-02 06:53:46 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2022-08-02 06:54:05 | INFO | train_inner | epoch 015:   2667 / 3715 loss=6.077, nll_loss=3.2, mask_ins=1.024, word_ins_ml=4.706, word_reposition=0.347, ppl=67.52, wps=14061.9, ups=0.97, wpb=14533.8, bsz=1024, num_updates=54600, lr=0.000151307, gnorm=1.182, clip=0, loss_scale=7381, train_wall=102, wall=57095
2022-08-02 06:55:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 06:55:49 | INFO | train_inner | epoch 015:   2768 / 3715 loss=6.084, nll_loss=3.208, mask_ins=1.02, word_ins_ml=4.713, word_reposition=0.352, ppl=67.84, wps=14095.8, ups=0.97, wpb=14605.5, bsz=1024, num_updates=54700, lr=0.000151169, gnorm=1.166, clip=0, loss_scale=3934, train_wall=102, wall=57199
2022-08-02 06:57:31 | INFO | train_inner | epoch 015:   2868 / 3715 loss=6.062, nll_loss=3.188, mask_ins=1.024, word_ins_ml=4.695, word_reposition=0.343, ppl=66.82, wps=14386.4, ups=0.98, wpb=14727.3, bsz=1024, num_updates=54800, lr=0.000151031, gnorm=1.176, clip=0, loss_scale=2048, train_wall=101, wall=57301
2022-08-02 06:57:59 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 06:59:14 | INFO | train_inner | epoch 015:   2969 / 3715 loss=6.068, nll_loss=3.184, mask_ins=1.024, word_ins_ml=4.692, word_reposition=0.352, ppl=67.07, wps=14375.9, ups=0.97, wpb=14755.1, bsz=1024, num_updates=54900, lr=0.000150893, gnorm=1.185, clip=0, loss_scale=1298, train_wall=101, wall=57404
2022-08-02 07:00:55 | INFO | train_inner | epoch 015:   3069 / 3715 loss=6.077, nll_loss=3.202, mask_ins=1.021, word_ins_ml=4.708, word_reposition=0.348, ppl=67.5, wps=14447.6, ups=0.99, wpb=14626.1, bsz=1024, num_updates=55000, lr=0.000150756, gnorm=1.171, clip=0, loss_scale=1024, train_wall=99, wall=57505
2022-08-02 07:02:37 | INFO | train_inner | epoch 015:   3169 / 3715 loss=6.069, nll_loss=3.207, mask_ins=1.024, word_ins_ml=4.711, word_reposition=0.334, ppl=67.11, wps=14348.9, ups=0.98, wpb=14610.8, bsz=1024, num_updates=55100, lr=0.000150619, gnorm=1.198, clip=0, loss_scale=1024, train_wall=100, wall=57607
2022-08-02 07:03:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-08-02 07:04:19 | INFO | train_inner | epoch 015:   3270 / 3715 loss=6.073, nll_loss=3.191, mask_ins=1.024, word_ins_ml=4.698, word_reposition=0.351, ppl=67.32, wps=14253, ups=0.97, wpb=14648.6, bsz=1024, num_updates=55200, lr=0.000150482, gnorm=1.261, clip=0, loss_scale=801, train_wall=101, wall=57709
2022-08-02 07:06:01 | INFO | train_inner | epoch 015:   3370 / 3715 loss=6.052, nll_loss=3.176, mask_ins=1.021, word_ins_ml=4.684, word_reposition=0.347, ppl=66.37, wps=14383.7, ups=0.98, wpb=14625.6, bsz=1024, num_updates=55300, lr=0.000150346, gnorm=1.22, clip=0, loss_scale=512, train_wall=100, wall=57811
2022-08-02 07:07:43 | INFO | train_inner | epoch 015:   3470 / 3715 loss=6.074, nll_loss=3.202, mask_ins=1.021, word_ins_ml=4.708, word_reposition=0.345, ppl=67.38, wps=14428.1, ups=0.98, wpb=14657.5, bsz=1024, num_updates=55400, lr=0.00015021, gnorm=1.178, clip=0, loss_scale=512, train_wall=100, wall=57913
2022-08-02 07:09:25 | INFO | train_inner | epoch 015:   3570 / 3715 loss=6.058, nll_loss=3.183, mask_ins=1.018, word_ins_ml=4.691, word_reposition=0.348, ppl=66.62, wps=14368.1, ups=0.98, wpb=14639.3, bsz=1024, num_updates=55500, lr=0.000150075, gnorm=1.18, clip=0, loss_scale=512, train_wall=100, wall=58015
2022-08-02 07:09:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-02 07:11:08 | INFO | train_inner | epoch 015:   3671 / 3715 loss=6.163, nll_loss=3.2, mask_ins=1.029, word_ins_ml=4.706, word_reposition=0.427, ppl=71.64, wps=14114.2, ups=0.96, wpb=14657.4, bsz=1024, num_updates=55600, lr=0.00014994, gnorm=2.679, clip=1, loss_scale=317, train_wall=102, wall=58118
2022-08-02 07:11:53 | INFO | train | epoch 015 | loss 6.071 | nll_loss 3.191 | mask_ins 1.024 | word_ins_ml 4.698 | word_reposition 0.348 | ppl 67.21 | wps 14052.7 | ups 0.96 | wpb 14662 | bsz 1023.7 | num_updates 55644 | lr 0.000149881 | gnorm 1.236 | clip 0 | loss_scale 2934 | train_wall 3727 | wall 58163
2022-08-02 07:13:03 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 6.295 | nll_loss 3.229 | mask_ins 1.053 | word_ins_ml 4.795 | word_reposition 0.447 | ppl 78.53 | wps 39446.2 | wpb 1849.4 | bsz 127.9 | num_updates 55644 | best_loss 6.238
2022-08-02 07:13:07 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_last.pt (epoch 15 @ 55644 updates, score 6.295) (writing took 4.439945748075843 seconds)
2022-08-02 07:14:05 | INFO | train_inner | epoch 016:     56 / 3715 loss=6.128, nll_loss=3.182, mask_ins=1.027, word_ins_ml=4.691, word_reposition=0.41, ppl=69.93, wps=8330.1, ups=0.57, wpb=14729.9, bsz=1014.7, num_updates=55700, lr=0.000149805, gnorm=2.037, clip=0, loss_scale=256, train_wall=101, wall=58295
2022-08-02 07:15:49 | INFO | train_inner | epoch 016:    156 / 3715 loss=6.015, nll_loss=3.14, mask_ins=1.014, word_ins_ml=4.653, word_reposition=0.347, ppl=64.66, wps=14227.9, ups=0.97, wpb=14728.8, bsz=1024, num_updates=55800, lr=0.000149671, gnorm=1.29, clip=0, loss_scale=256, train_wall=102, wall=58399
2022-08-02 07:17:31 | INFO | train_inner | epoch 016:    256 / 3715 loss=6.024, nll_loss=3.143, mask_ins=1.013, word_ins_ml=4.656, word_reposition=0.354, ppl=65.07, wps=14281.5, ups=0.98, wpb=14642.8, bsz=1024, num_updates=55900, lr=0.000149537, gnorm=1.544, clip=0, loss_scale=256, train_wall=101, wall=58501
2022-08-02 07:19:16 | INFO | train_inner | epoch 016:    356 / 3715 loss=6.036, nll_loss=3.157, mask_ins=1.018, word_ins_ml=4.668, word_reposition=0.35, ppl=65.6, wps=14073.9, ups=0.96, wpb=14720.3, bsz=1024, num_updates=56000, lr=0.000149404, gnorm=1.274, clip=0, loss_scale=256, train_wall=103, wall=58606
2022-08-02 07:21:00 | INFO | train_inner | epoch 016:    456 / 3715 loss=6.038, nll_loss=3.153, mask_ins=1.021, word_ins_ml=4.665, word_reposition=0.352, ppl=65.72, wps=14126.7, ups=0.96, wpb=14670.8, bsz=1024, num_updates=56100, lr=0.00014927, gnorm=1.203, clip=0, loss_scale=422, train_wall=102, wall=58710
2022-08-02 07:22:43 | INFO | train_inner | epoch 016:    556 / 3715 loss=6.045, nll_loss=3.178, mask_ins=1.02, word_ins_ml=4.687, word_reposition=0.338, ppl=66.04, wps=13975.2, ups=0.97, wpb=14478.8, bsz=1024, num_updates=56200, lr=0.000149137, gnorm=1.265, clip=0, loss_scale=512, train_wall=102, wall=58813
2022-08-02 07:24:29 | INFO | train_inner | epoch 016:    656 / 3715 loss=6.039, nll_loss=3.167, mask_ins=1.02, word_ins_ml=4.677, word_reposition=0.343, ppl=65.76, wps=13808.5, ups=0.94, wpb=14623.6, bsz=1024, num_updates=56300, lr=0.000149005, gnorm=1.191, clip=0, loss_scale=512, train_wall=104, wall=58919
2022-08-02 07:26:14 | INFO | train_inner | epoch 016:    756 / 3715 loss=6.035, nll_loss=3.157, mask_ins=1.016, word_ins_ml=4.668, word_reposition=0.35, ppl=65.55, wps=14191.3, ups=0.96, wpb=14815.8, bsz=1024, num_updates=56400, lr=0.000148873, gnorm=1.195, clip=0, loss_scale=512, train_wall=103, wall=59024
2022-08-02 07:27:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-02 07:27:58 | INFO | train_inner | epoch 016:    857 / 3715 loss=6.049, nll_loss=3.166, mask_ins=1.018, word_ins_ml=4.677, word_reposition=0.354, ppl=66.19, wps=14078.1, ups=0.96, wpb=14639.5, bsz=1024, num_updates=56500, lr=0.000148741, gnorm=1.333, clip=0, loss_scale=492, train_wall=102, wall=59128
2022-08-02 07:28:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-08-02 07:29:42 | INFO | train_inner | epoch 016:    958 / 3715 loss=6.022, nll_loss=3.139, mask_ins=1.019, word_ins_ml=4.653, word_reposition=0.35, ppl=64.98, wps=13991.9, ups=0.96, wpb=14645.4, bsz=1024, num_updates=56600, lr=0.00014861, gnorm=1.185, clip=0, loss_scale=196, train_wall=103, wall=59232
2022-08-02 07:31:27 | INFO | train_inner | epoch 016:   1058 / 3715 loss=6.044, nll_loss=3.165, mask_ins=1.02, word_ins_ml=4.675, word_reposition=0.349, ppl=65.96, wps=13879.5, ups=0.95, wpb=14590.1, bsz=1024, num_updates=56700, lr=0.000148478, gnorm=1.551, clip=0, loss_scale=128, train_wall=103, wall=59337
2022-08-02 07:33:11 | INFO | train_inner | epoch 016:   1158 / 3715 loss=6.047, nll_loss=3.171, mask_ins=1.021, word_ins_ml=4.681, word_reposition=0.345, ppl=66.1, wps=14187.9, ups=0.96, wpb=14738.6, bsz=1024, num_updates=56800, lr=0.000148348, gnorm=1.178, clip=0, loss_scale=128, train_wall=102, wall=59441
2022-08-02 07:34:55 | INFO | train_inner | epoch 016:   1258 / 3715 loss=6.036, nll_loss=3.168, mask_ins=1.016, word_ins_ml=4.678, word_reposition=0.342, ppl=65.6, wps=14239.9, ups=0.97, wpb=14719.8, bsz=1024, num_updates=56900, lr=0.000148217, gnorm=1.181, clip=0, loss_scale=128, train_wall=102, wall=59545
2022-08-02 07:36:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2022-08-02 07:36:37 | INFO | train_inner | epoch 016:   1359 / 3715 loss=6.03, nll_loss=3.159, mask_ins=1.015, word_ins_ml=4.67, word_reposition=0.345, ppl=65.32, wps=14362.6, ups=0.98, wpb=14703.1, bsz=1024, num_updates=57000, lr=0.000148087, gnorm=1.206, clip=0, loss_scale=108, train_wall=101, wall=59647
2022-08-02 07:38:18 | INFO | train_inner | epoch 016:   1459 / 3715 loss=6.051, nll_loss=3.172, mask_ins=1.02, word_ins_ml=4.681, word_reposition=0.349, ppl=66.28, wps=14522.4, ups=0.99, wpb=14725.5, bsz=1024, num_updates=57100, lr=0.000147957, gnorm=1.206, clip=0, loss_scale=64, train_wall=100, wall=59748
2022-08-02 07:40:01 | INFO | train_inner | epoch 016:   1559 / 3715 loss=6.023, nll_loss=3.146, mask_ins=1.02, word_ins_ml=4.658, word_reposition=0.345, ppl=65.05, wps=14287.5, ups=0.97, wpb=14657.9, bsz=1024, num_updates=57200, lr=0.000147828, gnorm=1.276, clip=0, loss_scale=64, train_wall=101, wall=59851
2022-08-02 07:41:44 | INFO | train_inner | epoch 016:   1659 / 3715 loss=6.022, nll_loss=3.157, mask_ins=1.021, word_ins_ml=4.668, word_reposition=0.334, ppl=65, wps=14176.8, ups=0.97, wpb=14656.7, bsz=1024, num_updates=57300, lr=0.000147699, gnorm=1.209, clip=0, loss_scale=64, train_wall=102, wall=59954
2022-08-02 07:43:28 | INFO | train_inner | epoch 016:   1759 / 3715 loss=6.035, nll_loss=3.168, mask_ins=1.015, word_ins_ml=4.677, word_reposition=0.342, ppl=65.59, wps=14212.2, ups=0.97, wpb=14655.7, bsz=1024, num_updates=57400, lr=0.00014757, gnorm=1.207, clip=0, loss_scale=64, train_wall=101, wall=60058
2022-08-02 07:45:12 | INFO | train_inner | epoch 016:   1859 / 3715 loss=6.052, nll_loss=3.175, mask_ins=1.016, word_ins_ml=4.684, word_reposition=0.353, ppl=66.36, wps=14016.8, ups=0.96, wpb=14619.2, bsz=1024, num_updates=57500, lr=0.000147442, gnorm=1.353, clip=0, loss_scale=77, train_wall=102, wall=60162
2022-08-02 07:46:57 | INFO | train_inner | epoch 016:   1959 / 3715 loss=6.029, nll_loss=3.151, mask_ins=1.02, word_ins_ml=4.662, word_reposition=0.347, ppl=65.29, wps=14030.2, ups=0.95, wpb=14705.9, bsz=1024, num_updates=57600, lr=0.000147314, gnorm=1.252, clip=0, loss_scale=128, train_wall=103, wall=60267
2022-08-02 07:48:41 | INFO | train_inner | epoch 016:   2059 / 3715 loss=6.046, nll_loss=3.174, mask_ins=1.018, word_ins_ml=4.683, word_reposition=0.345, ppl=66.08, wps=14110.1, ups=0.96, wpb=14648.2, bsz=1024, num_updates=57700, lr=0.000147186, gnorm=1.204, clip=0, loss_scale=128, train_wall=102, wall=60370
2022-08-02 07:50:24 | INFO | train_inner | epoch 016:   2159 / 3715 loss=6.058, nll_loss=3.172, mask_ins=1.022, word_ins_ml=4.681, word_reposition=0.355, ppl=66.63, wps=14325.5, ups=0.97, wpb=14811.8, bsz=1024, num_updates=57800, lr=0.000147059, gnorm=1.452, clip=0, loss_scale=128, train_wall=102, wall=60474
2022-08-02 07:52:07 | INFO | train_inner | epoch 016:   2259 / 3715 loss=6.072, nll_loss=3.194, mask_ins=1.023, word_ins_ml=4.7, word_reposition=0.349, ppl=67.29, wps=14244.6, ups=0.97, wpb=14634.8, bsz=1024, num_updates=57900, lr=0.000146932, gnorm=1.296, clip=0, loss_scale=128, train_wall=101, wall=60577
2022-08-02 07:53:48 | INFO | train_inner | epoch 016:   2359 / 3715 loss=6.05, nll_loss=3.171, mask_ins=1.023, word_ins_ml=4.68, word_reposition=0.347, ppl=66.26, wps=14397.8, ups=0.98, wpb=14629.8, bsz=1024, num_updates=58000, lr=0.000146805, gnorm=1.192, clip=0, loss_scale=138, train_wall=100, wall=60678
2022-08-02 07:55:31 | INFO | train_inner | epoch 016:   2459 / 3715 loss=6.017, nll_loss=3.147, mask_ins=1.014, word_ins_ml=4.66, word_reposition=0.343, ppl=64.75, wps=14361.8, ups=0.98, wpb=14696.8, bsz=1024, num_updates=58100, lr=0.000146679, gnorm=1.181, clip=0, loss_scale=256, train_wall=101, wall=60781
2022-08-02 07:57:15 | INFO | train_inner | epoch 016:   2559 / 3715 loss=6.058, nll_loss=3.184, mask_ins=1.023, word_ins_ml=4.691, word_reposition=0.344, ppl=66.63, wps=14115.2, ups=0.96, wpb=14730, bsz=1024, num_updates=58200, lr=0.000146553, gnorm=1.262, clip=0, loss_scale=256, train_wall=103, wall=60885
2022-08-02 07:59:00 | INFO | train_inner | epoch 016:   2659 / 3715 loss=6.033, nll_loss=3.172, mask_ins=1.015, word_ins_ml=4.681, word_reposition=0.337, ppl=65.48, wps=14030.5, ups=0.96, wpb=14680.5, bsz=1024, num_updates=58300, lr=0.000146427, gnorm=1.181, clip=0, loss_scale=256, train_wall=103, wall=60990
2022-08-02 08:00:45 | INFO | train_inner | epoch 016:   2759 / 3715 loss=6.028, nll_loss=3.168, mask_ins=1.015, word_ins_ml=4.677, word_reposition=0.336, ppl=65.25, wps=13874.8, ups=0.95, wpb=14630.2, bsz=1024, num_updates=58400, lr=0.000146301, gnorm=1.192, clip=0, loss_scale=256, train_wall=104, wall=61095
2022-08-02 08:02:29 | INFO | train_inner | epoch 016:   2859 / 3715 loss=6.034, nll_loss=3.161, mask_ins=1.017, word_ins_ml=4.672, word_reposition=0.345, ppl=65.52, wps=13991.3, ups=0.96, wpb=14615.7, bsz=1023.8, num_updates=58500, lr=0.000146176, gnorm=1.182, clip=0, loss_scale=256, train_wall=103, wall=61199
2022-08-02 08:04:14 | INFO | train_inner | epoch 016:   2959 / 3715 loss=6.045, nll_loss=3.175, mask_ins=1.018, word_ins_ml=4.684, word_reposition=0.343, ppl=66.04, wps=14205.1, ups=0.96, wpb=14787.4, bsz=1024, num_updates=58600, lr=0.000146052, gnorm=1.202, clip=0, loss_scale=502, train_wall=102, wall=61304
2022-08-02 08:05:56 | INFO | train_inner | epoch 016:   3059 / 3715 loss=6.054, nll_loss=3.177, mask_ins=1.023, word_ins_ml=4.686, word_reposition=0.345, ppl=66.42, wps=14136.6, ups=0.97, wpb=14520.8, bsz=1024, num_updates=58700, lr=0.000145927, gnorm=1.2, clip=0, loss_scale=512, train_wall=101, wall=61406
2022-08-02 08:07:39 | INFO | train_inner | epoch 016:   3159 / 3715 loss=6.037, nll_loss=3.162, mask_ins=1.021, word_ins_ml=4.672, word_reposition=0.345, ppl=65.67, wps=14117.8, ups=0.97, wpb=14531.6, bsz=1024, num_updates=58800, lr=0.000145803, gnorm=1.188, clip=0, loss_scale=512, train_wall=101, wall=61509
2022-08-02 08:09:22 | INFO | train_inner | epoch 016:   3259 / 3715 loss=6.031, nll_loss=3.158, mask_ins=1.018, word_ins_ml=4.668, word_reposition=0.345, ppl=65.4, wps=14279.6, ups=0.98, wpb=14642.5, bsz=1024, num_updates=58900, lr=0.000145679, gnorm=1.282, clip=0, loss_scale=512, train_wall=101, wall=61612
2022-08-02 08:11:05 | INFO | train_inner | epoch 016:   3359 / 3715 loss=6.049, nll_loss=3.186, mask_ins=1.016, word_ins_ml=4.693, word_reposition=0.341, ppl=66.23, wps=14240.1, ups=0.97, wpb=14636.3, bsz=1024, num_updates=59000, lr=0.000145556, gnorm=1.206, clip=0, loss_scale=512, train_wall=101, wall=61714
2022-08-02 08:12:47 | INFO | train_inner | epoch 016:   3459 / 3715 loss=6.052, nll_loss=3.178, mask_ins=1.017, word_ins_ml=4.687, word_reposition=0.349, ppl=66.35, wps=14337.3, ups=0.97, wpb=14730.5, bsz=1024, num_updates=59100, lr=0.000145432, gnorm=1.224, clip=0, loss_scale=942, train_wall=101, wall=61817
2022-08-02 08:14:30 | INFO | train_inner | epoch 016:   3559 / 3715 loss=6.06, nll_loss=3.195, mask_ins=1.017, word_ins_ml=4.701, word_reposition=0.342, ppl=66.71, wps=14197.5, ups=0.97, wpb=14605.8, bsz=1024, num_updates=59200, lr=0.00014531, gnorm=1.192, clip=0, loss_scale=1024, train_wall=101, wall=61920
2022-08-02 08:16:14 | INFO | train_inner | epoch 016:   3659 / 3715 loss=6.029, nll_loss=3.158, mask_ins=1.014, word_ins_ml=4.669, word_reposition=0.347, ppl=65.3, wps=14137.1, ups=0.97, wpb=14627.4, bsz=1024, num_updates=59300, lr=0.000145187, gnorm=1.18, clip=0, loss_scale=1024, train_wall=102, wall=62024
2022-08-02 08:17:11 | INFO | train | epoch 016 | loss 6.041 | nll_loss 3.166 | mask_ins 1.018 | word_ins_ml 4.676 | word_reposition 0.347 | ppl 65.83 | wps 13894.4 | ups 0.95 | wpb 14662.6 | bsz 1023.7 | num_updates 59356 | lr 0.000145118 | gnorm 1.262 | clip 0 | loss_scale 335 | train_wall 3776 | wall 62080
2022-08-02 08:18:21 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 6.189 | nll_loss 3.205 | mask_ins 1.043 | word_ins_ml 4.774 | word_reposition 0.372 | ppl 72.94 | wps 39145.1 | wpb 1849.4 | bsz 127.9 | num_updates 59356 | best_loss 6.189
2022-08-02 08:18:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_best.pt (epoch 16 @ 59356 updates, score 6.189) (writing took 6.984286937862635 seconds)
2022-08-02 08:19:13 | INFO | train_inner | epoch 017:     44 / 3715 loss=6.041, nll_loss=3.163, mask_ins=1.016, word_ins_ml=4.673, word_reposition=0.353, ppl=65.85, wps=8147.3, ups=0.56, wpb=14622.1, bsz=1014.7, num_updates=59400, lr=0.000145065, gnorm=1.229, clip=0, loss_scale=1024, train_wall=101, wall=62203
2022-08-02 08:20:57 | INFO | train_inner | epoch 017:    144 / 3715 loss=5.997, nll_loss=3.133, mask_ins=1.01, word_ins_ml=4.647, word_reposition=0.34, ppl=63.88, wps=14239, ups=0.97, wpb=14749.3, bsz=1024, num_updates=59500, lr=0.000144943, gnorm=1.19, clip=0, loss_scale=1024, train_wall=102, wall=62307
2022-08-02 08:22:42 | INFO | train_inner | epoch 017:    244 / 3715 loss=5.991, nll_loss=3.114, mask_ins=1.018, word_ins_ml=4.63, word_reposition=0.343, ppl=63.6, wps=13899.2, ups=0.95, wpb=14648.1, bsz=1024, num_updates=59600, lr=0.000144821, gnorm=1.212, clip=0, loss_scale=1761, train_wall=104, wall=62412
2022-08-02 08:24:28 | INFO | train_inner | epoch 017:    344 / 3715 loss=5.994, nll_loss=3.126, mask_ins=1.012, word_ins_ml=4.641, word_reposition=0.341, ppl=63.73, wps=13889.9, ups=0.95, wpb=14653.2, bsz=1024, num_updates=59700, lr=0.0001447, gnorm=1.199, clip=0, loss_scale=2048, train_wall=104, wall=62518
2022-08-02 08:26:11 | INFO | train_inner | epoch 017:    444 / 3715 loss=5.999, nll_loss=3.123, mask_ins=1.013, word_ins_ml=4.638, word_reposition=0.348, ppl=63.96, wps=14145.7, ups=0.97, wpb=14621.4, bsz=1024, num_updates=59800, lr=0.000144579, gnorm=1.21, clip=0, loss_scale=2048, train_wall=102, wall=62621
2022-08-02 08:27:54 | INFO | train_inner | epoch 017:    544 / 3715 loss=6.002, nll_loss=3.136, mask_ins=1.008, word_ins_ml=4.649, word_reposition=0.345, ppl=64.11, wps=14242.7, ups=0.97, wpb=14683.5, bsz=1024, num_updates=59900, lr=0.000144458, gnorm=1.202, clip=0, loss_scale=2048, train_wall=101, wall=62724
2022-08-02 08:29:37 | INFO | train_inner | epoch 017:    644 / 3715 loss=5.966, nll_loss=3.105, mask_ins=1.006, word_ins_ml=4.622, word_reposition=0.338, ppl=62.51, wps=14142.7, ups=0.97, wpb=14562, bsz=1024, num_updates=60000, lr=0.000144338, gnorm=1.21, clip=0, loss_scale=2048, train_wall=101, wall=62827
2022-08-02 08:31:20 | INFO | train_inner | epoch 017:    744 / 3715 loss=5.995, nll_loss=3.132, mask_ins=1.013, word_ins_ml=4.646, word_reposition=0.336, ppl=63.77, wps=14244.5, ups=0.97, wpb=14660.7, bsz=1024, num_updates=60100, lr=0.000144217, gnorm=1.215, clip=0, loss_scale=3277, train_wall=101, wall=62930
2022-08-02 08:33:03 | INFO | train_inner | epoch 017:    844 / 3715 loss=5.998, nll_loss=3.135, mask_ins=1.015, word_ins_ml=4.648, word_reposition=0.334, ppl=63.9, wps=13920, ups=0.97, wpb=14411.6, bsz=1024, num_updates=60200, lr=0.000144098, gnorm=1.233, clip=0, loss_scale=4096, train_wall=102, wall=63033
2022-08-02 08:34:48 | INFO | train_inner | epoch 017:    944 / 3715 loss=5.976, nll_loss=3.109, mask_ins=1.015, word_ins_ml=4.626, word_reposition=0.336, ppl=62.95, wps=14133.3, ups=0.96, wpb=14726.7, bsz=1024, num_updates=60300, lr=0.000143978, gnorm=1.184, clip=0, loss_scale=4096, train_wall=102, wall=63138
2022-08-02 08:35:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 08:36:32 | INFO | train_inner | epoch 017:   1045 / 3715 loss=5.985, nll_loss=3.115, mask_ins=1.011, word_ins_ml=4.631, word_reposition=0.344, ppl=63.35, wps=14154.7, ups=0.96, wpb=14712.6, bsz=1024, num_updates=60400, lr=0.000143859, gnorm=1.201, clip=0, loss_scale=2839, train_wall=102, wall=63242
2022-08-02 08:38:15 | INFO | train_inner | epoch 017:   1145 / 3715 loss=6.022, nll_loss=3.146, mask_ins=1.018, word_ins_ml=4.658, word_reposition=0.346, ppl=64.97, wps=14182, ups=0.97, wpb=14635.8, bsz=1024, num_updates=60500, lr=0.00014374, gnorm=1.203, clip=0, loss_scale=2048, train_wall=101, wall=63345
2022-08-02 08:39:58 | INFO | train_inner | epoch 017:   1245 / 3715 loss=5.999, nll_loss=3.136, mask_ins=1.012, word_ins_ml=4.649, word_reposition=0.338, ppl=63.95, wps=14197.1, ups=0.97, wpb=14639.3, bsz=1024, num_updates=60600, lr=0.000143621, gnorm=1.204, clip=0, loss_scale=2048, train_wall=101, wall=63448
2022-08-02 08:41:41 | INFO | train_inner | epoch 017:   1345 / 3715 loss=5.985, nll_loss=3.12, mask_ins=1.013, word_ins_ml=4.635, word_reposition=0.337, ppl=63.32, wps=14265.9, ups=0.97, wpb=14714.2, bsz=1024, num_updates=60700, lr=0.000143503, gnorm=1.21, clip=0, loss_scale=2048, train_wall=101, wall=63551
2022-08-02 08:42:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 08:42:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-08-02 08:43:26 | INFO | train_inner | epoch 017:   1447 / 3715 loss=6.016, nll_loss=3.15, mask_ins=1.017, word_ins_ml=4.662, word_reposition=0.337, ppl=64.7, wps=13900, ups=0.95, wpb=14625.7, bsz=1024, num_updates=60800, lr=0.000143385, gnorm=1.396, clip=0, loss_scale=1586, train_wall=103, wall=63656
2022-08-02 08:45:10 | INFO | train_inner | epoch 017:   1547 / 3715 loss=6, nll_loss=3.136, mask_ins=1.01, word_ins_ml=4.649, word_reposition=0.341, ppl=63.99, wps=14247.9, ups=0.97, wpb=14736.3, bsz=1024, num_updates=60900, lr=0.000143267, gnorm=1.224, clip=0, loss_scale=512, train_wall=102, wall=63760
2022-08-02 08:46:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-08-02 08:46:55 | INFO | train_inner | epoch 017:   1648 / 3715 loss=6.017, nll_loss=3.153, mask_ins=1.017, word_ins_ml=4.664, word_reposition=0.336, ppl=64.77, wps=13975.2, ups=0.95, wpb=14655.1, bsz=1024, num_updates=61000, lr=0.00014315, gnorm=1.739, clip=0, loss_scale=436, train_wall=103, wall=63865
2022-08-02 08:48:39 | INFO | train_inner | epoch 017:   1748 / 3715 loss=6.032, nll_loss=3.165, mask_ins=1.014, word_ins_ml=4.675, word_reposition=0.344, ppl=65.43, wps=14056.3, ups=0.96, wpb=14664.2, bsz=1024, num_updates=61100, lr=0.000143032, gnorm=1.27, clip=0, loss_scale=256, train_wall=103, wall=63969
2022-08-02 08:50:22 | INFO | train_inner | epoch 017:   1848 / 3715 loss=5.984, nll_loss=3.129, mask_ins=1.007, word_ins_ml=4.643, word_reposition=0.333, ppl=63.28, wps=14137.4, ups=0.97, wpb=14606, bsz=1024, num_updates=61200, lr=0.000142915, gnorm=1.203, clip=0, loss_scale=256, train_wall=102, wall=64072
2022-08-02 08:52:06 | INFO | train_inner | epoch 017:   1948 / 3715 loss=6.011, nll_loss=3.14, mask_ins=1.013, word_ins_ml=4.652, word_reposition=0.345, ppl=64.48, wps=14138.4, ups=0.96, wpb=14668.5, bsz=1024, num_updates=61300, lr=0.000142799, gnorm=1.21, clip=0, loss_scale=256, train_wall=102, wall=64176
2022-08-02 08:53:50 | INFO | train_inner | epoch 017:   2048 / 3715 loss=5.997, nll_loss=3.132, mask_ins=1.004, word_ins_ml=4.646, word_reposition=0.347, ppl=63.87, wps=14100.9, ups=0.96, wpb=14684.4, bsz=1024, num_updates=61400, lr=0.000142683, gnorm=1.39, clip=0, loss_scale=256, train_wall=102, wall=64280
2022-08-02 08:55:32 | INFO | train_inner | epoch 017:   2148 / 3715 loss=6.028, nll_loss=3.166, mask_ins=1.012, word_ins_ml=4.675, word_reposition=0.34, ppl=65.24, wps=14432.4, ups=0.98, wpb=14721.3, bsz=1024, num_updates=61500, lr=0.000142566, gnorm=1.21, clip=0, loss_scale=302, train_wall=100, wall=64382
2022-08-02 08:57:15 | INFO | train_inner | epoch 017:   2248 / 3715 loss=6.009, nll_loss=3.141, mask_ins=1.009, word_ins_ml=4.653, word_reposition=0.347, ppl=64.4, wps=14222.5, ups=0.97, wpb=14620.9, bsz=1023.8, num_updates=61600, lr=0.000142451, gnorm=1.231, clip=0, loss_scale=512, train_wall=101, wall=64485
2022-08-02 08:58:57 | INFO | train_inner | epoch 017:   2348 / 3715 loss=6.031, nll_loss=3.164, mask_ins=1.013, word_ins_ml=4.674, word_reposition=0.345, ppl=65.4, wps=14542.6, ups=0.98, wpb=14812.6, bsz=1024, num_updates=61700, lr=0.000142335, gnorm=1.202, clip=0, loss_scale=512, train_wall=100, wall=64587
2022-08-02 09:00:39 | INFO | train_inner | epoch 017:   2448 / 3715 loss=6.022, nll_loss=3.152, mask_ins=1.016, word_ins_ml=4.664, word_reposition=0.342, ppl=64.98, wps=14340, ups=0.98, wpb=14635, bsz=1024, num_updates=61800, lr=0.00014222, gnorm=1.373, clip=0, loss_scale=512, train_wall=100, wall=64689
2022-08-02 09:02:21 | INFO | train_inner | epoch 017:   2548 / 3715 loss=6.008, nll_loss=3.134, mask_ins=1.017, word_ins_ml=4.647, word_reposition=0.345, ppl=64.38, wps=14347.4, ups=0.98, wpb=14659.9, bsz=1024, num_updates=61900, lr=0.000142105, gnorm=1.302, clip=0, loss_scale=512, train_wall=100, wall=64791
2022-08-02 09:04:03 | INFO | train_inner | epoch 017:   2648 / 3715 loss=6.019, nll_loss=3.147, mask_ins=1.018, word_ins_ml=4.658, word_reposition=0.343, ppl=64.84, wps=14348.9, ups=0.98, wpb=14622.5, bsz=1024, num_updates=62000, lr=0.00014199, gnorm=1.202, clip=0, loss_scale=543, train_wall=100, wall=64893
2022-08-02 09:05:45 | INFO | train_inner | epoch 017:   2748 / 3715 loss=6.009, nll_loss=3.141, mask_ins=1.015, word_ins_ml=4.653, word_reposition=0.34, ppl=64.39, wps=14397, ups=0.98, wpb=14684.6, bsz=1024, num_updates=62100, lr=0.000141876, gnorm=1.198, clip=0, loss_scale=1024, train_wall=100, wall=64995
2022-08-02 09:07:27 | INFO | train_inner | epoch 017:   2848 / 3715 loss=6.009, nll_loss=3.141, mask_ins=1.016, word_ins_ml=4.653, word_reposition=0.34, ppl=64.39, wps=14356.4, ups=0.98, wpb=14654.3, bsz=1024, num_updates=62200, lr=0.000141762, gnorm=1.208, clip=0, loss_scale=1024, train_wall=100, wall=65097
2022-08-02 09:09:09 | INFO | train_inner | epoch 017:   2948 / 3715 loss=5.997, nll_loss=3.133, mask_ins=1.007, word_ins_ml=4.646, word_reposition=0.345, ppl=63.89, wps=14454.2, ups=0.98, wpb=14815.2, bsz=1024, num_updates=62300, lr=0.000141648, gnorm=1.207, clip=0, loss_scale=1024, train_wall=101, wall=65199
2022-08-02 09:10:51 | INFO | train_inner | epoch 017:   3048 / 3715 loss=6.027, nll_loss=3.159, mask_ins=1.015, word_ins_ml=4.669, word_reposition=0.344, ppl=65.21, wps=14409, ups=0.99, wpb=14621.9, bsz=1024, num_updates=62400, lr=0.000141535, gnorm=1.226, clip=0, loss_scale=1024, train_wall=100, wall=65301
2022-08-02 09:12:34 | INFO | train_inner | epoch 017:   3148 / 3715 loss=6.028, nll_loss=3.16, mask_ins=1.015, word_ins_ml=4.67, word_reposition=0.342, ppl=65.25, wps=14380.3, ups=0.97, wpb=14813.2, bsz=1024, num_updates=62500, lr=0.000141421, gnorm=1.2, clip=0, loss_scale=1024, train_wall=101, wall=65404
2022-08-02 09:14:18 | INFO | train_inner | epoch 017:   3248 / 3715 loss=5.997, nll_loss=3.138, mask_ins=1.011, word_ins_ml=4.65, word_reposition=0.336, ppl=63.87, wps=14138.4, ups=0.96, wpb=14674, bsz=1024, num_updates=62600, lr=0.000141308, gnorm=1.197, clip=0, loss_scale=1987, train_wall=102, wall=65508
2022-08-02 09:16:02 | INFO | train_inner | epoch 017:   3348 / 3715 loss=6.014, nll_loss=3.143, mask_ins=1.013, word_ins_ml=4.655, word_reposition=0.346, ppl=64.61, wps=14153.4, ups=0.96, wpb=14745.7, bsz=1024, num_updates=62700, lr=0.000141196, gnorm=1.218, clip=0, loss_scale=2048, train_wall=102, wall=65612
2022-08-02 09:17:44 | INFO | train_inner | epoch 017:   3448 / 3715 loss=6.004, nll_loss=3.14, mask_ins=1.011, word_ins_ml=4.653, word_reposition=0.341, ppl=64.17, wps=14230.5, ups=0.98, wpb=14558.6, bsz=1024, num_updates=62800, lr=0.000141083, gnorm=1.208, clip=0, loss_scale=2048, train_wall=101, wall=65714
2022-08-02 09:19:26 | INFO | train_inner | epoch 017:   3548 / 3715 loss=6.029, nll_loss=3.164, mask_ins=1.016, word_ins_ml=4.673, word_reposition=0.34, ppl=65.31, wps=14458.8, ups=0.99, wpb=14640.8, bsz=1024, num_updates=62900, lr=0.000140971, gnorm=1.212, clip=0, loss_scale=2048, train_wall=100, wall=65815
2022-08-02 09:21:07 | INFO | train_inner | epoch 017:   3648 / 3715 loss=6.007, nll_loss=3.148, mask_ins=1.015, word_ins_ml=4.659, word_reposition=0.333, ppl=64.3, wps=14346, ups=0.98, wpb=14596.9, bsz=1024, num_updates=63000, lr=0.000140859, gnorm=1.201, clip=0, loss_scale=2048, train_wall=100, wall=65917
2022-08-02 09:21:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-02 09:22:15 | INFO | train | epoch 017 | loss 6.006 | nll_loss 3.139 | mask_ins 1.013 | word_ins_ml 4.652 | word_reposition 0.341 | ppl 64.26 | wps 13932.2 | ups 0.95 | wpb 14662.5 | bsz 1023.7 | num_updates 63066 | lr 0.000140785 | gnorm 1.242 | clip 0 | loss_scale 1499 | train_wall 3761 | wall 65985
2022-08-02 09:23:25 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 6.2 | nll_loss 3.212 | mask_ins 1.048 | word_ins_ml 4.779 | word_reposition 0.373 | ppl 73.5 | wps 39252.9 | wpb 1849.4 | bsz 127.9 | num_updates 63066 | best_loss 6.189
2022-08-02 09:23:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased_Ggw/checkpoint_last.pt (epoch 17 @ 63066 updates, score 6.2) (writing took 4.463886916637421 seconds)
2022-08-02 09:24:04 | INFO | train_inner | epoch 018:     34 / 3715 loss=6.003, nll_loss=3.129, mask_ins=1.014, word_ins_ml=4.643, word_reposition=0.346, ppl=64.12, wps=8175.7, ups=0.57, wpb=14441.6, bsz=1014.7, num_updates=63100, lr=0.000140747, gnorm=1.308, clip=0, loss_scale=2677, train_wall=101, wall=66094
2022-08-02 09:25:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-08-02 09:25:47 | INFO | train_inner | epoch 018:    135 / 3715 loss=5.986, nll_loss=3.105, mask_ins=1.012, word_ins_ml=4.622, word_reposition=0.352, ppl=63.37, wps=14310.1, ups=0.97, wpb=14734.9, bsz=1024, num_updates=63200, lr=0.000140636, gnorm=1.338, clip=0, loss_scale=1936, train_wall=101, wall=66197
2022-08-02 09:27:30 | INFO | train_inner | epoch 018:    235 / 3715 loss=5.967, nll_loss=3.11, mask_ins=1.008, word_ins_ml=4.626, word_reposition=0.333, ppl=62.57, wps=14319.9, ups=0.97, wpb=14705.5, bsz=1023.8, num_updates=63300, lr=0.000140525, gnorm=1.282, clip=0, loss_scale=1024, train_wall=101, wall=66300
2022-08-02 09:29:12 | INFO | train_inner | epoch 018:    335 / 3715 loss=5.958, nll_loss=3.105, mask_ins=0.999, word_ins_ml=4.622, word_reposition=0.337, ppl=62.17, wps=14326.9, ups=0.98, wpb=14678, bsz=1024, num_updates=63400, lr=0.000140414, gnorm=1.221, clip=0, loss_scale=1024, train_wall=101, wall=66402
2022-08-02 09:30:55 | INFO | train_inner | epoch 018:    435 / 3715 loss=5.972, nll_loss=3.111, mask_ins=1.008, word_ins_ml=4.627, word_reposition=0.337, ppl=62.78, wps=14235.3, ups=0.97, wpb=14694.9, bsz=1024, num_updates=63500, lr=0.000140303, gnorm=1.216, clip=0, loss_scale=1024, train_wall=101, wall=66505
2022-08-02 09:32:37 | INFO | train_inner | epoch 018:    535 / 3715 loss=5.965, nll_loss=3.11, mask_ins=1.005, word_ins_ml=4.627, word_reposition=0.334, ppl=62.47, wps=14291.3, ups=0.98, wpb=14568.4, bsz=1024, num_updates=63600, lr=0.000140193, gnorm=1.226, clip=0, loss_scale=1024, train_wall=100, wall=66607
2022-08-02 09:34:20 | INFO | train_inner | epoch 018:    635 / 3715 loss=5.96, nll_loss=3.1, mask_ins=1.007, word_ins_ml=4.617, word_reposition=0.336, ppl=62.26, wps=14045.3, ups=0.97, wpb=14454.4, bsz=1024, num_updates=63700, lr=0.000140083, gnorm=1.284, clip=0, loss_scale=1024, train_wall=101, wall=66710
2022-08-02 09:36:03 | INFO | train_inner | epoch 018:    735 / 3715 loss=5.954, nll_loss=3.105, mask_ins=1.002, word_ins_ml=4.621, word_reposition=0.331, ppl=61.98, wps=14099.8, ups=0.97, wpb=14501.7, bsz=1024, num_updates=63800, lr=0.000139973, gnorm=1.23, clip=0, loss_scale=2038, train_wall=101, wall=66813
Traceback (most recent call last):
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq_cli/train.py", line 369, in cli_main
    torch.multiprocessing.spawn(
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 130, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGTERM
