nohup: ignoring input
2022-08-13 23:46:40 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:15202
2022-08-13 23:46:40 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:15202
2022-08-13 23:46:40 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:15202
2022-08-13 23:46:40 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:15202
2022-08-13 23:46:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2022-08-13 23:46:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2022-08-13 23:46:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2022-08-13 23:46:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2022-08-13 23:46:41 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-08-13 23:46:41 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 0
2022-08-13 23:46:41 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-08-13 23:46:41 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 2
2022-08-13 23:46:41 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-08-13 23:46:41 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 1
2022-08-13 23:46:41 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-08-13 23:46:41 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 3
2022-08-13 23:46:45 | INFO | fairseq_cli.train | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir='', seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, criterion='nat_loss', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', task='translation_lev', num_workers=0, skip_invalid_size_inputs_valid_test=True, max_tokens=None, max_sentences=32, required_batch_size_multiple=8, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, fixed_validation_seed=7, disable_validation=False, max_tokens_valid=None, max_sentences_valid=32, curriculum=0, distributed_world_size=4, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:15202', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, arch='kpe_editor_transformer_with_adapter', max_epoch=0, max_update=100000, clip_norm=25, sentence_avg=False, update_freq=[8], lr=[0.0005], min_lr=1e-09, use_bmuf=False, save_dir='../checkpoints_bert_bert12_adaptor_uncased_Ggw', restore_file='checkpoint_last.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, no_token_positional_embeddings=False, no_cross_attention=False, cross_self_attention=False, encoder_layerdrop=0, decoder_layerdrop=0, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, early_exit='12,12,12', layers_num='12,12,12', finetune_embeddings=False, finetune_whole_encoder=False, decoder_adapter_dimention=2048, finetune_position_embeddings=False, use_adapter_bert=True, keywords_num=40, constraint=False, label_smoothing=0.1, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, warmup_updates=5000, warmup_init_lr=1e-07, data='../data-bin-bert-uncased-Ggw', source_lang=None, target_lang=None, load_alignments=False, left_pad_source='False', left_pad_target='False', max_source_positions=512, max_target_positions=512, upsample_primary=1, truncate_source=False, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, noise='random_delete_shuffle', random_seed=1, cached_features_dir='../cached_examples_bert_cased_510', tokenizer_dir='/data/yukangliang/预训练模型/bert-base-uncased', encoder_adapter_dimention=2048, decoder_input='target', kpe=False, share_all_embeddings=True, no_share_discriminator=True, dropout=0.3, decoder_learned_pos=True, encoder_learned_pos=True, apply_bert_init=True, cache_dir='/data/yukangliang/预训练模型/bert-base-uncased', decoder_cache_dir='/data/yukangliang/预训练模型/bert-base-uncased-decoder', share_decoder_input_output_embed=False, encoder='bert_adaptor', decoder='bert_adaptor', keywords_gran='token', encoder_embed_path=None, encoder_embed_dim=768, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_attention_heads=8, encoder_normalize_before=False, decoder_embed_path=None, decoder_embed_dim=768, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_input=False, decoder_output_dim=768, decoder_input_dim=768, no_share_maskpredictor=False, share_discriminator_maskpredictor=False, no_share_last_layer=False, cached_dir='/data/yukangliang/预训练模型/bert-base-uncased')
2022-08-13 23:46:45 | INFO | fairseq.tasks.translation | [source] dictionary: 30522 types
2022-08-13 23:46:45 | INFO | fairseq.tasks.translation | [target] dictionary: 30522 types
2022-08-13 23:46:45 | INFO | fairseq.data.data_utils | loaded 189651 examples from: ../data-bin-bert-uncased-Ggw/valid.source-target.source
2022-08-13 23:46:45 | INFO | fairseq.data.data_utils | loaded 189651 examples from: ../data-bin-bert-uncased-Ggw/valid.source-target.target
2022-08-13 23:46:45 | INFO | fairseq.tasks.translation | ../data-bin-bert-uncased-Ggw valid source-target 189651 examples
2022-08-13 23:46:45 | INFO | transformer.configuration_utils | loading configuration file /data/yukangliang/预训练模型/bert-base-uncased/config.json
2022-08-13 23:46:45 | INFO | transformer.configuration_utils | Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "pruned_heads": {},
  "torchscript": false,
  "transformers_version": "4.6.0.dev0",
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "use_cache": true,
  "vocab_size": 30522
}

2022-08-13 23:46:45 | INFO | transformer.modeling_utils | loading weights file /data/yukangliang/预训练模型/bert-base-uncased/pytorch_model.bin
2022-08-13 23:46:49 | INFO | transformer.modeling_utils | Weights of BertEncoderWithAdaptor not initialized from pretrained model: ['bert.encoder.layer.0.adapter_ln.weight', 'bert.encoder.layer.0.adapter_ln.bias', 'bert.encoder.layer.0.adapter_w1.weight', 'bert.encoder.layer.0.adapter_w2.weight', 'bert.encoder.layer.1.adapter_ln.weight', 'bert.encoder.layer.1.adapter_ln.bias', 'bert.encoder.layer.1.adapter_w1.weight', 'bert.encoder.layer.1.adapter_w2.weight', 'bert.encoder.layer.2.adapter_ln.weight', 'bert.encoder.layer.2.adapter_ln.bias', 'bert.encoder.layer.2.adapter_w1.weight', 'bert.encoder.layer.2.adapter_w2.weight', 'bert.encoder.layer.3.adapter_ln.weight', 'bert.encoder.layer.3.adapter_ln.bias', 'bert.encoder.layer.3.adapter_w1.weight', 'bert.encoder.layer.3.adapter_w2.weight', 'bert.encoder.layer.4.adapter_ln.weight', 'bert.encoder.layer.4.adapter_ln.bias', 'bert.encoder.layer.4.adapter_w1.weight', 'bert.encoder.layer.4.adapter_w2.weight', 'bert.encoder.layer.5.adapter_ln.weight', 'bert.encoder.layer.5.adapter_ln.bias', 'bert.encoder.layer.5.adapter_w1.weight', 'bert.encoder.layer.5.adapter_w2.weight', 'bert.encoder.layer.6.adapter_ln.weight', 'bert.encoder.layer.6.adapter_ln.bias', 'bert.encoder.layer.6.adapter_w1.weight', 'bert.encoder.layer.6.adapter_w2.weight', 'bert.encoder.layer.7.adapter_ln.weight', 'bert.encoder.layer.7.adapter_ln.bias', 'bert.encoder.layer.7.adapter_w1.weight', 'bert.encoder.layer.7.adapter_w2.weight', 'bert.encoder.layer.8.adapter_ln.weight', 'bert.encoder.layer.8.adapter_ln.bias', 'bert.encoder.layer.8.adapter_w1.weight', 'bert.encoder.layer.8.adapter_w2.weight', 'bert.encoder.layer.9.adapter_ln.weight', 'bert.encoder.layer.9.adapter_ln.bias', 'bert.encoder.layer.9.adapter_w1.weight', 'bert.encoder.layer.9.adapter_w2.weight', 'bert.encoder.layer.10.adapter_ln.weight', 'bert.encoder.layer.10.adapter_ln.bias', 'bert.encoder.layer.10.adapter_w1.weight', 'bert.encoder.layer.10.adapter_w2.weight', 'bert.encoder.layer.11.adapter_ln.weight', 'bert.encoder.layer.11.adapter_ln.bias', 'bert.encoder.layer.11.adapter_w1.weight', 'bert.encoder.layer.11.adapter_w2.weight']
2022-08-13 23:46:49 | INFO | transformer.modeling_utils | Weights from pretrained model not used in BertEncoderWithAdaptor: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
2022-08-13 23:46:49 | INFO | transformer.configuration_utils | loading configuration file /data/yukangliang/预训练模型/bert-base-uncased/config.json
2022-08-13 23:46:49 | INFO | transformer.configuration_utils | Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "pruned_heads": {},
  "torchscript": false,
  "transformers_version": "4.6.0.dev0",
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "use_cache": true,
  "vocab_size": 30522
}

2022-08-13 23:46:49 | INFO | transformer.modeling_utils | loading weights file /data/yukangliang/预训练模型/bert-base-uncased-decoder/pytorch_model.bin
2022-08-13 23:46:51 | INFO | transformer.modeling_utils | Weights of BertDecoderWithAdaptor not initialized from pretrained model: ['embed_mask_ins.weight', 'layers.0.encoder_attn.k_proj.weight', 'layers.0.encoder_attn.k_proj.bias', 'layers.0.encoder_attn.v_proj.weight', 'layers.0.encoder_attn.v_proj.bias', 'layers.0.encoder_attn.q_proj.weight', 'layers.0.encoder_attn.q_proj.bias', 'layers.0.encoder_attn.out_proj.weight', 'layers.0.encoder_attn.out_proj.bias', 'layers.0.encoder_attn_layer_norm.weight', 'layers.0.encoder_attn_layer_norm.bias', 'layers.0.adapter.encoder_attn_fc1.weight', 'layers.0.adapter.encoder_attn_fc2.weight', 'layers.0.adapter.encoder_attn_final_layer_norm.weight', 'layers.0.adapter.encoder_attn_final_layer_norm.bias', 'layers.0.adapter_reposition.encoder_attn_fc1.weight', 'layers.0.adapter_reposition.encoder_attn_fc2.weight', 'layers.0.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.0.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.1.encoder_attn.k_proj.weight', 'layers.1.encoder_attn.k_proj.bias', 'layers.1.encoder_attn.v_proj.weight', 'layers.1.encoder_attn.v_proj.bias', 'layers.1.encoder_attn.q_proj.weight', 'layers.1.encoder_attn.q_proj.bias', 'layers.1.encoder_attn.out_proj.weight', 'layers.1.encoder_attn.out_proj.bias', 'layers.1.encoder_attn_layer_norm.weight', 'layers.1.encoder_attn_layer_norm.bias', 'layers.1.adapter.encoder_attn_fc1.weight', 'layers.1.adapter.encoder_attn_fc2.weight', 'layers.1.adapter.encoder_attn_final_layer_norm.weight', 'layers.1.adapter.encoder_attn_final_layer_norm.bias', 'layers.1.adapter_reposition.encoder_attn_fc1.weight', 'layers.1.adapter_reposition.encoder_attn_fc2.weight', 'layers.1.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.1.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.2.encoder_attn.k_proj.weight', 'layers.2.encoder_attn.k_proj.bias', 'layers.2.encoder_attn.v_proj.weight', 'layers.2.encoder_attn.v_proj.bias', 'layers.2.encoder_attn.q_proj.weight', 'layers.2.encoder_attn.q_proj.bias', 'layers.2.encoder_attn.out_proj.weight', 'layers.2.encoder_attn.out_proj.bias', 'layers.2.encoder_attn_layer_norm.weight', 'layers.2.encoder_attn_layer_norm.bias', 'layers.2.adapter.encoder_attn_fc1.weight', 'layers.2.adapter.encoder_attn_fc2.weight', 'layers.2.adapter.encoder_attn_final_layer_norm.weight', 'layers.2.adapter.encoder_attn_final_layer_norm.bias', 'layers.2.adapter_reposition.encoder_attn_fc1.weight', 'layers.2.adapter_reposition.encoder_attn_fc2.weight', 'layers.2.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.2.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.3.encoder_attn.k_proj.weight', 'layers.3.encoder_attn.k_proj.bias', 'layers.3.encoder_attn.v_proj.weight', 'layers.3.encoder_attn.v_proj.bias', 'layers.3.encoder_attn.q_proj.weight', 'layers.3.encoder_attn.q_proj.bias', 'layers.3.encoder_attn.out_proj.weight', 'layers.3.encoder_attn.out_proj.bias', 'layers.3.encoder_attn_layer_norm.weight', 'layers.3.encoder_attn_layer_norm.bias', 'layers.3.adapter.encoder_attn_fc1.weight', 'layers.3.adapter.encoder_attn_fc2.weight', 'layers.3.adapter.encoder_attn_final_layer_norm.weight', 'layers.3.adapter.encoder_attn_final_layer_norm.bias', 'layers.3.adapter_reposition.encoder_attn_fc1.weight', 'layers.3.adapter_reposition.encoder_attn_fc2.weight', 'layers.3.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.3.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.4.encoder_attn.k_proj.weight', 'layers.4.encoder_attn.k_proj.bias', 'layers.4.encoder_attn.v_proj.weight', 'layers.4.encoder_attn.v_proj.bias', 'layers.4.encoder_attn.q_proj.weight', 'layers.4.encoder_attn.q_proj.bias', 'layers.4.encoder_attn.out_proj.weight', 'layers.4.encoder_attn.out_proj.bias', 'layers.4.encoder_attn_layer_norm.weight', 'layers.4.encoder_attn_layer_norm.bias', 'layers.4.adapter.encoder_attn_fc1.weight', 'layers.4.adapter.encoder_attn_fc2.weight', 'layers.4.adapter.encoder_attn_final_layer_norm.weight', 'layers.4.adapter.encoder_attn_final_layer_norm.bias', 'layers.4.adapter_reposition.encoder_attn_fc1.weight', 'layers.4.adapter_reposition.encoder_attn_fc2.weight', 'layers.4.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.4.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.5.encoder_attn.k_proj.weight', 'layers.5.encoder_attn.k_proj.bias', 'layers.5.encoder_attn.v_proj.weight', 'layers.5.encoder_attn.v_proj.bias', 'layers.5.encoder_attn.q_proj.weight', 'layers.5.encoder_attn.q_proj.bias', 'layers.5.encoder_attn.out_proj.weight', 'layers.5.encoder_attn.out_proj.bias', 'layers.5.encoder_attn_layer_norm.weight', 'layers.5.encoder_attn_layer_norm.bias', 'layers.5.adapter.encoder_attn_fc1.weight', 'layers.5.adapter.encoder_attn_fc2.weight', 'layers.5.adapter.encoder_attn_final_layer_norm.weight', 'layers.5.adapter.encoder_attn_final_layer_norm.bias', 'layers.5.adapter_reposition.encoder_attn_fc1.weight', 'layers.5.adapter_reposition.encoder_attn_fc2.weight', 'layers.5.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.5.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.6.encoder_attn.k_proj.weight', 'layers.6.encoder_attn.k_proj.bias', 'layers.6.encoder_attn.v_proj.weight', 'layers.6.encoder_attn.v_proj.bias', 'layers.6.encoder_attn.q_proj.weight', 'layers.6.encoder_attn.q_proj.bias', 'layers.6.encoder_attn.out_proj.weight', 'layers.6.encoder_attn.out_proj.bias', 'layers.6.encoder_attn_layer_norm.weight', 'layers.6.encoder_attn_layer_norm.bias', 'layers.6.adapter.encoder_attn_fc1.weight', 'layers.6.adapter.encoder_attn_fc2.weight', 'layers.6.adapter.encoder_attn_final_layer_norm.weight', 'layers.6.adapter.encoder_attn_final_layer_norm.bias', 'layers.6.adapter_reposition.encoder_attn_fc1.weight', 'layers.6.adapter_reposition.encoder_attn_fc2.weight', 'layers.6.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.6.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.7.encoder_attn.k_proj.weight', 'layers.7.encoder_attn.k_proj.bias', 'layers.7.encoder_attn.v_proj.weight', 'layers.7.encoder_attn.v_proj.bias', 'layers.7.encoder_attn.q_proj.weight', 'layers.7.encoder_attn.q_proj.bias', 'layers.7.encoder_attn.out_proj.weight', 'layers.7.encoder_attn.out_proj.bias', 'layers.7.encoder_attn_layer_norm.weight', 'layers.7.encoder_attn_layer_norm.bias', 'layers.7.adapter.encoder_attn_fc1.weight', 'layers.7.adapter.encoder_attn_fc2.weight', 'layers.7.adapter.encoder_attn_final_layer_norm.weight', 'layers.7.adapter.encoder_attn_final_layer_norm.bias', 'layers.7.adapter_reposition.encoder_attn_fc1.weight', 'layers.7.adapter_reposition.encoder_attn_fc2.weight', 'layers.7.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.7.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.8.encoder_attn.k_proj.weight', 'layers.8.encoder_attn.k_proj.bias', 'layers.8.encoder_attn.v_proj.weight', 'layers.8.encoder_attn.v_proj.bias', 'layers.8.encoder_attn.q_proj.weight', 'layers.8.encoder_attn.q_proj.bias', 'layers.8.encoder_attn.out_proj.weight', 'layers.8.encoder_attn.out_proj.bias', 'layers.8.encoder_attn_layer_norm.weight', 'layers.8.encoder_attn_layer_norm.bias', 'layers.8.adapter.encoder_attn_fc1.weight', 'layers.8.adapter.encoder_attn_fc2.weight', 'layers.8.adapter.encoder_attn_final_layer_norm.weight', 'layers.8.adapter.encoder_attn_final_layer_norm.bias', 'layers.8.adapter_reposition.encoder_attn_fc1.weight', 'layers.8.adapter_reposition.encoder_attn_fc2.weight', 'layers.8.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.8.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.9.encoder_attn.k_proj.weight', 'layers.9.encoder_attn.k_proj.bias', 'layers.9.encoder_attn.v_proj.weight', 'layers.9.encoder_attn.v_proj.bias', 'layers.9.encoder_attn.q_proj.weight', 'layers.9.encoder_attn.q_proj.bias', 'layers.9.encoder_attn.out_proj.weight', 'layers.9.encoder_attn.out_proj.bias', 'layers.9.encoder_attn_layer_norm.weight', 'layers.9.encoder_attn_layer_norm.bias', 'layers.9.adapter.encoder_attn_fc1.weight', 'layers.9.adapter.encoder_attn_fc2.weight', 'layers.9.adapter.encoder_attn_final_layer_norm.weight', 'layers.9.adapter.encoder_attn_final_layer_norm.bias', 'layers.9.adapter_reposition.encoder_attn_fc1.weight', 'layers.9.adapter_reposition.encoder_attn_fc2.weight', 'layers.9.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.9.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.10.encoder_attn.k_proj.weight', 'layers.10.encoder_attn.k_proj.bias', 'layers.10.encoder_attn.v_proj.weight', 'layers.10.encoder_attn.v_proj.bias', 'layers.10.encoder_attn.q_proj.weight', 'layers.10.encoder_attn.q_proj.bias', 'layers.10.encoder_attn.out_proj.weight', 'layers.10.encoder_attn.out_proj.bias', 'layers.10.encoder_attn_layer_norm.weight', 'layers.10.encoder_attn_layer_norm.bias', 'layers.10.adapter.encoder_attn_fc1.weight', 'layers.10.adapter.encoder_attn_fc2.weight', 'layers.10.adapter.encoder_attn_final_layer_norm.weight', 'layers.10.adapter.encoder_attn_final_layer_norm.bias', 'layers.10.adapter_reposition.encoder_attn_fc1.weight', 'layers.10.adapter_reposition.encoder_attn_fc2.weight', 'layers.10.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.10.adapter_reposition.encoder_attn_final_layer_norm.bias', 'layers.11.encoder_attn.k_proj.weight', 'layers.11.encoder_attn.k_proj.bias', 'layers.11.encoder_attn.v_proj.weight', 'layers.11.encoder_attn.v_proj.bias', 'layers.11.encoder_attn.q_proj.weight', 'layers.11.encoder_attn.q_proj.bias', 'layers.11.encoder_attn.out_proj.weight', 'layers.11.encoder_attn.out_proj.bias', 'layers.11.encoder_attn_layer_norm.weight', 'layers.11.encoder_attn_layer_norm.bias', 'layers.11.adapter.encoder_attn_fc1.weight', 'layers.11.adapter.encoder_attn_fc2.weight', 'layers.11.adapter.encoder_attn_final_layer_norm.weight', 'layers.11.adapter.encoder_attn_final_layer_norm.bias', 'layers.11.adapter_reposition.encoder_attn_fc1.weight', 'layers.11.adapter_reposition.encoder_attn_fc2.weight', 'layers.11.adapter_reposition.encoder_attn_final_layer_norm.weight', 'layers.11.adapter_reposition.encoder_attn_final_layer_norm.bias', 'output_projection.weight']
2022-08-13 23:46:51 | INFO | transformer.modeling_utils | Weights from pretrained model not used in BertDecoderWithAdaptor: ['pooler.dense.weight', 'pooler.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
Trained parameters: len 265
Trained parameters: ['encoder.bert.encoder.layer.0.adapter_ln.weight', 'encoder.bert.encoder.layer.0.adapter_ln.bias', 'encoder.bert.encoder.layer.0.adapter_w1.weight', 'encoder.bert.encoder.layer.0.adapter_w2.weight', 'encoder.bert.encoder.layer.1.adapter_ln.weight', 'encoder.bert.encoder.layer.1.adapter_ln.bias', 'encoder.bert.encoder.layer.1.adapter_w1.weight', 'encoder.bert.encoder.layer.1.adapter_w2.weight', 'encoder.bert.encoder.layer.2.adapter_ln.weight', 'encoder.bert.encoder.layer.2.adapter_ln.bias', 'encoder.bert.encoder.layer.2.adapter_w1.weight', 'encoder.bert.encoder.layer.2.adapter_w2.weight', 'encoder.bert.encoder.layer.3.adapter_ln.weight', 'encoder.bert.encoder.layer.3.adapter_ln.bias', 'encoder.bert.encoder.layer.3.adapter_w1.weight', 'encoder.bert.encoder.layer.3.adapter_w2.weight', 'encoder.bert.encoder.layer.4.adapter_ln.weight', 'encoder.bert.encoder.layer.4.adapter_ln.bias', 'encoder.bert.encoder.layer.4.adapter_w1.weight', 'encoder.bert.encoder.layer.4.adapter_w2.weight', 'encoder.bert.encoder.layer.5.adapter_ln.weight', 'encoder.bert.encoder.layer.5.adapter_ln.bias', 'encoder.bert.encoder.layer.5.adapter_w1.weight', 'encoder.bert.encoder.layer.5.adapter_w2.weight', 'encoder.bert.encoder.layer.6.adapter_ln.weight', 'encoder.bert.encoder.layer.6.adapter_ln.bias', 'encoder.bert.encoder.layer.6.adapter_w1.weight', 'encoder.bert.encoder.layer.6.adapter_w2.weight', 'encoder.bert.encoder.layer.7.adapter_ln.weight', 'encoder.bert.encoder.layer.7.adapter_ln.bias', 'encoder.bert.encoder.layer.7.adapter_w1.weight', 'encoder.bert.encoder.layer.7.adapter_w2.weight', 'encoder.bert.encoder.layer.8.adapter_ln.weight', 'encoder.bert.encoder.layer.8.adapter_ln.bias', 'encoder.bert.encoder.layer.8.adapter_w1.weight', 'encoder.bert.encoder.layer.8.adapter_w2.weight', 'encoder.bert.encoder.layer.9.adapter_ln.weight', 'encoder.bert.encoder.layer.9.adapter_ln.bias', 'encoder.bert.encoder.layer.9.adapter_w1.weight', 'encoder.bert.encoder.layer.9.adapter_w2.weight', 'encoder.bert.encoder.layer.10.adapter_ln.weight', 'encoder.bert.encoder.layer.10.adapter_ln.bias', 'encoder.bert.encoder.layer.10.adapter_w1.weight', 'encoder.bert.encoder.layer.10.adapter_w2.weight', 'encoder.bert.encoder.layer.11.adapter_ln.weight', 'encoder.bert.encoder.layer.11.adapter_ln.bias', 'encoder.bert.encoder.layer.11.adapter_w1.weight', 'encoder.bert.encoder.layer.11.adapter_w2.weight', 'decoder.embed_mask_ins.weight', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.adapter.encoder_attn_fc1.weight', 'decoder.layers.0.adapter.encoder_attn_fc2.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.0.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.adapter.encoder_attn_fc1.weight', 'decoder.layers.1.adapter.encoder_attn_fc2.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.adapter.encoder_attn_fc1.weight', 'decoder.layers.2.adapter.encoder_attn_fc2.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.adapter.encoder_attn_fc1.weight', 'decoder.layers.3.adapter.encoder_attn_fc2.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.adapter.encoder_attn_fc1.weight', 'decoder.layers.4.adapter.encoder_attn_fc2.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.adapter.encoder_attn_fc1.weight', 'decoder.layers.5.adapter.encoder_attn_fc2.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.encoder_attn.k_proj.weight', 'decoder.layers.6.encoder_attn.k_proj.bias', 'decoder.layers.6.encoder_attn.v_proj.weight', 'decoder.layers.6.encoder_attn.v_proj.bias', 'decoder.layers.6.encoder_attn.q_proj.weight', 'decoder.layers.6.encoder_attn.q_proj.bias', 'decoder.layers.6.encoder_attn.out_proj.weight', 'decoder.layers.6.encoder_attn.out_proj.bias', 'decoder.layers.6.encoder_attn_layer_norm.weight', 'decoder.layers.6.encoder_attn_layer_norm.bias', 'decoder.layers.6.adapter.encoder_attn_fc1.weight', 'decoder.layers.6.adapter.encoder_attn_fc2.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.encoder_attn.k_proj.weight', 'decoder.layers.7.encoder_attn.k_proj.bias', 'decoder.layers.7.encoder_attn.v_proj.weight', 'decoder.layers.7.encoder_attn.v_proj.bias', 'decoder.layers.7.encoder_attn.q_proj.weight', 'decoder.layers.7.encoder_attn.q_proj.bias', 'decoder.layers.7.encoder_attn.out_proj.weight', 'decoder.layers.7.encoder_attn.out_proj.bias', 'decoder.layers.7.encoder_attn_layer_norm.weight', 'decoder.layers.7.encoder_attn_layer_norm.bias', 'decoder.layers.7.adapter.encoder_attn_fc1.weight', 'decoder.layers.7.adapter.encoder_attn_fc2.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.encoder_attn.k_proj.weight', 'decoder.layers.8.encoder_attn.k_proj.bias', 'decoder.layers.8.encoder_attn.v_proj.weight', 'decoder.layers.8.encoder_attn.v_proj.bias', 'decoder.layers.8.encoder_attn.q_proj.weight', 'decoder.layers.8.encoder_attn.q_proj.bias', 'decoder.layers.8.encoder_attn.out_proj.weight', 'decoder.layers.8.encoder_attn.out_proj.bias', 'decoder.layers.8.encoder_attn_layer_norm.weight', 'decoder.layers.8.encoder_attn_layer_norm.bias', 'decoder.layers.8.adapter.encoder_attn_fc1.weight', 'decoder.layers.8.adapter.encoder_attn_fc2.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.encoder_attn.k_proj.weight', 'decoder.layers.9.encoder_attn.k_proj.bias', 'decoder.layers.9.encoder_attn.v_proj.weight', 'decoder.layers.9.encoder_attn.v_proj.bias', 'decoder.layers.9.encoder_attn.q_proj.weight', 'decoder.layers.9.encoder_attn.q_proj.bias', 'decoder.layers.9.encoder_attn.out_proj.weight', 'decoder.layers.9.encoder_attn.out_proj.bias', 'decoder.layers.9.encoder_attn_layer_norm.weight', 'decoder.layers.9.encoder_attn_layer_norm.bias', 'decoder.layers.9.adapter.encoder_attn_fc1.weight', 'decoder.layers.9.adapter.encoder_attn_fc2.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.encoder_attn.k_proj.weight', 'decoder.layers.10.encoder_attn.k_proj.bias', 'decoder.layers.10.encoder_attn.v_proj.weight', 'decoder.layers.10.encoder_attn.v_proj.bias', 'decoder.layers.10.encoder_attn.q_proj.weight', 'decoder.layers.10.encoder_attn.q_proj.bias', 'decoder.layers.10.encoder_attn.out_proj.weight', 'decoder.layers.10.encoder_attn.out_proj.bias', 'decoder.layers.10.encoder_attn_layer_norm.weight', 'decoder.layers.10.encoder_attn_layer_norm.bias', 'decoder.layers.10.adapter.encoder_attn_fc1.weight', 'decoder.layers.10.adapter.encoder_attn_fc2.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.encoder_attn.k_proj.weight', 'decoder.layers.11.encoder_attn.k_proj.bias', 'decoder.layers.11.encoder_attn.v_proj.weight', 'decoder.layers.11.encoder_attn.v_proj.bias', 'decoder.layers.11.encoder_attn.q_proj.weight', 'decoder.layers.11.encoder_attn.q_proj.bias', 'decoder.layers.11.encoder_attn.out_proj.weight', 'decoder.layers.11.encoder_attn.out_proj.bias', 'decoder.layers.11.encoder_attn_layer_norm.weight', 'decoder.layers.11.encoder_attn_layer_norm.bias', 'decoder.layers.11.adapter.encoder_attn_fc1.weight', 'decoder.layers.11.adapter.encoder_attn_fc2.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.bias']
Trained parameters not adapter: len 1
Trained parameters not adapter: ['decoder.embed_mask_ins.weight']
2022-08-13 23:46:51 | INFO | fairseq_cli.train | KPEEDITORTransformerModel(
  (encoder): BertEncoderWithAdaptor(
    (bert): BertModelWithAdapter(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoderWithAdapter(
        (layer): ModuleList(
          (0): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (1): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (2): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (3): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (4): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (5): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (6): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (7): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (8): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (9): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (10): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
          (11): BertLayerWithAdapter(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (adapter_ln): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (adapter_w1): Linear(in_features=768, out_features=2048, bias=False)
            (adapter_w2): Linear(in_features=2048, out_features=768, bias=False)
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (decoder): BertDecoderWithAdaptor(
    (embed_mask_ins): Embedding(256, 1536)
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (layers): ModuleList(
      (0): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (6): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (7): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (8): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (9): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (10): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (11): BertAdapterDecoderLayer(
        (attention): BertAttention(
          (self): BertSelfAttention(
            (query): Linear(in_features=768, out_features=768, bias=True)
            (key): Linear(in_features=768, out_features=768, bias=True)
            (value): Linear(in_features=768, out_features=768, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (output): BertSelfOutput(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (intermediate): BertIntermediate(
          (dense): Linear(in_features=768, out_features=3072, bias=True)
        )
        (output): BertOutput(
          (dense): Linear(in_features=3072, out_features=768, bias=True)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (adapter): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (adapter_reposition): DecoderAdapter(
          (encoder_attn_fc1): Linear(in_features=768, out_features=2048, bias=False)
          (encoder_attn_fc2): Linear(in_features=2048, out_features=768, bias=False)
          (encoder_attn_final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (output_projection): Linear(in_features=768, out_features=30522, bias=False)
  )
)
2022-08-13 23:46:51 | INFO | fairseq_cli.train | model kpe_editor_transformer_with_adapter, criterion LabelSmoothedDualImitationCriterion
2022-08-13 23:46:51 | INFO | fairseq_cli.train | num. model params: 383876352 (num. trained: 142061568)
2022-08-13 23:46:51 | INFO | fairseq_cli.train | num. Encoder model params: 147249408 (Encoder num. trained: 37767168)
2022-08-13 23:46:51 | INFO | fairseq_cli.train | num. Decoder model params: 236626944 (Decoder num. trained: 104294400)
Trained parameters: len 265
Trained parameters: ['encoder.bert.encoder.layer.0.adapter_ln.weight', 'encoder.bert.encoder.layer.0.adapter_ln.bias', 'encoder.bert.encoder.layer.0.adapter_w1.weight', 'encoder.bert.encoder.layer.0.adapter_w2.weight', 'encoder.bert.encoder.layer.1.adapter_ln.weight', 'encoder.bert.encoder.layer.1.adapter_ln.bias', 'encoder.bert.encoder.layer.1.adapter_w1.weight', 'encoder.bert.encoder.layer.1.adapter_w2.weight', 'encoder.bert.encoder.layer.2.adapter_ln.weight', 'encoder.bert.encoder.layer.2.adapter_ln.bias', 'encoder.bert.encoder.layer.2.adapter_w1.weight', 'encoder.bert.encoder.layer.2.adapter_w2.weight', 'encoder.bert.encoder.layer.3.adapter_ln.weight', 'encoder.bert.encoder.layer.3.adapter_ln.bias', 'encoder.bert.encoder.layer.3.adapter_w1.weight', 'encoder.bert.encoder.layer.3.adapter_w2.weight', 'encoder.bert.encoder.layer.4.adapter_ln.weight', 'encoder.bert.encoder.layer.4.adapter_ln.bias', 'encoder.bert.encoder.layer.4.adapter_w1.weight', 'encoder.bert.encoder.layer.4.adapter_w2.weight', 'encoder.bert.encoder.layer.5.adapter_ln.weight', 'encoder.bert.encoder.layer.5.adapter_ln.bias', 'encoder.bert.encoder.layer.5.adapter_w1.weight', 'encoder.bert.encoder.layer.5.adapter_w2.weight', 'encoder.bert.encoder.layer.6.adapter_ln.weight', 'encoder.bert.encoder.layer.6.adapter_ln.bias', 'encoder.bert.encoder.layer.6.adapter_w1.weight', 'encoder.bert.encoder.layer.6.adapter_w2.weight', 'encoder.bert.encoder.layer.7.adapter_ln.weight', 'encoder.bert.encoder.layer.7.adapter_ln.bias', 'encoder.bert.encoder.layer.7.adapter_w1.weight', 'encoder.bert.encoder.layer.7.adapter_w2.weight', 'encoder.bert.encoder.layer.8.adapter_ln.weight', 'encoder.bert.encoder.layer.8.adapter_ln.bias', 'encoder.bert.encoder.layer.8.adapter_w1.weight', 'encoder.bert.encoder.layer.8.adapter_w2.weight', 'encoder.bert.encoder.layer.9.adapter_ln.weight', 'encoder.bert.encoder.layer.9.adapter_ln.bias', 'encoder.bert.encoder.layer.9.adapter_w1.weight', 'encoder.bert.encoder.layer.9.adapter_w2.weight', 'encoder.bert.encoder.layer.10.adapter_ln.weight', 'encoder.bert.encoder.layer.10.adapter_ln.bias', 'encoder.bert.encoder.layer.10.adapter_w1.weight', 'encoder.bert.encoder.layer.10.adapter_w2.weight', 'encoder.bert.encoder.layer.11.adapter_ln.weight', 'encoder.bert.encoder.layer.11.adapter_ln.bias', 'encoder.bert.encoder.layer.11.adapter_w1.weight', 'encoder.bert.encoder.layer.11.adapter_w2.weight', 'decoder.embed_mask_ins.weight', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.adapter.encoder_attn_fc1.weight', 'decoder.layers.0.adapter.encoder_attn_fc2.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.0.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.adapter.encoder_attn_fc1.weight', 'decoder.layers.1.adapter.encoder_attn_fc2.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.adapter.encoder_attn_fc1.weight', 'decoder.layers.2.adapter.encoder_attn_fc2.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.adapter.encoder_attn_fc1.weight', 'decoder.layers.3.adapter.encoder_attn_fc2.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.adapter.encoder_attn_fc1.weight', 'decoder.layers.4.adapter.encoder_attn_fc2.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.adapter.encoder_attn_fc1.weight', 'decoder.layers.5.adapter.encoder_attn_fc2.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.encoder_attn.k_proj.weight', 'decoder.layers.6.encoder_attn.k_proj.bias', 'decoder.layers.6.encoder_attn.v_proj.weight', 'decoder.layers.6.encoder_attn.v_proj.bias', 'decoder.layers.6.encoder_attn.q_proj.weight', 'decoder.layers.6.encoder_attn.q_proj.bias', 'decoder.layers.6.encoder_attn.out_proj.weight', 'decoder.layers.6.encoder_attn.out_proj.bias', 'decoder.layers.6.encoder_attn_layer_norm.weight', 'decoder.layers.6.encoder_attn_layer_norm.bias', 'decoder.layers.6.adapter.encoder_attn_fc1.weight', 'decoder.layers.6.adapter.encoder_attn_fc2.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.encoder_attn.k_proj.weight', 'decoder.layers.7.encoder_attn.k_proj.bias', 'decoder.layers.7.encoder_attn.v_proj.weight', 'decoder.layers.7.encoder_attn.v_proj.bias', 'decoder.layers.7.encoder_attn.q_proj.weight', 'decoder.layers.7.encoder_attn.q_proj.bias', 'decoder.layers.7.encoder_attn.out_proj.weight', 'decoder.layers.7.encoder_attn.out_proj.bias', 'decoder.layers.7.encoder_attn_layer_norm.weight', 'decoder.layers.7.encoder_attn_layer_norm.bias', 'decoder.layers.7.adapter.encoder_attn_fc1.weight', 'decoder.layers.7.adapter.encoder_attn_fc2.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.encoder_attn.k_proj.weight', 'decoder.layers.8.encoder_attn.k_proj.bias', 'decoder.layers.8.encoder_attn.v_proj.weight', 'decoder.layers.8.encoder_attn.v_proj.bias', 'decoder.layers.8.encoder_attn.q_proj.weight', 'decoder.layers.8.encoder_attn.q_proj.bias', 'decoder.layers.8.encoder_attn.out_proj.weight', 'decoder.layers.8.encoder_attn.out_proj.bias', 'decoder.layers.8.encoder_attn_layer_norm.weight', 'decoder.layers.8.encoder_attn_layer_norm.bias', 'decoder.layers.8.adapter.encoder_attn_fc1.weight', 'decoder.layers.8.adapter.encoder_attn_fc2.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.encoder_attn.k_proj.weight', 'decoder.layers.9.encoder_attn.k_proj.bias', 'decoder.layers.9.encoder_attn.v_proj.weight', 'decoder.layers.9.encoder_attn.v_proj.bias', 'decoder.layers.9.encoder_attn.q_proj.weight', 'decoder.layers.9.encoder_attn.q_proj.bias', 'decoder.layers.9.encoder_attn.out_proj.weight', 'decoder.layers.9.encoder_attn.out_proj.bias', 'decoder.layers.9.encoder_attn_layer_norm.weight', 'decoder.layers.9.encoder_attn_layer_norm.bias', 'decoder.layers.9.adapter.encoder_attn_fc1.weight', 'decoder.layers.9.adapter.encoder_attn_fc2.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.encoder_attn.k_proj.weight', 'decoder.layers.10.encoder_attn.k_proj.bias', 'decoder.layers.10.encoder_attn.v_proj.weight', 'decoder.layers.10.encoder_attn.v_proj.bias', 'decoder.layers.10.encoder_attn.q_proj.weight', 'decoder.layers.10.encoder_attn.q_proj.bias', 'decoder.layers.10.encoder_attn.out_proj.weight', 'decoder.layers.10.encoder_attn.out_proj.bias', 'decoder.layers.10.encoder_attn_layer_norm.weight', 'decoder.layers.10.encoder_attn_layer_norm.bias', 'decoder.layers.10.adapter.encoder_attn_fc1.weight', 'decoder.layers.10.adapter.encoder_attn_fc2.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.encoder_attn.k_proj.weight', 'decoder.layers.11.encoder_attn.k_proj.bias', 'decoder.layers.11.encoder_attn.v_proj.weight', 'decoder.layers.11.encoder_attn.v_proj.bias', 'decoder.layers.11.encoder_attn.q_proj.weight', 'decoder.layers.11.encoder_attn.q_proj.bias', 'decoder.layers.11.encoder_attn.out_proj.weight', 'decoder.layers.11.encoder_attn.out_proj.bias', 'decoder.layers.11.encoder_attn_layer_norm.weight', 'decoder.layers.11.encoder_attn_layer_norm.bias', 'decoder.layers.11.adapter.encoder_attn_fc1.weight', 'decoder.layers.11.adapter.encoder_attn_fc2.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.bias']Trained parameters: len 265
Trained parameters: ['encoder.bert.encoder.layer.0.adapter_ln.weight', 'encoder.bert.encoder.layer.0.adapter_ln.bias', 'encoder.bert.encoder.layer.0.adapter_w1.weight', 'encoder.bert.encoder.layer.0.adapter_w2.weight', 'encoder.bert.encoder.layer.1.adapter_ln.weight', 'encoder.bert.encoder.layer.1.adapter_ln.bias', 'encoder.bert.encoder.layer.1.adapter_w1.weight', 'encoder.bert.encoder.layer.1.adapter_w2.weight', 'encoder.bert.encoder.layer.2.adapter_ln.weight', 'encoder.bert.encoder.layer.2.adapter_ln.bias', 'encoder.bert.encoder.layer.2.adapter_w1.weight', 'encoder.bert.encoder.layer.2.adapter_w2.weight', 'encoder.bert.encoder.layer.3.adapter_ln.weight', 'encoder.bert.encoder.layer.3.adapter_ln.bias', 'encoder.bert.encoder.layer.3.adapter_w1.weight', 'encoder.bert.encoder.layer.3.adapter_w2.weight', 'encoder.bert.encoder.layer.4.adapter_ln.weight', 'encoder.bert.encoder.layer.4.adapter_ln.bias', 'encoder.bert.encoder.layer.4.adapter_w1.weight', 'encoder.bert.encoder.layer.4.adapter_w2.weight', 'encoder.bert.encoder.layer.5.adapter_ln.weight', 'encoder.bert.encoder.layer.5.adapter_ln.bias', 'encoder.bert.encoder.layer.5.adapter_w1.weight', 'encoder.bert.encoder.layer.5.adapter_w2.weight', 'encoder.bert.encoder.layer.6.adapter_ln.weight', 'encoder.bert.encoder.layer.6.adapter_ln.bias', 'encoder.bert.encoder.layer.6.adapter_w1.weight', 'encoder.bert.encoder.layer.6.adapter_w2.weight', 'encoder.bert.encoder.layer.7.adapter_ln.weight', 'encoder.bert.encoder.layer.7.adapter_ln.bias', 'encoder.bert.encoder.layer.7.adapter_w1.weight', 'encoder.bert.encoder.layer.7.adapter_w2.weight', 'encoder.bert.encoder.layer.8.adapter_ln.weight', 'encoder.bert.encoder.layer.8.adapter_ln.bias', 'encoder.bert.encoder.layer.8.adapter_w1.weight', 'encoder.bert.encoder.layer.8.adapter_w2.weight', 'encoder.bert.encoder.layer.9.adapter_ln.weight', 'encoder.bert.encoder.layer.9.adapter_ln.bias', 'encoder.bert.encoder.layer.9.adapter_w1.weight', 'encoder.bert.encoder.layer.9.adapter_w2.weight', 'encoder.bert.encoder.layer.10.adapter_ln.weight', 'encoder.bert.encoder.layer.10.adapter_ln.bias', 'encoder.bert.encoder.layer.10.adapter_w1.weight', 'encoder.bert.encoder.layer.10.adapter_w2.weight', 'encoder.bert.encoder.layer.11.adapter_ln.weight', 'encoder.bert.encoder.layer.11.adapter_ln.bias', 'encoder.bert.encoder.layer.11.adapter_w1.weight', 'encoder.bert.encoder.layer.11.adapter_w2.weight', 'decoder.embed_mask_ins.weight', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.adapter.encoder_attn_fc1.weight', 'decoder.layers.0.adapter.encoder_attn_fc2.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.0.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.adapter.encoder_attn_fc1.weight', 'decoder.layers.1.adapter.encoder_attn_fc2.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.adapter.encoder_attn_fc1.weight', 'decoder.layers.2.adapter.encoder_attn_fc2.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.adapter.encoder_attn_fc1.weight', 'decoder.layers.3.adapter.encoder_attn_fc2.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.adapter.encoder_attn_fc1.weight', 'decoder.layers.4.adapter.encoder_attn_fc2.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.adapter.encoder_attn_fc1.weight', 'decoder.layers.5.adapter.encoder_attn_fc2.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.encoder_attn.k_proj.weight', 'decoder.layers.6.encoder_attn.k_proj.bias', 'decoder.layers.6.encoder_attn.v_proj.weight', 'decoder.layers.6.encoder_attn.v_proj.bias', 'decoder.layers.6.encoder_attn.q_proj.weight', 'decoder.layers.6.encoder_attn.q_proj.bias', 'decoder.layers.6.encoder_attn.out_proj.weight', 'decoder.layers.6.encoder_attn.out_proj.bias', 'decoder.layers.6.encoder_attn_layer_norm.weight', 'decoder.layers.6.encoder_attn_layer_norm.bias', 'decoder.layers.6.adapter.encoder_attn_fc1.weight', 'decoder.layers.6.adapter.encoder_attn_fc2.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.encoder_attn.k_proj.weight', 'decoder.layers.7.encoder_attn.k_proj.bias', 'decoder.layers.7.encoder_attn.v_proj.weight', 'decoder.layers.7.encoder_attn.v_proj.bias', 'decoder.layers.7.encoder_attn.q_proj.weight', 'decoder.layers.7.encoder_attn.q_proj.bias', 'decoder.layers.7.encoder_attn.out_proj.weight', 'decoder.layers.7.encoder_attn.out_proj.bias', 'decoder.layers.7.encoder_attn_layer_norm.weight', 'decoder.layers.7.encoder_attn_layer_norm.bias', 'decoder.layers.7.adapter.encoder_attn_fc1.weight', 'decoder.layers.7.adapter.encoder_attn_fc2.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.encoder_attn.k_proj.weight', 'decoder.layers.8.encoder_attn.k_proj.bias', 'decoder.layers.8.encoder_attn.v_proj.weight', 'decoder.layers.8.encoder_attn.v_proj.bias', 'decoder.layers.8.encoder_attn.q_proj.weight', 'decoder.layers.8.encoder_attn.q_proj.bias', 'decoder.layers.8.encoder_attn.out_proj.weight', 'decoder.layers.8.encoder_attn.out_proj.bias', 'decoder.layers.8.encoder_attn_layer_norm.weight', 'decoder.layers.8.encoder_attn_layer_norm.bias', 'decoder.layers.8.adapter.encoder_attn_fc1.weight', 'decoder.layers.8.adapter.encoder_attn_fc2.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.encoder_attn.k_proj.weight', 'decoder.layers.9.encoder_attn.k_proj.bias', 'decoder.layers.9.encoder_attn.v_proj.weight', 'decoder.layers.9.encoder_attn.v_proj.bias', 'decoder.layers.9.encoder_attn.q_proj.weight', 'decoder.layers.9.encoder_attn.q_proj.bias', 'decoder.layers.9.encoder_attn.out_proj.weight', 'decoder.layers.9.encoder_attn.out_proj.bias', 'decoder.layers.9.encoder_attn_layer_norm.weight', 'decoder.layers.9.encoder_attn_layer_norm.bias', 'decoder.layers.9.adapter.encoder_attn_fc1.weight', 'decoder.layers.9.adapter.encoder_attn_fc2.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.encoder_attn.k_proj.weight', 'decoder.layers.10.encoder_attn.k_proj.bias', 'decoder.layers.10.encoder_attn.v_proj.weight', 'decoder.layers.10.encoder_attn.v_proj.bias', 'decoder.layers.10.encoder_attn.q_proj.weight', 'decoder.layers.10.encoder_attn.q_proj.bias', 'decoder.layers.10.encoder_attn.out_proj.weight', 'decoder.layers.10.encoder_attn.out_proj.bias', 'decoder.layers.10.encoder_attn_layer_norm.weight', 'decoder.layers.10.encoder_attn_layer_norm.bias', 'decoder.layers.10.adapter.encoder_attn_fc1.weight', 'decoder.layers.10.adapter.encoder_attn_fc2.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.encoder_attn.k_proj.weight', 'decoder.layers.11.encoder_attn.k_proj.bias', 'decoder.layers.11.encoder_attn.v_proj.weight', 'decoder.layers.11.encoder_attn.v_proj.bias', 'decoder.layers.11.encoder_attn.q_proj.weight', 'decoder.layers.11.encoder_attn.q_proj.bias', 'decoder.layers.11.encoder_attn.out_proj.weight', 'decoder.layers.11.encoder_attn.out_proj.bias', 'decoder.layers.11.encoder_attn_layer_norm.weight', 'decoder.layers.11.encoder_attn_layer_norm.bias', 'decoder.layers.11.adapter.encoder_attn_fc1.weight', 'decoder.layers.11.adapter.encoder_attn_fc2.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.bias']Trained parameters: len 265
Trained parameters: ['encoder.bert.encoder.layer.0.adapter_ln.weight', 'encoder.bert.encoder.layer.0.adapter_ln.bias', 'encoder.bert.encoder.layer.0.adapter_w1.weight', 'encoder.bert.encoder.layer.0.adapter_w2.weight', 'encoder.bert.encoder.layer.1.adapter_ln.weight', 'encoder.bert.encoder.layer.1.adapter_ln.bias', 'encoder.bert.encoder.layer.1.adapter_w1.weight', 'encoder.bert.encoder.layer.1.adapter_w2.weight', 'encoder.bert.encoder.layer.2.adapter_ln.weight', 'encoder.bert.encoder.layer.2.adapter_ln.bias', 'encoder.bert.encoder.layer.2.adapter_w1.weight', 'encoder.bert.encoder.layer.2.adapter_w2.weight', 'encoder.bert.encoder.layer.3.adapter_ln.weight', 'encoder.bert.encoder.layer.3.adapter_ln.bias', 'encoder.bert.encoder.layer.3.adapter_w1.weight', 'encoder.bert.encoder.layer.3.adapter_w2.weight', 'encoder.bert.encoder.layer.4.adapter_ln.weight', 'encoder.bert.encoder.layer.4.adapter_ln.bias', 'encoder.bert.encoder.layer.4.adapter_w1.weight', 'encoder.bert.encoder.layer.4.adapter_w2.weight', 'encoder.bert.encoder.layer.5.adapter_ln.weight', 'encoder.bert.encoder.layer.5.adapter_ln.bias', 'encoder.bert.encoder.layer.5.adapter_w1.weight', 'encoder.bert.encoder.layer.5.adapter_w2.weight', 'encoder.bert.encoder.layer.6.adapter_ln.weight', 'encoder.bert.encoder.layer.6.adapter_ln.bias', 'encoder.bert.encoder.layer.6.adapter_w1.weight', 'encoder.bert.encoder.layer.6.adapter_w2.weight', 'encoder.bert.encoder.layer.7.adapter_ln.weight', 'encoder.bert.encoder.layer.7.adapter_ln.bias', 'encoder.bert.encoder.layer.7.adapter_w1.weight', 'encoder.bert.encoder.layer.7.adapter_w2.weight', 'encoder.bert.encoder.layer.8.adapter_ln.weight', 'encoder.bert.encoder.layer.8.adapter_ln.bias', 'encoder.bert.encoder.layer.8.adapter_w1.weight', 'encoder.bert.encoder.layer.8.adapter_w2.weight', 'encoder.bert.encoder.layer.9.adapter_ln.weight', 'encoder.bert.encoder.layer.9.adapter_ln.bias', 'encoder.bert.encoder.layer.9.adapter_w1.weight', 'encoder.bert.encoder.layer.9.adapter_w2.weight', 'encoder.bert.encoder.layer.10.adapter_ln.weight', 'encoder.bert.encoder.layer.10.adapter_ln.bias', 'encoder.bert.encoder.layer.10.adapter_w1.weight', 'encoder.bert.encoder.layer.10.adapter_w2.weight', 'encoder.bert.encoder.layer.11.adapter_ln.weight', 'encoder.bert.encoder.layer.11.adapter_ln.bias', 'encoder.bert.encoder.layer.11.adapter_w1.weight', 'encoder.bert.encoder.layer.11.adapter_w2.weight', 'decoder.embed_mask_ins.weight', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.adapter.encoder_attn_fc1.weight', 'decoder.layers.0.adapter.encoder_attn_fc2.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.0.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.0.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.adapter.encoder_attn_fc1.weight', 'decoder.layers.1.adapter.encoder_attn_fc2.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.1.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.1.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.adapter.encoder_attn_fc1.weight', 'decoder.layers.2.adapter.encoder_attn_fc2.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.2.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.2.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.adapter.encoder_attn_fc1.weight', 'decoder.layers.3.adapter.encoder_attn_fc2.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.3.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.3.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.adapter.encoder_attn_fc1.weight', 'decoder.layers.4.adapter.encoder_attn_fc2.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.4.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.4.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.adapter.encoder_attn_fc1.weight', 'decoder.layers.5.adapter.encoder_attn_fc2.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.5.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.5.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.encoder_attn.k_proj.weight', 'decoder.layers.6.encoder_attn.k_proj.bias', 'decoder.layers.6.encoder_attn.v_proj.weight', 'decoder.layers.6.encoder_attn.v_proj.bias', 'decoder.layers.6.encoder_attn.q_proj.weight', 'decoder.layers.6.encoder_attn.q_proj.bias', 'decoder.layers.6.encoder_attn.out_proj.weight', 'decoder.layers.6.encoder_attn.out_proj.bias', 'decoder.layers.6.encoder_attn_layer_norm.weight', 'decoder.layers.6.encoder_attn_layer_norm.bias', 'decoder.layers.6.adapter.encoder_attn_fc1.weight', 'decoder.layers.6.adapter.encoder_attn_fc2.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.6.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.6.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.encoder_attn.k_proj.weight', 'decoder.layers.7.encoder_attn.k_proj.bias', 'decoder.layers.7.encoder_attn.v_proj.weight', 'decoder.layers.7.encoder_attn.v_proj.bias', 'decoder.layers.7.encoder_attn.q_proj.weight', 'decoder.layers.7.encoder_attn.q_proj.bias', 'decoder.layers.7.encoder_attn.out_proj.weight', 'decoder.layers.7.encoder_attn.out_proj.bias', 'decoder.layers.7.encoder_attn_layer_norm.weight', 'decoder.layers.7.encoder_attn_layer_norm.bias', 'decoder.layers.7.adapter.encoder_attn_fc1.weight', 'decoder.layers.7.adapter.encoder_attn_fc2.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.7.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.7.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.encoder_attn.k_proj.weight', 'decoder.layers.8.encoder_attn.k_proj.bias', 'decoder.layers.8.encoder_attn.v_proj.weight', 'decoder.layers.8.encoder_attn.v_proj.bias', 'decoder.layers.8.encoder_attn.q_proj.weight', 'decoder.layers.8.encoder_attn.q_proj.bias', 'decoder.layers.8.encoder_attn.out_proj.weight', 'decoder.layers.8.encoder_attn.out_proj.bias', 'decoder.layers.8.encoder_attn_layer_norm.weight', 'decoder.layers.8.encoder_attn_layer_norm.bias', 'decoder.layers.8.adapter.encoder_attn_fc1.weight', 'decoder.layers.8.adapter.encoder_attn_fc2.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.8.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.8.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.encoder_attn.k_proj.weight', 'decoder.layers.9.encoder_attn.k_proj.bias', 'decoder.layers.9.encoder_attn.v_proj.weight', 'decoder.layers.9.encoder_attn.v_proj.bias', 'decoder.layers.9.encoder_attn.q_proj.weight', 'decoder.layers.9.encoder_attn.q_proj.bias', 'decoder.layers.9.encoder_attn.out_proj.weight', 'decoder.layers.9.encoder_attn.out_proj.bias', 'decoder.layers.9.encoder_attn_layer_norm.weight', 'decoder.layers.9.encoder_attn_layer_norm.bias', 'decoder.layers.9.adapter.encoder_attn_fc1.weight', 'decoder.layers.9.adapter.encoder_attn_fc2.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.9.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.9.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.encoder_attn.k_proj.weight', 'decoder.layers.10.encoder_attn.k_proj.bias', 'decoder.layers.10.encoder_attn.v_proj.weight', 'decoder.layers.10.encoder_attn.v_proj.bias', 'decoder.layers.10.encoder_attn.q_proj.weight', 'decoder.layers.10.encoder_attn.q_proj.bias', 'decoder.layers.10.encoder_attn.out_proj.weight', 'decoder.layers.10.encoder_attn.out_proj.bias', 'decoder.layers.10.encoder_attn_layer_norm.weight', 'decoder.layers.10.encoder_attn_layer_norm.bias', 'decoder.layers.10.adapter.encoder_attn_fc1.weight', 'decoder.layers.10.adapter.encoder_attn_fc2.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.10.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.10.adapter_reposition.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.encoder_attn.k_proj.weight', 'decoder.layers.11.encoder_attn.k_proj.bias', 'decoder.layers.11.encoder_attn.v_proj.weight', 'decoder.layers.11.encoder_attn.v_proj.bias', 'decoder.layers.11.encoder_attn.q_proj.weight', 'decoder.layers.11.encoder_attn.q_proj.bias', 'decoder.layers.11.encoder_attn.out_proj.weight', 'decoder.layers.11.encoder_attn.out_proj.bias', 'decoder.layers.11.encoder_attn_layer_norm.weight', 'decoder.layers.11.encoder_attn_layer_norm.bias', 'decoder.layers.11.adapter.encoder_attn_fc1.weight', 'decoder.layers.11.adapter.encoder_attn_fc2.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter.encoder_attn_final_layer_norm.bias', 'decoder.layers.11.adapter_reposition.encoder_attn_fc1.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_fc2.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.weight', 'decoder.layers.11.adapter_reposition.encoder_attn_final_layer_norm.bias']2022-08-13 23:46:56 | INFO | fairseq_cli.train | training on 4 GPUs
2022-08-13 23:46:56 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 32
2022-08-13 23:46:56 | INFO | fairseq.trainer | no existing checkpoint found ../checkpoints_bert_bert12_adaptor_uncased_Ggw/checkpoint_last.pt
2022-08-13 23:46:56 | INFO | fairseq.trainer | loading train data for epoch 1
2022-08-13 23:46:56 | INFO | fairseq.data.data_utils | loaded 3803957 examples from: ../data-bin-bert-uncased-Ggw/train.source-target.source
2022-08-13 23:46:56 | INFO | fairseq.data.data_utils | loaded 3803957 examples from: ../data-bin-bert-uncased-Ggw/train.source-target.target
2022-08-13 23:46:56 | INFO | fairseq.tasks.translation | ../data-bin-bert-uncased-Ggw train source-target 3803957 examples
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
2022-08-13 23:49:55 | INFO | train_inner | epoch 001:    100 / 3715 loss=24.457, nll_loss=13.1, mask_ins=7.591, word_ins_ml=13.444, word_reposition=3.423, ppl=2.30326e+07, wps=8223.6, ups=0.66, wpb=12381, bsz=1024, num_updates=100, lr=1.0098e-05, gnorm=21.017, clip=18, loss_scale=128, train_wall=150, wall=180
2022-08-13 23:52:25 | INFO | train_inner | epoch 001:    200 / 3715 loss=19.961, nll_loss=11.913, mask_ins=4.807, word_ins_ml=12.402, word_reposition=2.751, ppl=1.02034e+06, wps=8266.2, ups=0.67, wpb=12393, bsz=1024, num_updates=200, lr=2.0096e-05, gnorm=17.093, clip=0, loss_scale=128, train_wall=148, wall=330
2022-08-13 23:54:56 | INFO | train_inner | epoch 001:    300 / 3715 loss=16.206, nll_loss=11.485, mask_ins=2.523, word_ins_ml=12.027, word_reposition=1.655, ppl=75603.8, wps=8113.3, ups=0.66, wpb=12211.9, bsz=1024, num_updates=300, lr=3.0094e-05, gnorm=5.629, clip=0, loss_scale=128, train_wall=149, wall=480
2022-08-13 23:57:26 | INFO | train_inner | epoch 001:    400 / 3715 loss=15.213, nll_loss=11.027, mask_ins=2.196, word_ins_ml=11.626, word_reposition=1.39, ppl=37973.7, wps=8229.7, ups=0.67, wpb=12339.2, bsz=1024, num_updates=400, lr=4.0092e-05, gnorm=3.17, clip=0, loss_scale=128, train_wall=148, wall=630
2022-08-13 23:59:55 | INFO | train_inner | epoch 001:    500 / 3715 loss=14.707, nll_loss=10.698, mask_ins=2.086, word_ins_ml=11.335, word_reposition=1.285, ppl=26738.2, wps=8216.6, ups=0.67, wpb=12295.7, bsz=1024, num_updates=500, lr=5.009e-05, gnorm=3.123, clip=0, loss_scale=128, train_wall=148, wall=780
2022-08-14 00:02:26 | INFO | train_inner | epoch 001:    600 / 3715 loss=14.261, nll_loss=10.417, mask_ins=2.028, word_ins_ml=11.089, word_reposition=1.145, ppl=19631.3, wps=8176.3, ups=0.67, wpb=12290.3, bsz=1024, num_updates=600, lr=6.0088e-05, gnorm=3.003, clip=0, loss_scale=242, train_wall=148, wall=930
2022-08-14 00:05:00 | INFO | train_inner | epoch 001:    700 / 3715 loss=13.757, nll_loss=10.169, mask_ins=1.972, word_ins_ml=10.871, word_reposition=0.914, ppl=13841.8, wps=8063.9, ups=0.65, wpb=12403.6, bsz=1024, num_updates=700, lr=7.0086e-05, gnorm=3.208, clip=0, loss_scale=256, train_wall=152, wall=1084
2022-08-14 00:07:42 | INFO | train_inner | epoch 001:    800 / 3715 loss=13.37, nll_loss=9.949, mask_ins=1.925, word_ins_ml=10.679, word_reposition=0.767, ppl=10589.7, wps=7576.7, ups=0.62, wpb=12281.2, bsz=1024, num_updates=800, lr=8.0084e-05, gnorm=3.075, clip=0, loss_scale=256, train_wall=160, wall=1246
2022-08-14 00:10:32 | INFO | train_inner | epoch 001:    900 / 3715 loss=13.074, nll_loss=9.724, mask_ins=1.899, word_ins_ml=10.482, word_reposition=0.694, ppl=8625.18, wps=7255.8, ups=0.59, wpb=12382.1, bsz=1024, num_updates=900, lr=9.0082e-05, gnorm=2.879, clip=0, loss_scale=256, train_wall=169, wall=1417
2022-08-14 00:13:15 | INFO | train_inner | epoch 001:   1000 / 3715 loss=12.86, nll_loss=9.501, mask_ins=1.898, word_ins_ml=10.286, word_reposition=0.676, ppl=7434.79, wps=7572.1, ups=0.61, wpb=12326.2, bsz=1024, num_updates=1000, lr=0.00010008, gnorm=2.871, clip=0, loss_scale=256, train_wall=161, wall=1579
2022-08-14 00:16:14 | INFO | train_inner | epoch 001:   1100 / 3715 loss=12.608, nll_loss=9.236, mask_ins=1.886, word_ins_ml=10.054, word_reposition=0.668, ppl=6243.87, wps=6877.1, ups=0.56, wpb=12278.7, bsz=1024, num_updates=1100, lr=0.000110078, gnorm=2.715, clip=0, loss_scale=453, train_wall=177, wall=1758
2022-08-14 00:19:05 | INFO | train_inner | epoch 001:   1200 / 3715 loss=12.304, nll_loss=8.894, mask_ins=1.877, word_ins_ml=9.755, word_reposition=0.672, ppl=5057.63, wps=7201.8, ups=0.59, wpb=12304.7, bsz=1024, num_updates=1200, lr=0.000120076, gnorm=2.797, clip=0, loss_scale=512, train_wall=169, wall=1929
2022-08-14 00:22:03 | INFO | train_inner | epoch 001:   1300 / 3715 loss=12.006, nll_loss=8.549, mask_ins=1.868, word_ins_ml=9.454, word_reposition=0.685, ppl=4113.67, wps=6876.7, ups=0.56, wpb=12250.6, bsz=1023.9, num_updates=1300, lr=0.000130074, gnorm=2.876, clip=0, loss_scale=512, train_wall=176, wall=2107
2022-08-14 00:25:00 | INFO | train_inner | epoch 001:   1400 / 3715 loss=11.715, nll_loss=8.258, mask_ins=1.838, word_ins_ml=9.202, word_reposition=0.675, ppl=3360.86, wps=6930.3, ups=0.56, wpb=12314.3, bsz=1024, num_updates=1400, lr=0.000140072, gnorm=2.831, clip=0, loss_scale=512, train_wall=176, wall=2285
2022-08-14 00:28:00 | INFO | train_inner | epoch 001:   1500 / 3715 loss=11.489, nll_loss=8.032, mask_ins=1.802, word_ins_ml=9.007, word_reposition=0.681, ppl=2874.47, wps=6883.7, ups=0.56, wpb=12339.9, bsz=1024, num_updates=1500, lr=0.00015007, gnorm=2.826, clip=0, loss_scale=512, train_wall=177, wall=2464
2022-08-14 00:31:01 | INFO | train_inner | epoch 001:   1600 / 3715 loss=11.262, nll_loss=7.812, mask_ins=1.775, word_ins_ml=8.817, word_reposition=0.669, ppl=2455.04, wps=6791.9, ups=0.55, wpb=12311.6, bsz=1024, num_updates=1600, lr=0.000160068, gnorm=2.707, clip=0, loss_scale=845, train_wall=179, wall=2645
2022-08-14 00:34:01 | INFO | train_inner | epoch 001:   1700 / 3715 loss=11.057, nll_loss=7.615, mask_ins=1.75, word_ins_ml=8.648, word_reposition=0.659, ppl=2131.08, wps=6805.7, ups=0.56, wpb=12246.1, bsz=1024, num_updates=1700, lr=0.000170066, gnorm=2.589, clip=0, loss_scale=1024, train_wall=178, wall=2825
2022-08-14 00:37:05 | INFO | train_inner | epoch 001:   1800 / 3715 loss=10.901, nll_loss=7.455, mask_ins=1.734, word_ins_ml=8.512, word_reposition=0.655, ppl=1911.67, wps=6665.2, ups=0.54, wpb=12286.9, bsz=1024, num_updates=1800, lr=0.000180064, gnorm=2.551, clip=0, loss_scale=1024, train_wall=182, wall=3010
2022-08-14 00:40:06 | INFO | train_inner | epoch 001:   1900 / 3715 loss=10.745, nll_loss=7.296, mask_ins=1.707, word_ins_ml=8.377, word_reposition=0.66, ppl=1715.89, wps=6787.7, ups=0.55, wpb=12279.5, bsz=1024, num_updates=1900, lr=0.000190062, gnorm=2.473, clip=0, loss_scale=1024, train_wall=179, wall=3190
2022-08-14 00:43:10 | INFO | train_inner | epoch 001:   2000 / 3715 loss=10.618, nll_loss=7.172, mask_ins=1.705, word_ins_ml=8.273, word_reposition=0.64, ppl=1571.31, wps=6673.7, ups=0.54, wpb=12297.6, bsz=1024, num_updates=2000, lr=0.00020006, gnorm=2.426, clip=0, loss_scale=1024, train_wall=182, wall=3375
2022-08-14 00:46:12 | INFO | train_inner | epoch 001:   2100 / 3715 loss=10.502, nll_loss=7.046, mask_ins=1.697, word_ins_ml=8.166, word_reposition=0.639, ppl=1450.32, wps=6848.6, ups=0.55, wpb=12429, bsz=1024, num_updates=2100, lr=0.000210058, gnorm=2.301, clip=0, loss_scale=1567, train_wall=179, wall=3556
2022-08-14 00:49:12 | INFO | train_inner | epoch 001:   2200 / 3715 loss=10.396, nll_loss=6.931, mask_ins=1.683, word_ins_ml=8.07, word_reposition=0.643, ppl=1347.57, wps=6863.8, ups=0.55, wpb=12387.6, bsz=1024, num_updates=2200, lr=0.000220056, gnorm=2.358, clip=0, loss_scale=2048, train_wall=178, wall=3737
2022-08-14 00:52:12 | INFO | train_inner | epoch 001:   2300 / 3715 loss=10.278, nll_loss=6.814, mask_ins=1.673, word_ins_ml=7.971, word_reposition=0.634, ppl=1241.62, wps=6889.9, ups=0.56, wpb=12383.7, bsz=1024, num_updates=2300, lr=0.000230054, gnorm=2.131, clip=0, loss_scale=2048, train_wall=178, wall=3916
2022-08-14 00:55:11 | INFO | train_inner | epoch 001:   2400 / 3715 loss=10.15, nll_loss=6.71, mask_ins=1.649, word_ins_ml=7.884, word_reposition=0.617, ppl=1136.48, wps=6856.9, ups=0.56, wpb=12293, bsz=1024, num_updates=2400, lr=0.000240052, gnorm=2.178, clip=0, loss_scale=2048, train_wall=177, wall=4096
2022-08-14 00:58:12 | INFO | train_inner | epoch 001:   2500 / 3715 loss=10.039, nll_loss=6.608, mask_ins=1.623, word_ins_ml=7.797, word_reposition=0.619, ppl=1052.06, wps=6802, ups=0.55, wpb=12321.2, bsz=1024, num_updates=2500, lr=0.00025005, gnorm=2.103, clip=0, loss_scale=2048, train_wall=179, wall=4277
2022-08-14 01:01:14 | INFO | train_inner | epoch 001:   2600 / 3715 loss=9.896, nll_loss=6.491, mask_ins=1.601, word_ins_ml=7.699, word_reposition=0.596, ppl=952.75, wps=6794.6, ups=0.55, wpb=12323, bsz=1024, num_updates=2600, lr=0.000260048, gnorm=2.076, clip=0, loss_scale=2888, train_wall=179, wall=4458
2022-08-14 01:04:14 | INFO | train_inner | epoch 001:   2700 / 3715 loss=9.768, nll_loss=6.372, mask_ins=1.582, word_ins_ml=7.598, word_reposition=0.588, ppl=871.75, wps=6796.6, ups=0.56, wpb=12244.9, bsz=1024, num_updates=2700, lr=0.000270046, gnorm=1.995, clip=0, loss_scale=4096, train_wall=178, wall=4638
2022-08-14 01:07:15 | INFO | train_inner | epoch 001:   2800 / 3715 loss=9.688, nll_loss=6.282, mask_ins=1.568, word_ins_ml=7.522, word_reposition=0.599, ppl=825.04, wps=6843.2, ups=0.55, wpb=12379, bsz=1024, num_updates=2800, lr=0.000280044, gnorm=1.956, clip=0, loss_scale=4096, train_wall=179, wall=4819
2022-08-14 01:10:15 | INFO | train_inner | epoch 001:   2900 / 3715 loss=9.602, nll_loss=6.22, mask_ins=1.553, word_ins_ml=7.469, word_reposition=0.58, ppl=776.94, wps=6810, ups=0.56, wpb=12241.4, bsz=1024, num_updates=2900, lr=0.000290042, gnorm=1.899, clip=0, loss_scale=4096, train_wall=178, wall=4999
2022-08-14 01:13:13 | INFO | train_inner | epoch 001:   3000 / 3715 loss=9.512, nll_loss=6.14, mask_ins=1.54, word_ins_ml=7.402, word_reposition=0.57, ppl=730.14, wps=6899.7, ups=0.56, wpb=12293.5, bsz=1024, num_updates=3000, lr=0.00030004, gnorm=1.896, clip=0, loss_scale=4096, train_wall=176, wall=5177
2022-08-14 01:16:12 | INFO | train_inner | epoch 001:   3100 / 3715 loss=9.441, nll_loss=6.073, mask_ins=1.532, word_ins_ml=7.346, word_reposition=0.564, ppl=695.23, wps=6886.6, ups=0.56, wpb=12362.2, bsz=1024, num_updates=3100, lr=0.000310038, gnorm=1.854, clip=0, loss_scale=5284, train_wall=178, wall=5357
2022-08-14 01:19:11 | INFO | train_inner | epoch 001:   3200 / 3715 loss=9.344, nll_loss=5.974, mask_ins=1.52, word_ins_ml=7.26, word_reposition=0.564, ppl=650.03, wps=6844.1, ups=0.56, wpb=12255.8, bsz=1024, num_updates=3200, lr=0.000320036, gnorm=2.001, clip=0, loss_scale=8192, train_wall=177, wall=5536
2022-08-14 01:22:13 | INFO | train_inner | epoch 001:   3300 / 3715 loss=9.297, nll_loss=5.944, mask_ins=1.511, word_ins_ml=7.236, word_reposition=0.55, ppl=628.82, wps=6741.2, ups=0.55, wpb=12231.8, bsz=1024, num_updates=3300, lr=0.000330034, gnorm=1.812, clip=0, loss_scale=8192, train_wall=180, wall=5717
2022-08-14 01:25:14 | INFO | train_inner | epoch 001:   3400 / 3715 loss=9.252, nll_loss=5.897, mask_ins=1.5, word_ins_ml=7.196, word_reposition=0.556, ppl=609.81, wps=6820.1, ups=0.55, wpb=12361.9, bsz=1024, num_updates=3400, lr=0.000340032, gnorm=1.848, clip=0, loss_scale=8192, train_wall=179, wall=5899
2022-08-14 01:28:14 | INFO | train_inner | epoch 001:   3500 / 3715 loss=9.185, nll_loss=5.832, mask_ins=1.494, word_ins_ml=7.14, word_reposition=0.551, ppl=581.88, wps=6862.2, ups=0.56, wpb=12360.7, bsz=1024, num_updates=3500, lr=0.00035003, gnorm=1.747, clip=0, loss_scale=8192, train_wall=178, wall=6079
2022-08-14 01:31:14 | INFO | train_inner | epoch 001:   3600 / 3715 loss=9.166, nll_loss=5.816, mask_ins=1.491, word_ins_ml=7.127, word_reposition=0.548, ppl=574.33, wps=6894.7, ups=0.56, wpb=12366, bsz=1024, num_updates=3600, lr=0.000360028, gnorm=1.861, clip=0, loss_scale=9585, train_wall=177, wall=6258
2022-08-14 01:34:12 | INFO | train_inner | epoch 001:   3700 / 3715 loss=9.13, nll_loss=5.78, mask_ins=1.492, word_ins_ml=7.096, word_reposition=0.542, ppl=560.31, wps=6979.7, ups=0.56, wpb=12428, bsz=1024, num_updates=3700, lr=0.000370026, gnorm=1.734, clip=0, loss_scale=16384, train_wall=176, wall=6436
2022-08-14 01:34:38 | INFO | train | epoch 001 | loss 11.806 | nll_loss 7.97 | mask_ins 1.987 | word_ins_ml 8.974 | word_reposition 0.845 | ppl 3580.39 | wps 7114 | ups 0.58 | wpb 12319.7 | bsz 1023.8 | num_updates 3715 | lr 0.000371526 | gnorm 3.389 | clip 0.5 | loss_scale 2823 | train_wall 6363 | wall 6463
2022-08-14 01:37:02 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.799 | nll_loss 5.326 | mask_ins 1.419 | word_ins_ml 6.817 | word_reposition 0.562 | ppl 445.27 | wps 16134.7 | wpb 1555.8 | bsz 128 | num_updates 3715
2022-08-14 01:37:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_bert12_adaptor_uncased_Ggw/checkpoint_best.pt (epoch 1 @ 3715 updates, score 8.799) (writing took 3.689930370077491 seconds)
2022-08-14 01:39:37 | INFO | train_inner | epoch 002:     85 / 3715 loss=9.032, nll_loss=5.699, mask_ins=1.472, word_ins_ml=7.026, word_reposition=0.534, ppl=523.36, wps=3750.8, ups=0.31, wpb=12205.4, bsz=1018.2, num_updates=3800, lr=0.000380024, gnorm=1.75, clip=0, loss_scale=16384, train_wall=176, wall=6761
2022-08-14 01:42:35 | INFO | train_inner | epoch 002:    185 / 3715 loss=9.022, nll_loss=5.688, mask_ins=1.475, word_ins_ml=7.017, word_reposition=0.531, ppl=519.92, wps=6960, ups=0.56, wpb=12371.5, bsz=1024, num_updates=3900, lr=0.000390022, gnorm=1.768, clip=0, loss_scale=16384, train_wall=176, wall=6939
2022-08-14 01:45:32 | INFO | train_inner | epoch 002:    285 / 3715 loss=8.993, nll_loss=5.654, mask_ins=1.468, word_ins_ml=6.987, word_reposition=0.539, ppl=509.56, wps=6938.9, ups=0.57, wpb=12276.5, bsz=1024, num_updates=4000, lr=0.00040002, gnorm=1.713, clip=0, loss_scale=16384, train_wall=175, wall=7116
2022-08-14 01:46:05 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2022-08-14 01:48:31 | INFO | train_inner | epoch 002:    386 / 3715 loss=8.93, nll_loss=5.616, mask_ins=1.458, word_ins_ml=6.954, word_reposition=0.518, ppl=487.67, wps=6877.7, ups=0.56, wpb=12307.5, bsz=1024, num_updates=4100, lr=0.000410018, gnorm=1.76, clip=0, loss_scale=9652, train_wall=177, wall=7295
2022-08-14 01:51:28 | INFO | train_inner | epoch 002:    486 / 3715 loss=8.906, nll_loss=5.576, mask_ins=1.458, word_ins_ml=6.92, word_reposition=0.528, ppl=479.58, wps=6906.5, ups=0.56, wpb=12241.2, bsz=1024, num_updates=4200, lr=0.000420016, gnorm=1.731, clip=0, loss_scale=8192, train_wall=175, wall=7472
2022-08-14 01:54:26 | INFO | train_inner | epoch 002:    586 / 3715 loss=8.87, nll_loss=5.559, mask_ins=1.451, word_ins_ml=6.904, word_reposition=0.515, ppl=467.96, wps=6947.3, ups=0.56, wpb=12355.5, bsz=1024, num_updates=4300, lr=0.000430014, gnorm=1.639, clip=0, loss_scale=8192, train_wall=176, wall=7650
2022-08-14 01:56:04 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2022-08-14 01:57:25 | INFO | train_inner | epoch 002:    687 / 3715 loss=8.868, nll_loss=5.555, mask_ins=1.445, word_ins_ml=6.901, word_reposition=0.523, ppl=467.33, wps=6893.6, ups=0.56, wpb=12374.9, bsz=1024, num_updates=4400, lr=0.000440012, gnorm=1.571, clip=0, loss_scale=6286, train_wall=178, wall=7830
2022-08-14 02:00:22 | INFO | train_inner | epoch 002:    787 / 3715 loss=8.853, nll_loss=5.528, mask_ins=1.453, word_ins_ml=6.876, word_reposition=0.523, ppl=462.52, wps=7023.8, ups=0.57, wpb=12406.9, bsz=1024, num_updates=4500, lr=0.00045001, gnorm=1.768, clip=0, loss_scale=4096, train_wall=175, wall=8006
2022-08-14 02:03:21 | INFO | train_inner | epoch 002:    887 / 3715 loss=8.824, nll_loss=5.511, mask_ins=1.441, word_ins_ml=6.862, word_reposition=0.521, ppl=453.3, wps=6915.1, ups=0.56, wpb=12389.1, bsz=1024, num_updates=4600, lr=0.000460008, gnorm=1.655, clip=0, loss_scale=4096, train_wall=177, wall=8186
2022-08-14 02:06:20 | INFO | train_inner | epoch 002:    987 / 3715 loss=8.803, nll_loss=5.496, mask_ins=1.446, word_ins_ml=6.848, word_reposition=0.509, ppl=446.7, wps=6888, ups=0.56, wpb=12302.4, bsz=1024, num_updates=4700, lr=0.000470006, gnorm=1.667, clip=0, loss_scale=4096, train_wall=177, wall=8364
2022-08-14 02:09:16 | INFO | train_inner | epoch 002:   1087 / 3715 loss=8.777, nll_loss=5.469, mask_ins=1.437, word_ins_ml=6.825, word_reposition=0.514, ppl=438.56, wps=6957.1, ups=0.57, wpb=12280.3, bsz=1024, num_updates=4800, lr=0.000480004, gnorm=1.769, clip=0, loss_scale=4096, train_wall=175, wall=8541
2022-08-14 02:12:12 | INFO | train_inner | epoch 002:   1187 / 3715 loss=8.726, nll_loss=5.428, mask_ins=1.427, word_ins_ml=6.788, word_reposition=0.511, ppl=423.35, wps=6959.7, ups=0.57, wpb=12266, bsz=1024, num_updates=4900, lr=0.000490002, gnorm=1.676, clip=0, loss_scale=5530, train_wall=174, wall=8717
2022-08-14 02:15:12 | INFO | train_inner | epoch 002:   1287 / 3715 loss=8.692, nll_loss=5.399, mask_ins=1.421, word_ins_ml=6.763, word_reposition=0.508, ppl=413.68, wps=6856.7, ups=0.56, wpb=12292.6, bsz=1024, num_updates=5000, lr=0.0005, gnorm=1.614, clip=0, loss_scale=8192, train_wall=177, wall=8896
2022-08-14 02:17:51 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2022-08-14 02:18:14 | INFO | train_inner | epoch 002:   1388 / 3715 loss=8.691, nll_loss=5.403, mask_ins=1.42, word_ins_ml=6.766, word_reposition=0.504, ppl=413.21, wps=6720.2, ups=0.55, wpb=12238.3, bsz=1024, num_updates=5100, lr=0.000495074, gnorm=1.569, clip=0, loss_scale=7624, train_wall=180, wall=9078
2022-08-14 02:20:48 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-08-14 02:21:15 | INFO | train_inner | epoch 002:   1489 / 3715 loss=8.683, nll_loss=5.372, mask_ins=1.426, word_ins_ml=6.739, word_reposition=0.517, ppl=410.91, wps=6777.3, ups=0.55, wpb=12262.9, bsz=1024, num_updates=5200, lr=0.00049029, gnorm=1.665, clip=0, loss_scale=3772, train_wall=179, wall=9259
2022-08-14 02:24:14 | INFO | train_inner | epoch 002:   1589 / 3715 loss=8.645, nll_loss=5.356, mask_ins=1.41, word_ins_ml=6.724, word_reposition=0.511, ppl=400.19, wps=6893, ups=0.56, wpb=12367.6, bsz=1024, num_updates=5300, lr=0.000485643, gnorm=1.465, clip=0, loss_scale=2048, train_wall=177, wall=9439
2022-08-14 02:27:16 | INFO | train_inner | epoch 002:   1689 / 3715 loss=8.622, nll_loss=5.339, mask_ins=1.414, word_ins_ml=6.709, word_reposition=0.499, ppl=393.94, wps=6786.5, ups=0.55, wpb=12316.9, bsz=1024, num_updates=5400, lr=0.000481125, gnorm=1.696, clip=0, loss_scale=2048, train_wall=180, wall=9620
2022-08-14 02:30:15 | INFO | train_inner | epoch 002:   1789 / 3715 loss=8.584, nll_loss=5.296, mask_ins=1.41, word_ins_ml=6.67, word_reposition=0.504, ppl=383.65, wps=6826.7, ups=0.56, wpb=12240, bsz=1024, num_updates=5500, lr=0.000476731, gnorm=1.492, clip=0, loss_scale=2048, train_wall=177, wall=9799
2022-08-14 02:33:14 | INFO | train_inner | epoch 002:   1889 / 3715 loss=8.553, nll_loss=5.28, mask_ins=1.402, word_ins_ml=6.656, word_reposition=0.495, ppl=375.63, wps=6912.2, ups=0.56, wpb=12346.4, bsz=1024, num_updates=5600, lr=0.000472456, gnorm=1.47, clip=0, loss_scale=2048, train_wall=177, wall=9978
2022-08-14 02:36:10 | INFO | train_inner | epoch 002:   1989 / 3715 loss=8.547, nll_loss=5.27, mask_ins=1.406, word_ins_ml=6.647, word_reposition=0.494, ppl=373.94, wps=6966.8, ups=0.57, wpb=12319, bsz=1024, num_updates=5700, lr=0.000468293, gnorm=1.566, clip=0, loss_scale=2130, train_wall=175, wall=10155
2022-08-14 02:39:08 | INFO | train_inner | epoch 002:   2089 / 3715 loss=8.528, nll_loss=5.261, mask_ins=1.395, word_ins_ml=6.638, word_reposition=0.496, ppl=369.23, wps=6966.1, ups=0.56, wpb=12399.9, bsz=1023.9, num_updates=5800, lr=0.000464238, gnorm=1.412, clip=0, loss_scale=4096, train_wall=176, wall=10333
2022-08-14 02:42:07 | INFO | train_inner | epoch 002:   2189 / 3715 loss=8.481, nll_loss=5.216, mask_ins=1.398, word_ins_ml=6.598, word_reposition=0.485, ppl=357.41, wps=6961.1, ups=0.56, wpb=12426.9, bsz=1024, num_updates=5900, lr=0.000460287, gnorm=1.613, clip=0, loss_scale=4096, train_wall=177, wall=10511
2022-08-14 02:45:05 | INFO | train_inner | epoch 002:   2289 / 3715 loss=8.453, nll_loss=5.194, mask_ins=1.388, word_ins_ml=6.578, word_reposition=0.487, ppl=350.51, wps=6892.7, ups=0.56, wpb=12247.8, bsz=1024, num_updates=6000, lr=0.000456435, gnorm=1.422, clip=0, loss_scale=4096, train_wall=176, wall=10689
2022-08-14 02:48:21 | INFO | train_inner | epoch 002:   2389 / 3715 loss=8.418, nll_loss=5.161, mask_ins=1.382, word_ins_ml=6.55, word_reposition=0.486, ppl=342.01, wps=6292.8, ups=0.51, wpb=12324.7, bsz=1024, num_updates=6100, lr=0.000452679, gnorm=1.48, clip=0, loss_scale=4096, train_wall=194, wall=10885
2022-08-14 02:51:23 | INFO | train_inner | epoch 002:   2489 / 3715 loss=8.377, nll_loss=5.125, mask_ins=1.377, word_ins_ml=6.517, word_reposition=0.483, ppl=332.39, wps=6734.2, ups=0.55, wpb=12316.2, bsz=1024, num_updates=6200, lr=0.000449013, gnorm=1.43, clip=0, loss_scale=4096, train_wall=181, wall=11068
2022-08-14 02:54:22 | INFO | train_inner | epoch 002:   2589 / 3715 loss=8.387, nll_loss=5.137, mask_ins=1.374, word_ins_ml=6.527, word_reposition=0.486, ppl=334.85, wps=6870.4, ups=0.56, wpb=12285.3, bsz=1024, num_updates=6300, lr=0.000445435, gnorm=1.522, clip=0, loss_scale=7864, train_wall=177, wall=11247
2022-08-14 02:57:22 | INFO | train_inner | epoch 002:   2689 / 3715 loss=8.374, nll_loss=5.126, mask_ins=1.374, word_ins_ml=6.517, word_reposition=0.483, ppl=331.83, wps=6832.7, ups=0.56, wpb=12298.2, bsz=1024, num_updates=6400, lr=0.000441942, gnorm=1.505, clip=0, loss_scale=8192, train_wall=178, wall=11427
2022-08-14 03:00:36 | INFO | train_inner | epoch 002:   2789 / 3715 loss=8.325, nll_loss=5.075, mask_ins=1.375, word_ins_ml=6.472, word_reposition=0.478, ppl=320.59, wps=6362.8, ups=0.52, wpb=12344.2, bsz=1024, num_updates=6500, lr=0.000438529, gnorm=1.532, clip=0, loss_scale=8192, train_wall=192, wall=11621
2022-08-14 03:03:38 | INFO | train_inner | epoch 002:   2889 / 3715 loss=8.363, nll_loss=5.104, mask_ins=1.375, word_ins_ml=6.496, word_reposition=0.492, ppl=329.21, wps=6806.1, ups=0.55, wpb=12362.7, bsz=1024, num_updates=6600, lr=0.000435194, gnorm=1.383, clip=0, loss_scale=8192, train_wall=180, wall=11802
2022-08-14 03:06:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2022-08-14 03:06:43 | INFO | train_inner | epoch 002:   2990 / 3715 loss=8.304, nll_loss=5.065, mask_ins=1.369, word_ins_ml=6.461, word_reposition=0.474, ppl=316.14, wps=6683.1, ups=0.54, wpb=12344.6, bsz=1024, num_updates=6700, lr=0.000431934, gnorm=1.433, clip=0, loss_scale=7827, train_wall=183, wall=11987
2022-08-14 03:09:56 | INFO | train_inner | epoch 002:   3090 / 3715 loss=8.314, nll_loss=5.076, mask_ins=1.362, word_ins_ml=6.471, word_reposition=0.481, ppl=318.29, wps=6405.7, ups=0.52, wpb=12362.4, bsz=1024, num_updates=6800, lr=0.000428746, gnorm=1.334, clip=0, loss_scale=4096, train_wall=191, wall=12180
2022-08-14 03:12:57 | INFO | train_inner | epoch 002:   3190 / 3715 loss=8.276, nll_loss=5.041, mask_ins=1.362, word_ins_ml=6.44, word_reposition=0.473, ppl=309.92, wps=6762.1, ups=0.55, wpb=12286.9, bsz=1024, num_updates=6900, lr=0.000425628, gnorm=1.384, clip=0, loss_scale=4096, train_wall=180, wall=12362
2022-08-14 03:15:57 | INFO | train_inner | epoch 002:   3290 / 3715 loss=8.288, nll_loss=5.057, mask_ins=1.36, word_ins_ml=6.454, word_reposition=0.475, ppl=312.67, wps=6928.7, ups=0.56, wpb=12433.9, bsz=1024, num_updates=7000, lr=0.000422577, gnorm=1.408, clip=0, loss_scale=4096, train_wall=178, wall=12541
2022-08-14 03:18:57 | INFO | train_inner | epoch 002:   3390 / 3715 loss=8.242, nll_loss=5.012, mask_ins=1.352, word_ins_ml=6.414, word_reposition=0.476, ppl=302.71, wps=6860.1, ups=0.56, wpb=12355, bsz=1024, num_updates=7100, lr=0.000419591, gnorm=1.414, clip=0, loss_scale=4096, train_wall=178, wall=12721
2022-08-14 03:21:59 | INFO | train_inner | epoch 002:   3490 / 3715 loss=8.234, nll_loss=5.011, mask_ins=1.353, word_ins_ml=6.412, word_reposition=0.469, ppl=301.09, wps=6778.3, ups=0.55, wpb=12325.5, bsz=1024, num_updates=7200, lr=0.000416667, gnorm=1.3, clip=0, loss_scale=4096, train_wall=180, wall=12903
2022-08-14 03:24:55 | INFO | train_inner | epoch 002:   3590 / 3715 loss=8.208, nll_loss=4.986, mask_ins=1.356, word_ins_ml=6.39, word_reposition=0.462, ppl=295.74, wps=6996.4, ups=0.57, wpb=12324.2, bsz=1024, num_updates=7300, lr=0.000413803, gnorm=1.411, clip=0, loss_scale=8069, train_wall=174, wall=13079
2022-08-14 03:27:53 | INFO | train_inner | epoch 002:   3690 / 3715 loss=8.183, nll_loss=4.958, mask_ins=1.349, word_ins_ml=6.365, word_reposition=0.469, ppl=290.58, wps=6919, ups=0.56, wpb=12308.2, bsz=1024, num_updates=7400, lr=0.000410997, gnorm=1.402, clip=0, loss_scale=8192, train_wall=176, wall=13257
2022-08-14 03:28:37 | INFO | train | epoch 002 | loss 8.573 | nll_loss 5.296 | mask_ins 1.406 | word_ins_ml 6.669 | word_reposition 0.498 | ppl 380.89 | wps 6683.7 | ups 0.54 | wpb 12319.8 | bsz 1023.8 | num_updates 7425 | lr 0.000410305 | gnorm 1.548 | clip 0 | loss_scale 6211 | train_wall 6620 | wall 13301
2022-08-14 03:30:59 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.961 | nll_loss 4.633 | mask_ins 1.307 | word_ins_ml 6.178 | word_reposition 0.476 | ppl 249.18 | wps 16212.4 | wpb 1555.8 | bsz 128 | num_updates 7425 | best_loss 7.961
2022-08-14 03:31:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_bert12_adaptor_uncased_Ggw/checkpoint_best.pt (epoch 2 @ 7425 updates, score 7.961) (writing took 23.39096497744322 seconds)
2022-08-14 03:33:39 | INFO | train_inner | epoch 003:     75 / 3715 loss=8.166, nll_loss=4.945, mask_ins=1.347, word_ins_ml=6.354, word_reposition=0.465, ppl=287.24, wps=3546.1, ups=0.29, wpb=12283.8, bsz=1018.2, num_updates=7500, lr=0.000408248, gnorm=1.428, clip=0, loss_scale=8192, train_wall=179, wall=13604
2022-08-14 03:36:39 | INFO | train_inner | epoch 003:    175 / 3715 loss=8.143, nll_loss=4.919, mask_ins=1.347, word_ins_ml=6.33, word_reposition=0.466, ppl=282.72, wps=6821.7, ups=0.56, wpb=12282.9, bsz=1024, num_updates=7600, lr=0.000405554, gnorm=1.347, clip=0, loss_scale=8192, train_wall=178, wall=13784
2022-08-14 03:39:37 | INFO | train_inner | epoch 003:    275 / 3715 loss=8.119, nll_loss=4.906, mask_ins=1.341, word_ins_ml=6.319, word_reposition=0.459, ppl=277.95, wps=6860.4, ups=0.56, wpb=12221.1, bsz=1024, num_updates=7700, lr=0.000402911, gnorm=1.31, clip=0, loss_scale=8192, train_wall=176, wall=13962
2022-08-14 03:42:39 | INFO | train_inner | epoch 003:    375 / 3715 loss=8.128, nll_loss=4.912, mask_ins=1.343, word_ins_ml=6.324, word_reposition=0.46, ppl=279.68, wps=6761.1, ups=0.55, wpb=12259.9, bsz=1024, num_updates=7800, lr=0.00040032, gnorm=1.386, clip=0, loss_scale=15155, train_wall=179, wall=14143
2022-08-14 03:42:50 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2022-08-14 03:45:43 | INFO | train_inner | epoch 003:    476 / 3715 loss=8.093, nll_loss=4.886, mask_ins=1.333, word_ins_ml=6.301, word_reposition=0.459, ppl=273.01, wps=6634.6, ups=0.54, wpb=12236, bsz=1024, num_updates=7900, lr=0.000397779, gnorm=1.38, clip=0, loss_scale=8598, train_wall=182, wall=14328
2022-08-14 03:48:45 | INFO | train_inner | epoch 003:    576 / 3715 loss=8.1, nll_loss=4.891, mask_ins=1.339, word_ins_ml=6.305, word_reposition=0.457, ppl=274.41, wps=6746.8, ups=0.55, wpb=12260.4, bsz=1024, num_updates=8000, lr=0.000395285, gnorm=1.39, clip=0, loss_scale=8192, train_wall=180, wall=14509
2022-08-14 03:51:44 | INFO | train_inner | epoch 003:    676 / 3715 loss=8.072, nll_loss=4.873, mask_ins=1.326, word_ins_ml=6.288, word_reposition=0.457, ppl=269.01, wps=6885.3, ups=0.56, wpb=12332.8, bsz=1024, num_updates=8100, lr=0.000392837, gnorm=1.317, clip=0, loss_scale=8192, train_wall=177, wall=14688
2022-08-14 03:54:42 | INFO | train_inner | epoch 003:    776 / 3715 loss=8.061, nll_loss=4.86, mask_ins=1.332, word_ins_ml=6.277, word_reposition=0.452, ppl=267.01, wps=6905, ups=0.56, wpb=12317, bsz=1024, num_updates=8200, lr=0.000390434, gnorm=1.278, clip=0, loss_scale=8192, train_wall=177, wall=14867
2022-08-14 03:57:41 | INFO | train_inner | epoch 003:    876 / 3715 loss=8.05, nll_loss=4.854, mask_ins=1.322, word_ins_ml=6.271, word_reposition=0.457, ppl=264.94, wps=6858, ups=0.56, wpb=12248.9, bsz=1024, num_updates=8300, lr=0.000388075, gnorm=1.256, clip=0, loss_scale=8192, train_wall=177, wall=15045
2022-08-14 04:00:38 | INFO | train_inner | epoch 003:    976 / 3715 loss=8.038, nll_loss=4.851, mask_ins=1.327, word_ins_ml=6.268, word_reposition=0.444, ppl=262.91, wps=6910.9, ups=0.56, wpb=12268.1, bsz=1024, num_updates=8400, lr=0.000385758, gnorm=1.391, clip=0, loss_scale=15073, train_wall=176, wall=15223
2022-08-14 04:03:37 | INFO | train_inner | epoch 003:   1076 / 3715 loss=8.034, nll_loss=4.844, mask_ins=1.326, word_ins_ml=6.26, word_reposition=0.447, ppl=262.12, wps=6955.3, ups=0.56, wpb=12399.6, bsz=1024, num_updates=8500, lr=0.000383482, gnorm=1.224, clip=0, loss_scale=16384, train_wall=176, wall=15401
2022-08-14 04:06:34 | INFO | train_inner | epoch 003:   1176 / 3715 loss=8.026, nll_loss=4.827, mask_ins=1.326, word_ins_ml=6.246, word_reposition=0.454, ppl=260.61, wps=6915, ups=0.56, wpb=12267.3, bsz=1023.9, num_updates=8600, lr=0.000381246, gnorm=1.371, clip=0, loss_scale=16384, train_wall=176, wall=15579
2022-08-14 04:09:35 | INFO | train_inner | epoch 003:   1276 / 3715 loss=8.003, nll_loss=4.81, mask_ins=1.324, word_ins_ml=6.231, word_reposition=0.447, ppl=256.44, wps=6817.2, ups=0.55, wpb=12314.2, bsz=1024, num_updates=8700, lr=0.000379049, gnorm=1.226, clip=0, loss_scale=16384, train_wall=179, wall=15759
2022-08-14 04:10:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2022-08-14 04:12:36 | INFO | train_inner | epoch 003:   1377 / 3715 loss=8.019, nll_loss=4.828, mask_ins=1.323, word_ins_ml=6.246, word_reposition=0.45, ppl=259.41, wps=6766.6, ups=0.55, wpb=12269.7, bsz=1024, num_updates=8800, lr=0.000376889, gnorm=1.303, clip=0, loss_scale=9895, train_wall=179, wall=15940
2022-08-14 04:15:36 | INFO | train_inner | epoch 003:   1477 / 3715 loss=7.987, nll_loss=4.796, mask_ins=1.317, word_ins_ml=6.218, word_reposition=0.452, ppl=253.71, wps=6910.4, ups=0.56, wpb=12427.7, bsz=1024, num_updates=8900, lr=0.000374766, gnorm=1.245, clip=0, loss_scale=8192, train_wall=178, wall=16120
2022-08-14 04:18:38 | INFO | train_inner | epoch 003:   1577 / 3715 loss=8.001, nll_loss=4.809, mask_ins=1.323, word_ins_ml=6.229, word_reposition=0.449, ppl=256.16, wps=6776.3, ups=0.55, wpb=12307.8, bsz=1024, num_updates=9000, lr=0.000372678, gnorm=1.349, clip=0, loss_scale=8192, train_wall=180, wall=16302
2022-08-14 04:21:39 | INFO | train_inner | epoch 003:   1677 / 3715 loss=7.968, nll_loss=4.784, mask_ins=1.311, word_ins_ml=6.208, word_reposition=0.45, ppl=250.4, wps=6805, ups=0.55, wpb=12369.2, bsz=1024, num_updates=9100, lr=0.000370625, gnorm=1.275, clip=0, loss_scale=8192, train_wall=180, wall=16484
2022-08-14 04:24:41 | INFO | train_inner | epoch 003:   1777 / 3715 loss=7.962, nll_loss=4.772, mask_ins=1.316, word_ins_ml=6.197, word_reposition=0.449, ppl=249.31, wps=6827.1, ups=0.55, wpb=12380.4, bsz=1024, num_updates=9200, lr=0.000368605, gnorm=1.2, clip=0, loss_scale=8192, train_wall=179, wall=16665
2022-08-14 04:27:41 | INFO | train_inner | epoch 003:   1877 / 3715 loss=7.982, nll_loss=4.791, mask_ins=1.317, word_ins_ml=6.213, word_reposition=0.451, ppl=252.78, wps=6821.7, ups=0.55, wpb=12314.6, bsz=1024, num_updates=9300, lr=0.000366618, gnorm=1.249, clip=0, loss_scale=13763, train_wall=179, wall=16846
2022-08-14 04:30:40 | INFO | train_inner | epoch 003:   1977 / 3715 loss=7.939, nll_loss=4.747, mask_ins=1.315, word_ins_ml=6.173, word_reposition=0.452, ppl=245.39, wps=6985.6, ups=0.56, wpb=12461.1, bsz=1024, num_updates=9400, lr=0.000364662, gnorm=1.308, clip=0, loss_scale=16384, train_wall=177, wall=17024
2022-08-14 04:33:40 | INFO | train_inner | epoch 003:   2077 / 3715 loss=7.977, nll_loss=4.784, mask_ins=1.32, word_ins_ml=6.205, word_reposition=0.452, ppl=251.97, wps=6833.9, ups=0.56, wpb=12312.4, bsz=1024, num_updates=9500, lr=0.000362738, gnorm=1.237, clip=0, loss_scale=16384, train_wall=178, wall=17204
2022-08-14 04:35:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2022-08-14 04:36:38 | INFO | train_inner | epoch 003:   2178 / 3715 loss=7.932, nll_loss=4.747, mask_ins=1.31, word_ins_ml=6.173, word_reposition=0.449, ppl=244.23, wps=6872.8, ups=0.56, wpb=12246.8, bsz=1024, num_updates=9600, lr=0.000360844, gnorm=1.251, clip=0, loss_scale=13464, train_wall=176, wall=17382
2022-08-14 04:39:38 | INFO | train_inner | epoch 003:   2278 / 3715 loss=7.908, nll_loss=4.735, mask_ins=1.302, word_ins_ml=6.162, word_reposition=0.443, ppl=240.11, wps=6785.3, ups=0.55, wpb=12246, bsz=1024, num_updates=9700, lr=0.000358979, gnorm=1.217, clip=0, loss_scale=8192, train_wall=179, wall=17563
2022-08-14 04:42:40 | INFO | train_inner | epoch 003:   2378 / 3715 loss=7.926, nll_loss=4.744, mask_ins=1.306, word_ins_ml=6.17, word_reposition=0.451, ppl=243.26, wps=6822.9, ups=0.55, wpb=12375.9, bsz=1024, num_updates=9800, lr=0.000357143, gnorm=1.29, clip=0, loss_scale=8192, train_wall=179, wall=17744
2022-08-14 04:44:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2022-08-14 04:45:41 | INFO | train_inner | epoch 003:   2479 / 3715 loss=7.937, nll_loss=4.756, mask_ins=1.314, word_ins_ml=6.18, word_reposition=0.443, ppl=245.04, wps=6812.6, ups=0.55, wpb=12350.2, bsz=1024, num_updates=9900, lr=0.000355335, gnorm=1.406, clip=0, loss_scale=7138, train_wall=179, wall=17926
2022-08-14 04:48:40 | INFO | train_inner | epoch 003:   2579 / 3715 loss=7.931, nll_loss=4.752, mask_ins=1.305, word_ins_ml=6.177, word_reposition=0.449, ppl=244, wps=6951.7, ups=0.56, wpb=12425.2, bsz=1024, num_updates=10000, lr=0.000353553, gnorm=1.256, clip=0, loss_scale=4096, train_wall=177, wall=18104
2022-08-14 04:51:38 | INFO | train_inner | epoch 003:   2679 / 3715 loss=7.907, nll_loss=4.72, mask_ins=1.309, word_ins_ml=6.148, word_reposition=0.45, ppl=240.02, wps=6963.3, ups=0.56, wpb=12374.4, bsz=1024, num_updates=10100, lr=0.000351799, gnorm=1.277, clip=0, loss_scale=4096, train_wall=176, wall=18282
2022-08-14 04:54:36 | INFO | train_inner | epoch 003:   2779 / 3715 loss=7.884, nll_loss=4.704, mask_ins=1.307, word_ins_ml=6.133, word_reposition=0.444, ppl=236.23, wps=6960.9, ups=0.56, wpb=12387.3, bsz=1024, num_updates=10200, lr=0.00035007, gnorm=1.222, clip=0, loss_scale=4096, train_wall=176, wall=18460
2022-08-14 04:57:35 | INFO | train_inner | epoch 003:   2879 / 3715 loss=7.889, nll_loss=4.715, mask_ins=1.302, word_ins_ml=6.144, word_reposition=0.442, ppl=236.97, wps=6909.4, ups=0.56, wpb=12373, bsz=1024, num_updates=10300, lr=0.000348367, gnorm=1.195, clip=0, loss_scale=4096, train_wall=177, wall=18639
2022-08-14 05:00:35 | INFO | train_inner | epoch 003:   2979 / 3715 loss=7.871, nll_loss=4.701, mask_ins=1.304, word_ins_ml=6.131, word_reposition=0.437, ppl=234.08, wps=6839.3, ups=0.55, wpb=12336, bsz=1024, num_updates=10400, lr=0.000346688, gnorm=1.264, clip=0, loss_scale=4669, train_wall=179, wall=18819
2022-08-14 05:03:34 | INFO | train_inner | epoch 003:   3079 / 3715 loss=7.866, nll_loss=4.695, mask_ins=1.304, word_ins_ml=6.125, word_reposition=0.438, ppl=233.28, wps=6844.2, ups=0.56, wpb=12282.3, bsz=1024, num_updates=10500, lr=0.000345033, gnorm=1.212, clip=0, loss_scale=8192, train_wall=178, wall=18999
2022-08-14 05:06:33 | INFO | train_inner | epoch 003:   3179 / 3715 loss=7.867, nll_loss=4.701, mask_ins=1.297, word_ins_ml=6.13, word_reposition=0.44, ppl=233.38, wps=6861.2, ups=0.56, wpb=12219.6, bsz=1024, num_updates=10600, lr=0.000343401, gnorm=1.303, clip=0, loss_scale=8192, train_wall=176, wall=19177
2022-08-14 05:09:31 | INFO | train_inner | epoch 003:   3279 / 3715 loss=7.861, nll_loss=4.693, mask_ins=1.302, word_ins_ml=6.123, word_reposition=0.436, ppl=232.53, wps=6914.2, ups=0.56, wpb=12360.1, bsz=1024, num_updates=10700, lr=0.000341793, gnorm=1.26, clip=0, loss_scale=8192, train_wall=177, wall=19356
2022-08-14 05:12:29 | INFO | train_inner | epoch 003:   3379 / 3715 loss=7.831, nll_loss=4.664, mask_ins=1.295, word_ins_ml=6.097, word_reposition=0.439, ppl=227.63, wps=6899.2, ups=0.56, wpb=12268.2, bsz=1024, num_updates=10800, lr=0.000340207, gnorm=1.201, clip=0, loss_scale=8192, train_wall=176, wall=19533
2022-08-14 05:15:28 | INFO | train_inner | epoch 003:   3479 / 3715 loss=7.862, nll_loss=4.699, mask_ins=1.294, word_ins_ml=6.127, word_reposition=0.44, ppl=232.59, wps=6895.1, ups=0.56, wpb=12339.8, bsz=1024, num_updates=10900, lr=0.000338643, gnorm=1.243, clip=0, loss_scale=8356, train_wall=177, wall=19712
2022-08-14 05:18:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2022-08-14 05:18:30 | INFO | train_inner | epoch 003:   3580 / 3715 loss=7.828, nll_loss=4.66, mask_ins=1.294, word_ins_ml=6.092, word_reposition=0.442, ppl=227.31, wps=6776.8, ups=0.55, wpb=12307, bsz=1024, num_updates=11000, lr=0.0003371, gnorm=1.18, clip=0, loss_scale=16141, train_wall=180, wall=19894
2022-08-14 05:21:29 | INFO | train_inner | epoch 003:   3680 / 3715 loss=7.844, nll_loss=4.68, mask_ins=1.294, word_ins_ml=6.11, word_reposition=0.439, ppl=229.71, wps=6878.7, ups=0.56, wpb=12316.3, bsz=1024, num_updates=11100, lr=0.000335578, gnorm=1.21, clip=0, loss_scale=8192, train_wall=177, wall=20073
2022-08-14 05:22:32 | INFO | train | epoch 003 | loss 7.97 | nll_loss 4.783 | mask_ins 1.316 | word_ins_ml 6.205 | word_reposition 0.449 | ppl 250.78 | wps 6686.3 | ups 0.54 | wpb 12319.3 | bsz 1023.8 | num_updates 11135 | lr 0.00033505 | gnorm 1.283 | clip 0 | loss_scale 9674 | train_wall 6600 | wall 20137
2022-08-14 05:24:56 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.654 | nll_loss 4.379 | mask_ins 1.278 | word_ins_ml 5.935 | word_reposition 0.441 | ppl 201.44 | wps 16007.6 | wpb 1555.8 | bsz 128 | num_updates 11135 | best_loss 7.654
2022-08-14 05:25:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_bert12_adaptor_uncased_Ggw/checkpoint_best.pt (epoch 3 @ 11135 updates, score 7.654) (writing took 21.157804729416966 seconds)
2022-08-14 05:27:15 | INFO | train_inner | epoch 004:     65 / 3715 loss=7.783, nll_loss=4.618, mask_ins=1.29, word_ins_ml=6.055, word_reposition=0.437, ppl=220.25, wps=3563, ups=0.29, wpb=12321.6, bsz=1018.2, num_updates=11200, lr=0.000334077, gnorm=1.263, clip=0, loss_scale=8192, train_wall=179, wall=20419
2022-08-14 05:30:15 | INFO | train_inner | epoch 004:    165 / 3715 loss=7.768, nll_loss=4.61, mask_ins=1.285, word_ins_ml=6.049, word_reposition=0.434, ppl=217.96, wps=6815.8, ups=0.56, wpb=12278.2, bsz=1023.9, num_updates=11300, lr=0.000332595, gnorm=1.183, clip=0, loss_scale=8192, train_wall=178, wall=20599
2022-08-14 05:33:14 | INFO | train_inner | epoch 004:    265 / 3715 loss=7.748, nll_loss=4.59, mask_ins=1.286, word_ins_ml=6.031, word_reposition=0.432, ppl=215, wps=6883.7, ups=0.56, wpb=12371, bsz=1024, num_updates=11400, lr=0.000331133, gnorm=1.19, clip=0, loss_scale=8192, train_wall=178, wall=20779
2022-08-14 05:33:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2022-08-14 05:36:14 | INFO | train_inner | epoch 004:    366 / 3715 loss=7.755, nll_loss=4.597, mask_ins=1.286, word_ins_ml=6.037, word_reposition=0.432, ppl=216.07, wps=6801, ups=0.56, wpb=12216.7, bsz=1024, num_updates=11500, lr=0.00032969, gnorm=1.227, clip=0, loss_scale=4988, train_wall=178, wall=20958
2022-08-14 05:39:13 | INFO | train_inner | epoch 004:    466 / 3715 loss=7.74, nll_loss=4.575, mask_ins=1.284, word_ins_ml=6.018, word_reposition=0.438, ppl=213.75, wps=6866.9, ups=0.56, wpb=12281.1, bsz=1024, num_updates=11600, lr=0.000328266, gnorm=1.191, clip=0, loss_scale=4096, train_wall=177, wall=21137
2022-08-14 05:42:10 | INFO | train_inner | epoch 004:    566 / 3715 loss=7.737, nll_loss=4.577, mask_ins=1.283, word_ins_ml=6.019, word_reposition=0.435, ppl=213.29, wps=6940, ups=0.56, wpb=12311.8, bsz=1024, num_updates=11700, lr=0.00032686, gnorm=1.198, clip=0, loss_scale=4096, train_wall=176, wall=21315
2022-08-14 05:45:07 | INFO | train_inner | epoch 004:    666 / 3715 loss=7.736, nll_loss=4.582, mask_ins=1.28, word_ins_ml=6.023, word_reposition=0.433, ppl=213.22, wps=7003, ups=0.57, wpb=12340.6, bsz=1024, num_updates=11800, lr=0.000325472, gnorm=1.232, clip=0, loss_scale=4096, train_wall=174, wall=21491
Traceback (most recent call last):
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq_cli/train.py", line 369, in cli_main
    torch.multiprocessing.spawn(
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 130, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGTERM
