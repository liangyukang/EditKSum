nohup: ignoring input
2022-07-12 08:06:41 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:19981
2022-07-12 08:06:41 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:19981
2022-07-12 08:06:41 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:19981
2022-07-12 08:06:41 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:19981
2022-07-12 08:06:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2022-07-12 08:06:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2022-07-12 08:06:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2022-07-12 08:06:42 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2022-07-12 08:06:42 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-07-12 08:06:42 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 0
2022-07-12 08:06:42 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-07-12 08:06:42 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 1
2022-07-12 08:06:42 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-07-12 08:06:42 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 2
2022-07-12 08:06:42 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-07-12 08:06:42 | INFO | fairseq.distributed_utils | initialized host ubuntu as rank 3
2022-07-12 08:06:46 | INFO | fairseq_cli.train | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir='', seed=1, cpu=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, criterion='nat_loss', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', task='translation_lev', num_workers=0, skip_invalid_size_inputs_valid_test=True, max_tokens=None, max_sentences=8, required_batch_size_multiple=8, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, fixed_validation_seed=7, disable_validation=False, max_tokens_valid=None, max_sentences_valid=8, curriculum=0, distributed_world_size=4, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:19981', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, arch='kpe_editor_transformer_with_adapter', max_epoch=0, max_update=100000, clip_norm=25, sentence_avg=False, update_freq=[8], lr=[0.0005], min_lr=1e-09, use_bmuf=False, save_dir='../checkpoints_bert_transformer_cased', restore_file='checkpoint_last.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_last_epochs=-1, keep_best_checkpoints=3, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, no_token_positional_embeddings=False, no_cross_attention=False, cross_self_attention=False, encoder_layerdrop=0, decoder_layerdrop=0, encoder_layers_to_keep=None, decoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, early_exit='6,6,6', layers_num='6,6,6', finetune_embeddings=False, finetune_whole_encoder=False, decoder_adapter_dimention=2048, finetune_position_embeddings=False, use_adapter_bert=False, keywords_num=40, label_smoothing=0.1, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, warmup_updates=5000, warmup_init_lr=1e-07, data='/data/yukangliang/实验/BertKpeEditorWithAdaptor/data-bin-bert-cased-510', source_lang=None, target_lang=None, load_alignments=False, left_pad_source='False', left_pad_target='False', max_source_positions=512, max_target_positions=512, upsample_primary=1, truncate_source=False, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, noise='random_delete_shuffle', random_seed=1, cached_features_dir='/data/yukangliang/实验/BertKpeEditorWithAdaptor/cached_examples_bert_cased_510', tokenizer_dir='/data/yukangliang/预训练模型/bert-base-cased', encoder_adapter_dimention=2048, decoder_input='target', kpe=False, share_all_embeddings=True, no_share_discriminator=True, dropout=0.3, decoder_learned_pos=True, encoder_learned_pos=True, apply_bert_init=True, cache_dir='/data/yukangliang/预训练模型/bert-base-cased', decoder_cache_dir='/data/yukangliang/预训练模型/bert-base-cased-decoder', share_decoder_input_output_embed=False, encoder='bert', decoder='transformer', encoder_embed_path=None, encoder_embed_dim=768, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_attention_heads=8, encoder_normalize_before=False, decoder_embed_path=None, decoder_embed_dim=768, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, adaptive_input=False, decoder_output_dim=768, decoder_input_dim=768, no_share_maskpredictor=False, share_discriminator_maskpredictor=False, no_share_last_layer=False, cached_dir='/data/yukangliang/预训练模型/bert-base-cased')
2022-07-12 08:06:46 | INFO | fairseq.tasks.translation | [source] dictionary: 28996 types
2022-07-12 08:06:46 | INFO | fairseq.tasks.translation | [target] dictionary: 28996 types
2022-07-12 08:06:46 | INFO | fairseq.data.data_utils | loaded 13368 examples from: /data/yukangliang/实验/BertKpeEditorWithAdaptor/data-bin-bert-cased-510/valid.source-target.source
2022-07-12 08:06:46 | INFO | fairseq.data.data_utils | loaded 13368 examples from: /data/yukangliang/实验/BertKpeEditorWithAdaptor/data-bin-bert-cased-510/valid.source-target.target
2022-07-12 08:06:46 | INFO | fairseq.tasks.translation | /data/yukangliang/实验/BertKpeEditorWithAdaptor/data-bin-bert-cased-510 valid source-target 13368 examples
2022-07-12 08:06:46 | INFO | transformer.configuration_utils | loading configuration file /data/yukangliang/预训练模型/bert-base-cased/config.json
2022-07-12 08:06:46 | INFO | transformer.configuration_utils | Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "pruned_heads": {},
  "torchscript": false,
  "transformers_version": "4.6.0.dev0",
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "use_cache": true,
  "vocab_size": 28996
}

2022-07-12 08:06:46 | INFO | transformer.modeling_utils | loading weights file /data/yukangliang/预训练模型/bert-base-cased/pytorch_model.bin
2022-07-12 08:06:48 | INFO | transformer.modeling_utils | Weights from pretrained model not used in BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
Trained parameters: len 514
Trained parameters: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.encoder_attn.k_proj.weight', 'decoder.layers_reposition.0.encoder_attn.k_proj.bias', 'decoder.layers_reposition.0.encoder_attn.v_proj.weight', 'decoder.layers_reposition.0.encoder_attn.v_proj.bias', 'decoder.layers_reposition.0.encoder_attn.q_proj.weight', 'decoder.layers_reposition.0.encoder_attn.q_proj.bias', 'decoder.layers_reposition.0.encoder_attn.out_proj.weight', 'decoder.layers_reposition.0.encoder_attn.out_proj.bias', 'decoder.layers_reposition.0.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.0.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.encoder_attn.k_proj.weight', 'decoder.layers_reposition.1.encoder_attn.k_proj.bias', 'decoder.layers_reposition.1.encoder_attn.v_proj.weight', 'decoder.layers_reposition.1.encoder_attn.v_proj.bias', 'decoder.layers_reposition.1.encoder_attn.q_proj.weight', 'decoder.layers_reposition.1.encoder_attn.q_proj.bias', 'decoder.layers_reposition.1.encoder_attn.out_proj.weight', 'decoder.layers_reposition.1.encoder_attn.out_proj.bias', 'decoder.layers_reposition.1.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.1.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.encoder_attn.k_proj.weight', 'decoder.layers_reposition.2.encoder_attn.k_proj.bias', 'decoder.layers_reposition.2.encoder_attn.v_proj.weight', 'decoder.layers_reposition.2.encoder_attn.v_proj.bias', 'decoder.layers_reposition.2.encoder_attn.q_proj.weight', 'decoder.layers_reposition.2.encoder_attn.q_proj.bias', 'decoder.layers_reposition.2.encoder_attn.out_proj.weight', 'decoder.layers_reposition.2.encoder_attn.out_proj.bias', 'decoder.layers_reposition.2.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.2.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.encoder_attn.k_proj.weight', 'decoder.layers_reposition.3.encoder_attn.k_proj.bias', 'decoder.layers_reposition.3.encoder_attn.v_proj.weight', 'decoder.layers_reposition.3.encoder_attn.v_proj.bias', 'decoder.layers_reposition.3.encoder_attn.q_proj.weight', 'decoder.layers_reposition.3.encoder_attn.q_proj.bias', 'decoder.layers_reposition.3.encoder_attn.out_proj.weight', 'decoder.layers_reposition.3.encoder_attn.out_proj.bias', 'decoder.layers_reposition.3.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.3.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.encoder_attn.k_proj.weight', 'decoder.layers_reposition.4.encoder_attn.k_proj.bias', 'decoder.layers_reposition.4.encoder_attn.v_proj.weight', 'decoder.layers_reposition.4.encoder_attn.v_proj.bias', 'decoder.layers_reposition.4.encoder_attn.q_proj.weight', 'decoder.layers_reposition.4.encoder_attn.q_proj.bias', 'decoder.layers_reposition.4.encoder_attn.out_proj.weight', 'decoder.layers_reposition.4.encoder_attn.out_proj.bias', 'decoder.layers_reposition.4.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.4.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.encoder_attn.k_proj.weight', 'decoder.layers_reposition.5.encoder_attn.k_proj.bias', 'decoder.layers_reposition.5.encoder_attn.v_proj.weight', 'decoder.layers_reposition.5.encoder_attn.v_proj.bias', 'decoder.layers_reposition.5.encoder_attn.q_proj.weight', 'decoder.layers_reposition.5.encoder_attn.q_proj.bias', 'decoder.layers_reposition.5.encoder_attn.out_proj.weight', 'decoder.layers_reposition.5.encoder_attn.out_proj.bias', 'decoder.layers_reposition.5.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.5.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
Trained parameters not adapter: len 394
Trained parameters not adapter: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
2022-07-12 08:06:49 | INFO | fairseq_cli.train | KPEEDITORTransformerModel(
  (encoder): BertEncoder(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(28996, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (decoder): EditorTransformerDecoder(
    (embed_tokens): Embedding(28996, 768, padding_idx=0)
    (embed_positions): LearnedPositionalEmbedding(513, 768, padding_idx=0)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=768, out_features=28996, bias=False)
    (embed_mask_ins): Embedding(256, 1536)
    (layers_reposition): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
2022-07-12 08:06:49 | INFO | fairseq_cli.train | model kpe_editor_transformer_with_adapter, criterion LabelSmoothedDualImitationCriterion
2022-07-12 08:06:49 | INFO | fairseq_cli.train | num. model params: 225901056 (num. trained: 225901056)
2022-07-12 08:06:49 | INFO | fairseq_cli.train | num. Encoder model params: 108310272 (Encoder num. trained: 108310272)
2022-07-12 08:06:49 | INFO | fairseq_cli.train | num. Decoder model params: 117590784 (Decoder num. trained: 117590784)
Trained parameters: len 514
Trained parameters: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.encoder_attn.k_proj.weight', 'decoder.layers_reposition.0.encoder_attn.k_proj.bias', 'decoder.layers_reposition.0.encoder_attn.v_proj.weight', 'decoder.layers_reposition.0.encoder_attn.v_proj.bias', 'decoder.layers_reposition.0.encoder_attn.q_proj.weight', 'decoder.layers_reposition.0.encoder_attn.q_proj.bias', 'decoder.layers_reposition.0.encoder_attn.out_proj.weight', 'decoder.layers_reposition.0.encoder_attn.out_proj.bias', 'decoder.layers_reposition.0.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.0.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.encoder_attn.k_proj.weight', 'decoder.layers_reposition.1.encoder_attn.k_proj.bias', 'decoder.layers_reposition.1.encoder_attn.v_proj.weight', 'decoder.layers_reposition.1.encoder_attn.v_proj.bias', 'decoder.layers_reposition.1.encoder_attn.q_proj.weight', 'decoder.layers_reposition.1.encoder_attn.q_proj.bias', 'decoder.layers_reposition.1.encoder_attn.out_proj.weight', 'decoder.layers_reposition.1.encoder_attn.out_proj.bias', 'decoder.layers_reposition.1.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.1.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.encoder_attn.k_proj.weight', 'decoder.layers_reposition.2.encoder_attn.k_proj.bias', 'decoder.layers_reposition.2.encoder_attn.v_proj.weight', 'decoder.layers_reposition.2.encoder_attn.v_proj.bias', 'decoder.layers_reposition.2.encoder_attn.q_proj.weight', 'decoder.layers_reposition.2.encoder_attn.q_proj.bias', 'decoder.layers_reposition.2.encoder_attn.out_proj.weight', 'decoder.layers_reposition.2.encoder_attn.out_proj.bias', 'decoder.layers_reposition.2.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.2.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.encoder_attn.k_proj.weight', 'decoder.layers_reposition.3.encoder_attn.k_proj.bias', 'decoder.layers_reposition.3.encoder_attn.v_proj.weight', 'decoder.layers_reposition.3.encoder_attn.v_proj.bias', 'decoder.layers_reposition.3.encoder_attn.q_proj.weight', 'decoder.layers_reposition.3.encoder_attn.q_proj.bias', 'decoder.layers_reposition.3.encoder_attn.out_proj.weight', 'decoder.layers_reposition.3.encoder_attn.out_proj.bias', 'decoder.layers_reposition.3.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.3.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.encoder_attn.k_proj.weight', 'decoder.layers_reposition.4.encoder_attn.k_proj.bias', 'decoder.layers_reposition.4.encoder_attn.v_proj.weight', 'decoder.layers_reposition.4.encoder_attn.v_proj.bias', 'decoder.layers_reposition.4.encoder_attn.q_proj.weight', 'decoder.layers_reposition.4.encoder_attn.q_proj.bias', 'decoder.layers_reposition.4.encoder_attn.out_proj.weight', 'decoder.layers_reposition.4.encoder_attn.out_proj.bias', 'decoder.layers_reposition.4.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.4.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.encoder_attn.k_proj.weight', 'decoder.layers_reposition.5.encoder_attn.k_proj.bias', 'decoder.layers_reposition.5.encoder_attn.v_proj.weight', 'decoder.layers_reposition.5.encoder_attn.v_proj.bias', 'decoder.layers_reposition.5.encoder_attn.q_proj.weight', 'decoder.layers_reposition.5.encoder_attn.q_proj.bias', 'decoder.layers_reposition.5.encoder_attn.out_proj.weight', 'decoder.layers_reposition.5.encoder_attn.out_proj.bias', 'decoder.layers_reposition.5.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.5.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
Trained parameters not adapter: len 394
Trained parameters not adapter: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']Trained parameters: len 514
Trained parameters: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.encoder_attn.k_proj.weight', 'decoder.layers_reposition.0.encoder_attn.k_proj.bias', 'decoder.layers_reposition.0.encoder_attn.v_proj.weight', 'decoder.layers_reposition.0.encoder_attn.v_proj.bias', 'decoder.layers_reposition.0.encoder_attn.q_proj.weight', 'decoder.layers_reposition.0.encoder_attn.q_proj.bias', 'decoder.layers_reposition.0.encoder_attn.out_proj.weight', 'decoder.layers_reposition.0.encoder_attn.out_proj.bias', 'decoder.layers_reposition.0.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.0.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.encoder_attn.k_proj.weight', 'decoder.layers_reposition.1.encoder_attn.k_proj.bias', 'decoder.layers_reposition.1.encoder_attn.v_proj.weight', 'decoder.layers_reposition.1.encoder_attn.v_proj.bias', 'decoder.layers_reposition.1.encoder_attn.q_proj.weight', 'decoder.layers_reposition.1.encoder_attn.q_proj.bias', 'decoder.layers_reposition.1.encoder_attn.out_proj.weight', 'decoder.layers_reposition.1.encoder_attn.out_proj.bias', 'decoder.layers_reposition.1.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.1.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.encoder_attn.k_proj.weight', 'decoder.layers_reposition.2.encoder_attn.k_proj.bias', 'decoder.layers_reposition.2.encoder_attn.v_proj.weight', 'decoder.layers_reposition.2.encoder_attn.v_proj.bias', 'decoder.layers_reposition.2.encoder_attn.q_proj.weight', 'decoder.layers_reposition.2.encoder_attn.q_proj.bias', 'decoder.layers_reposition.2.encoder_attn.out_proj.weight', 'decoder.layers_reposition.2.encoder_attn.out_proj.bias', 'decoder.layers_reposition.2.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.2.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.encoder_attn.k_proj.weight', 'decoder.layers_reposition.3.encoder_attn.k_proj.bias', 'decoder.layers_reposition.3.encoder_attn.v_proj.weight', 'decoder.layers_reposition.3.encoder_attn.v_proj.bias', 'decoder.layers_reposition.3.encoder_attn.q_proj.weight', 'decoder.layers_reposition.3.encoder_attn.q_proj.bias', 'decoder.layers_reposition.3.encoder_attn.out_proj.weight', 'decoder.layers_reposition.3.encoder_attn.out_proj.bias', 'decoder.layers_reposition.3.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.3.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.encoder_attn.k_proj.weight', 'decoder.layers_reposition.4.encoder_attn.k_proj.bias', 'decoder.layers_reposition.4.encoder_attn.v_proj.weight', 'decoder.layers_reposition.4.encoder_attn.v_proj.bias', 'decoder.layers_reposition.4.encoder_attn.q_proj.weight', 'decoder.layers_reposition.4.encoder_attn.q_proj.bias', 'decoder.layers_reposition.4.encoder_attn.out_proj.weight', 'decoder.layers_reposition.4.encoder_attn.out_proj.bias', 'decoder.layers_reposition.4.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.4.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.encoder_attn.k_proj.weight', 'decoder.layers_reposition.5.encoder_attn.k_proj.bias', 'decoder.layers_reposition.5.encoder_attn.v_proj.weight', 'decoder.layers_reposition.5.encoder_attn.v_proj.bias', 'decoder.layers_reposition.5.encoder_attn.q_proj.weight', 'decoder.layers_reposition.5.encoder_attn.q_proj.bias', 'decoder.layers_reposition.5.encoder_attn.out_proj.weight', 'decoder.layers_reposition.5.encoder_attn.out_proj.bias', 'decoder.layers_reposition.5.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.5.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
Trained parameters not adapter: len 394
Trained parameters not adapter: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']Trained parameters: len 514
Trained parameters: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.k_proj.bias', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.0.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.v_proj.bias', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'decoder.layers.2.encoder_attn.out_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.encoder_attn.k_proj.weight', 'decoder.layers.3.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.3.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'decoder.layers.3.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.encoder_attn.k_proj.weight', 'decoder.layers_reposition.0.encoder_attn.k_proj.bias', 'decoder.layers_reposition.0.encoder_attn.v_proj.weight', 'decoder.layers_reposition.0.encoder_attn.v_proj.bias', 'decoder.layers_reposition.0.encoder_attn.q_proj.weight', 'decoder.layers_reposition.0.encoder_attn.q_proj.bias', 'decoder.layers_reposition.0.encoder_attn.out_proj.weight', 'decoder.layers_reposition.0.encoder_attn.out_proj.bias', 'decoder.layers_reposition.0.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.0.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.encoder_attn.k_proj.weight', 'decoder.layers_reposition.1.encoder_attn.k_proj.bias', 'decoder.layers_reposition.1.encoder_attn.v_proj.weight', 'decoder.layers_reposition.1.encoder_attn.v_proj.bias', 'decoder.layers_reposition.1.encoder_attn.q_proj.weight', 'decoder.layers_reposition.1.encoder_attn.q_proj.bias', 'decoder.layers_reposition.1.encoder_attn.out_proj.weight', 'decoder.layers_reposition.1.encoder_attn.out_proj.bias', 'decoder.layers_reposition.1.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.1.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.encoder_attn.k_proj.weight', 'decoder.layers_reposition.2.encoder_attn.k_proj.bias', 'decoder.layers_reposition.2.encoder_attn.v_proj.weight', 'decoder.layers_reposition.2.encoder_attn.v_proj.bias', 'decoder.layers_reposition.2.encoder_attn.q_proj.weight', 'decoder.layers_reposition.2.encoder_attn.q_proj.bias', 'decoder.layers_reposition.2.encoder_attn.out_proj.weight', 'decoder.layers_reposition.2.encoder_attn.out_proj.bias', 'decoder.layers_reposition.2.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.2.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.encoder_attn.k_proj.weight', 'decoder.layers_reposition.3.encoder_attn.k_proj.bias', 'decoder.layers_reposition.3.encoder_attn.v_proj.weight', 'decoder.layers_reposition.3.encoder_attn.v_proj.bias', 'decoder.layers_reposition.3.encoder_attn.q_proj.weight', 'decoder.layers_reposition.3.encoder_attn.q_proj.bias', 'decoder.layers_reposition.3.encoder_attn.out_proj.weight', 'decoder.layers_reposition.3.encoder_attn.out_proj.bias', 'decoder.layers_reposition.3.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.3.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.encoder_attn.k_proj.weight', 'decoder.layers_reposition.4.encoder_attn.k_proj.bias', 'decoder.layers_reposition.4.encoder_attn.v_proj.weight', 'decoder.layers_reposition.4.encoder_attn.v_proj.bias', 'decoder.layers_reposition.4.encoder_attn.q_proj.weight', 'decoder.layers_reposition.4.encoder_attn.q_proj.bias', 'decoder.layers_reposition.4.encoder_attn.out_proj.weight', 'decoder.layers_reposition.4.encoder_attn.out_proj.bias', 'decoder.layers_reposition.4.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.4.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.encoder_attn.k_proj.weight', 'decoder.layers_reposition.5.encoder_attn.k_proj.bias', 'decoder.layers_reposition.5.encoder_attn.v_proj.weight', 'decoder.layers_reposition.5.encoder_attn.v_proj.bias', 'decoder.layers_reposition.5.encoder_attn.q_proj.weight', 'decoder.layers_reposition.5.encoder_attn.q_proj.bias', 'decoder.layers_reposition.5.encoder_attn.out_proj.weight', 'decoder.layers_reposition.5.encoder_attn.out_proj.bias', 'decoder.layers_reposition.5.encoder_attn_layer_norm.weight', 'decoder.layers_reposition.5.encoder_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']
Trained parameters not adapter: len 394
Trained parameters not adapter: ['encoder.bert.embeddings.word_embeddings.weight', 'encoder.bert.embeddings.position_embeddings.weight', 'encoder.bert.embeddings.token_type_embeddings.weight', 'encoder.bert.embeddings.LayerNorm.weight', 'encoder.bert.embeddings.LayerNorm.bias', 'encoder.bert.encoder.layer.0.attention.self.query.weight', 'encoder.bert.encoder.layer.0.attention.self.query.bias', 'encoder.bert.encoder.layer.0.attention.self.key.weight', 'encoder.bert.encoder.layer.0.attention.self.key.bias', 'encoder.bert.encoder.layer.0.attention.self.value.weight', 'encoder.bert.encoder.layer.0.attention.self.value.bias', 'encoder.bert.encoder.layer.0.attention.output.dense.weight', 'encoder.bert.encoder.layer.0.attention.output.dense.bias', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.0.intermediate.dense.weight', 'encoder.bert.encoder.layer.0.intermediate.dense.bias', 'encoder.bert.encoder.layer.0.output.dense.weight', 'encoder.bert.encoder.layer.0.output.dense.bias', 'encoder.bert.encoder.layer.0.output.LayerNorm.weight', 'encoder.bert.encoder.layer.0.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.attention.self.query.weight', 'encoder.bert.encoder.layer.1.attention.self.query.bias', 'encoder.bert.encoder.layer.1.attention.self.key.weight', 'encoder.bert.encoder.layer.1.attention.self.key.bias', 'encoder.bert.encoder.layer.1.attention.self.value.weight', 'encoder.bert.encoder.layer.1.attention.self.value.bias', 'encoder.bert.encoder.layer.1.attention.output.dense.weight', 'encoder.bert.encoder.layer.1.attention.output.dense.bias', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.1.intermediate.dense.weight', 'encoder.bert.encoder.layer.1.intermediate.dense.bias', 'encoder.bert.encoder.layer.1.output.dense.weight', 'encoder.bert.encoder.layer.1.output.dense.bias', 'encoder.bert.encoder.layer.1.output.LayerNorm.weight', 'encoder.bert.encoder.layer.1.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.attention.self.query.weight', 'encoder.bert.encoder.layer.2.attention.self.query.bias', 'encoder.bert.encoder.layer.2.attention.self.key.weight', 'encoder.bert.encoder.layer.2.attention.self.key.bias', 'encoder.bert.encoder.layer.2.attention.self.value.weight', 'encoder.bert.encoder.layer.2.attention.self.value.bias', 'encoder.bert.encoder.layer.2.attention.output.dense.weight', 'encoder.bert.encoder.layer.2.attention.output.dense.bias', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.2.intermediate.dense.weight', 'encoder.bert.encoder.layer.2.intermediate.dense.bias', 'encoder.bert.encoder.layer.2.output.dense.weight', 'encoder.bert.encoder.layer.2.output.dense.bias', 'encoder.bert.encoder.layer.2.output.LayerNorm.weight', 'encoder.bert.encoder.layer.2.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.attention.self.query.weight', 'encoder.bert.encoder.layer.3.attention.self.query.bias', 'encoder.bert.encoder.layer.3.attention.self.key.weight', 'encoder.bert.encoder.layer.3.attention.self.key.bias', 'encoder.bert.encoder.layer.3.attention.self.value.weight', 'encoder.bert.encoder.layer.3.attention.self.value.bias', 'encoder.bert.encoder.layer.3.attention.output.dense.weight', 'encoder.bert.encoder.layer.3.attention.output.dense.bias', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.3.intermediate.dense.weight', 'encoder.bert.encoder.layer.3.intermediate.dense.bias', 'encoder.bert.encoder.layer.3.output.dense.weight', 'encoder.bert.encoder.layer.3.output.dense.bias', 'encoder.bert.encoder.layer.3.output.LayerNorm.weight', 'encoder.bert.encoder.layer.3.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.attention.self.query.weight', 'encoder.bert.encoder.layer.4.attention.self.query.bias', 'encoder.bert.encoder.layer.4.attention.self.key.weight', 'encoder.bert.encoder.layer.4.attention.self.key.bias', 'encoder.bert.encoder.layer.4.attention.self.value.weight', 'encoder.bert.encoder.layer.4.attention.self.value.bias', 'encoder.bert.encoder.layer.4.attention.output.dense.weight', 'encoder.bert.encoder.layer.4.attention.output.dense.bias', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.4.intermediate.dense.weight', 'encoder.bert.encoder.layer.4.intermediate.dense.bias', 'encoder.bert.encoder.layer.4.output.dense.weight', 'encoder.bert.encoder.layer.4.output.dense.bias', 'encoder.bert.encoder.layer.4.output.LayerNorm.weight', 'encoder.bert.encoder.layer.4.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.attention.self.query.weight', 'encoder.bert.encoder.layer.5.attention.self.query.bias', 'encoder.bert.encoder.layer.5.attention.self.key.weight', 'encoder.bert.encoder.layer.5.attention.self.key.bias', 'encoder.bert.encoder.layer.5.attention.self.value.weight', 'encoder.bert.encoder.layer.5.attention.self.value.bias', 'encoder.bert.encoder.layer.5.attention.output.dense.weight', 'encoder.bert.encoder.layer.5.attention.output.dense.bias', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.5.intermediate.dense.weight', 'encoder.bert.encoder.layer.5.intermediate.dense.bias', 'encoder.bert.encoder.layer.5.output.dense.weight', 'encoder.bert.encoder.layer.5.output.dense.bias', 'encoder.bert.encoder.layer.5.output.LayerNorm.weight', 'encoder.bert.encoder.layer.5.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.attention.self.query.weight', 'encoder.bert.encoder.layer.6.attention.self.query.bias', 'encoder.bert.encoder.layer.6.attention.self.key.weight', 'encoder.bert.encoder.layer.6.attention.self.key.bias', 'encoder.bert.encoder.layer.6.attention.self.value.weight', 'encoder.bert.encoder.layer.6.attention.self.value.bias', 'encoder.bert.encoder.layer.6.attention.output.dense.weight', 'encoder.bert.encoder.layer.6.attention.output.dense.bias', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.6.intermediate.dense.weight', 'encoder.bert.encoder.layer.6.intermediate.dense.bias', 'encoder.bert.encoder.layer.6.output.dense.weight', 'encoder.bert.encoder.layer.6.output.dense.bias', 'encoder.bert.encoder.layer.6.output.LayerNorm.weight', 'encoder.bert.encoder.layer.6.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.attention.self.query.weight', 'encoder.bert.encoder.layer.7.attention.self.query.bias', 'encoder.bert.encoder.layer.7.attention.self.key.weight', 'encoder.bert.encoder.layer.7.attention.self.key.bias', 'encoder.bert.encoder.layer.7.attention.self.value.weight', 'encoder.bert.encoder.layer.7.attention.self.value.bias', 'encoder.bert.encoder.layer.7.attention.output.dense.weight', 'encoder.bert.encoder.layer.7.attention.output.dense.bias', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.7.intermediate.dense.weight', 'encoder.bert.encoder.layer.7.intermediate.dense.bias', 'encoder.bert.encoder.layer.7.output.dense.weight', 'encoder.bert.encoder.layer.7.output.dense.bias', 'encoder.bert.encoder.layer.7.output.LayerNorm.weight', 'encoder.bert.encoder.layer.7.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.attention.self.query.weight', 'encoder.bert.encoder.layer.8.attention.self.query.bias', 'encoder.bert.encoder.layer.8.attention.self.key.weight', 'encoder.bert.encoder.layer.8.attention.self.key.bias', 'encoder.bert.encoder.layer.8.attention.self.value.weight', 'encoder.bert.encoder.layer.8.attention.self.value.bias', 'encoder.bert.encoder.layer.8.attention.output.dense.weight', 'encoder.bert.encoder.layer.8.attention.output.dense.bias', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.8.intermediate.dense.weight', 'encoder.bert.encoder.layer.8.intermediate.dense.bias', 'encoder.bert.encoder.layer.8.output.dense.weight', 'encoder.bert.encoder.layer.8.output.dense.bias', 'encoder.bert.encoder.layer.8.output.LayerNorm.weight', 'encoder.bert.encoder.layer.8.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.attention.self.query.weight', 'encoder.bert.encoder.layer.9.attention.self.query.bias', 'encoder.bert.encoder.layer.9.attention.self.key.weight', 'encoder.bert.encoder.layer.9.attention.self.key.bias', 'encoder.bert.encoder.layer.9.attention.self.value.weight', 'encoder.bert.encoder.layer.9.attention.self.value.bias', 'encoder.bert.encoder.layer.9.attention.output.dense.weight', 'encoder.bert.encoder.layer.9.attention.output.dense.bias', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.9.intermediate.dense.weight', 'encoder.bert.encoder.layer.9.intermediate.dense.bias', 'encoder.bert.encoder.layer.9.output.dense.weight', 'encoder.bert.encoder.layer.9.output.dense.bias', 'encoder.bert.encoder.layer.9.output.LayerNorm.weight', 'encoder.bert.encoder.layer.9.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.attention.self.query.weight', 'encoder.bert.encoder.layer.10.attention.self.query.bias', 'encoder.bert.encoder.layer.10.attention.self.key.weight', 'encoder.bert.encoder.layer.10.attention.self.key.bias', 'encoder.bert.encoder.layer.10.attention.self.value.weight', 'encoder.bert.encoder.layer.10.attention.self.value.bias', 'encoder.bert.encoder.layer.10.attention.output.dense.weight', 'encoder.bert.encoder.layer.10.attention.output.dense.bias', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.10.intermediate.dense.weight', 'encoder.bert.encoder.layer.10.intermediate.dense.bias', 'encoder.bert.encoder.layer.10.output.dense.weight', 'encoder.bert.encoder.layer.10.output.dense.bias', 'encoder.bert.encoder.layer.10.output.LayerNorm.weight', 'encoder.bert.encoder.layer.10.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.attention.self.query.weight', 'encoder.bert.encoder.layer.11.attention.self.query.bias', 'encoder.bert.encoder.layer.11.attention.self.key.weight', 'encoder.bert.encoder.layer.11.attention.self.key.bias', 'encoder.bert.encoder.layer.11.attention.self.value.weight', 'encoder.bert.encoder.layer.11.attention.self.value.bias', 'encoder.bert.encoder.layer.11.attention.output.dense.weight', 'encoder.bert.encoder.layer.11.attention.output.dense.bias', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.bert.encoder.layer.11.intermediate.dense.weight', 'encoder.bert.encoder.layer.11.intermediate.dense.bias', 'encoder.bert.encoder.layer.11.output.dense.weight', 'encoder.bert.encoder.layer.11.output.dense.bias', 'encoder.bert.encoder.layer.11.output.LayerNorm.weight', 'encoder.bert.encoder.layer.11.output.LayerNorm.bias', 'encoder.bert.pooler.dense.weight', 'encoder.bert.pooler.dense.bias', 'decoder.embed_tokens.weight', 'decoder.embed_positions.weight', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.fc1.bias', 'decoder.layers.0.fc2.weight', 'decoder.layers.0.fc2.bias', 'decoder.layers.0.final_layer_norm.weight', 'decoder.layers.0.final_layer_norm.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'decoder.layers.1.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn_layer_norm.bias', 'decoder.layers.1.fc1.weight', 'decoder.layers.1.fc1.bias', 'decoder.layers.1.fc2.weight', 'decoder.layers.1.fc2.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.self_attn.q_proj.bias', 'decoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'decoder.layers.2.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.weight', 'decoder.layers.2.fc1.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.2.fc2.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.3.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.out_proj.bias', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.3.fc1.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.3.fc2.weight', 'decoder.layers.3.fc2.bias', 'decoder.layers.3.final_layer_norm.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.4.self_attn.v_proj.bias', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.4.fc1.weight', 'decoder.layers.4.fc1.bias', 'decoder.layers.4.fc2.weight', 'decoder.layers.4.fc2.bias', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.5.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'decoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.5.fc1.weight', 'decoder.layers.5.fc1.bias', 'decoder.layers.5.fc2.weight', 'decoder.layers.5.fc2.bias', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.embed_mask_ins.weight', 'decoder.layers_reposition.0.self_attn.k_proj.weight', 'decoder.layers_reposition.0.self_attn.k_proj.bias', 'decoder.layers_reposition.0.self_attn.v_proj.weight', 'decoder.layers_reposition.0.self_attn.v_proj.bias', 'decoder.layers_reposition.0.self_attn.q_proj.weight', 'decoder.layers_reposition.0.self_attn.q_proj.bias', 'decoder.layers_reposition.0.self_attn.out_proj.weight', 'decoder.layers_reposition.0.self_attn.out_proj.bias', 'decoder.layers_reposition.0.self_attn_layer_norm.weight', 'decoder.layers_reposition.0.self_attn_layer_norm.bias', 'decoder.layers_reposition.0.fc1.weight', 'decoder.layers_reposition.0.fc1.bias', 'decoder.layers_reposition.0.fc2.weight', 'decoder.layers_reposition.0.fc2.bias', 'decoder.layers_reposition.0.final_layer_norm.weight', 'decoder.layers_reposition.0.final_layer_norm.bias', 'decoder.layers_reposition.1.self_attn.k_proj.weight', 'decoder.layers_reposition.1.self_attn.k_proj.bias', 'decoder.layers_reposition.1.self_attn.v_proj.weight', 'decoder.layers_reposition.1.self_attn.v_proj.bias', 'decoder.layers_reposition.1.self_attn.q_proj.weight', 'decoder.layers_reposition.1.self_attn.q_proj.bias', 'decoder.layers_reposition.1.self_attn.out_proj.weight', 'decoder.layers_reposition.1.self_attn.out_proj.bias', 'decoder.layers_reposition.1.self_attn_layer_norm.weight', 'decoder.layers_reposition.1.self_attn_layer_norm.bias', 'decoder.layers_reposition.1.fc1.weight', 'decoder.layers_reposition.1.fc1.bias', 'decoder.layers_reposition.1.fc2.weight', 'decoder.layers_reposition.1.fc2.bias', 'decoder.layers_reposition.1.final_layer_norm.weight', 'decoder.layers_reposition.1.final_layer_norm.bias', 'decoder.layers_reposition.2.self_attn.k_proj.weight', 'decoder.layers_reposition.2.self_attn.k_proj.bias', 'decoder.layers_reposition.2.self_attn.v_proj.weight', 'decoder.layers_reposition.2.self_attn.v_proj.bias', 'decoder.layers_reposition.2.self_attn.q_proj.weight', 'decoder.layers_reposition.2.self_attn.q_proj.bias', 'decoder.layers_reposition.2.self_attn.out_proj.weight', 'decoder.layers_reposition.2.self_attn.out_proj.bias', 'decoder.layers_reposition.2.self_attn_layer_norm.weight', 'decoder.layers_reposition.2.self_attn_layer_norm.bias', 'decoder.layers_reposition.2.fc1.weight', 'decoder.layers_reposition.2.fc1.bias', 'decoder.layers_reposition.2.fc2.weight', 'decoder.layers_reposition.2.fc2.bias', 'decoder.layers_reposition.2.final_layer_norm.weight', 'decoder.layers_reposition.2.final_layer_norm.bias', 'decoder.layers_reposition.3.self_attn.k_proj.weight', 'decoder.layers_reposition.3.self_attn.k_proj.bias', 'decoder.layers_reposition.3.self_attn.v_proj.weight', 'decoder.layers_reposition.3.self_attn.v_proj.bias', 'decoder.layers_reposition.3.self_attn.q_proj.weight', 'decoder.layers_reposition.3.self_attn.q_proj.bias', 'decoder.layers_reposition.3.self_attn.out_proj.weight', 'decoder.layers_reposition.3.self_attn.out_proj.bias', 'decoder.layers_reposition.3.self_attn_layer_norm.weight', 'decoder.layers_reposition.3.self_attn_layer_norm.bias', 'decoder.layers_reposition.3.fc1.weight', 'decoder.layers_reposition.3.fc1.bias', 'decoder.layers_reposition.3.fc2.weight', 'decoder.layers_reposition.3.fc2.bias', 'decoder.layers_reposition.3.final_layer_norm.weight', 'decoder.layers_reposition.3.final_layer_norm.bias', 'decoder.layers_reposition.4.self_attn.k_proj.weight', 'decoder.layers_reposition.4.self_attn.k_proj.bias', 'decoder.layers_reposition.4.self_attn.v_proj.weight', 'decoder.layers_reposition.4.self_attn.v_proj.bias', 'decoder.layers_reposition.4.self_attn.q_proj.weight', 'decoder.layers_reposition.4.self_attn.q_proj.bias', 'decoder.layers_reposition.4.self_attn.out_proj.weight', 'decoder.layers_reposition.4.self_attn.out_proj.bias', 'decoder.layers_reposition.4.self_attn_layer_norm.weight', 'decoder.layers_reposition.4.self_attn_layer_norm.bias', 'decoder.layers_reposition.4.fc1.weight', 'decoder.layers_reposition.4.fc1.bias', 'decoder.layers_reposition.4.fc2.weight', 'decoder.layers_reposition.4.fc2.bias', 'decoder.layers_reposition.4.final_layer_norm.weight', 'decoder.layers_reposition.4.final_layer_norm.bias', 'decoder.layers_reposition.5.self_attn.k_proj.weight', 'decoder.layers_reposition.5.self_attn.k_proj.bias', 'decoder.layers_reposition.5.self_attn.v_proj.weight', 'decoder.layers_reposition.5.self_attn.v_proj.bias', 'decoder.layers_reposition.5.self_attn.q_proj.weight', 'decoder.layers_reposition.5.self_attn.q_proj.bias', 'decoder.layers_reposition.5.self_attn.out_proj.weight', 'decoder.layers_reposition.5.self_attn.out_proj.bias', 'decoder.layers_reposition.5.self_attn_layer_norm.weight', 'decoder.layers_reposition.5.self_attn_layer_norm.bias', 'decoder.layers_reposition.5.fc1.weight', 'decoder.layers_reposition.5.fc1.bias', 'decoder.layers_reposition.5.fc2.weight', 'decoder.layers_reposition.5.fc2.bias', 'decoder.layers_reposition.5.final_layer_norm.weight', 'decoder.layers_reposition.5.final_layer_norm.bias']2022-07-12 08:06:52 | INFO | fairseq_cli.train | training on 4 GPUs
2022-07-12 08:06:52 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 8
2022-07-12 08:06:52 | INFO | fairseq.trainer | no existing checkpoint found ../checkpoints_bert_transformer_cased/checkpoint_last.pt
2022-07-12 08:06:52 | INFO | fairseq.trainer | loading train data for epoch 1
2022-07-12 08:06:52 | INFO | fairseq.data.data_utils | loaded 287112 examples from: /data/yukangliang/实验/BertKpeEditorWithAdaptor/data-bin-bert-cased-510/train.source-target.source
2022-07-12 08:06:52 | INFO | fairseq.data.data_utils | loaded 287112 examples from: /data/yukangliang/实验/BertKpeEditorWithAdaptor/data-bin-bert-cased-510/train.source-target.target
2022-07-12 08:06:52 | INFO | fairseq.tasks.translation | /data/yukangliang/实验/BertKpeEditorWithAdaptor/data-bin-bert-cased-510 train source-target 287112 examples
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
2022-07-12 08:09:24 | INFO | train_inner | epoch 001:    100 / 1122 loss=24.186, nll_loss=13.925, mask_ins=7.548, word_ins_ml=14.095, word_reposition=2.544, ppl=1.90809e+07, wps=13966.3, ups=0.68, wpb=20527, bsz=256, num_updates=100, lr=1.0098e-05, gnorm=20.374, clip=2, loss_scale=128, train_wall=149, wall=152
2022-07-12 08:11:51 | INFO | train_inner | epoch 001:    200 / 1122 loss=18.402, nll_loss=12.217, mask_ins=4.326, word_ins_ml=12.562, word_reposition=1.513, ppl=346299, wps=14011.4, ups=0.68, wpb=20583.2, bsz=256, num_updates=200, lr=2.0096e-05, gnorm=18.888, clip=0, loss_scale=128, train_wall=146, wall=299
2022-07-12 08:14:17 | INFO | train_inner | epoch 001:    300 / 1122 loss=15.41, nll_loss=11.263, mask_ins=2.219, word_ins_ml=11.731, word_reposition=1.46, ppl=43533.6, wps=14053.5, ups=0.68, wpb=20561.3, bsz=256, num_updates=300, lr=3.0094e-05, gnorm=4.219, clip=0, loss_scale=128, train_wall=146, wall=445
2022-07-12 08:16:44 | INFO | train_inner | epoch 001:    400 / 1122 loss=14.85, nll_loss=10.856, mask_ins=1.995, word_ins_ml=11.412, word_reposition=1.443, ppl=29533, wps=14046.6, ups=0.68, wpb=20576.5, bsz=256, num_updates=400, lr=4.0092e-05, gnorm=2.042, clip=0, loss_scale=128, train_wall=146, wall=592
2022-07-12 08:19:10 | INFO | train_inner | epoch 001:    500 / 1122 loss=14.59, nll_loss=10.754, mask_ins=1.856, word_ins_ml=11.34, word_reposition=1.393, ppl=24663.2, wps=14019.2, ups=0.68, wpb=20523.5, bsz=256, num_updates=500, lr=5.009e-05, gnorm=1.385, clip=0, loss_scale=128, train_wall=146, wall=738
2022-07-12 08:21:36 | INFO | train_inner | epoch 001:    600 / 1122 loss=14.522, nll_loss=10.69, mask_ins=1.838, word_ins_ml=11.289, word_reposition=1.395, ppl=23527.3, wps=14015.1, ups=0.68, wpb=20491.4, bsz=256, num_updates=600, lr=6.0088e-05, gnorm=1.431, clip=0, loss_scale=242, train_wall=145, wall=884
2022-07-12 08:24:02 | INFO | train_inner | epoch 001:    700 / 1122 loss=14.445, nll_loss=10.627, mask_ins=1.829, word_ins_ml=11.236, word_reposition=1.38, ppl=22305.3, wps=14100.1, ups=0.69, wpb=20542.5, bsz=256, num_updates=700, lr=7.0086e-05, gnorm=1.58, clip=0, loss_scale=256, train_wall=145, wall=1030
2022-07-12 08:26:27 | INFO | train_inner | epoch 001:    800 / 1122 loss=14.376, nll_loss=10.551, mask_ins=1.837, word_ins_ml=11.17, word_reposition=1.369, ppl=21260.2, wps=14191.6, ups=0.69, wpb=20579, bsz=256, num_updates=800, lr=8.0084e-05, gnorm=1.446, clip=0, loss_scale=256, train_wall=144, wall=1175
2022-07-12 08:28:52 | INFO | train_inner | epoch 001:    900 / 1122 loss=14.299, nll_loss=10.481, mask_ins=1.829, word_ins_ml=11.111, word_reposition=1.359, ppl=20157.4, wps=14096.7, ups=0.69, wpb=20464, bsz=256, num_updates=900, lr=9.0082e-05, gnorm=1.389, clip=0, loss_scale=256, train_wall=144, wall=1320
2022-07-12 08:31:18 | INFO | train_inner | epoch 001:   1000 / 1122 loss=14.221, nll_loss=10.391, mask_ins=1.825, word_ins_ml=11.035, word_reposition=1.361, ppl=19101.8, wps=14175.1, ups=0.69, wpb=20597.8, bsz=256, num_updates=1000, lr=0.00010008, gnorm=1.497, clip=0, loss_scale=256, train_wall=145, wall=1466
2022-07-12 08:33:44 | INFO | train_inner | epoch 001:   1100 / 1122 loss=14.198, nll_loss=10.336, mask_ins=1.842, word_ins_ml=10.988, word_reposition=1.368, ppl=18797.2, wps=13963.7, ups=0.68, wpb=20473.7, bsz=256, num_updates=1100, lr=0.000110078, gnorm=1.334, clip=0, loss_scale=453, train_wall=146, wall=1612
2022-07-12 08:34:16 | INFO | train | epoch 001 | loss 15.742 | nll_loss 11.084 | mask_ins 2.616 | word_ins_ml 11.62 | word_reposition 1.505 | ppl 54790.6 | wps 14051.6 | ups 0.68 | wpb 20520.3 | bsz 255.8 | num_updates 1122 | lr 0.000112278 | gnorm 4.991 | clip 0.2 | loss_scale 220 | train_wall 1634 | wall 1644
2022-07-12 08:34:42 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 14.568 | nll_loss 10.394 | mask_ins 2.216 | word_ins_ml 11.057 | word_reposition 1.295 | ppl 24286 | wps 37938.1 | wpb 2367.6 | bsz 32 | num_updates 1122
2022-07-12 08:34:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 1 @ 1122 updates, score 14.568) (writing took 5.234784632921219 seconds)
2022-07-12 08:36:40 | INFO | train_inner | epoch 002:     78 / 1122 loss=14.124, nll_loss=10.257, mask_ins=1.844, word_ins_ml=10.921, word_reposition=1.359, ppl=17857.6, wps=11592.5, ups=0.57, wpb=20333.3, bsz=253.8, num_updates=1200, lr=0.000120076, gnorm=1.507, clip=0, loss_scale=512, train_wall=143, wall=1788
2022-07-12 08:39:05 | INFO | train_inner | epoch 002:    178 / 1122 loss=14.047, nll_loss=10.191, mask_ins=1.832, word_ins_ml=10.866, word_reposition=1.349, ppl=16922.3, wps=14210.1, ups=0.69, wpb=20587.3, bsz=256, num_updates=1300, lr=0.000130074, gnorm=1.391, clip=0, loss_scale=512, train_wall=144, wall=1933
2022-07-12 08:41:30 | INFO | train_inner | epoch 002:    278 / 1122 loss=14.017, nll_loss=10.143, mask_ins=1.83, word_ins_ml=10.826, word_reposition=1.36, ppl=16573.6, wps=14168.6, ups=0.69, wpb=20599.8, bsz=256, num_updates=1400, lr=0.000140072, gnorm=1.4, clip=0, loss_scale=512, train_wall=145, wall=2078
2022-07-12 08:43:54 | INFO | train_inner | epoch 002:    378 / 1122 loss=13.948, nll_loss=10.088, mask_ins=1.829, word_ins_ml=10.78, word_reposition=1.34, ppl=15804.5, wps=14091.6, ups=0.69, wpb=20347.3, bsz=256, num_updates=1500, lr=0.00015007, gnorm=1.519, clip=0, loss_scale=512, train_wall=144, wall=2222
2022-07-12 08:46:19 | INFO | train_inner | epoch 002:    478 / 1122 loss=13.914, nll_loss=10.04, mask_ins=1.831, word_ins_ml=10.739, word_reposition=1.345, ppl=15438.9, wps=14185, ups=0.69, wpb=20567.7, bsz=256, num_updates=1600, lr=0.000160068, gnorm=1.408, clip=0, loss_scale=845, train_wall=144, wall=2367
2022-07-12 08:48:44 | INFO | train_inner | epoch 002:    578 / 1122 loss=13.885, nll_loss=9.996, mask_ins=1.833, word_ins_ml=10.702, word_reposition=1.35, ppl=15133.2, wps=14181.6, ups=0.69, wpb=20536.9, bsz=256, num_updates=1700, lr=0.000170066, gnorm=1.301, clip=0, loss_scale=1024, train_wall=144, wall=2512
2022-07-12 08:51:10 | INFO | train_inner | epoch 002:    678 / 1122 loss=13.841, nll_loss=9.951, mask_ins=1.845, word_ins_ml=10.664, word_reposition=1.332, ppl=14677.7, wps=14079, ups=0.69, wpb=20477.4, bsz=256, num_updates=1800, lr=0.000180064, gnorm=1.401, clip=0, loss_scale=1024, train_wall=145, wall=2658
2022-07-12 08:53:35 | INFO | train_inner | epoch 002:    778 / 1122 loss=13.776, nll_loss=9.912, mask_ins=1.828, word_ins_ml=10.631, word_reposition=1.317, ppl=14028.5, wps=14122, ups=0.69, wpb=20576, bsz=256, num_updates=1900, lr=0.000190062, gnorm=1.381, clip=0, loss_scale=1024, train_wall=145, wall=2803
2022-07-12 08:56:01 | INFO | train_inner | epoch 002:    878 / 1122 loss=13.747, nll_loss=9.879, mask_ins=1.818, word_ins_ml=10.603, word_reposition=1.326, ppl=13748.6, wps=14048.6, ups=0.69, wpb=20447.7, bsz=256, num_updates=2000, lr=0.00020006, gnorm=1.346, clip=0, loss_scale=1024, train_wall=145, wall=2949
2022-07-12 08:58:27 | INFO | train_inner | epoch 002:    978 / 1122 loss=13.734, nll_loss=9.849, mask_ins=1.828, word_ins_ml=10.577, word_reposition=1.33, ppl=13628.8, wps=14065.4, ups=0.69, wpb=20513.5, bsz=256, num_updates=2100, lr=0.000210058, gnorm=1.396, clip=0, loss_scale=1567, train_wall=145, wall=3095
2022-07-12 09:00:52 | INFO | train_inner | epoch 002:   1078 / 1122 loss=13.707, nll_loss=9.813, mask_ins=1.831, word_ins_ml=10.547, word_reposition=1.329, ppl=13371, wps=14266.5, ups=0.69, wpb=20708.1, bsz=256, num_updates=2200, lr=0.000220056, gnorm=1.338, clip=0, loss_scale=2048, train_wall=144, wall=3240
2022-07-12 09:01:56 | INFO | train | epoch 002 | loss 13.873 | nll_loss 9.997 | mask_ins 1.831 | word_ins_ml 10.703 | word_reposition 1.339 | ppl 15001.4 | wps 13871.7 | ups 0.68 | wpb 20521 | bsz 255.8 | num_updates 2244 | lr 0.000224455 | gnorm 1.384 | clip 0 | loss_scale 1015 | train_wall 1621 | wall 3304
2022-07-12 09:02:22 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 14.157 | nll_loss 9.936 | mask_ins 2.261 | word_ins_ml 10.662 | word_reposition 1.234 | ppl 18273.4 | wps 37959.8 | wpb 2367.6 | bsz 32 | num_updates 2244 | best_loss 14.157
2022-07-12 09:02:29 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 2 @ 2244 updates, score 14.157) (writing took 7.291145393624902 seconds)
2022-07-12 09:03:51 | INFO | train_inner | epoch 003:     56 / 1122 loss=13.674, nll_loss=9.771, mask_ins=1.829, word_ins_ml=10.51, word_reposition=1.335, ppl=13068.5, wps=11396.1, ups=0.56, wpb=20387.7, bsz=253.8, num_updates=2300, lr=0.000230054, gnorm=1.408, clip=0, loss_scale=2048, train_wall=145, wall=3419
2022-07-12 09:06:16 | INFO | train_inner | epoch 003:    156 / 1122 loss=13.617, nll_loss=9.717, mask_ins=1.832, word_ins_ml=10.464, word_reposition=1.321, ppl=12563.5, wps=14066.1, ups=0.69, wpb=20466.9, bsz=256, num_updates=2400, lr=0.000240052, gnorm=1.436, clip=0, loss_scale=2048, train_wall=145, wall=3564
2022-07-12 09:08:42 | INFO | train_inner | epoch 003:    256 / 1122 loss=13.586, nll_loss=9.701, mask_ins=1.815, word_ins_ml=10.451, word_reposition=1.321, ppl=12298.9, wps=14135.8, ups=0.69, wpb=20590.4, bsz=256, num_updates=2500, lr=0.00025005, gnorm=1.338, clip=0, loss_scale=2048, train_wall=145, wall=3710
2022-07-12 09:11:07 | INFO | train_inner | epoch 003:    356 / 1122 loss=13.566, nll_loss=9.664, mask_ins=1.828, word_ins_ml=10.419, word_reposition=1.319, ppl=12125.5, wps=14122.7, ups=0.69, wpb=20552.9, bsz=256, num_updates=2600, lr=0.000260048, gnorm=1.309, clip=0, loss_scale=2888, train_wall=145, wall=3855
2022-07-12 09:13:32 | INFO | train_inner | epoch 003:    456 / 1122 loss=13.51, nll_loss=9.639, mask_ins=1.805, word_ins_ml=10.398, word_reposition=1.307, ppl=11664.9, wps=14144, ups=0.69, wpb=20384, bsz=256, num_updates=2700, lr=0.000270046, gnorm=1.266, clip=0, loss_scale=4096, train_wall=143, wall=4000
2022-07-12 09:15:56 | INFO | train_inner | epoch 003:    556 / 1122 loss=13.529, nll_loss=9.634, mask_ins=1.824, word_ins_ml=10.394, word_reposition=1.311, ppl=11824.5, wps=14167.5, ups=0.69, wpb=20480.9, bsz=256, num_updates=2800, lr=0.000280044, gnorm=1.281, clip=0, loss_scale=4096, train_wall=144, wall=4144
2022-07-12 09:18:21 | INFO | train_inner | epoch 003:    656 / 1122 loss=13.511, nll_loss=9.612, mask_ins=1.821, word_ins_ml=10.375, word_reposition=1.315, ppl=11671.7, wps=14258.6, ups=0.69, wpb=20612.3, bsz=256, num_updates=2900, lr=0.000290042, gnorm=1.34, clip=0, loss_scale=4096, train_wall=144, wall=4289
2022-07-12 09:20:46 | INFO | train_inner | epoch 003:    756 / 1122 loss=13.479, nll_loss=9.571, mask_ins=1.828, word_ins_ml=10.34, word_reposition=1.311, ppl=11421.2, wps=14188.9, ups=0.69, wpb=20597.8, bsz=256, num_updates=3000, lr=0.00030004, gnorm=1.258, clip=0, loss_scale=4096, train_wall=144, wall=4434
2022-07-12 09:23:11 | INFO | train_inner | epoch 003:    856 / 1122 loss=13.46, nll_loss=9.528, mask_ins=1.813, word_ins_ml=10.301, word_reposition=1.346, ppl=11271.8, wps=14206.3, ups=0.69, wpb=20609.8, bsz=256, num_updates=3100, lr=0.000310038, gnorm=1.358, clip=0, loss_scale=5284, train_wall=144, wall=4579
2022-07-12 09:25:36 | INFO | train_inner | epoch 003:    956 / 1122 loss=13.403, nll_loss=9.407, mask_ins=1.832, word_ins_ml=10.193, word_reposition=1.377, ppl=10830.9, wps=14171.4, ups=0.69, wpb=20572.9, bsz=256, num_updates=3200, lr=0.000320036, gnorm=1.512, clip=0, loss_scale=8192, train_wall=144, wall=4724
2022-07-12 09:28:01 | INFO | train_inner | epoch 003:   1056 / 1122 loss=13.338, nll_loss=9.298, mask_ins=1.824, word_ins_ml=10.097, word_reposition=1.416, ppl=10352.9, wps=14109.9, ups=0.69, wpb=20512.4, bsz=256, num_updates=3300, lr=0.000330034, gnorm=1.701, clip=0, loss_scale=8192, train_wall=145, wall=4869
2022-07-12 09:28:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2022-07-12 09:29:37 | INFO | train | epoch 003 | loss 13.495 | nll_loss 9.566 | mask_ins 1.822 | word_ins_ml 10.333 | word_reposition 1.34 | ppl 11541.8 | wps 13848.5 | ups 0.67 | wpb 20522 | bsz 255.8 | num_updates 3365 | lr 0.000336533 | gnorm 1.443 | clip 0 | loss_scale 4481 | train_wall 1620 | wall 4965
2022-07-12 09:30:03 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 13.883 | nll_loss 9.617 | mask_ins 2.078 | word_ins_ml 10.407 | word_reposition 1.398 | ppl 15110.6 | wps 38018 | wpb 2367.6 | bsz 32 | num_updates 3365 | best_loss 13.883
2022-07-12 09:30:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 3 @ 3365 updates, score 13.883) (writing took 7.36140151694417 seconds)
2022-07-12 09:31:01 | INFO | train_inner | epoch 004:     35 / 1122 loss=13.249, nll_loss=9.205, mask_ins=1.81, word_ins_ml=10.016, word_reposition=1.423, ppl=9734.22, wps=11357.5, ups=0.56, wpb=20346.5, bsz=253.8, num_updates=3400, lr=0.000340032, gnorm=2.201, clip=0, loss_scale=5475, train_wall=145, wall=5049
2022-07-12 09:31:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-07-12 09:33:26 | INFO | train_inner | epoch 004:    136 / 1122 loss=13.157, nll_loss=9.092, mask_ins=1.813, word_ins_ml=9.917, word_reposition=1.427, ppl=9134.42, wps=14069.4, ups=0.69, wpb=20497.4, bsz=256, num_updates=3500, lr=0.00035003, gnorm=2.3, clip=0, loss_scale=2149, train_wall=145, wall=5194
2022-07-12 09:33:58 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 09:35:52 | INFO | train_inner | epoch 004:    237 / 1122 loss=13.149, nll_loss=9.057, mask_ins=1.809, word_ins_ml=9.889, word_reposition=1.451, ppl=9081.94, wps=14151, ups=0.69, wpb=20601, bsz=256, num_updates=3600, lr=0.000360028, gnorm=2.56, clip=1, loss_scale=1237, train_wall=145, wall=5340
2022-07-12 09:38:17 | INFO | train_inner | epoch 004:    337 / 1122 loss=13.109, nll_loss=8.978, mask_ins=1.823, word_ins_ml=9.819, word_reposition=1.466, ppl=8833.69, wps=14103, ups=0.69, wpb=20433.7, bsz=256, num_updates=3700, lr=0.000370026, gnorm=2.154, clip=0, loss_scale=1024, train_wall=144, wall=5485
2022-07-12 09:40:42 | INFO | train_inner | epoch 004:    437 / 1122 loss=13.084, nll_loss=8.937, mask_ins=1.825, word_ins_ml=9.784, word_reposition=1.474, ppl=8681.12, wps=14266.6, ups=0.69, wpb=20661.5, bsz=256, num_updates=3800, lr=0.000380024, gnorm=2.019, clip=0, loss_scale=1024, train_wall=144, wall=5630
2022-07-12 09:43:06 | INFO | train_inner | epoch 004:    537 / 1122 loss=13.031, nll_loss=8.895, mask_ins=1.811, word_ins_ml=9.748, word_reposition=1.472, ppl=8368.31, wps=14214.8, ups=0.69, wpb=20503.2, bsz=256, num_updates=3900, lr=0.000390022, gnorm=2.335, clip=0, loss_scale=1024, train_wall=144, wall=5774
2022-07-12 09:45:31 | INFO | train_inner | epoch 004:    637 / 1122 loss=13.013, nll_loss=8.853, mask_ins=1.817, word_ins_ml=9.712, word_reposition=1.485, ppl=8266.62, wps=14150.9, ups=0.69, wpb=20500.5, bsz=256, num_updates=4000, lr=0.00040002, gnorm=2.127, clip=0, loss_scale=1024, train_wall=144, wall=5919
2022-07-12 09:47:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 09:47:56 | INFO | train_inner | epoch 004:    738 / 1122 loss=12.933, nll_loss=8.804, mask_ins=1.803, word_ins_ml=9.669, word_reposition=1.461, ppl=7822.09, wps=14176.7, ups=0.69, wpb=20620.6, bsz=256, num_updates=4100, lr=0.000410018, gnorm=2.158, clip=0, loss_scale=1480, train_wall=145, wall=6064
2022-07-12 09:50:20 | INFO | train_inner | epoch 004:    838 / 1122 loss=12.903, nll_loss=8.754, mask_ins=1.8, word_ins_ml=9.625, word_reposition=1.478, ppl=7661.06, wps=14168.1, ups=0.69, wpb=20449.1, bsz=256, num_updates=4200, lr=0.000420016, gnorm=2.307, clip=0, loss_scale=1024, train_wall=144, wall=6209
2022-07-12 09:52:45 | INFO | train_inner | epoch 004:    938 / 1122 loss=12.877, nll_loss=8.715, mask_ins=1.803, word_ins_ml=9.59, word_reposition=1.484, ppl=7524.49, wps=14267.7, ups=0.69, wpb=20632, bsz=256, num_updates=4300, lr=0.000430014, gnorm=2.224, clip=0, loss_scale=1024, train_wall=144, wall=6353
2022-07-12 09:55:09 | INFO | train_inner | epoch 004:   1038 / 1122 loss=12.829, nll_loss=8.636, mask_ins=1.799, word_ins_ml=9.522, word_reposition=1.509, ppl=7276.19, wps=14189.2, ups=0.69, wpb=20458.4, bsz=256, num_updates=4400, lr=0.000440012, gnorm=2.399, clip=0, loss_scale=1024, train_wall=143, wall=6497
2022-07-12 09:57:11 | INFO | train | epoch 004 | loss 12.997 | nll_loss 8.86 | mask_ins 1.809 | word_ins_ml 9.716 | word_reposition 1.472 | ppl 8175.56 | wps 13883.9 | ups 0.68 | wpb 20519.7 | bsz 255.8 | num_updates 4484 | lr 0.00044841 | gnorm 2.279 | clip 0.1 | loss_scale 1281 | train_wall 1613 | wall 6619
2022-07-12 09:57:37 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 14.05 | nll_loss 9.36 | mask_ins 2.213 | word_ins_ml 10.226 | word_reposition 1.611 | ppl 16958.9 | wps 38023.8 | wpb 2367.6 | bsz 32 | num_updates 4484 | best_loss 13.883
2022-07-12 09:57:41 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 4 @ 4484 updates, score 14.05) (writing took 4.183784286491573 seconds)
2022-07-12 09:58:04 | INFO | train_inner | epoch 005:     16 / 1122 loss=12.767, nll_loss=8.567, mask_ins=1.794, word_ins_ml=9.461, word_reposition=1.511, ppl=6970.71, wps=11666.9, ups=0.57, wpb=20373.5, bsz=253.8, num_updates=4500, lr=0.00045001, gnorm=2.774, clip=0, loss_scale=1024, train_wall=144, wall=6672
2022-07-12 10:00:28 | INFO | train_inner | epoch 005:    116 / 1122 loss=12.652, nll_loss=8.401, mask_ins=1.804, word_ins_ml=9.317, word_reposition=1.531, ppl=6437.92, wps=14281.1, ups=0.69, wpb=20638.2, bsz=256, num_updates=4600, lr=0.000460008, gnorm=2.704, clip=0, loss_scale=1147, train_wall=144, wall=6816
2022-07-12 10:01:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 10:02:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-07-12 10:02:56 | INFO | train_inner | epoch 005:    218 / 1122 loss=12.609, nll_loss=8.359, mask_ins=1.796, word_ins_ml=9.281, word_reposition=1.532, ppl=6247.77, wps=13908.4, ups=0.68, wpb=20523.7, bsz=256, num_updates=4700, lr=0.000470006, gnorm=3.829, clip=0, loss_scale=1536, train_wall=147, wall=6964
2022-07-12 10:05:20 | INFO | train_inner | epoch 005:    318 / 1122 loss=12.445, nll_loss=8.17, mask_ins=1.801, word_ins_ml=9.115, word_reposition=1.529, ppl=5575.2, wps=14270.1, ups=0.69, wpb=20586.1, bsz=256, num_updates=4800, lr=0.000480004, gnorm=3.32, clip=1, loss_scale=512, train_wall=144, wall=7108
2022-07-12 10:06:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-07-12 10:07:47 | INFO | train_inner | epoch 005:    419 / 1122 loss=12.346, nll_loss=8.045, mask_ins=1.795, word_ins_ml=9.007, word_reposition=1.545, ppl=5207.79, wps=13930.1, ups=0.68, wpb=20469.5, bsz=256, num_updates=4900, lr=0.000490002, gnorm=4.117, clip=2, loss_scale=335, train_wall=146, wall=7255
2022-07-12 10:10:13 | INFO | train_inner | epoch 005:    519 / 1122 loss=12.156, nll_loss=7.831, mask_ins=1.777, word_ins_ml=8.819, word_reposition=1.56, ppl=4562.72, wps=13983, ups=0.69, wpb=20378.1, bsz=256, num_updates=5000, lr=0.0005, gnorm=3.88, clip=0, loss_scale=256, train_wall=145, wall=7401
2022-07-12 10:12:38 | INFO | train_inner | epoch 005:    619 / 1122 loss=12.015, nll_loss=7.678, mask_ins=1.775, word_ins_ml=8.686, word_reposition=1.553, ppl=4139.38, wps=14146.1, ups=0.69, wpb=20521, bsz=256, num_updates=5100, lr=0.000495074, gnorm=4.368, clip=1, loss_scale=256, train_wall=144, wall=7546
2022-07-12 10:15:03 | INFO | train_inner | epoch 005:    719 / 1122 loss=11.698, nll_loss=7.304, mask_ins=1.786, word_ins_ml=8.359, word_reposition=1.553, ppl=3323.29, wps=14118.4, ups=0.69, wpb=20519.1, bsz=256, num_updates=5200, lr=0.00049029, gnorm=3.731, clip=1, loss_scale=256, train_wall=145, wall=7691
2022-07-12 10:17:29 | INFO | train_inner | epoch 005:    819 / 1122 loss=11.413, nll_loss=7.013, mask_ins=1.768, word_ins_ml=8.105, word_reposition=1.54, ppl=2727.35, wps=14212.7, ups=0.69, wpb=20648.6, bsz=256, num_updates=5300, lr=0.000485643, gnorm=3.482, clip=0, loss_scale=256, train_wall=144, wall=7837
2022-07-12 10:18:52 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-07-12 10:19:55 | INFO | train_inner | epoch 005:    920 / 1122 loss=11.225, nll_loss=6.788, mask_ins=1.776, word_ins_ml=7.91, word_reposition=1.539, ppl=2393.79, wps=14066.7, ups=0.68, wpb=20564.8, bsz=256, num_updates=5400, lr=0.000481125, gnorm=4.758, clip=2, loss_scale=294, train_wall=145, wall=7983
2022-07-12 10:21:10 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-07-12 10:22:21 | INFO | train_inner | epoch 005:   1021 / 1122 loss=10.937, nll_loss=6.497, mask_ins=1.751, word_ins_ml=7.658, word_reposition=1.528, ppl=1960.18, wps=14000.2, ups=0.68, wpb=20449, bsz=256, num_updates=5500, lr=0.000476731, gnorm=4.378, clip=0, loss_scale=193, train_wall=145, wall=8129
2022-07-12 10:24:46 | INFO | train_inner | epoch 005:   1121 / 1122 loss=10.681, nll_loss=6.206, mask_ins=1.755, word_ins_ml=7.405, word_reposition=1.521, ppl=1642.28, wps=14189.4, ups=0.69, wpb=20571, bsz=256, num_updates=5600, lr=0.000472456, gnorm=6.027, clip=2, loss_scale=128, train_wall=144, wall=8274
2022-07-12 10:24:47 | INFO | train | epoch 005 | loss 11.848 | nll_loss 7.496 | mask_ins 1.781 | word_ins_ml 8.528 | word_reposition 1.539 | ppl 3686.62 | wps 13839 | ups 0.67 | wpb 20520.3 | bsz 255.8 | num_updates 5601 | lr 0.000472413 | gnorm 4.056 | clip 0.8 | loss_scale 479 | train_wall 1617 | wall 8275
2022-07-12 10:25:13 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 12.861 | nll_loss 8.151 | mask_ins 2.022 | word_ins_ml 9.208 | word_reposition 1.63 | ppl 7440.43 | wps 38089.7 | wpb 2367.6 | bsz 32 | num_updates 5601 | best_loss 12.861
2022-07-12 10:25:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 5 @ 5601 updates, score 12.861) (writing took 7.067612938582897 seconds)
2022-07-12 10:27:43 | INFO | train_inner | epoch 006:     99 / 1122 loss=10.456, nll_loss=5.981, mask_ins=1.744, word_ins_ml=7.212, word_reposition=1.5, ppl=1404.68, wps=11484.7, ups=0.56, wpb=20373.6, bsz=253.8, num_updates=5700, lr=0.000468293, gnorm=4.401, clip=0, loss_scale=128, train_wall=143, wall=8451
2022-07-12 10:30:07 | INFO | train_inner | epoch 006:    199 / 1122 loss=10.075, nll_loss=5.642, mask_ins=1.704, word_ins_ml=6.916, word_reposition=1.455, ppl=1078.52, wps=14299, ups=0.7, wpb=20573.8, bsz=256, num_updates=5800, lr=0.000464238, gnorm=3.778, clip=0, loss_scale=128, train_wall=143, wall=8595
2022-07-12 10:32:31 | INFO | train_inner | epoch 006:    299 / 1122 loss=9.868, nll_loss=5.441, mask_ins=1.677, word_ins_ml=6.743, word_reposition=1.448, ppl=934.69, wps=14354.5, ups=0.7, wpb=20619.7, bsz=256, num_updates=5900, lr=0.000460287, gnorm=3.894, clip=0, loss_scale=128, train_wall=143, wall=8739
2022-07-12 10:34:54 | INFO | train_inner | epoch 006:    399 / 1122 loss=9.612, nll_loss=5.216, mask_ins=1.648, word_ins_ml=6.548, word_reposition=1.416, ppl=782.36, wps=14347.3, ups=0.7, wpb=20575.5, bsz=256, num_updates=6000, lr=0.000456435, gnorm=4.17, clip=0, loss_scale=177, train_wall=143, wall=8882
2022-07-12 10:37:18 | INFO | train_inner | epoch 006:    499 / 1122 loss=9.327, nll_loss=4.997, mask_ins=1.589, word_ins_ml=6.358, word_reposition=1.379, ppl=642.05, wps=14248.8, ups=0.7, wpb=20480.4, bsz=256, num_updates=6100, lr=0.000452679, gnorm=4.552, clip=0, loss_scale=256, train_wall=143, wall=9026
2022-07-12 10:39:42 | INFO | train_inner | epoch 006:    599 / 1122 loss=9.067, nll_loss=4.779, mask_ins=1.539, word_ins_ml=6.169, word_reposition=1.36, ppl=536.51, wps=14181.7, ups=0.7, wpb=20362.5, bsz=256, num_updates=6200, lr=0.000449013, gnorm=4.413, clip=0, loss_scale=256, train_wall=143, wall=9170
2022-07-12 10:40:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-07-12 10:42:07 | INFO | train_inner | epoch 006:    700 / 1122 loss=8.849, nll_loss=4.636, mask_ins=1.476, word_ins_ml=6.043, word_reposition=1.33, ppl=461.24, wps=14183.5, ups=0.69, wpb=20639.3, bsz=256, num_updates=6300, lr=0.000445435, gnorm=6.501, clip=4, loss_scale=191, train_wall=145, wall=9315
2022-07-12 10:44:30 | INFO | train_inner | epoch 006:    800 / 1122 loss=8.703, nll_loss=4.551, mask_ins=1.424, word_ins_ml=5.968, word_reposition=1.312, ppl=416.84, wps=14310.8, ups=0.7, wpb=20486.8, bsz=256, num_updates=6400, lr=0.000441942, gnorm=7.692, clip=5, loss_scale=128, train_wall=142, wall=9458
2022-07-12 10:44:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2022-07-12 10:45:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2022-07-12 10:46:56 | INFO | train_inner | epoch 006:    902 / 1122 loss=8.675, nll_loss=4.513, mask_ins=1.433, word_ins_ml=5.934, word_reposition=1.308, ppl=408.73, wps=14086.3, ups=0.68, wpb=20606.4, bsz=256, num_updates=6500, lr=0.000438529, gnorm=12.636, clip=7, loss_scale=43, train_wall=146, wall=9604
2022-07-12 10:49:20 | INFO | train_inner | epoch 006:   1002 / 1122 loss=8.211, nll_loss=4.158, mask_ins=1.334, word_ins_ml=5.622, word_reposition=1.255, ppl=296.33, wps=14286.3, ups=0.7, wpb=20515.9, bsz=256, num_updates=6600, lr=0.000435194, gnorm=5.42, clip=3, loss_scale=32, train_wall=143, wall=9748
2022-07-12 10:51:44 | INFO | train_inner | epoch 006:   1102 / 1122 loss=8.062, nll_loss=4.033, mask_ins=1.304, word_ins_ml=5.512, word_reposition=1.246, ppl=267.17, wps=14252.9, ups=0.7, wpb=20470.1, bsz=256, num_updates=6700, lr=0.000431934, gnorm=3.752, clip=0, loss_scale=32, train_wall=143, wall=9892
2022-07-12 10:52:12 | INFO | train | epoch 006 | loss 9.156 | nll_loss 4.892 | mask_ins 1.53 | word_ins_ml 6.264 | word_reposition 1.363 | ppl 570.44 | wps 13951.8 | ups 0.68 | wpb 20517.3 | bsz 255.8 | num_updates 6720 | lr 0.000431291 | gnorm 5.734 | clip 1.8 | loss_scale 134 | train_wall 1605 | wall 9920
2022-07-12 10:52:38 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 11.433 | nll_loss 6.867 | mask_ins 1.743 | word_ins_ml 8.127 | word_reposition 1.563 | ppl 2765.08 | wps 38060.9 | wpb 2367.6 | bsz 32 | num_updates 6720 | best_loss 11.433
2022-07-12 10:52:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 6 @ 6720 updates, score 11.433) (writing took 7.067687773145735 seconds)
2022-07-12 10:54:41 | INFO | train_inner | epoch 007:     80 / 1122 loss=8.022, nll_loss=4.018, mask_ins=1.289, word_ins_ml=5.498, word_reposition=1.235, ppl=260.02, wps=11484.2, ups=0.57, wpb=20321.7, bsz=253.8, num_updates=6800, lr=0.000428746, gnorm=6.773, clip=1, loss_scale=32, train_wall=143, wall=10069
2022-07-12 10:57:04 | INFO | train_inner | epoch 007:    180 / 1122 loss=7.766, nll_loss=3.809, mask_ins=1.253, word_ins_ml=5.313, word_reposition=1.201, ppl=217.7, wps=14336.2, ups=0.7, wpb=20615.6, bsz=256, num_updates=6900, lr=0.000425628, gnorm=4.053, clip=1, loss_scale=32, train_wall=143, wall=10212
2022-07-12 10:59:28 | INFO | train_inner | epoch 007:    280 / 1122 loss=7.734, nll_loss=3.826, mask_ins=1.233, word_ins_ml=5.326, word_reposition=1.175, ppl=212.95, wps=14354.5, ups=0.7, wpb=20644.4, bsz=256, num_updates=7000, lr=0.000422577, gnorm=4.964, clip=3, loss_scale=50, train_wall=143, wall=10356
2022-07-12 11:01:53 | INFO | train_inner | epoch 007:    380 / 1122 loss=7.555, nll_loss=3.678, mask_ins=1.207, word_ins_ml=5.196, word_reposition=1.152, ppl=188, wps=14214.8, ups=0.69, wpb=20518.4, bsz=256, num_updates=7100, lr=0.000419591, gnorm=4.056, clip=1, loss_scale=64, train_wall=144, wall=10501
2022-07-12 11:04:17 | INFO | train_inner | epoch 007:    480 / 1122 loss=7.419, nll_loss=3.578, mask_ins=1.185, word_ins_ml=5.106, word_reposition=1.128, ppl=171.1, wps=14211.7, ups=0.69, wpb=20510.4, bsz=256, num_updates=7200, lr=0.000416667, gnorm=3.533, clip=1, loss_scale=64, train_wall=144, wall=10645
2022-07-12 11:06:41 | INFO | train_inner | epoch 007:    580 / 1122 loss=7.364, nll_loss=3.544, mask_ins=1.171, word_ins_ml=5.075, word_reposition=1.118, ppl=164.72, wps=14176.3, ups=0.69, wpb=20460.8, bsz=256, num_updates=7300, lr=0.000413803, gnorm=3.147, clip=0, loss_scale=64, train_wall=144, wall=10789
2022-07-12 11:09:06 | INFO | train_inner | epoch 007:    680 / 1122 loss=7.258, nll_loss=3.471, mask_ins=1.151, word_ins_ml=5.009, word_reposition=1.097, ppl=153.03, wps=14218.2, ups=0.69, wpb=20521.5, bsz=256, num_updates=7400, lr=0.000410997, gnorm=3.372, clip=1, loss_scale=64, train_wall=144, wall=10934
2022-07-12 11:11:29 | INFO | train_inner | epoch 007:    780 / 1122 loss=7.177, nll_loss=3.399, mask_ins=1.143, word_ins_ml=4.946, word_reposition=1.088, ppl=144.74, wps=14326, ups=0.7, wpb=20569.3, bsz=256, num_updates=7500, lr=0.000408248, gnorm=3.268, clip=0, loss_scale=92, train_wall=143, wall=11077
2022-07-12 11:13:53 | INFO | train_inner | epoch 007:    880 / 1122 loss=7.114, nll_loss=3.387, mask_ins=1.114, word_ins_ml=4.933, word_reposition=1.067, ppl=138.49, wps=14228, ups=0.69, wpb=20524.2, bsz=256, num_updates=7600, lr=0.000405554, gnorm=3.3, clip=0, loss_scale=128, train_wall=144, wall=11221
2022-07-12 11:16:17 | INFO | train_inner | epoch 007:    980 / 1122 loss=7.067, nll_loss=3.348, mask_ins=1.109, word_ins_ml=4.898, word_reposition=1.06, ppl=134.05, wps=14344.6, ups=0.7, wpb=20583.2, bsz=256, num_updates=7700, lr=0.000402911, gnorm=3.214, clip=0, loss_scale=128, train_wall=143, wall=11365
2022-07-12 11:18:41 | INFO | train_inner | epoch 007:   1080 / 1122 loss=7.113, nll_loss=3.4, mask_ins=1.119, word_ins_ml=4.942, word_reposition=1.052, ppl=138.43, wps=14274.7, ups=0.7, wpb=20520, bsz=256, num_updates=7800, lr=0.00040032, gnorm=6.146, clip=1, loss_scale=128, train_wall=143, wall=11509
2022-07-12 11:19:41 | INFO | train | epoch 007 | loss 7.385 | nll_loss 3.564 | mask_ins 1.175 | word_ins_ml 5.093 | word_reposition 1.118 | ppl 167.2 | wps 13970 | ups 0.68 | wpb 20520.3 | bsz 255.8 | num_updates 7842 | lr 0.000399247 | gnorm 3.931 | clip 0.7 | loss_scale 80 | train_wall 1607 | wall 11569
2022-07-12 11:20:06 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 11.251 | nll_loss 6.622 | mask_ins 1.759 | word_ins_ml 7.915 | word_reposition 1.577 | ppl 2436.77 | wps 38215.2 | wpb 2367.6 | bsz 32 | num_updates 7842 | best_loss 11.251
2022-07-12 11:20:14 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 7 @ 7842 updates, score 11.251) (writing took 7.360673083923757 seconds)
2022-07-12 11:21:38 | INFO | train_inner | epoch 008:     58 / 1122 loss=6.96, nll_loss=3.267, mask_ins=1.103, word_ins_ml=4.825, word_reposition=1.032, ppl=124.54, wps=11521.5, ups=0.56, wpb=20400.5, bsz=253.8, num_updates=7900, lr=0.000397779, gnorm=3.274, clip=0, loss_scale=128, train_wall=143, wall=11686
2022-07-12 11:24:01 | INFO | train_inner | epoch 008:    158 / 1122 loss=6.841, nll_loss=3.189, mask_ins=1.072, word_ins_ml=4.755, word_reposition=1.015, ppl=114.67, wps=14285.3, ups=0.7, wpb=20511.7, bsz=256, num_updates=8000, lr=0.000395285, gnorm=3.095, clip=0, loss_scale=169, train_wall=143, wall=11829
2022-07-12 11:26:25 | INFO | train_inner | epoch 008:    258 / 1122 loss=6.801, nll_loss=3.171, mask_ins=1.061, word_ins_ml=4.738, word_reposition=1.002, ppl=111.54, wps=14255.3, ups=0.7, wpb=20480.2, bsz=256, num_updates=8100, lr=0.000392837, gnorm=3.352, clip=0, loss_scale=256, train_wall=143, wall=11973
2022-07-12 11:28:49 | INFO | train_inner | epoch 008:    358 / 1122 loss=6.78, nll_loss=3.159, mask_ins=1.054, word_ins_ml=4.726, word_reposition=1.001, ppl=109.93, wps=14235.3, ups=0.69, wpb=20560, bsz=256, num_updates=8200, lr=0.000390434, gnorm=3.226, clip=0, loss_scale=256, train_wall=144, wall=12117
2022-07-12 11:31:13 | INFO | train_inner | epoch 008:    458 / 1122 loss=6.658, nll_loss=3.066, mask_ins=1.032, word_ins_ml=4.643, word_reposition=0.984, ppl=101.01, wps=14291.3, ups=0.69, wpb=20564.6, bsz=256, num_updates=8300, lr=0.000388075, gnorm=2.944, clip=0, loss_scale=256, train_wall=143, wall=12261
2022-07-12 11:33:37 | INFO | train_inner | epoch 008:    558 / 1122 loss=6.661, nll_loss=3.077, mask_ins=1.032, word_ins_ml=4.651, word_reposition=0.978, ppl=101.22, wps=14328.5, ups=0.7, wpb=20553.8, bsz=256, num_updates=8400, lr=0.000385758, gnorm=3.026, clip=0, loss_scale=256, train_wall=143, wall=12405
2022-07-12 11:36:00 | INFO | train_inner | epoch 008:    658 / 1122 loss=6.636, nll_loss=3.071, mask_ins=1.02, word_ins_ml=4.645, word_reposition=0.971, ppl=99.43, wps=14337.6, ups=0.7, wpb=20603, bsz=256, num_updates=8500, lr=0.000383482, gnorm=3.378, clip=0, loss_scale=307, train_wall=143, wall=12549
2022-07-12 11:38:24 | INFO | train_inner | epoch 008:    758 / 1122 loss=6.588, nll_loss=3.022, mask_ins=1.02, word_ins_ml=4.601, word_reposition=0.966, ppl=96.18, wps=14273.9, ups=0.7, wpb=20481.6, bsz=256, num_updates=8600, lr=0.000381246, gnorm=3.187, clip=0, loss_scale=512, train_wall=143, wall=12692
2022-07-12 11:40:48 | INFO | train_inner | epoch 008:    858 / 1122 loss=6.546, nll_loss=3.016, mask_ins=1.007, word_ins_ml=4.594, word_reposition=0.945, ppl=93.46, wps=14357.3, ups=0.7, wpb=20618.4, bsz=256, num_updates=8700, lr=0.000379049, gnorm=2.977, clip=1, loss_scale=512, train_wall=143, wall=12836
2022-07-12 11:41:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-07-12 11:42:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-07-12 11:43:14 | INFO | train_inner | epoch 008:    960 / 1122 loss=6.533, nll_loss=2.991, mask_ins=1.009, word_ins_ml=4.571, word_reposition=0.954, ppl=92.63, wps=14064, ups=0.68, wpb=20546.9, bsz=256, num_updates=8800, lr=0.000376889, gnorm=5.029, clip=2, loss_scale=262, train_wall=145, wall=12982
2022-07-12 11:45:37 | INFO | train_inner | epoch 008:   1060 / 1122 loss=6.545, nll_loss=3.022, mask_ins=1.005, word_ins_ml=4.599, word_reposition=0.941, ppl=93.36, wps=14194.9, ups=0.7, wpb=20352.2, bsz=256, num_updates=8900, lr=0.000374766, gnorm=6.277, clip=3, loss_scale=128, train_wall=143, wall=13125
2022-07-12 11:47:06 | INFO | train | epoch 008 | loss 6.668 | nll_loss 3.084 | mask_ins 1.033 | word_ins_ml 4.657 | word_reposition 0.977 | ppl 101.69 | wps 13970.4 | ups 0.68 | wpb 20521.8 | bsz 255.8 | num_updates 8962 | lr 0.000373467 | gnorm 3.582 | clip 0.5 | loss_scale 274 | train_wall 1604 | wall 13214
2022-07-12 11:47:32 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 10.787 | nll_loss 6.21 | mask_ins 1.634 | word_ins_ml 7.533 | word_reposition 1.62 | ppl 1767.25 | wps 38226.3 | wpb 2367.6 | bsz 32 | num_updates 8962 | best_loss 10.787
2022-07-12 11:47:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 8 @ 8962 updates, score 10.787) (writing took 7.333686183206737 seconds)
2022-07-12 11:48:34 | INFO | train_inner | epoch 009:     38 / 1122 loss=6.504, nll_loss=2.992, mask_ins=0.996, word_ins_ml=4.571, word_reposition=0.937, ppl=90.77, wps=11494.8, ups=0.57, wpb=20323.6, bsz=253.8, num_updates=9000, lr=0.000372678, gnorm=2.808, clip=0, loss_scale=128, train_wall=143, wall=13302
2022-07-12 11:50:58 | INFO | train_inner | epoch 009:    138 / 1122 loss=6.421, nll_loss=2.919, mask_ins=0.988, word_ins_ml=4.506, word_reposition=0.928, ppl=85.69, wps=14271.8, ups=0.69, wpb=20618.8, bsz=256, num_updates=9100, lr=0.000370625, gnorm=3.354, clip=2, loss_scale=128, train_wall=144, wall=13446
2022-07-12 11:53:23 | INFO | train_inner | epoch 009:    238 / 1122 loss=6.374, nll_loss=2.89, mask_ins=0.98, word_ins_ml=4.479, word_reposition=0.916, ppl=82.96, wps=14197.1, ups=0.69, wpb=20480, bsz=256, num_updates=9200, lr=0.000368605, gnorm=2.656, clip=0, loss_scale=128, train_wall=143, wall=13591
2022-07-12 11:55:47 | INFO | train_inner | epoch 009:    338 / 1122 loss=6.313, nll_loss=2.842, mask_ins=0.965, word_ins_ml=4.435, word_reposition=0.912, ppl=79.48, wps=14190.2, ups=0.69, wpb=20446.5, bsz=256, num_updates=9300, lr=0.000366618, gnorm=2.755, clip=0, loss_scale=157, train_wall=143, wall=13735
2022-07-12 11:58:11 | INFO | train_inner | epoch 009:    438 / 1122 loss=6.291, nll_loss=2.836, mask_ins=0.96, word_ins_ml=4.429, word_reposition=0.902, ppl=78.29, wps=14209.6, ups=0.69, wpb=20466.1, bsz=256, num_updates=9400, lr=0.000364662, gnorm=2.954, clip=0, loss_scale=256, train_wall=143, wall=13879
2022-07-12 12:00:34 | INFO | train_inner | epoch 009:    538 / 1122 loss=6.295, nll_loss=2.86, mask_ins=0.952, word_ins_ml=4.451, word_reposition=0.893, ppl=78.53, wps=14342.8, ups=0.7, wpb=20552.4, bsz=256, num_updates=9500, lr=0.000362738, gnorm=2.631, clip=0, loss_scale=256, train_wall=143, wall=14022
2022-07-12 12:02:58 | INFO | train_inner | epoch 009:    638 / 1122 loss=6.278, nll_loss=2.828, mask_ins=0.955, word_ins_ml=4.421, word_reposition=0.902, ppl=77.59, wps=14332.7, ups=0.7, wpb=20584.1, bsz=256, num_updates=9600, lr=0.000360844, gnorm=2.632, clip=0, loss_scale=256, train_wall=143, wall=14166
2022-07-12 12:03:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 128.0
2022-07-12 12:05:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2022-07-12 12:05:24 | INFO | train_inner | epoch 009:    740 / 1122 loss=6.224, nll_loss=2.78, mask_ins=0.953, word_ins_ml=4.378, word_reposition=0.893, ppl=74.74, wps=14008, ups=0.68, wpb=20568.8, bsz=256, num_updates=9700, lr=0.000358979, gnorm=3.489, clip=1, loss_scale=131, train_wall=146, wall=14312
2022-07-12 12:07:48 | INFO | train_inner | epoch 009:    840 / 1122 loss=6.312, nll_loss=2.868, mask_ins=0.957, word_ins_ml=4.455, word_reposition=0.9, ppl=79.44, wps=14288.6, ups=0.7, wpb=20473.1, bsz=256, num_updates=9800, lr=0.000357143, gnorm=4.047, clip=2, loss_scale=64, train_wall=143, wall=14456
2022-07-12 12:09:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2022-07-12 12:10:12 | INFO | train_inner | epoch 009:    941 / 1122 loss=6.665, nll_loss=3.143, mask_ins=1.028, word_ins_ml=4.699, word_reposition=0.939, ppl=101.51, wps=14236.1, ups=0.69, wpb=20591.7, bsz=256, num_updates=9900, lr=0.000355335, gnorm=15.039, clip=14, loss_scale=52, train_wall=144, wall=14600
2022-07-12 12:12:36 | INFO | train_inner | epoch 009:   1041 / 1122 loss=6.345, nll_loss=2.886, mask_ins=0.974, word_ins_ml=4.472, word_reposition=0.899, ppl=81.29, wps=14328.4, ups=0.7, wpb=20514, bsz=256, num_updates=10000, lr=0.000353553, gnorm=15.624, clip=6, loss_scale=32, train_wall=142, wall=14744
2022-07-12 12:14:32 | INFO | train | epoch 009 | loss 6.345 | nll_loss 2.88 | mask_ins 0.969 | word_ins_ml 4.468 | word_reposition 0.908 | ppl 81.28 | wps 13950.8 | ups 0.68 | wpb 20521.8 | bsz 255.8 | num_updates 10081 | lr 0.00035213 | gnorm 5.245 | clip 2.2 | loss_scale 137 | train_wall 1604 | wall 14860
2022-07-12 12:14:58 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 10.56 | nll_loss 6.195 | mask_ins 1.58 | word_ins_ml 7.525 | word_reposition 1.454 | ppl 1509.15 | wps 38220.9 | wpb 2367.6 | bsz 32 | num_updates 10081 | best_loss 10.56
2022-07-12 12:15:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 9 @ 10081 updates, score 10.56) (writing took 7.474593496881425 seconds)
2022-07-12 12:15:33 | INFO | train_inner | epoch 010:     19 / 1122 loss=6.225, nll_loss=2.793, mask_ins=0.949, word_ins_ml=4.387, word_reposition=0.889, ppl=74.8, wps=11548.9, ups=0.56, wpb=20489.4, bsz=253.8, num_updates=10100, lr=0.000351799, gnorm=4.055, clip=1, loss_scale=32, train_wall=143, wall=14921
2022-07-12 12:17:58 | INFO | train_inner | epoch 010:    119 / 1122 loss=6.092, nll_loss=2.688, mask_ins=0.923, word_ins_ml=4.295, word_reposition=0.874, ppl=68.22, wps=14194.8, ups=0.69, wpb=20558.6, bsz=256, num_updates=10200, lr=0.00035007, gnorm=2.785, clip=0, loss_scale=32, train_wall=144, wall=15066
2022-07-12 12:20:23 | INFO | train_inner | epoch 010:    219 / 1122 loss=6.096, nll_loss=2.697, mask_ins=0.922, word_ins_ml=4.301, word_reposition=0.872, ppl=68.39, wps=14152.1, ups=0.69, wpb=20527.1, bsz=256, num_updates=10300, lr=0.000348367, gnorm=2.859, clip=0, loss_scale=32, train_wall=144, wall=15211
2022-07-12 12:22:47 | INFO | train_inner | epoch 010:    319 / 1122 loss=6.096, nll_loss=2.698, mask_ins=0.926, word_ins_ml=4.3, word_reposition=0.869, ppl=68.39, wps=14278.7, ups=0.69, wpb=20598.8, bsz=256, num_updates=10400, lr=0.000346688, gnorm=3.398, clip=1, loss_scale=40, train_wall=144, wall=15355
2022-07-12 12:25:11 | INFO | train_inner | epoch 010:    419 / 1122 loss=6.07, nll_loss=2.682, mask_ins=0.923, word_ins_ml=4.287, word_reposition=0.861, ppl=67.19, wps=14333.9, ups=0.7, wpb=20558.3, bsz=256, num_updates=10500, lr=0.000345033, gnorm=2.359, clip=0, loss_scale=64, train_wall=143, wall=15499
2022-07-12 12:27:34 | INFO | train_inner | epoch 010:    519 / 1122 loss=6.018, nll_loss=2.65, mask_ins=0.912, word_ins_ml=4.257, word_reposition=0.849, ppl=64.81, wps=14314.3, ups=0.7, wpb=20527.4, bsz=256, num_updates=10600, lr=0.000343401, gnorm=2.32, clip=0, loss_scale=64, train_wall=143, wall=15642
2022-07-12 12:29:58 | INFO | train_inner | epoch 010:    619 / 1122 loss=6.045, nll_loss=2.664, mask_ins=0.914, word_ins_ml=4.269, word_reposition=0.862, ppl=66.01, wps=14326.2, ups=0.69, wpb=20671.8, bsz=256, num_updates=10700, lr=0.000341793, gnorm=3.01, clip=1, loss_scale=64, train_wall=144, wall=15786
2022-07-12 12:32:22 | INFO | train_inner | epoch 010:    719 / 1122 loss=6.023, nll_loss=2.651, mask_ins=0.91, word_ins_ml=4.257, word_reposition=0.856, ppl=65.04, wps=14200.4, ups=0.7, wpb=20403.4, bsz=256, num_updates=10800, lr=0.000340207, gnorm=2.538, clip=0, loss_scale=64, train_wall=143, wall=15930
2022-07-12 12:34:46 | INFO | train_inner | epoch 010:    819 / 1122 loss=6.03, nll_loss=2.66, mask_ins=0.908, word_ins_ml=4.264, word_reposition=0.858, ppl=65.36, wps=14259, ups=0.69, wpb=20574.3, bsz=256, num_updates=10900, lr=0.000338643, gnorm=3.422, clip=1, loss_scale=72, train_wall=144, wall=16074
2022-07-12 12:37:09 | INFO | train_inner | epoch 010:    919 / 1122 loss=5.948, nll_loss=2.598, mask_ins=0.894, word_ins_ml=4.209, word_reposition=0.846, ppl=61.75, wps=14322, ups=0.7, wpb=20516.5, bsz=256, num_updates=11000, lr=0.0003371, gnorm=2.356, clip=0, loss_scale=128, train_wall=143, wall=16217
2022-07-12 12:39:33 | INFO | train_inner | epoch 010:   1019 / 1122 loss=5.873, nll_loss=2.541, mask_ins=0.89, word_ins_ml=4.158, word_reposition=0.826, ppl=58.62, wps=14270.6, ups=0.7, wpb=20454.3, bsz=256, num_updates=11100, lr=0.000335578, gnorm=2.222, clip=0, loss_scale=128, train_wall=143, wall=16361
2022-07-12 12:41:56 | INFO | train_inner | epoch 010:   1119 / 1122 loss=5.868, nll_loss=2.525, mask_ins=0.89, word_ins_ml=4.143, word_reposition=0.834, ppl=58.41, wps=14256.3, ups=0.7, wpb=20471.2, bsz=256, num_updates=11200, lr=0.000334077, gnorm=2.289, clip=0, loss_scale=128, train_wall=143, wall=16504
2022-07-12 12:42:00 | INFO | train | epoch 010 | loss 6.019 | nll_loss 2.644 | mask_ins 0.911 | word_ins_ml 4.252 | word_reposition 0.856 | ppl 64.86 | wps 13967.6 | ups 0.68 | wpb 20521.4 | bsz 255.8 | num_updates 11203 | lr 0.000334032 | gnorm 2.789 | clip 0.4 | loss_scale 74 | train_wall 1607 | wall 16508
2022-07-12 12:42:26 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 10.158 | nll_loss 5.851 | mask_ins 1.572 | word_ins_ml 7.196 | word_reposition 1.39 | ppl 1142.8 | wps 38130.1 | wpb 2367.6 | bsz 32 | num_updates 11203 | best_loss 10.158
2022-07-12 12:42:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 10 @ 11203 updates, score 10.158) (writing took 7.2984469858929515 seconds)
2022-07-12 12:44:53 | INFO | train_inner | epoch 011:     97 / 1122 loss=5.916, nll_loss=2.578, mask_ins=0.887, word_ins_ml=4.189, word_reposition=0.839, ppl=60.39, wps=11580.6, ups=0.57, wpb=20430.9, bsz=253.8, num_updates=11300, lr=0.000332595, gnorm=2.623, clip=0, loss_scale=128, train_wall=142, wall=16681
2022-07-12 12:47:16 | INFO | train_inner | epoch 011:    197 / 1122 loss=5.831, nll_loss=2.508, mask_ins=0.88, word_ins_ml=4.127, word_reposition=0.824, ppl=56.92, wps=14279.2, ups=0.7, wpb=20477.9, bsz=256, num_updates=11400, lr=0.000331133, gnorm=2.32, clip=0, loss_scale=129, train_wall=143, wall=16824
2022-07-12 12:49:39 | INFO | train_inner | epoch 011:    297 / 1122 loss=5.85, nll_loss=2.528, mask_ins=0.881, word_ins_ml=4.144, word_reposition=0.825, ppl=57.67, wps=14334.7, ups=0.7, wpb=20494, bsz=256, num_updates=11500, lr=0.00032969, gnorm=2.346, clip=0, loss_scale=256, train_wall=142, wall=16967
2022-07-12 12:52:03 | INFO | train_inner | epoch 011:    397 / 1122 loss=5.838, nll_loss=2.516, mask_ins=0.877, word_ins_ml=4.133, word_reposition=0.828, ppl=57.22, wps=14336.3, ups=0.7, wpb=20593.1, bsz=256, num_updates=11600, lr=0.000328266, gnorm=2.728, clip=0, loss_scale=256, train_wall=143, wall=17111
2022-07-12 12:54:27 | INFO | train_inner | epoch 011:    497 / 1122 loss=5.852, nll_loss=2.543, mask_ins=0.869, word_ins_ml=4.156, word_reposition=0.826, ppl=57.74, wps=14351.9, ups=0.7, wpb=20621.5, bsz=256, num_updates=11700, lr=0.00032686, gnorm=2.306, clip=0, loss_scale=256, train_wall=143, wall=17255
2022-07-12 12:56:52 | INFO | train_inner | epoch 011:    597 / 1122 loss=5.884, nll_loss=2.561, mask_ins=0.877, word_ins_ml=4.172, word_reposition=0.836, ppl=59.06, wps=14156.7, ups=0.69, wpb=20555.7, bsz=256, num_updates=11800, lr=0.000325472, gnorm=5.746, clip=5, loss_scale=256, train_wall=145, wall=17400
2022-07-12 12:59:18 | INFO | train_inner | epoch 011:    697 / 1122 loss=5.792, nll_loss=2.488, mask_ins=0.866, word_ins_ml=4.107, word_reposition=0.819, ppl=55.41, wps=14034, ups=0.68, wpb=20529.5, bsz=256, num_updates=11900, lr=0.000324102, gnorm=2.391, clip=0, loss_scale=256, train_wall=146, wall=17546
2022-07-12 13:01:42 | INFO | train_inner | epoch 011:    797 / 1122 loss=5.814, nll_loss=2.501, mask_ins=0.87, word_ins_ml=4.118, word_reposition=0.826, ppl=56.25, wps=14102.5, ups=0.69, wpb=20332.6, bsz=256, num_updates=12000, lr=0.000322749, gnorm=2.482, clip=1, loss_scale=484, train_wall=143, wall=17690
2022-07-12 13:04:06 | INFO | train_inner | epoch 011:    897 / 1122 loss=5.788, nll_loss=2.494, mask_ins=0.857, word_ins_ml=4.111, word_reposition=0.82, ppl=55.24, wps=14307.2, ups=0.69, wpb=20602.1, bsz=256, num_updates=12100, lr=0.000321412, gnorm=2.361, clip=0, loss_scale=512, train_wall=143, wall=17834
2022-07-12 13:06:30 | INFO | train_inner | epoch 011:    997 / 1122 loss=5.784, nll_loss=2.479, mask_ins=0.863, word_ins_ml=4.097, word_reposition=0.823, ppl=55.11, wps=14238.3, ups=0.69, wpb=20503.8, bsz=256, num_updates=12200, lr=0.000320092, gnorm=2.177, clip=0, loss_scale=512, train_wall=143, wall=17978
2022-07-12 13:08:54 | INFO | train_inner | epoch 011:   1097 / 1122 loss=5.748, nll_loss=2.457, mask_ins=0.856, word_ins_ml=4.077, word_reposition=0.815, ppl=53.75, wps=14292.2, ups=0.69, wpb=20577.4, bsz=256, num_updates=12300, lr=0.000318788, gnorm=2.07, clip=0, loss_scale=512, train_wall=143, wall=18122
2022-07-12 13:09:30 | INFO | train | epoch 011 | loss 5.825 | nll_loss 2.512 | mask_ins 0.871 | word_ins_ml 4.129 | word_reposition 0.826 | ppl 56.69 | wps 13958.2 | ups 0.68 | wpb 20521.7 | bsz 255.8 | num_updates 12325 | lr 0.000318465 | gnorm 2.674 | clip 0.5 | loss_scale 328 | train_wall 1608 | wall 18158
2022-07-12 13:09:56 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 10.316 | nll_loss 6.005 | mask_ins 1.507 | word_ins_ml 7.351 | word_reposition 1.458 | ppl 1274.69 | wps 38157.1 | wpb 2367.6 | bsz 32 | num_updates 12325 | best_loss 10.158
2022-07-12 13:10:00 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 11 @ 12325 updates, score 10.316) (writing took 4.112201918847859 seconds)
2022-07-12 13:11:49 | INFO | train_inner | epoch 012:     75 / 1122 loss=5.792, nll_loss=2.495, mask_ins=0.86, word_ins_ml=4.111, word_reposition=0.821, ppl=55.39, wps=11708.3, ups=0.57, wpb=20449.1, bsz=253.8, num_updates=12400, lr=0.0003175, gnorm=2.231, clip=0, loss_scale=512, train_wall=144, wall=18297
2022-07-12 13:14:14 | INFO | train_inner | epoch 012:    175 / 1122 loss=5.722, nll_loss=2.439, mask_ins=0.853, word_ins_ml=4.06, word_reposition=0.809, ppl=52.79, wps=14161.1, ups=0.69, wpb=20487.2, bsz=256, num_updates=12500, lr=0.000316228, gnorm=2.119, clip=0, loss_scale=906, train_wall=144, wall=18442
2022-07-12 13:14:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-07-12 13:16:39 | INFO | train_inner | epoch 012:    276 / 1122 loss=5.717, nll_loss=2.442, mask_ins=0.85, word_ins_ml=4.063, word_reposition=0.805, ppl=52.61, wps=14071.7, ups=0.69, wpb=20521.1, bsz=256, num_updates=12600, lr=0.00031497, gnorm=2.15, clip=0, loss_scale=578, train_wall=145, wall=18587
2022-07-12 13:17:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-07-12 13:19:05 | INFO | train_inner | epoch 012:    377 / 1122 loss=5.705, nll_loss=2.431, mask_ins=0.849, word_ins_ml=4.052, word_reposition=0.803, ppl=52.17, wps=14136.5, ups=0.69, wpb=20610.2, bsz=256, num_updates=12700, lr=0.000313728, gnorm=3, clip=1, loss_scale=324, train_wall=145, wall=18733
2022-07-12 13:21:29 | INFO | train_inner | epoch 012:    477 / 1122 loss=5.734, nll_loss=2.466, mask_ins=0.845, word_ins_ml=4.083, word_reposition=0.806, ppl=53.23, wps=14232.8, ups=0.69, wpb=20496.2, bsz=256, num_updates=12800, lr=0.0003125, gnorm=2.657, clip=0, loss_scale=256, train_wall=143, wall=18877
2022-07-12 13:23:54 | INFO | train_inner | epoch 012:    577 / 1122 loss=5.699, nll_loss=2.426, mask_ins=0.845, word_ins_ml=4.047, word_reposition=0.807, ppl=51.95, wps=14244.9, ups=0.69, wpb=20579.3, bsz=256, num_updates=12900, lr=0.000311286, gnorm=2.072, clip=0, loss_scale=256, train_wall=144, wall=19022
2022-07-12 13:26:17 | INFO | train_inner | epoch 012:    677 / 1122 loss=5.65, nll_loss=2.379, mask_ins=0.843, word_ins_ml=4.006, word_reposition=0.801, ppl=50.22, wps=14234.9, ups=0.7, wpb=20415.2, bsz=256, num_updates=13000, lr=0.000310087, gnorm=2.165, clip=0, loss_scale=256, train_wall=143, wall=19165
2022-07-12 13:28:41 | INFO | train_inner | epoch 012:    777 / 1122 loss=5.693, nll_loss=2.422, mask_ins=0.845, word_ins_ml=4.042, word_reposition=0.806, ppl=51.73, wps=14308, ups=0.69, wpb=20592.1, bsz=256, num_updates=13100, lr=0.000308901, gnorm=2.441, clip=0, loss_scale=256, train_wall=143, wall=19309
2022-07-12 13:31:04 | INFO | train_inner | epoch 012:    877 / 1122 loss=5.719, nll_loss=2.43, mask_ins=0.857, word_ins_ml=4.05, word_reposition=0.812, ppl=52.68, wps=14329.1, ups=0.7, wpb=20561, bsz=256, num_updates=13200, lr=0.000307729, gnorm=2.847, clip=0, loss_scale=415, train_wall=143, wall=19452
2022-07-12 13:33:28 | INFO | train_inner | epoch 012:    977 / 1122 loss=5.617, nll_loss=2.364, mask_ins=0.83, word_ins_ml=3.991, word_reposition=0.796, ppl=49.07, wps=14328.3, ups=0.7, wpb=20520.9, bsz=256, num_updates=13300, lr=0.00030657, gnorm=2.155, clip=0, loss_scale=512, train_wall=143, wall=19596
2022-07-12 13:35:53 | INFO | train_inner | epoch 012:   1077 / 1122 loss=5.638, nll_loss=2.385, mask_ins=0.835, word_ins_ml=4.01, word_reposition=0.793, ppl=49.8, wps=14138, ups=0.69, wpb=20482.9, bsz=256, num_updates=13400, lr=0.000305424, gnorm=2.109, clip=0, loss_scale=512, train_wall=144, wall=19741
2022-07-12 13:36:58 | INFO | train | epoch 012 | loss 5.697 | nll_loss 2.424 | mask_ins 0.846 | word_ins_ml 4.046 | word_reposition 0.805 | ppl 51.87 | wps 13946.6 | ups 0.68 | wpb 20520.9 | bsz 255.8 | num_updates 13445 | lr 0.000304912 | gnorm 2.353 | clip 0.1 | loss_scale 436 | train_wall 1610 | wall 19806
2022-07-12 13:37:24 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 10.183 | nll_loss 5.887 | mask_ins 1.567 | word_ins_ml 7.231 | word_reposition 1.384 | ppl 1162.39 | wps 38082.5 | wpb 2367.6 | bsz 32 | num_updates 13445 | best_loss 10.158
2022-07-12 13:37:28 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 12 @ 13445 updates, score 10.183) (writing took 4.095966509543359 seconds)
2022-07-12 13:38:48 | INFO | train_inner | epoch 013:     55 / 1122 loss=5.668, nll_loss=2.407, mask_ins=0.842, word_ins_ml=4.029, word_reposition=0.796, ppl=50.83, wps=11639.7, ups=0.57, wpb=20389.8, bsz=253.8, num_updates=13500, lr=0.00030429, gnorm=2.159, clip=0, loss_scale=512, train_wall=144, wall=19916
2022-07-12 13:41:12 | INFO | train_inner | epoch 013:    155 / 1122 loss=5.614, nll_loss=2.363, mask_ins=0.833, word_ins_ml=3.989, word_reposition=0.793, ppl=48.99, wps=14235.8, ups=0.69, wpb=20589.8, bsz=256, num_updates=13600, lr=0.00030317, gnorm=2.163, clip=0, loss_scale=512, train_wall=144, wall=20060
2022-07-12 13:43:38 | INFO | train_inner | epoch 013:    255 / 1122 loss=5.689, nll_loss=2.43, mask_ins=0.846, word_ins_ml=4.048, word_reposition=0.795, ppl=51.6, wps=14052.6, ups=0.69, wpb=20456.7, bsz=256, num_updates=13700, lr=0.000302061, gnorm=2.326, clip=0, loss_scale=768, train_wall=145, wall=20206
2022-07-12 13:45:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-07-12 13:46:04 | INFO | train_inner | epoch 013:    356 / 1122 loss=5.628, nll_loss=2.391, mask_ins=0.825, word_ins_ml=4.014, word_reposition=0.79, ppl=49.45, wps=14027, ups=0.68, wpb=20515, bsz=256, num_updates=13800, lr=0.000300965, gnorm=2.596, clip=0, loss_scale=806, train_wall=145, wall=20352
2022-07-12 13:48:29 | INFO | train_inner | epoch 013:    456 / 1122 loss=5.649, nll_loss=2.4, mask_ins=0.835, word_ins_ml=4.021, word_reposition=0.793, ppl=50.19, wps=14196.1, ups=0.69, wpb=20605, bsz=256, num_updates=13900, lr=0.00029988, gnorm=2.666, clip=0, loss_scale=512, train_wall=144, wall=20497
2022-07-12 13:50:53 | INFO | train_inner | epoch 013:    556 / 1122 loss=5.613, nll_loss=2.363, mask_ins=0.832, word_ins_ml=3.988, word_reposition=0.794, ppl=48.93, wps=14240.1, ups=0.69, wpb=20508.6, bsz=256, num_updates=14000, lr=0.000298807, gnorm=2.214, clip=0, loss_scale=512, train_wall=143, wall=20641
2022-07-12 13:53:17 | INFO | train_inner | epoch 013:    656 / 1122 loss=5.586, nll_loss=2.335, mask_ins=0.83, word_ins_ml=3.963, word_reposition=0.793, ppl=48.03, wps=14289.1, ups=0.7, wpb=20465.6, bsz=256, num_updates=14100, lr=0.000297746, gnorm=2.132, clip=0, loss_scale=512, train_wall=143, wall=20785
2022-07-12 13:55:40 | INFO | train_inner | epoch 013:    756 / 1122 loss=5.629, nll_loss=2.397, mask_ins=0.822, word_ins_ml=4.017, word_reposition=0.79, ppl=49.5, wps=14296.4, ups=0.7, wpb=20550, bsz=256, num_updates=14200, lr=0.000296695, gnorm=2.184, clip=0, loss_scale=512, train_wall=143, wall=20928
2022-07-12 13:58:05 | INFO | train_inner | epoch 013:    856 / 1122 loss=5.625, nll_loss=2.382, mask_ins=0.833, word_ins_ml=4.004, word_reposition=0.789, ppl=49.36, wps=14138.6, ups=0.69, wpb=20513.8, bsz=256, num_updates=14300, lr=0.000295656, gnorm=2.2, clip=0, loss_scale=671, train_wall=144, wall=21073
2022-07-12 14:00:29 | INFO | train_inner | epoch 013:    956 / 1122 loss=5.561, nll_loss=2.328, mask_ins=0.826, word_ins_ml=3.955, word_reposition=0.78, ppl=47.21, wps=14258, ups=0.7, wpb=20479.1, bsz=256, num_updates=14400, lr=0.000294628, gnorm=2.029, clip=0, loss_scale=1024, train_wall=143, wall=21217
2022-07-12 14:02:53 | INFO | train_inner | epoch 013:   1056 / 1122 loss=5.561, nll_loss=2.321, mask_ins=0.826, word_ins_ml=3.949, word_reposition=0.786, ppl=47.2, wps=14364.2, ups=0.7, wpb=20644.2, bsz=256, num_updates=14500, lr=0.00029361, gnorm=2.133, clip=0, loss_scale=1024, train_wall=143, wall=21361
2022-07-12 14:04:27 | INFO | train | epoch 013 | loss 5.618 | nll_loss 2.374 | mask_ins 0.831 | word_ins_ml 3.998 | word_reposition 0.79 | ppl 49.12 | wps 13945.4 | ups 0.68 | wpb 20518.7 | bsz 255.8 | num_updates 14566 | lr 0.000292944 | gnorm 2.254 | clip 0 | loss_scale 697 | train_wall 1611 | wall 21455
2022-07-12 14:04:53 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 10.205 | nll_loss 5.932 | mask_ins 1.568 | word_ins_ml 7.286 | word_reposition 1.351 | ppl 1180.15 | wps 38163.9 | wpb 2367.6 | bsz 32 | num_updates 14566 | best_loss 10.158
2022-07-12 14:04:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 13 @ 14566 updates, score 10.205) (writing took 4.148449268192053 seconds)
2022-07-12 14:05:47 | INFO | train_inner | epoch 014:     34 / 1122 loss=5.614, nll_loss=2.388, mask_ins=0.816, word_ins_ml=4.008, word_reposition=0.79, ppl=48.97, wps=11735, ups=0.58, wpb=20397.3, bsz=253.8, num_updates=14600, lr=0.000292603, gnorm=2.134, clip=0, loss_scale=1024, train_wall=143, wall=21535
2022-07-12 14:07:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-07-12 14:07:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 256.0
2022-07-12 14:08:15 | INFO | train_inner | epoch 014:    136 / 1122 loss=5.592, nll_loss=2.362, mask_ins=0.824, word_ins_ml=3.985, word_reposition=0.783, ppl=48.23, wps=13851.3, ups=0.68, wpb=20517.3, bsz=256, num_updates=14700, lr=0.000291606, gnorm=2.436, clip=0, loss_scale=745, train_wall=147, wall=21683
2022-07-12 14:10:42 | INFO | train_inner | epoch 014:    236 / 1122 loss=5.596, nll_loss=2.369, mask_ins=0.827, word_ins_ml=3.991, word_reposition=0.778, ppl=48.37, wps=13972.3, ups=0.68, wpb=20545.8, bsz=256, num_updates=14800, lr=0.000290619, gnorm=2.925, clip=0, loss_scale=256, train_wall=146, wall=21830
2022-07-12 14:13:07 | INFO | train_inner | epoch 014:    336 / 1122 loss=5.561, nll_loss=2.327, mask_ins=0.821, word_ins_ml=3.954, word_reposition=0.786, ppl=47.21, wps=14195.1, ups=0.69, wpb=20546, bsz=256, num_updates=14900, lr=0.000289642, gnorm=2.483, clip=0, loss_scale=256, train_wall=144, wall=21975
2022-07-12 14:15:30 | INFO | train_inner | epoch 014:    436 / 1122 loss=5.539, nll_loss=2.308, mask_ins=0.819, word_ins_ml=3.937, word_reposition=0.784, ppl=46.48, wps=14256.4, ups=0.7, wpb=20503.6, bsz=256, num_updates=15000, lr=0.000288675, gnorm=2.478, clip=0, loss_scale=256, train_wall=143, wall=22118
2022-07-12 14:17:54 | INFO | train_inner | epoch 014:    536 / 1122 loss=5.506, nll_loss=2.293, mask_ins=0.808, word_ins_ml=3.923, word_reposition=0.776, ppl=45.46, wps=14221, ups=0.69, wpb=20496.6, bsz=256, num_updates=15100, lr=0.000287718, gnorm=2.105, clip=0, loss_scale=256, train_wall=143, wall=22262
2022-07-12 14:20:19 | INFO | train_inner | epoch 014:    636 / 1122 loss=5.523, nll_loss=2.303, mask_ins=0.816, word_ins_ml=3.931, word_reposition=0.776, ppl=45.98, wps=14179.5, ups=0.69, wpb=20538.6, bsz=256, num_updates=15200, lr=0.00028677, gnorm=1.972, clip=0, loss_scale=289, train_wall=144, wall=22407
2022-07-12 14:22:44 | INFO | train_inner | epoch 014:    736 / 1122 loss=5.524, nll_loss=2.306, mask_ins=0.811, word_ins_ml=3.933, word_reposition=0.78, ppl=46.02, wps=14282.7, ups=0.69, wpb=20617.9, bsz=256, num_updates=15300, lr=0.000285831, gnorm=1.979, clip=0, loss_scale=512, train_wall=144, wall=22552
2022-07-12 14:25:07 | INFO | train_inner | epoch 014:    836 / 1122 loss=5.553, nll_loss=2.33, mask_ins=0.818, word_ins_ml=3.954, word_reposition=0.781, ppl=46.96, wps=14216.5, ups=0.7, wpb=20408.2, bsz=256, num_updates=15400, lr=0.000284901, gnorm=2.032, clip=0, loss_scale=512, train_wall=143, wall=22695
2022-07-12 14:27:32 | INFO | train_inner | epoch 014:    936 / 1122 loss=5.529, nll_loss=2.306, mask_ins=0.821, word_ins_ml=3.932, word_reposition=0.775, ppl=46.17, wps=14203.1, ups=0.69, wpb=20511.4, bsz=256, num_updates=15500, lr=0.000283981, gnorm=2.15, clip=0, loss_scale=512, train_wall=144, wall=22840
2022-07-12 14:29:55 | INFO | train_inner | epoch 014:   1036 / 1122 loss=5.512, nll_loss=2.294, mask_ins=0.816, word_ins_ml=3.922, word_reposition=0.774, ppl=45.62, wps=14319.4, ups=0.7, wpb=20562.6, bsz=256, num_updates=15600, lr=0.000283069, gnorm=1.971, clip=0, loss_scale=512, train_wall=143, wall=22983
2022-07-12 14:31:59 | INFO | train | epoch 014 | loss 5.541 | nll_loss 2.318 | mask_ins 0.817 | word_ins_ml 3.944 | word_reposition 0.78 | ppl 46.57 | wps 13912 | ups 0.68 | wpb 20521.4 | bsz 255.8 | num_updates 15686 | lr 0.000282292 | gnorm 2.228 | clip 0 | loss_scale 438 | train_wall 1614 | wall 23107
2022-07-12 14:32:25 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 10.018 | nll_loss 5.8 | mask_ins 1.551 | word_ins_ml 7.152 | word_reposition 1.315 | ppl 1036.68 | wps 38157 | wpb 2367.6 | bsz 32 | num_updates 15686 | best_loss 10.018
2022-07-12 14:32:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 14 @ 15686 updates, score 10.018) (writing took 7.257882973179221 seconds)
2022-07-12 14:32:53 | INFO | train_inner | epoch 015:     14 / 1122 loss=5.493, nll_loss=2.279, mask_ins=0.805, word_ins_ml=3.908, word_reposition=0.78, ppl=45.03, wps=11522.5, ups=0.56, wpb=20468.3, bsz=253.8, num_updates=15700, lr=0.000282166, gnorm=2.296, clip=0, loss_scale=517, train_wall=144, wall=23161
2022-07-12 14:35:18 | INFO | train_inner | epoch 015:    114 / 1122 loss=5.494, nll_loss=2.288, mask_ins=0.801, word_ins_ml=3.916, word_reposition=0.776, ppl=45.06, wps=14176.7, ups=0.69, wpb=20638.2, bsz=256, num_updates=15800, lr=0.000281272, gnorm=1.924, clip=0, loss_scale=1024, train_wall=145, wall=23306
2022-07-12 14:37:43 | INFO | train_inner | epoch 015:    214 / 1122 loss=5.447, nll_loss=2.245, mask_ins=0.799, word_ins_ml=3.878, word_reposition=0.77, ppl=43.62, wps=14248.8, ups=0.69, wpb=20577.2, bsz=256, num_updates=15900, lr=0.000280386, gnorm=1.853, clip=0, loss_scale=1024, train_wall=144, wall=23451
2022-07-12 14:40:09 | INFO | train_inner | epoch 015:    314 / 1122 loss=5.422, nll_loss=2.227, mask_ins=0.798, word_ins_ml=3.862, word_reposition=0.762, ppl=42.87, wps=14098.2, ups=0.69, wpb=20536.6, bsz=256, num_updates=16000, lr=0.000279508, gnorm=1.901, clip=0, loss_scale=1024, train_wall=145, wall=23597
2022-07-12 14:42:36 | INFO | train_inner | epoch 015:    414 / 1122 loss=5.497, nll_loss=2.284, mask_ins=0.806, word_ins_ml=3.912, word_reposition=0.78, ppl=45.16, wps=13930.8, ups=0.68, wpb=20532.1, bsz=256, num_updates=16100, lr=0.000278639, gnorm=1.907, clip=0, loss_scale=1024, train_wall=147, wall=23744
2022-07-12 14:45:05 | INFO | train_inner | epoch 015:    514 / 1122 loss=5.492, nll_loss=2.282, mask_ins=0.81, word_ins_ml=3.91, word_reposition=0.772, ppl=45.01, wps=13704.6, ups=0.67, wpb=20493.1, bsz=256, num_updates=16200, lr=0.000277778, gnorm=1.895, clip=0, loss_scale=1024, train_wall=149, wall=23893
2022-07-12 14:47:34 | INFO | train_inner | epoch 015:    614 / 1122 loss=5.517, nll_loss=2.32, mask_ins=0.803, word_ins_ml=3.943, word_reposition=0.771, ppl=45.79, wps=13768.6, ups=0.67, wpb=20509.3, bsz=256, num_updates=16300, lr=0.000276924, gnorm=1.994, clip=0, loss_scale=1935, train_wall=148, wall=24042
2022-07-12 14:50:04 | INFO | train_inner | epoch 015:    714 / 1122 loss=5.492, nll_loss=2.304, mask_ins=0.795, word_ins_ml=3.929, word_reposition=0.768, ppl=45.01, wps=13691.6, ups=0.67, wpb=20500.2, bsz=256, num_updates=16400, lr=0.000276079, gnorm=1.951, clip=0, loss_scale=2048, train_wall=149, wall=24192
2022-07-12 14:52:34 | INFO | train_inner | epoch 015:    814 / 1122 loss=5.439, nll_loss=2.259, mask_ins=0.789, word_ins_ml=3.889, word_reposition=0.761, ppl=43.38, wps=13747.8, ups=0.67, wpb=20537.6, bsz=256, num_updates=16500, lr=0.000275241, gnorm=1.931, clip=0, loss_scale=2048, train_wall=149, wall=24342
2022-07-12 14:55:03 | INFO | train_inner | epoch 015:    914 / 1122 loss=5.47, nll_loss=2.283, mask_ins=0.799, word_ins_ml=3.91, word_reposition=0.761, ppl=44.33, wps=13700.2, ups=0.67, wpb=20464.1, bsz=256, num_updates=16600, lr=0.000274411, gnorm=1.88, clip=0, loss_scale=2048, train_wall=149, wall=24491
2022-07-12 14:57:32 | INFO | train_inner | epoch 015:   1014 / 1122 loss=5.457, nll_loss=2.257, mask_ins=0.805, word_ins_ml=3.886, word_reposition=0.766, ppl=43.93, wps=13763.4, ups=0.67, wpb=20529.6, bsz=256, num_updates=16700, lr=0.000273588, gnorm=1.896, clip=0, loss_scale=2048, train_wall=148, wall=24640
2022-07-12 15:00:01 | INFO | train_inner | epoch 015:   1114 / 1122 loss=5.423, nll_loss=2.232, mask_ins=0.795, word_ins_ml=3.863, word_reposition=0.765, ppl=42.91, wps=13798.1, ups=0.67, wpb=20610, bsz=256, num_updates=16800, lr=0.000272772, gnorm=1.944, clip=0, loss_scale=3625, train_wall=149, wall=24789
2022-07-12 15:00:13 | INFO | train | epoch 015 | loss 5.469 | nll_loss 2.272 | mask_ins 0.8 | word_ins_ml 3.9 | word_reposition 0.768 | ppl 44.28 | wps 13594.3 | ups 0.66 | wpb 20520.8 | bsz 255.8 | num_updates 16808 | lr 0.000272707 | gnorm 1.946 | clip 0 | loss_scale 1718 | train_wall 1651 | wall 24801
2022-07-12 15:00:40 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 10.135 | nll_loss 5.852 | mask_ins 1.586 | word_ins_ml 7.199 | word_reposition 1.351 | ppl 1124.66 | wps 37225.2 | wpb 2367.6 | bsz 32 | num_updates 16808 | best_loss 10.018
2022-07-12 15:00:44 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 15 @ 16808 updates, score 10.135) (writing took 4.799956216476858 seconds)
2022-07-12 15:03:02 | INFO | train_inner | epoch 016:     92 / 1122 loss=5.434, nll_loss=2.236, mask_ins=0.802, word_ins_ml=3.868, word_reposition=0.765, ppl=43.24, wps=11231.3, ups=0.55, wpb=20282.2, bsz=253.8, num_updates=16900, lr=0.000271964, gnorm=2.03, clip=0, loss_scale=4096, train_wall=148, wall=24970
2022-07-12 15:03:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-07-12 15:04:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 15:04:53 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-07-12 15:05:36 | INFO | train_inner | epoch 016:    195 / 1122 loss=5.467, nll_loss=2.269, mask_ins=0.8, word_ins_ml=3.897, word_reposition=0.77, ppl=44.22, wps=13309.7, ups=0.65, wpb=20488.8, bsz=256, num_updates=17000, lr=0.000271163, gnorm=2.013, clip=0, loss_scale=2118, train_wall=153, wall=25124
2022-07-12 15:08:05 | INFO | train_inner | epoch 016:    295 / 1122 loss=5.431, nll_loss=2.233, mask_ins=0.803, word_ins_ml=3.864, word_reposition=0.763, ppl=43.13, wps=13860.1, ups=0.67, wpb=20643.1, bsz=256, num_updates=17100, lr=0.000270369, gnorm=2.039, clip=0, loss_scale=512, train_wall=148, wall=25273
2022-07-12 15:10:33 | INFO | train_inner | epoch 016:    395 / 1122 loss=5.4, nll_loss=2.217, mask_ins=0.79, word_ins_ml=3.849, word_reposition=0.761, ppl=42.22, wps=13775.6, ups=0.67, wpb=20443.8, bsz=256, num_updates=17200, lr=0.000269582, gnorm=1.897, clip=0, loss_scale=512, train_wall=148, wall=25421
2022-07-12 15:13:02 | INFO | train_inner | epoch 016:    495 / 1122 loss=5.422, nll_loss=2.233, mask_ins=0.793, word_ins_ml=3.864, word_reposition=0.765, ppl=42.87, wps=13861.1, ups=0.67, wpb=20640.4, bsz=256, num_updates=17300, lr=0.000268802, gnorm=1.907, clip=0, loss_scale=512, train_wall=148, wall=25570
2022-07-12 15:15:31 | INFO | train_inner | epoch 016:    595 / 1122 loss=5.379, nll_loss=2.199, mask_ins=0.79, word_ins_ml=3.834, word_reposition=0.755, ppl=41.62, wps=13811.9, ups=0.67, wpb=20533.1, bsz=256, num_updates=17400, lr=0.000268028, gnorm=1.839, clip=0, loss_scale=512, train_wall=148, wall=25719
2022-07-12 15:18:01 | INFO | train_inner | epoch 016:    695 / 1122 loss=5.371, nll_loss=2.204, mask_ins=0.778, word_ins_ml=3.837, word_reposition=0.756, ppl=41.38, wps=13754.6, ups=0.67, wpb=20598.4, bsz=256, num_updates=17500, lr=0.000267261, gnorm=1.852, clip=0, loss_scale=604, train_wall=149, wall=25869
2022-07-12 15:20:30 | INFO | train_inner | epoch 016:    795 / 1122 loss=5.387, nll_loss=2.194, mask_ins=0.796, word_ins_ml=3.829, word_reposition=0.762, ppl=41.83, wps=13707.5, ups=0.67, wpb=20506.8, bsz=256, num_updates=17600, lr=0.000266501, gnorm=1.816, clip=0, loss_scale=1024, train_wall=149, wall=26018
2022-07-12 15:22:59 | INFO | train_inner | epoch 016:    895 / 1122 loss=5.388, nll_loss=2.216, mask_ins=0.786, word_ins_ml=3.848, word_reposition=0.755, ppl=41.88, wps=13817.5, ups=0.67, wpb=20557.5, bsz=256, num_updates=17700, lr=0.000265747, gnorm=1.861, clip=0, loss_scale=1024, train_wall=148, wall=26167
2022-07-12 15:25:28 | INFO | train_inner | epoch 016:    995 / 1122 loss=5.38, nll_loss=2.199, mask_ins=0.789, word_ins_ml=3.833, word_reposition=0.759, ppl=41.65, wps=13759.3, ups=0.67, wpb=20512.9, bsz=256, num_updates=17800, lr=0.000264999, gnorm=1.815, clip=0, loss_scale=1024, train_wall=148, wall=26316
2022-07-12 15:27:57 | INFO | train_inner | epoch 016:   1095 / 1122 loss=5.39, nll_loss=2.21, mask_ins=0.789, word_ins_ml=3.842, word_reposition=0.759, ppl=41.93, wps=13798.1, ups=0.67, wpb=20503.2, bsz=256, num_updates=17900, lr=0.000264258, gnorm=1.851, clip=0, loss_scale=1024, train_wall=148, wall=26465
2022-07-12 15:28:36 | INFO | train | epoch 016 | loss 5.404 | nll_loss 2.219 | mask_ins 0.792 | word_ins_ml 3.851 | word_reposition 0.761 | ppl 42.34 | wps 13479.9 | ups 0.66 | wpb 20520.4 | bsz 255.8 | num_updates 17927 | lr 0.000264059 | gnorm 1.899 | clip 0 | loss_scale 1156 | train_wall 1663 | wall 26504
2022-07-12 15:29:03 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 10.104 | nll_loss 5.785 | mask_ins 1.553 | word_ins_ml 7.141 | word_reposition 1.41 | ppl 1100.86 | wps 37325.1 | wpb 2367.6 | bsz 32 | num_updates 17927 | best_loss 10.018
2022-07-12 15:29:08 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 16 @ 17927 updates, score 10.104) (writing took 4.657922746613622 seconds)
2022-07-12 15:30:56 | INFO | train_inner | epoch 017:     73 / 1122 loss=5.376, nll_loss=2.193, mask_ins=0.791, word_ins_ml=3.827, word_reposition=0.757, ppl=41.52, wps=11385.4, ups=0.56, wpb=20448.9, bsz=253.8, num_updates=18000, lr=0.000263523, gnorm=1.871, clip=0, loss_scale=1085, train_wall=148, wall=26644
2022-07-12 15:33:26 | INFO | train_inner | epoch 017:    173 / 1122 loss=5.412, nll_loss=2.223, mask_ins=0.797, word_ins_ml=3.854, word_reposition=0.761, ppl=42.57, wps=13726.4, ups=0.67, wpb=20504.3, bsz=256, num_updates=18100, lr=0.000262794, gnorm=1.926, clip=0, loss_scale=2048, train_wall=149, wall=26794
2022-07-12 15:35:55 | INFO | train_inner | epoch 017:    273 / 1122 loss=5.337, nll_loss=2.165, mask_ins=0.783, word_ins_ml=3.802, word_reposition=0.752, ppl=40.43, wps=13740.9, ups=0.67, wpb=20488.6, bsz=256, num_updates=18200, lr=0.000262071, gnorm=1.884, clip=0, loss_scale=2048, train_wall=148, wall=26943
2022-07-12 15:36:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 15:38:28 | INFO | train_inner | epoch 017:    374 / 1122 loss=5.389, nll_loss=2.228, mask_ins=0.78, word_ins_ml=3.857, word_reposition=0.752, ppl=41.89, wps=13333, ups=0.65, wpb=20385.5, bsz=256, num_updates=18300, lr=0.000261354, gnorm=1.85, clip=0, loss_scale=1146, train_wall=152, wall=27096
2022-07-12 15:40:57 | INFO | train_inner | epoch 017:    474 / 1122 loss=5.332, nll_loss=2.175, mask_ins=0.773, word_ins_ml=3.81, word_reposition=0.748, ppl=40.27, wps=13710.9, ups=0.67, wpb=20497.5, bsz=256, num_updates=18400, lr=0.000260643, gnorm=1.849, clip=0, loss_scale=1024, train_wall=149, wall=27245
2022-07-12 15:43:26 | INFO | train_inner | epoch 017:    574 / 1122 loss=5.325, nll_loss=2.156, mask_ins=0.778, word_ins_ml=3.794, word_reposition=0.753, ppl=40.09, wps=13784, ups=0.67, wpb=20511.5, bsz=256, num_updates=18500, lr=0.000259938, gnorm=1.937, clip=0, loss_scale=1024, train_wall=148, wall=27394
2022-07-12 15:45:54 | INFO | train_inner | epoch 017:    674 / 1122 loss=5.326, nll_loss=2.16, mask_ins=0.777, word_ins_ml=3.797, word_reposition=0.752, ppl=40.11, wps=13890.6, ups=0.67, wpb=20623.2, bsz=256, num_updates=18600, lr=0.000259238, gnorm=1.843, clip=0, loss_scale=1024, train_wall=148, wall=27542
2022-07-12 15:48:24 | INFO | train_inner | epoch 017:    774 / 1122 loss=5.356, nll_loss=2.191, mask_ins=0.775, word_ins_ml=3.824, word_reposition=0.757, ppl=40.96, wps=13872.7, ups=0.67, wpb=20750.8, bsz=256, num_updates=18700, lr=0.000258544, gnorm=1.81, clip=0, loss_scale=1024, train_wall=149, wall=27692
2022-07-12 15:50:54 | INFO | train_inner | epoch 017:    874 / 1122 loss=5.363, nll_loss=2.191, mask_ins=0.778, word_ins_ml=3.824, word_reposition=0.761, ppl=41.14, wps=13681.5, ups=0.67, wpb=20449.2, bsz=256, num_updates=18800, lr=0.000257855, gnorm=1.84, clip=0, loss_scale=1812, train_wall=149, wall=27842
2022-07-12 15:53:22 | INFO | train_inner | epoch 017:    974 / 1122 loss=5.335, nll_loss=2.16, mask_ins=0.783, word_ins_ml=3.796, word_reposition=0.755, ppl=40.35, wps=13759.4, ups=0.67, wpb=20495.8, bsz=256, num_updates=18900, lr=0.000257172, gnorm=1.959, clip=0, loss_scale=2048, train_wall=148, wall=27990
2022-07-12 15:55:51 | INFO | train_inner | epoch 017:   1074 / 1122 loss=5.335, nll_loss=2.171, mask_ins=0.775, word_ins_ml=3.806, word_reposition=0.754, ppl=40.38, wps=13818.3, ups=0.67, wpb=20549.3, bsz=256, num_updates=19000, lr=0.000256495, gnorm=2.321, clip=0, loss_scale=2048, train_wall=148, wall=28139
2022-07-12 15:57:02 | INFO | train | epoch 017 | loss 5.349 | nll_loss 2.179 | mask_ins 0.781 | word_ins_ml 3.814 | word_reposition 0.755 | ppl 40.76 | wps 13482.9 | ups 0.66 | wpb 20518.5 | bsz 255.8 | num_updates 19048 | lr 0.000256171 | gnorm 1.939 | clip 0 | loss_scale 1520 | train_wall 1665 | wall 28210
2022-07-12 15:57:29 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 9.982 | nll_loss 5.743 | mask_ins 1.556 | word_ins_ml 7.101 | word_reposition 1.325 | ppl 1011.53 | wps 37151.3 | wpb 2367.6 | bsz 32 | num_updates 19048 | best_loss 9.982
2022-07-12 15:57:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 17 @ 19048 updates, score 9.982) (writing took 8.036127336323261 seconds)
2022-07-12 15:58:55 | INFO | train_inner | epoch 018:     52 / 1122 loss=5.35, nll_loss=2.174, mask_ins=0.785, word_ins_ml=3.809, word_reposition=0.756, ppl=40.79, wps=11066.4, ups=0.54, wpb=20306.8, bsz=253.8, num_updates=19100, lr=0.000255822, gnorm=2.151, clip=0, loss_scale=2048, train_wall=148, wall=28323
2022-07-12 16:01:24 | INFO | train_inner | epoch 018:    152 / 1122 loss=5.302, nll_loss=2.148, mask_ins=0.77, word_ins_ml=3.785, word_reposition=0.747, ppl=39.46, wps=13776.5, ups=0.67, wpb=20561.5, bsz=256, num_updates=19200, lr=0.000255155, gnorm=1.915, clip=0, loss_scale=2048, train_wall=148, wall=28472
2022-07-12 16:03:53 | INFO | train_inner | epoch 018:    252 / 1122 loss=5.285, nll_loss=2.143, mask_ins=0.764, word_ins_ml=3.78, word_reposition=0.74, ppl=38.98, wps=13814.5, ups=0.67, wpb=20583.9, bsz=256, num_updates=19300, lr=0.000254493, gnorm=1.832, clip=0, loss_scale=3379, train_wall=148, wall=28621
2022-07-12 16:04:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-07-12 16:06:24 | INFO | train_inner | epoch 018:    353 / 1122 loss=5.332, nll_loss=2.177, mask_ins=0.772, word_ins_ml=3.81, word_reposition=0.75, ppl=40.28, wps=13579.7, ups=0.66, wpb=20488.5, bsz=256, num_updates=19400, lr=0.000253837, gnorm=1.85, clip=0, loss_scale=2372, train_wall=150, wall=28772
2022-07-12 16:08:29 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 16:08:54 | INFO | train_inner | epoch 018:    454 / 1122 loss=5.296, nll_loss=2.14, mask_ins=0.77, word_ins_ml=3.777, word_reposition=0.749, ppl=39.29, wps=13668.7, ups=0.66, wpb=20560.2, bsz=256, num_updates=19500, lr=0.000253185, gnorm=1.866, clip=0, loss_scale=1866, train_wall=150, wall=28922
2022-07-12 16:11:23 | INFO | train_inner | epoch 018:    554 / 1122 loss=5.318, nll_loss=2.182, mask_ins=0.765, word_ins_ml=3.815, word_reposition=0.738, ppl=39.89, wps=13731.1, ups=0.67, wpb=20435.5, bsz=256, num_updates=19600, lr=0.000252538, gnorm=1.946, clip=0, loss_scale=1024, train_wall=148, wall=29071
2022-07-12 16:13:52 | INFO | train_inner | epoch 018:    654 / 1122 loss=5.309, nll_loss=2.172, mask_ins=0.769, word_ins_ml=3.805, word_reposition=0.736, ppl=39.65, wps=13741.4, ups=0.67, wpb=20442.9, bsz=256, num_updates=19700, lr=0.000251896, gnorm=1.966, clip=0, loss_scale=1024, train_wall=148, wall=29220
2022-07-12 16:16:21 | INFO | train_inner | epoch 018:    754 / 1122 loss=5.294, nll_loss=2.141, mask_ins=0.773, word_ins_ml=3.778, word_reposition=0.744, ppl=39.24, wps=13866.4, ups=0.67, wpb=20644.1, bsz=256, num_updates=19800, lr=0.000251259, gnorm=1.797, clip=0, loss_scale=1024, train_wall=148, wall=29369
2022-07-12 16:18:50 | INFO | train_inner | epoch 018:    854 / 1122 loss=5.298, nll_loss=2.144, mask_ins=0.765, word_ins_ml=3.78, word_reposition=0.752, ppl=39.33, wps=13827.5, ups=0.67, wpb=20686.8, bsz=256, num_updates=19900, lr=0.000250627, gnorm=1.79, clip=0, loss_scale=1024, train_wall=149, wall=29518
2022-07-12 16:21:19 | INFO | train_inner | epoch 018:    954 / 1122 loss=5.306, nll_loss=2.166, mask_ins=0.767, word_ins_ml=3.8, word_reposition=0.739, ppl=39.56, wps=13750.4, ups=0.67, wpb=20467.6, bsz=256, num_updates=20000, lr=0.00025, gnorm=1.881, clip=0, loss_scale=1085, train_wall=148, wall=29667
2022-07-12 16:23:48 | INFO | train_inner | epoch 018:   1054 / 1122 loss=5.305, nll_loss=2.156, mask_ins=0.771, word_ins_ml=3.79, word_reposition=0.744, ppl=39.54, wps=13754.4, ups=0.67, wpb=20519.8, bsz=256, num_updates=20100, lr=0.000249377, gnorm=1.788, clip=0, loss_scale=2048, train_wall=148, wall=29816
2022-07-12 16:25:29 | INFO | train | epoch 018 | loss 5.31 | nll_loss 2.16 | mask_ins 0.771 | word_ins_ml 3.795 | word_reposition 0.745 | ppl 39.67 | wps 13464.5 | ups 0.66 | wpb 20521.7 | bsz 255.8 | num_updates 20168 | lr 0.000248957 | gnorm 1.865 | clip 0 | loss_scale 1729 | train_wall 1663 | wall 29917
2022-07-12 16:25:56 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 9.884 | nll_loss 5.656 | mask_ins 1.531 | word_ins_ml 7.02 | word_reposition 1.333 | ppl 944.58 | wps 37353.7 | wpb 2367.6 | bsz 32 | num_updates 20168 | best_loss 9.884
2022-07-12 16:26:04 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 18 @ 20168 updates, score 9.884) (writing took 7.897537721320987 seconds)
2022-07-12 16:26:52 | INFO | train_inner | epoch 019:     32 / 1122 loss=5.299, nll_loss=2.138, mask_ins=0.775, word_ins_ml=3.775, word_reposition=0.75, ppl=39.38, wps=11092.6, ups=0.55, wpb=20314.8, bsz=253.8, num_updates=20200, lr=0.000248759, gnorm=1.906, clip=0, loss_scale=2048, train_wall=148, wall=30000
2022-07-12 16:29:21 | INFO | train_inner | epoch 019:    132 / 1122 loss=5.281, nll_loss=2.124, mask_ins=0.772, word_ins_ml=3.762, word_reposition=0.747, ppl=38.87, wps=13611.4, ups=0.67, wpb=20340.2, bsz=256, num_updates=20300, lr=0.000248146, gnorm=1.825, clip=0, loss_scale=2048, train_wall=149, wall=30149
2022-07-12 16:31:50 | INFO | train_inner | epoch 019:    232 / 1122 loss=5.306, nll_loss=2.151, mask_ins=0.771, word_ins_ml=3.786, word_reposition=0.749, ppl=39.56, wps=13781.2, ups=0.67, wpb=20537.6, bsz=256, num_updates=20400, lr=0.000247537, gnorm=1.794, clip=0, loss_scale=2048, train_wall=148, wall=30298
2022-07-12 16:34:21 | INFO | train_inner | epoch 019:    332 / 1122 loss=5.306, nll_loss=2.16, mask_ins=0.77, word_ins_ml=3.794, word_reposition=0.743, ppl=39.57, wps=13567.5, ups=0.66, wpb=20525.1, bsz=256, num_updates=20500, lr=0.000246932, gnorm=1.79, clip=0, loss_scale=2048, train_wall=150, wall=30449
2022-07-12 16:36:50 | INFO | train_inner | epoch 019:    432 / 1122 loss=5.276, nll_loss=2.133, mask_ins=0.772, word_ins_ml=3.77, word_reposition=0.734, ppl=38.74, wps=13669.1, ups=0.67, wpb=20384.4, bsz=256, num_updates=20600, lr=0.000246332, gnorm=1.823, clip=0, loss_scale=3973, train_wall=148, wall=30598
2022-07-12 16:39:20 | INFO | train_inner | epoch 019:    532 / 1122 loss=5.287, nll_loss=2.157, mask_ins=0.762, word_ins_ml=3.791, word_reposition=0.735, ppl=39.05, wps=13851.5, ups=0.67, wpb=20677.3, bsz=256, num_updates=20700, lr=0.000245737, gnorm=1.769, clip=0, loss_scale=4096, train_wall=148, wall=30748
2022-07-12 16:41:49 | INFO | train_inner | epoch 019:    632 / 1122 loss=5.255, nll_loss=2.12, mask_ins=0.761, word_ins_ml=3.757, word_reposition=0.738, ppl=38.19, wps=13787.4, ups=0.67, wpb=20618.1, bsz=256, num_updates=20800, lr=0.000245145, gnorm=1.815, clip=0, loss_scale=4096, train_wall=149, wall=30897
2022-07-12 16:44:18 | INFO | train_inner | epoch 019:    732 / 1122 loss=5.277, nll_loss=2.136, mask_ins=0.76, word_ins_ml=3.772, word_reposition=0.744, ppl=38.76, wps=13879.6, ups=0.67, wpb=20698.7, bsz=256, num_updates=20900, lr=0.000244558, gnorm=1.856, clip=0, loss_scale=4096, train_wall=148, wall=31046
2022-07-12 16:46:47 | INFO | train_inner | epoch 019:    832 / 1122 loss=5.27, nll_loss=2.136, mask_ins=0.759, word_ins_ml=3.772, word_reposition=0.739, ppl=38.57, wps=13808.4, ups=0.67, wpb=20546.3, bsz=256, num_updates=21000, lr=0.000243975, gnorm=1.856, clip=0, loss_scale=4096, train_wall=148, wall=31195
2022-07-12 16:49:16 | INFO | train_inner | epoch 019:    932 / 1122 loss=5.258, nll_loss=2.112, mask_ins=0.766, word_ins_ml=3.75, word_reposition=0.742, ppl=38.26, wps=13771.8, ups=0.67, wpb=20451.4, bsz=256, num_updates=21100, lr=0.000243396, gnorm=1.813, clip=0, loss_scale=7455, train_wall=148, wall=31344
2022-07-12 16:51:46 | INFO | train_inner | epoch 019:   1032 / 1122 loss=5.235, nll_loss=2.097, mask_ins=0.757, word_ins_ml=3.737, word_reposition=0.742, ppl=37.67, wps=13717.4, ups=0.67, wpb=20602.5, bsz=256, num_updates=21200, lr=0.000242821, gnorm=1.78, clip=0, loss_scale=8192, train_wall=149, wall=31494
2022-07-12 16:51:56 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2022-07-12 16:54:00 | INFO | train | epoch 019 | loss 5.276 | nll_loss 2.133 | mask_ins 0.765 | word_ins_ml 3.769 | word_reposition 0.742 | ppl 38.75 | wps 13449.4 | ups 0.66 | wpb 20520 | bsz 255.8 | num_updates 21289 | lr 0.000242313 | gnorm 1.822 | clip 0 | loss_scale 4165 | train_wall 1667 | wall 31628
2022-07-12 16:54:26 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 10.131 | nll_loss 5.779 | mask_ins 1.576 | word_ins_ml 7.141 | word_reposition 1.414 | ppl 1121.27 | wps 37329.4 | wpb 2367.6 | bsz 32 | num_updates 21289 | best_loss 9.884
2022-07-12 16:54:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 19 @ 21289 updates, score 10.131) (writing took 4.497038302011788 seconds)
2022-07-12 16:54:47 | INFO | train_inner | epoch 020:     11 / 1122 loss=5.289, nll_loss=2.141, mask_ins=0.767, word_ins_ml=3.775, word_reposition=0.747, ppl=39.11, wps=11289, ups=0.55, wpb=20448.9, bsz=253.8, num_updates=21300, lr=0.000242251, gnorm=1.94, clip=0, loss_scale=4339, train_wall=149, wall=31675
2022-07-12 16:57:17 | INFO | train_inner | epoch 020:    111 / 1122 loss=5.243, nll_loss=2.099, mask_ins=0.762, word_ins_ml=3.739, word_reposition=0.742, ppl=37.88, wps=13699.9, ups=0.67, wpb=20518.1, bsz=256, num_updates=21400, lr=0.000241684, gnorm=1.792, clip=0, loss_scale=4096, train_wall=149, wall=31825
2022-07-12 16:59:45 | INFO | train_inner | epoch 020:    211 / 1122 loss=5.226, nll_loss=2.098, mask_ins=0.75, word_ins_ml=3.738, word_reposition=0.738, ppl=37.43, wps=13823.3, ups=0.67, wpb=20528.1, bsz=256, num_updates=21500, lr=0.000241121, gnorm=1.776, clip=0, loss_scale=4096, train_wall=148, wall=31973
2022-07-12 17:02:15 | INFO | train_inner | epoch 020:    311 / 1122 loss=5.261, nll_loss=2.104, mask_ins=0.774, word_ins_ml=3.743, word_reposition=0.744, ppl=38.34, wps=13740, ups=0.67, wpb=20590.5, bsz=256, num_updates=21600, lr=0.000240563, gnorm=1.805, clip=0, loss_scale=4096, train_wall=149, wall=32123
2022-07-12 17:04:44 | INFO | train_inner | epoch 020:    411 / 1122 loss=5.218, nll_loss=2.089, mask_ins=0.752, word_ins_ml=3.729, word_reposition=0.736, ppl=37.22, wps=13803, ups=0.67, wpb=20583.9, bsz=256, num_updates=21700, lr=0.000240008, gnorm=1.76, clip=0, loss_scale=4096, train_wall=148, wall=32272
2022-07-12 17:07:13 | INFO | train_inner | epoch 020:    511 / 1122 loss=5.195, nll_loss=2.075, mask_ins=0.749, word_ins_ml=3.717, word_reposition=0.729, ppl=36.62, wps=13761.2, ups=0.67, wpb=20497.8, bsz=256, num_updates=21800, lr=0.000239457, gnorm=1.778, clip=0, loss_scale=7496, train_wall=148, wall=32421
2022-07-12 17:09:42 | INFO | train_inner | epoch 020:    611 / 1122 loss=5.23, nll_loss=2.096, mask_ins=0.761, word_ins_ml=3.735, word_reposition=0.734, ppl=37.53, wps=13854.6, ups=0.67, wpb=20618.5, bsz=256, num_updates=21900, lr=0.000238909, gnorm=1.74, clip=0, loss_scale=8192, train_wall=148, wall=32570
2022-07-12 17:12:11 | INFO | train_inner | epoch 020:    711 / 1122 loss=5.257, nll_loss=2.127, mask_ins=0.761, word_ins_ml=3.763, word_reposition=0.732, ppl=38.23, wps=13693, ups=0.67, wpb=20401.1, bsz=256, num_updates=22000, lr=0.000238366, gnorm=1.817, clip=0, loss_scale=8192, train_wall=148, wall=32719
2022-07-12 17:14:40 | INFO | train_inner | epoch 020:    811 / 1122 loss=5.193, nll_loss=2.08, mask_ins=0.75, word_ins_ml=3.721, word_reposition=0.722, ppl=36.59, wps=13744.1, ups=0.67, wpb=20484.1, bsz=256, num_updates=22100, lr=0.000237826, gnorm=1.733, clip=0, loss_scale=8192, train_wall=148, wall=32868
2022-07-12 17:17:10 | INFO | train_inner | epoch 020:    911 / 1122 loss=5.225, nll_loss=2.082, mask_ins=0.763, word_ins_ml=3.722, word_reposition=0.74, ppl=37.4, wps=13782.2, ups=0.67, wpb=20597.6, bsz=256, num_updates=22200, lr=0.000237289, gnorm=1.768, clip=0, loss_scale=8192, train_wall=149, wall=33018
2022-07-12 17:18:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8192.0
2022-07-12 17:19:40 | INFO | train_inner | epoch 020:   1012 / 1122 loss=5.226, nll_loss=2.098, mask_ins=0.752, word_ins_ml=3.736, word_reposition=0.738, ppl=37.42, wps=13627.1, ups=0.66, wpb=20539.4, bsz=256, num_updates=22300, lr=0.000236757, gnorm=1.766, clip=0, loss_scale=9246, train_wall=150, wall=33168
2022-07-12 17:22:10 | INFO | train_inner | epoch 020:   1112 / 1122 loss=5.228, nll_loss=2.096, mask_ins=0.758, word_ins_ml=3.734, word_reposition=0.736, ppl=37.47, wps=13724.1, ups=0.67, wpb=20490.5, bsz=256, num_updates=22400, lr=0.000236228, gnorm=1.707, clip=0, loss_scale=8192, train_wall=148, wall=33318
2022-07-12 17:22:24 | INFO | train | epoch 020 | loss 5.227 | nll_loss 2.095 | mask_ins 0.757 | word_ins_ml 3.734 | word_reposition 0.736 | ppl 37.46 | wps 13495.9 | ups 0.66 | wpb 20519.9 | bsz 255.8 | num_updates 22410 | lr 0.000236175 | gnorm 1.777 | clip 0 | loss_scale 6724 | train_wall 1664 | wall 33332
2022-07-12 17:22:51 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 9.924 | nll_loss 5.641 | mask_ins 1.516 | word_ins_ml 7.009 | word_reposition 1.399 | ppl 971.34 | wps 37008.9 | wpb 2367.6 | bsz 32 | num_updates 22410 | best_loss 9.884
2022-07-12 17:22:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 20 @ 22410 updates, score 9.924) (writing took 4.539731791242957 seconds)
2022-07-12 17:23:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4096.0
2022-07-12 17:25:11 | INFO | train_inner | epoch 021:     91 / 1122 loss=5.224, nll_loss=2.096, mask_ins=0.757, word_ins_ml=3.734, word_reposition=0.732, ppl=37.37, wps=11273.6, ups=0.55, wpb=20470.6, bsz=253.8, num_updates=22500, lr=0.000235702, gnorm=1.781, clip=0, loss_scale=4826, train_wall=149, wall=33499
2022-07-12 17:26:55 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-07-12 17:27:41 | INFO | train_inner | epoch 021:    192 / 1122 loss=5.22, nll_loss=2.096, mask_ins=0.76, word_ins_ml=3.735, word_reposition=0.725, ppl=37.27, wps=13614.4, ups=0.67, wpb=20466, bsz=256, num_updates=22600, lr=0.00023518, gnorm=1.816, clip=0, loss_scale=3447, train_wall=149, wall=33649
2022-07-12 17:30:12 | INFO | train_inner | epoch 021:    292 / 1122 loss=5.196, nll_loss=2.08, mask_ins=0.746, word_ins_ml=3.72, word_reposition=0.73, ppl=36.66, wps=13674, ups=0.66, wpb=20633.5, bsz=256, num_updates=22700, lr=0.000234662, gnorm=1.759, clip=0, loss_scale=2048, train_wall=150, wall=33800
2022-07-12 17:32:42 | INFO | train_inner | epoch 021:    392 / 1122 loss=5.168, nll_loss=2.046, mask_ins=0.749, word_ins_ml=3.69, word_reposition=0.729, ppl=35.96, wps=13709.2, ups=0.67, wpb=20517.7, bsz=256, num_updates=22800, lr=0.000234146, gnorm=1.713, clip=0, loss_scale=2048, train_wall=149, wall=33950
2022-07-12 17:35:11 | INFO | train_inner | epoch 021:    492 / 1122 loss=5.173, nll_loss=2.053, mask_ins=0.751, word_ins_ml=3.695, word_reposition=0.727, ppl=36.07, wps=13808.7, ups=0.67, wpb=20638.4, bsz=256, num_updates=22900, lr=0.000233635, gnorm=1.743, clip=0, loss_scale=2048, train_wall=149, wall=34099
2022-07-12 17:37:41 | INFO | train_inner | epoch 021:    592 / 1122 loss=5.15, nll_loss=2.028, mask_ins=0.753, word_ins_ml=3.674, word_reposition=0.723, ppl=35.49, wps=13736.2, ups=0.67, wpb=20503.2, bsz=256, num_updates=23000, lr=0.000233126, gnorm=1.704, clip=0, loss_scale=2048, train_wall=148, wall=34249
2022-07-12 17:40:10 | INFO | train_inner | epoch 021:    692 / 1122 loss=5.21, nll_loss=2.098, mask_ins=0.749, word_ins_ml=3.736, word_reposition=0.725, ppl=37.01, wps=13715, ups=0.67, wpb=20432.8, bsz=256, num_updates=23100, lr=0.000232621, gnorm=1.712, clip=0, loss_scale=2458, train_wall=148, wall=34398
2022-07-12 17:42:39 | INFO | train_inner | epoch 021:    792 / 1122 loss=5.183, nll_loss=2.058, mask_ins=0.749, word_ins_ml=3.7, word_reposition=0.735, ppl=36.33, wps=13784, ups=0.67, wpb=20552.8, bsz=256, num_updates=23200, lr=0.000232119, gnorm=1.744, clip=0, loss_scale=4096, train_wall=148, wall=34547
2022-07-12 17:44:09 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-07-12 17:45:09 | INFO | train_inner | epoch 021:    893 / 1122 loss=5.156, nll_loss=2.035, mask_ins=0.753, word_ins_ml=3.68, word_reposition=0.723, ppl=35.65, wps=13630.1, ups=0.67, wpb=20431, bsz=256, num_updates=23300, lr=0.000231621, gnorm=1.723, clip=0, loss_scale=3265, train_wall=149, wall=34697
2022-07-12 17:47:38 | INFO | train_inner | epoch 021:    993 / 1122 loss=5.204, nll_loss=2.077, mask_ins=0.755, word_ins_ml=3.716, word_reposition=0.733, ppl=36.86, wps=13785.6, ups=0.67, wpb=20567.1, bsz=256, num_updates=23400, lr=0.000231125, gnorm=1.792, clip=0, loss_scale=2048, train_wall=148, wall=34846
2022-07-12 17:50:07 | INFO | train_inner | epoch 021:   1093 / 1122 loss=5.21, nll_loss=2.102, mask_ins=0.746, word_ins_ml=3.738, word_reposition=0.726, ppl=37.01, wps=13785.1, ups=0.67, wpb=20496.2, bsz=256, num_updates=23500, lr=0.000230633, gnorm=1.785, clip=0, loss_scale=2048, train_wall=148, wall=34995
2022-07-12 17:50:50 | INFO | train | epoch 021 | loss 5.19 | nll_loss 2.07 | mask_ins 0.751 | word_ins_ml 3.711 | word_reposition 0.728 | ppl 36.51 | wps 13464.7 | ups 0.66 | wpb 20522.7 | bsz 255.8 | num_updates 23529 | lr 0.000230491 | gnorm 1.751 | clip 0 | loss_scale 2698 | train_wall 1665 | wall 35038
2022-07-12 17:51:17 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 9.832 | nll_loss 5.608 | mask_ins 1.555 | word_ins_ml 6.973 | word_reposition 1.305 | ppl 911.29 | wps 36953.4 | wpb 2367.6 | bsz 32 | num_updates 23529 | best_loss 9.832
2022-07-12 17:51:25 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 21 @ 23529 updates, score 9.832) (writing took 8.385152969509363 seconds)
2022-07-12 17:53:11 | INFO | train_inner | epoch 022:     71 / 1122 loss=5.192, nll_loss=2.082, mask_ins=0.742, word_ins_ml=3.721, word_reposition=0.729, ppl=36.56, wps=11049.8, ups=0.54, wpb=20341.5, bsz=253.8, num_updates=23600, lr=0.000230144, gnorm=1.812, clip=0, loss_scale=2048, train_wall=148, wall=35179
2022-07-12 17:55:40 | INFO | train_inner | epoch 022:    171 / 1122 loss=5.156, nll_loss=2.038, mask_ins=0.749, word_ins_ml=3.681, word_reposition=0.725, ppl=35.64, wps=13799.7, ups=0.67, wpb=20554.7, bsz=256, num_updates=23700, lr=0.000229658, gnorm=1.759, clip=0, loss_scale=2048, train_wall=148, wall=35328
2022-07-12 17:58:09 | INFO | train_inner | epoch 022:    271 / 1122 loss=5.127, nll_loss=2.011, mask_ins=0.743, word_ins_ml=3.657, word_reposition=0.726, ppl=34.94, wps=13834.2, ups=0.67, wpb=20622.8, bsz=256, num_updates=23800, lr=0.000229175, gnorm=1.892, clip=0, loss_scale=2642, train_wall=148, wall=35477
2022-07-12 17:58:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-07-12 18:00:40 | INFO | train_inner | epoch 022:    372 / 1122 loss=5.159, nll_loss=2.044, mask_ins=0.742, word_ins_ml=3.687, word_reposition=0.73, ppl=35.74, wps=13640.5, ups=0.66, wpb=20627.7, bsz=256, num_updates=23900, lr=0.000228695, gnorm=1.743, clip=0, loss_scale=2677, train_wall=150, wall=35628
2022-07-12 18:03:10 | INFO | train_inner | epoch 022:    472 / 1122 loss=5.168, nll_loss=2.051, mask_ins=0.748, word_ins_ml=3.693, word_reposition=0.727, ppl=35.95, wps=13763.8, ups=0.67, wpb=20631.7, bsz=256, num_updates=24000, lr=0.000228218, gnorm=1.891, clip=0, loss_scale=2048, train_wall=149, wall=35778
2022-07-12 18:04:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 18:05:40 | INFO | train_inner | epoch 022:    573 / 1122 loss=5.209, nll_loss=2.091, mask_ins=0.752, word_ins_ml=3.728, word_reposition=0.728, ppl=36.98, wps=13635.4, ups=0.66, wpb=20508.8, bsz=256, num_updates=24100, lr=0.000227744, gnorm=1.85, clip=0, loss_scale=1379, train_wall=150, wall=35928
2022-07-12 18:08:09 | INFO | train_inner | epoch 022:    673 / 1122 loss=5.19, nll_loss=2.076, mask_ins=0.751, word_ins_ml=3.715, word_reposition=0.724, ppl=36.5, wps=13836.7, ups=0.67, wpb=20604.8, bsz=256, num_updates=24200, lr=0.000227273, gnorm=1.778, clip=0, loss_scale=1024, train_wall=148, wall=36077
2022-07-12 18:10:38 | INFO | train_inner | epoch 022:    773 / 1122 loss=5.145, nll_loss=2.045, mask_ins=0.738, word_ins_ml=3.687, word_reposition=0.721, ppl=35.39, wps=13811.7, ups=0.67, wpb=20520.9, bsz=256, num_updates=24300, lr=0.000226805, gnorm=1.728, clip=0, loss_scale=1024, train_wall=148, wall=36226
2022-07-12 18:13:07 | INFO | train_inner | epoch 022:    873 / 1122 loss=5.154, nll_loss=2.047, mask_ins=0.744, word_ins_ml=3.689, word_reposition=0.721, ppl=35.6, wps=13698.9, ups=0.67, wpb=20407.3, bsz=256, num_updates=24400, lr=0.000226339, gnorm=1.893, clip=0, loss_scale=1024, train_wall=148, wall=36375
2022-07-12 18:15:36 | INFO | train_inner | epoch 022:    973 / 1122 loss=5.143, nll_loss=2.033, mask_ins=0.739, word_ins_ml=3.677, word_reposition=0.728, ppl=35.35, wps=13828.9, ups=0.67, wpb=20623.8, bsz=256, num_updates=24500, lr=0.000225877, gnorm=1.743, clip=0, loss_scale=1024, train_wall=148, wall=36524
2022-07-12 18:18:05 | INFO | train_inner | epoch 022:   1073 / 1122 loss=5.154, nll_loss=2.054, mask_ins=0.74, word_ins_ml=3.695, word_reposition=0.719, ppl=35.6, wps=13731.7, ups=0.67, wpb=20416.7, bsz=256, num_updates=24600, lr=0.000225417, gnorm=1.795, clip=0, loss_scale=1577, train_wall=148, wall=36673
2022-07-12 18:18:31 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 18:18:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-07-12 18:19:17 | INFO | train | epoch 022 | loss 5.165 | nll_loss 2.053 | mask_ins 0.745 | word_ins_ml 3.694 | word_reposition 0.726 | ppl 35.88 | wps 13439.4 | ups 0.65 | wpb 20523.2 | bsz 255.8 | num_updates 24647 | lr 0.000225202 | gnorm 1.839 | clip 0 | loss_scale 1649 | train_wall 1663 | wall 36745
2022-07-12 18:19:44 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 9.862 | nll_loss 5.655 | mask_ins 1.506 | word_ins_ml 7.024 | word_reposition 1.332 | ppl 930.87 | wps 37249.6 | wpb 2367.6 | bsz 32 | num_updates 24647 | best_loss 9.832
2022-07-12 18:19:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 22 @ 24647 updates, score 9.862) (writing took 4.236062249168754 seconds)
2022-07-12 18:21:07 | INFO | train_inner | epoch 023:     53 / 1122 loss=5.21, nll_loss=2.086, mask_ins=0.755, word_ins_ml=3.723, word_reposition=0.732, ppl=37.01, wps=11104.3, ups=0.55, wpb=20278.2, bsz=253.8, num_updates=24700, lr=0.000224961, gnorm=2.167, clip=0, loss_scale=798, train_wall=151, wall=36855
2022-07-12 18:23:36 | INFO | train_inner | epoch 023:    153 / 1122 loss=5.061, nll_loss=1.966, mask_ins=0.724, word_ins_ml=3.617, word_reposition=0.721, ppl=33.39, wps=13900.5, ups=0.67, wpb=20670.3, bsz=256, num_updates=24800, lr=0.000224507, gnorm=1.719, clip=0, loss_scale=512, train_wall=148, wall=37004
2022-07-12 18:26:07 | INFO | train_inner | epoch 023:    253 / 1122 loss=5.113, nll_loss=2.007, mask_ins=0.739, word_ins_ml=3.653, word_reposition=0.721, ppl=34.62, wps=13569.5, ups=0.66, wpb=20522.8, bsz=256, num_updates=24900, lr=0.000224055, gnorm=1.727, clip=0, loss_scale=512, train_wall=150, wall=37155
2022-07-12 18:28:37 | INFO | train_inner | epoch 023:    353 / 1122 loss=5.157, nll_loss=2.045, mask_ins=0.742, word_ins_ml=3.687, word_reposition=0.728, ppl=35.67, wps=13723.4, ups=0.67, wpb=20542.8, bsz=256, num_updates=25000, lr=0.000223607, gnorm=1.741, clip=0, loss_scale=512, train_wall=149, wall=37305
2022-07-12 18:31:06 | INFO | train_inner | epoch 023:    453 / 1122 loss=5.117, nll_loss=2.017, mask_ins=0.731, word_ins_ml=3.662, word_reposition=0.725, ppl=34.7, wps=13801.8, ups=0.67, wpb=20526, bsz=256, num_updates=25100, lr=0.000223161, gnorm=1.713, clip=0, loss_scale=512, train_wall=148, wall=37454
2022-07-12 18:33:35 | INFO | train_inner | epoch 023:    553 / 1122 loss=5.114, nll_loss=2.014, mask_ins=0.739, word_ins_ml=3.659, word_reposition=0.716, ppl=34.62, wps=13761.8, ups=0.67, wpb=20515.7, bsz=256, num_updates=25200, lr=0.000222718, gnorm=1.721, clip=0, loss_scale=855, train_wall=148, wall=37603
2022-07-12 18:36:04 | INFO | train_inner | epoch 023:    653 / 1122 loss=5.169, nll_loss=2.065, mask_ins=0.741, word_ins_ml=3.703, word_reposition=0.725, ppl=35.98, wps=13799, ups=0.67, wpb=20561.8, bsz=256, num_updates=25300, lr=0.000222277, gnorm=1.724, clip=0, loss_scale=1024, train_wall=148, wall=37752
2022-07-12 18:38:32 | INFO | train_inner | epoch 023:    753 / 1122 loss=5.095, nll_loss=1.999, mask_ins=0.727, word_ins_ml=3.645, word_reposition=0.723, ppl=34.18, wps=13814.4, ups=0.67, wpb=20563, bsz=256, num_updates=25400, lr=0.000221839, gnorm=1.71, clip=0, loss_scale=1024, train_wall=148, wall=37900
2022-07-12 18:41:02 | INFO | train_inner | epoch 023:    853 / 1122 loss=5.115, nll_loss=2.012, mask_ins=0.739, word_ins_ml=3.657, word_reposition=0.719, ppl=34.66, wps=13709.8, ups=0.67, wpb=20509.9, bsz=256, num_updates=25500, lr=0.000221404, gnorm=1.744, clip=0, loss_scale=1024, train_wall=149, wall=38050
2022-07-12 18:43:31 | INFO | train_inner | epoch 023:    953 / 1122 loss=5.135, nll_loss=2.038, mask_ins=0.737, word_ins_ml=3.679, word_reposition=0.719, ppl=35.14, wps=13822.6, ups=0.67, wpb=20615.4, bsz=256, num_updates=25600, lr=0.000220971, gnorm=1.711, clip=0, loss_scale=1024, train_wall=148, wall=38199
2022-07-12 18:46:00 | INFO | train_inner | epoch 023:   1053 / 1122 loss=5.134, nll_loss=2.033, mask_ins=0.736, word_ins_ml=3.675, word_reposition=0.723, ppl=35.11, wps=13737, ups=0.67, wpb=20427.9, bsz=256, num_updates=25700, lr=0.000220541, gnorm=1.742, clip=0, loss_scale=1587, train_wall=148, wall=38348
2022-07-12 18:47:42 | INFO | train | epoch 023 | loss 5.125 | nll_loss 2.024 | mask_ins 0.736 | word_ins_ml 3.668 | word_reposition 0.722 | ppl 34.91 | wps 13502.2 | ups 0.66 | wpb 20520.9 | bsz 255.8 | num_updates 25769 | lr 0.000220245 | gnorm 1.736 | clip 0 | loss_scale 915 | train_wall 1665 | wall 38450
2022-07-12 18:48:09 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 9.793 | nll_loss 5.598 | mask_ins 1.544 | word_ins_ml 6.962 | word_reposition 1.288 | ppl 887.4 | wps 37291.5 | wpb 2367.6 | bsz 32 | num_updates 25769 | best_loss 9.793
2022-07-12 18:48:17 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 23 @ 25769 updates, score 9.793) (writing took 8.23786057997495 seconds)
2022-07-12 18:49:03 | INFO | train_inner | epoch 024:     31 / 1122 loss=5.126, nll_loss=2.03, mask_ins=0.737, word_ins_ml=3.673, word_reposition=0.716, ppl=34.92, wps=11039.1, ups=0.55, wpb=20241.5, bsz=253.8, num_updates=25800, lr=0.000220113, gnorm=1.834, clip=0, loss_scale=2048, train_wall=148, wall=38531
2022-07-12 18:51:33 | INFO | train_inner | epoch 024:    131 / 1122 loss=5.092, nll_loss=2.009, mask_ins=0.728, word_ins_ml=3.654, word_reposition=0.71, ppl=34.1, wps=13721.6, ups=0.67, wpb=20497.4, bsz=256, num_updates=25900, lr=0.000219687, gnorm=1.934, clip=0, loss_scale=2048, train_wall=149, wall=38681
2022-07-12 18:54:01 | INFO | train_inner | epoch 024:    231 / 1122 loss=5.078, nll_loss=1.983, mask_ins=0.73, word_ins_ml=3.631, word_reposition=0.717, ppl=33.79, wps=13783, ups=0.67, wpb=20487.2, bsz=256, num_updates=26000, lr=0.000219265, gnorm=1.818, clip=0, loss_scale=2048, train_wall=148, wall=38829
2022-07-12 18:56:30 | INFO | train_inner | epoch 024:    331 / 1122 loss=5.103, nll_loss=2.002, mask_ins=0.734, word_ins_ml=3.648, word_reposition=0.721, ppl=34.36, wps=13776.2, ups=0.67, wpb=20504.6, bsz=256, num_updates=26100, lr=0.000218844, gnorm=1.804, clip=0, loss_scale=2048, train_wall=148, wall=38978
2022-07-12 18:59:00 | INFO | train_inner | epoch 024:    431 / 1122 loss=5.153, nll_loss=2.045, mask_ins=0.746, word_ins_ml=3.685, word_reposition=0.722, ppl=35.59, wps=13757, ups=0.67, wpb=20576.4, bsz=256, num_updates=26200, lr=0.000218426, gnorm=1.83, clip=0, loss_scale=2929, train_wall=149, wall=39128
2022-07-12 18:59:45 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-07-12 19:01:31 | INFO | train_inner | epoch 024:    532 / 1122 loss=5.096, nll_loss=2.005, mask_ins=0.73, word_ins_ml=3.65, word_reposition=0.716, ppl=34.21, wps=13597.2, ups=0.66, wpb=20547.3, bsz=256, num_updates=26300, lr=0.00021801, gnorm=1.79, clip=0, loss_scale=2636, train_wall=150, wall=39279
2022-07-12 19:04:00 | INFO | train_inner | epoch 024:    632 / 1122 loss=5.109, nll_loss=2.016, mask_ins=0.739, word_ins_ml=3.659, word_reposition=0.712, ppl=34.51, wps=13708.3, ups=0.67, wpb=20496.4, bsz=256, num_updates=26400, lr=0.000217597, gnorm=1.794, clip=0, loss_scale=2048, train_wall=149, wall=39428
2022-07-12 19:06:29 | INFO | train_inner | epoch 024:    732 / 1122 loss=5.119, nll_loss=2.027, mask_ins=0.731, word_ins_ml=3.669, word_reposition=0.719, ppl=34.76, wps=13849.2, ups=0.67, wpb=20585.7, bsz=256, num_updates=26500, lr=0.000217186, gnorm=1.722, clip=0, loss_scale=2048, train_wall=148, wall=39577
2022-07-12 19:07:06 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 19:08:59 | INFO | train_inner | epoch 024:    833 / 1122 loss=5.092, nll_loss=2, mask_ins=0.733, word_ins_ml=3.645, word_reposition=0.714, ppl=34.11, wps=13673, ups=0.67, wpb=20559.3, bsz=256, num_updates=26600, lr=0.000216777, gnorm=1.863, clip=0, loss_scale=1267, train_wall=150, wall=39727
2022-07-12 19:11:29 | INFO | train_inner | epoch 024:    933 / 1122 loss=5.108, nll_loss=2.004, mask_ins=0.742, word_ins_ml=3.648, word_reposition=0.718, ppl=34.49, wps=13770.9, ups=0.67, wpb=20582.2, bsz=256, num_updates=26700, lr=0.000216371, gnorm=1.801, clip=0, loss_scale=1024, train_wall=149, wall=39877
2022-07-12 19:13:58 | INFO | train_inner | epoch 024:   1033 / 1122 loss=5.143, nll_loss=2.027, mask_ins=0.751, word_ins_ml=3.669, word_reposition=0.723, ppl=35.34, wps=13797.5, ups=0.67, wpb=20515.8, bsz=256, num_updates=26800, lr=0.000215967, gnorm=1.797, clip=0, loss_scale=1024, train_wall=148, wall=40026
2022-07-12 19:16:10 | INFO | train | epoch 024 | loss 5.11 | nll_loss 2.012 | mask_ins 0.736 | word_ins_ml 3.656 | word_reposition 0.718 | ppl 34.54 | wps 13458.9 | ups 0.66 | wpb 20521.7 | bsz 255.8 | num_updates 26889 | lr 0.000215609 | gnorm 1.809 | clip 0 | loss_scale 1845 | train_wall 1663 | wall 40158
2022-07-12 19:16:36 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 9.771 | nll_loss 5.531 | mask_ins 1.528 | word_ins_ml 6.894 | word_reposition 1.349 | ppl 873.71 | wps 37340.4 | wpb 2367.6 | bsz 32 | num_updates 26889 | best_loss 9.771
2022-07-12 19:16:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 24 @ 26889 updates, score 9.771) (writing took 8.088159983977675 seconds)
2022-07-12 19:17:01 | INFO | train_inner | epoch 025:     11 / 1122 loss=5.122, nll_loss=2.02, mask_ins=0.735, word_ins_ml=3.662, word_reposition=0.724, ppl=34.83, wps=11143, ups=0.54, wpb=20459.6, bsz=253.8, num_updates=26900, lr=0.000215565, gnorm=1.75, clip=0, loss_scale=1024, train_wall=148, wall=40209
2022-07-12 19:19:30 | INFO | train_inner | epoch 025:    111 / 1122 loss=5.104, nll_loss=2.004, mask_ins=0.735, word_ins_ml=3.649, word_reposition=0.721, ppl=34.39, wps=13830.7, ups=0.67, wpb=20600.8, bsz=256, num_updates=27000, lr=0.000215166, gnorm=1.716, clip=0, loss_scale=1024, train_wall=148, wall=40358
2022-07-12 19:22:01 | INFO | train_inner | epoch 025:    211 / 1122 loss=5.053, nll_loss=1.969, mask_ins=0.726, word_ins_ml=3.618, word_reposition=0.709, ppl=33.2, wps=13617.9, ups=0.66, wpb=20535.5, bsz=256, num_updates=27100, lr=0.000214768, gnorm=1.707, clip=0, loss_scale=1690, train_wall=150, wall=40509
2022-07-12 19:24:30 | INFO | train_inner | epoch 025:    311 / 1122 loss=5.045, nll_loss=1.962, mask_ins=0.726, word_ins_ml=3.611, word_reposition=0.708, ppl=33.02, wps=13787.3, ups=0.67, wpb=20596.7, bsz=256, num_updates=27200, lr=0.000214373, gnorm=1.741, clip=0, loss_scale=2048, train_wall=149, wall=40658
2022-07-12 19:26:59 | INFO | train_inner | epoch 025:    411 / 1122 loss=5.099, nll_loss=2.003, mask_ins=0.728, word_ins_ml=3.647, word_reposition=0.723, ppl=34.27, wps=13820.5, ups=0.67, wpb=20622.4, bsz=256, num_updates=27300, lr=0.00021398, gnorm=1.693, clip=0, loss_scale=2048, train_wall=148, wall=40808
2022-07-12 19:29:28 | INFO | train_inner | epoch 025:    511 / 1122 loss=5.074, nll_loss=1.974, mask_ins=0.733, word_ins_ml=3.621, word_reposition=0.72, ppl=33.69, wps=13824.5, ups=0.67, wpb=20486.9, bsz=256, num_updates=27400, lr=0.000213589, gnorm=1.743, clip=0, loss_scale=2048, train_wall=147, wall=40956
2022-07-12 19:31:57 | INFO | train_inner | epoch 025:    611 / 1122 loss=5.065, nll_loss=1.974, mask_ins=0.732, word_ins_ml=3.622, word_reposition=0.711, ppl=33.47, wps=13669.2, ups=0.67, wpb=20422.5, bsz=256, num_updates=27500, lr=0.000213201, gnorm=1.726, clip=0, loss_scale=2048, train_wall=149, wall=41105
2022-07-12 19:34:26 | INFO | train_inner | epoch 025:    711 / 1122 loss=5.061, nll_loss=1.972, mask_ins=0.729, word_ins_ml=3.62, word_reposition=0.712, ppl=33.37, wps=13749.4, ups=0.67, wpb=20501.8, bsz=256, num_updates=27600, lr=0.000212814, gnorm=1.643, clip=0, loss_scale=3133, train_wall=148, wall=41254
2022-07-12 19:36:55 | INFO | train_inner | epoch 025:    811 / 1122 loss=5.059, nll_loss=1.961, mask_ins=0.73, word_ins_ml=3.61, word_reposition=0.72, ppl=33.34, wps=13921.1, ups=0.67, wpb=20740.7, bsz=256, num_updates=27700, lr=0.00021243, gnorm=1.688, clip=0, loss_scale=4096, train_wall=148, wall=41403
2022-07-12 19:39:24 | INFO | train_inner | epoch 025:    911 / 1122 loss=5.077, nll_loss=1.982, mask_ins=0.734, word_ins_ml=3.629, word_reposition=0.715, ppl=33.75, wps=13720.5, ups=0.67, wpb=20421.5, bsz=256, num_updates=27800, lr=0.000212047, gnorm=1.745, clip=0, loss_scale=4096, train_wall=148, wall=41552
2022-07-12 19:41:53 | INFO | train_inner | epoch 025:   1011 / 1122 loss=5.09, nll_loss=1.994, mask_ins=0.734, word_ins_ml=3.639, word_reposition=0.716, ppl=34.06, wps=13726.9, ups=0.67, wpb=20417.1, bsz=256, num_updates=27900, lr=0.000211667, gnorm=1.762, clip=0, loss_scale=4096, train_wall=148, wall=41701
2022-07-12 19:43:10 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-07-12 19:44:24 | INFO | train_inner | epoch 025:   1112 / 1122 loss=5.094, nll_loss=2.008, mask_ins=0.727, word_ins_ml=3.651, word_reposition=0.716, ppl=34.16, wps=13575.5, ups=0.66, wpb=20467.5, bsz=256, num_updates=28000, lr=0.000211289, gnorm=1.791, clip=0, loss_scale=3082, train_wall=150, wall=41852
2022-07-12 19:44:38 | INFO | train | epoch 025 | loss 5.076 | nll_loss 1.984 | mask_ins 0.73 | word_ins_ml 3.63 | word_reposition 0.715 | ppl 33.72 | wps 13466.4 | ups 0.66 | wpb 20520.9 | bsz 255.8 | num_updates 28010 | lr 0.000211251 | gnorm 1.73 | clip 0 | loss_scale 2652 | train_wall 1664 | wall 41866
2022-07-12 19:45:05 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 9.897 | nll_loss 5.546 | mask_ins 1.549 | word_ins_ml 6.913 | word_reposition 1.434 | ppl 953.23 | wps 37152.7 | wpb 2367.6 | bsz 32 | num_updates 28010 | best_loss 9.771
2022-07-12 19:45:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 25 @ 28010 updates, score 9.897) (writing took 4.7468974851071835 seconds)
2022-07-12 19:46:37 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 19:47:26 | INFO | train_inner | epoch 026:     91 / 1122 loss=5.092, nll_loss=2.005, mask_ins=0.731, word_ins_ml=3.649, word_reposition=0.713, ppl=34.12, wps=11203.1, ups=0.55, wpb=20425.9, bsz=253.8, num_updates=28100, lr=0.000210912, gnorm=2.033, clip=0, loss_scale=1703, train_wall=150, wall=42034
2022-07-12 19:49:54 | INFO | train_inner | epoch 026:    191 / 1122 loss=5.053, nll_loss=1.975, mask_ins=0.723, word_ins_ml=3.622, word_reposition=0.707, ppl=33.19, wps=13814.3, ups=0.67, wpb=20510.3, bsz=256, num_updates=28200, lr=0.000210538, gnorm=1.719, clip=0, loss_scale=1024, train_wall=148, wall=42182
2022-07-12 19:52:23 | INFO | train_inner | epoch 026:    291 / 1122 loss=5.031, nll_loss=1.943, mask_ins=0.728, word_ins_ml=3.594, word_reposition=0.71, ppl=32.7, wps=13739.9, ups=0.67, wpb=20418.4, bsz=256, num_updates=28300, lr=0.000210166, gnorm=1.836, clip=0, loss_scale=1024, train_wall=148, wall=42331
2022-07-12 19:54:36 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-07-12 19:54:54 | INFO | train_inner | epoch 026:    392 / 1122 loss=5.073, nll_loss=1.992, mask_ins=0.721, word_ins_ml=3.637, word_reposition=0.715, ppl=33.67, wps=13657.9, ups=0.66, wpb=20623.8, bsz=256, num_updates=28400, lr=0.000209795, gnorm=1.744, clip=0, loss_scale=958, train_wall=150, wall=42482
2022-07-12 19:57:23 | INFO | train_inner | epoch 026:    492 / 1122 loss=5.079, nll_loss=1.983, mask_ins=0.731, word_ins_ml=3.628, word_reposition=0.72, ppl=33.8, wps=13749.8, ups=0.67, wpb=20534.5, bsz=256, num_updates=28500, lr=0.000209427, gnorm=1.857, clip=0, loss_scale=512, train_wall=148, wall=42631
2022-07-12 19:59:52 | INFO | train_inner | epoch 026:    592 / 1122 loss=5.044, nll_loss=1.977, mask_ins=0.718, word_ins_ml=3.623, word_reposition=0.703, ppl=32.99, wps=13703.7, ups=0.67, wpb=20434.2, bsz=256, num_updates=28600, lr=0.000209061, gnorm=1.753, clip=0, loss_scale=512, train_wall=148, wall=42780
2022-07-12 20:02:21 | INFO | train_inner | epoch 026:    692 / 1122 loss=5.058, nll_loss=1.963, mask_ins=0.73, word_ins_ml=3.61, word_reposition=0.717, ppl=33.31, wps=13815.1, ups=0.67, wpb=20589.7, bsz=256, num_updates=28700, lr=0.000208696, gnorm=2.435, clip=1, loss_scale=512, train_wall=148, wall=42929
2022-07-12 20:04:50 | INFO | train_inner | epoch 026:    792 / 1122 loss=5.024, nll_loss=1.945, mask_ins=0.721, word_ins_ml=3.595, word_reposition=0.708, ppl=32.53, wps=13831.8, ups=0.67, wpb=20574.5, bsz=256, num_updates=28800, lr=0.000208333, gnorm=1.71, clip=0, loss_scale=512, train_wall=148, wall=43078
2022-07-12 20:07:19 | INFO | train_inner | epoch 026:    892 / 1122 loss=5.103, nll_loss=2.005, mask_ins=0.735, word_ins_ml=3.648, word_reposition=0.72, ppl=34.36, wps=13830.5, ups=0.67, wpb=20627.2, bsz=256, num_updates=28900, lr=0.000207973, gnorm=2.05, clip=1, loss_scale=517, train_wall=148, wall=43227
2022-07-12 20:09:48 | INFO | train_inner | epoch 026:    992 / 1122 loss=5.08, nll_loss=1.991, mask_ins=0.731, word_ins_ml=3.635, word_reposition=0.713, ppl=33.83, wps=13824.9, ups=0.67, wpb=20546.1, bsz=256, num_updates=29000, lr=0.000207614, gnorm=1.819, clip=0, loss_scale=1024, train_wall=148, wall=43376
2022-07-12 20:12:17 | INFO | train_inner | epoch 026:   1092 / 1122 loss=5.082, nll_loss=1.994, mask_ins=0.731, word_ins_ml=3.638, word_reposition=0.713, ppl=33.88, wps=13815.8, ups=0.67, wpb=20558.4, bsz=256, num_updates=29100, lr=0.000207257, gnorm=1.795, clip=0, loss_scale=1024, train_wall=148, wall=43525
2022-07-12 20:13:01 | INFO | train | epoch 026 | loss 5.065 | nll_loss 1.979 | mask_ins 0.727 | word_ins_ml 3.625 | word_reposition 0.713 | ppl 33.48 | wps 13498.6 | ups 0.66 | wpb 20522 | bsz 255.8 | num_updates 29130 | lr 0.00020715 | gnorm 1.881 | clip 0.2 | loss_scale 842 | train_wall 1662 | wall 43569
2022-07-12 20:13:28 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 9.868 | nll_loss 5.581 | mask_ins 1.581 | word_ins_ml 6.949 | word_reposition 1.339 | ppl 934.67 | wps 37118.7 | wpb 2367.6 | bsz 32 | num_updates 29130 | best_loss 9.771
2022-07-12 20:13:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 26 @ 29130 updates, score 9.868) (writing took 4.259674818255007 seconds)
2022-07-12 20:15:17 | INFO | train_inner | epoch 027:     70 / 1122 loss=5.061, nll_loss=1.973, mask_ins=0.729, word_ins_ml=3.62, word_reposition=0.712, ppl=33.37, wps=11305.5, ups=0.56, wpb=20348.1, bsz=253.8, num_updates=29200, lr=0.000206901, gnorm=1.791, clip=0, loss_scale=1024, train_wall=148, wall=43705
2022-07-12 20:16:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-07-12 20:17:50 | INFO | train_inner | epoch 027:    171 / 1122 loss=5.028, nll_loss=1.942, mask_ins=0.721, word_ins_ml=3.592, word_reposition=0.715, ppl=32.62, wps=13535, ups=0.65, wpb=20685.4, bsz=256, num_updates=29300, lr=0.000206548, gnorm=1.733, clip=0, loss_scale=745, train_wall=152, wall=43858
2022-07-12 20:20:19 | INFO | train_inner | epoch 027:    271 / 1122 loss=5.061, nll_loss=1.978, mask_ins=0.725, word_ins_ml=3.624, word_reposition=0.712, ppl=33.37, wps=13862.4, ups=0.67, wpb=20652.7, bsz=256, num_updates=29400, lr=0.000206197, gnorm=1.777, clip=0, loss_scale=512, train_wall=148, wall=44007
2022-07-12 20:22:48 | INFO | train_inner | epoch 027:    371 / 1122 loss=5.029, nll_loss=1.948, mask_ins=0.727, word_ins_ml=3.598, word_reposition=0.704, ppl=32.66, wps=13593.9, ups=0.67, wpb=20299, bsz=256, num_updates=29500, lr=0.000205847, gnorm=1.838, clip=0, loss_scale=512, train_wall=148, wall=44156
2022-07-12 20:25:17 | INFO | train_inner | epoch 027:    471 / 1122 loss=5.049, nll_loss=1.969, mask_ins=0.729, word_ins_ml=3.616, word_reposition=0.705, ppl=33.11, wps=13701, ups=0.67, wpb=20467, bsz=256, num_updates=29600, lr=0.000205499, gnorm=1.715, clip=0, loss_scale=512, train_wall=149, wall=44305
2022-07-12 20:27:47 | INFO | train_inner | epoch 027:    571 / 1122 loss=5.055, nll_loss=1.971, mask_ins=0.726, word_ins_ml=3.618, word_reposition=0.712, ppl=33.24, wps=13733.1, ups=0.67, wpb=20546.8, bsz=256, num_updates=29700, lr=0.000205152, gnorm=1.881, clip=0, loss_scale=512, train_wall=149, wall=44455
2022-07-12 20:30:15 | INFO | train_inner | epoch 027:    671 / 1122 loss=5.021, nll_loss=1.948, mask_ins=0.72, word_ins_ml=3.597, word_reposition=0.704, ppl=32.46, wps=13836.1, ups=0.67, wpb=20557.9, bsz=256, num_updates=29800, lr=0.000204808, gnorm=1.698, clip=0, loss_scale=732, train_wall=148, wall=44603
2022-07-12 20:32:45 | INFO | train_inner | epoch 027:    771 / 1122 loss=5.063, nll_loss=1.98, mask_ins=0.725, word_ins_ml=3.625, word_reposition=0.714, ppl=33.44, wps=13749.7, ups=0.67, wpb=20540.3, bsz=256, num_updates=29900, lr=0.000204465, gnorm=1.749, clip=0, loss_scale=1024, train_wall=149, wall=44753
2022-07-12 20:35:03 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-07-12 20:35:15 | INFO | train_inner | epoch 027:    872 / 1122 loss=5.033, nll_loss=1.947, mask_ins=0.726, word_ins_ml=3.596, word_reposition=0.712, ppl=32.75, wps=13687.8, ups=0.67, wpb=20549, bsz=256, num_updates=30000, lr=0.000204124, gnorm=1.89, clip=0, loss_scale=978, train_wall=149, wall=44903
2022-07-12 20:37:44 | INFO | train_inner | epoch 027:    972 / 1122 loss=5.032, nll_loss=1.96, mask_ins=0.715, word_ins_ml=3.608, word_reposition=0.709, ppl=32.72, wps=13839, ups=0.67, wpb=20592.6, bsz=256, num_updates=30100, lr=0.000203785, gnorm=1.765, clip=0, loss_scale=512, train_wall=148, wall=45052
2022-07-12 20:40:13 | INFO | train_inner | epoch 027:   1072 / 1122 loss=5.019, nll_loss=1.946, mask_ins=0.719, word_ins_ml=3.595, word_reposition=0.706, ppl=32.43, wps=13745.7, ups=0.67, wpb=20504.3, bsz=256, num_updates=30200, lr=0.000203447, gnorm=1.715, clip=0, loss_scale=512, train_wall=148, wall=45201
2022-07-12 20:41:26 | INFO | train | epoch 027 | loss 5.039 | nll_loss 1.96 | mask_ins 0.723 | word_ins_ml 3.607 | word_reposition 0.709 | ppl 32.88 | wps 13476.1 | ups 0.66 | wpb 20521.3 | bsz 255.8 | num_updates 30250 | lr 0.000203279 | gnorm 1.778 | clip 0 | loss_scale 672 | train_wall 1665 | wall 45274
2022-07-12 20:41:53 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 9.641 | nll_loss 5.561 | mask_ins 1.512 | word_ins_ml 6.923 | word_reposition 1.207 | ppl 798.67 | wps 37376.1 | wpb 2367.6 | bsz 32 | num_updates 30250 | best_loss 9.641
2022-07-12 20:42:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 27 @ 30250 updates, score 9.641) (writing took 7.941398178227246 seconds)
2022-07-12 20:43:16 | INFO | train_inner | epoch 028:     50 / 1122 loss=5.011, nll_loss=1.949, mask_ins=0.714, word_ins_ml=3.598, word_reposition=0.699, ppl=32.25, wps=11136.3, ups=0.55, wpb=20339.9, bsz=253.8, num_updates=30300, lr=0.000203111, gnorm=1.789, clip=0, loss_scale=512, train_wall=147, wall=45384
2022-07-12 20:45:44 | INFO | train_inner | epoch 028:    150 / 1122 loss=5.02, nll_loss=1.949, mask_ins=0.724, word_ins_ml=3.597, word_reposition=0.698, ppl=32.45, wps=13778.6, ups=0.67, wpb=20507.1, bsz=256, num_updates=30400, lr=0.000202777, gnorm=1.716, clip=0, loss_scale=512, train_wall=148, wall=45532
2022-07-12 20:48:14 | INFO | train_inner | epoch 028:    250 / 1122 loss=4.984, nll_loss=1.912, mask_ins=0.716, word_ins_ml=3.565, word_reposition=0.703, ppl=31.65, wps=13769.7, ups=0.67, wpb=20532.5, bsz=256, num_updates=30500, lr=0.000202444, gnorm=1.853, clip=0, loss_scale=512, train_wall=148, wall=45682
2022-07-12 20:50:43 | INFO | train_inner | epoch 028:    350 / 1122 loss=5.045, nll_loss=1.971, mask_ins=0.725, word_ins_ml=3.616, word_reposition=0.704, ppl=33.02, wps=13752.3, ups=0.67, wpb=20494, bsz=256, num_updates=30600, lr=0.000202113, gnorm=1.751, clip=0, loss_scale=1009, train_wall=148, wall=45831
2022-07-12 20:53:11 | INFO | train_inner | epoch 028:    450 / 1122 loss=5.009, nll_loss=1.935, mask_ins=0.715, word_ins_ml=3.585, word_reposition=0.709, ppl=32.2, wps=13901.4, ups=0.67, wpb=20691.6, bsz=256, num_updates=30700, lr=0.000201784, gnorm=1.737, clip=0, loss_scale=1024, train_wall=148, wall=45979
2022-07-12 20:55:41 | INFO | train_inner | epoch 028:    550 / 1122 loss=4.996, nll_loss=1.921, mask_ins=0.718, word_ins_ml=3.572, word_reposition=0.705, ppl=31.9, wps=13681.7, ups=0.67, wpb=20487.6, bsz=256, num_updates=30800, lr=0.000201456, gnorm=1.71, clip=0, loss_scale=1024, train_wall=149, wall=46129
2022-07-12 20:58:10 | INFO | train_inner | epoch 028:    650 / 1122 loss=5.017, nll_loss=1.947, mask_ins=0.717, word_ins_ml=3.595, word_reposition=0.705, ppl=32.37, wps=13753, ups=0.67, wpb=20475, bsz=256, num_updates=30900, lr=0.000201129, gnorm=1.654, clip=0, loss_scale=1024, train_wall=148, wall=46278
2022-07-12 21:00:40 | INFO | train_inner | epoch 028:    750 / 1122 loss=5.014, nll_loss=1.943, mask_ins=0.72, word_ins_ml=3.592, word_reposition=0.703, ppl=32.31, wps=13688.2, ups=0.67, wpb=20465.5, bsz=256, num_updates=31000, lr=0.000200805, gnorm=1.701, clip=0, loss_scale=1024, train_wall=149, wall=46428
2022-07-12 21:03:08 | INFO | train_inner | epoch 028:    850 / 1122 loss=4.974, nll_loss=1.9, mask_ins=0.715, word_ins_ml=3.554, word_reposition=0.705, ppl=31.42, wps=13763.7, ups=0.67, wpb=20481.8, bsz=256, num_updates=31100, lr=0.000200482, gnorm=1.698, clip=0, loss_scale=1894, train_wall=148, wall=46576
2022-07-12 21:05:37 | INFO | train_inner | epoch 028:    950 / 1122 loss=5.02, nll_loss=1.943, mask_ins=0.721, word_ins_ml=3.591, word_reposition=0.708, ppl=32.46, wps=13780.4, ups=0.67, wpb=20498.2, bsz=256, num_updates=31200, lr=0.00020016, gnorm=1.724, clip=0, loss_scale=2048, train_wall=148, wall=46725
2022-07-12 21:08:06 | INFO | train_inner | epoch 028:   1050 / 1122 loss=5.025, nll_loss=1.945, mask_ins=0.722, word_ins_ml=3.593, word_reposition=0.711, ppl=32.55, wps=13814.2, ups=0.67, wpb=20590.3, bsz=256, num_updates=31300, lr=0.00019984, gnorm=1.654, clip=0, loss_scale=2048, train_wall=148, wall=46874
2022-07-12 21:09:53 | INFO | train | epoch 028 | loss 5.011 | nll_loss 1.936 | mask_ins 0.719 | word_ins_ml 3.586 | word_reposition 0.705 | ppl 32.23 | wps 13489.9 | ups 0.66 | wpb 20520.7 | bsz 255.8 | num_updates 31372 | lr 0.000199611 | gnorm 1.722 | clip 0 | loss_scale 1234 | train_wall 1663 | wall 46981
2022-07-12 21:10:20 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 9.785 | nll_loss 5.549 | mask_ins 1.514 | word_ins_ml 6.91 | word_reposition 1.361 | ppl 882.13 | wps 37249.8 | wpb 2367.6 | bsz 32 | num_updates 31372 | best_loss 9.641
2022-07-12 21:10:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 28 @ 31372 updates, score 9.785) (writing took 4.552820548415184 seconds)
2022-07-12 21:11:06 | INFO | train_inner | epoch 029:     28 / 1122 loss=5.017, nll_loss=1.945, mask_ins=0.715, word_ins_ml=3.593, word_reposition=0.709, ppl=32.37, wps=11382, ups=0.56, wpb=20468.5, bsz=253.8, num_updates=31400, lr=0.000199522, gnorm=1.745, clip=0, loss_scale=2048, train_wall=148, wall=47054
2022-07-12 21:13:37 | INFO | train_inner | epoch 029:    128 / 1122 loss=5.008, nll_loss=1.938, mask_ins=0.716, word_ins_ml=3.587, word_reposition=0.705, ppl=32.19, wps=13625.2, ups=0.66, wpb=20579.7, bsz=256, num_updates=31500, lr=0.000199205, gnorm=1.742, clip=0, loss_scale=2048, train_wall=150, wall=47205
2022-07-12 21:16:06 | INFO | train_inner | epoch 029:    228 / 1122 loss=4.965, nll_loss=1.9, mask_ins=0.711, word_ins_ml=3.554, word_reposition=0.7, ppl=31.24, wps=13764.5, ups=0.67, wpb=20524.7, bsz=256, num_updates=31600, lr=0.000198889, gnorm=1.705, clip=0, loss_scale=3543, train_wall=148, wall=47354
2022-07-12 21:18:36 | INFO | train_inner | epoch 029:    328 / 1122 loss=4.997, nll_loss=1.929, mask_ins=0.713, word_ins_ml=3.579, word_reposition=0.705, ppl=31.94, wps=13702.4, ups=0.67, wpb=20527.6, bsz=256, num_updates=31700, lr=0.000198575, gnorm=1.675, clip=0, loss_scale=4096, train_wall=149, wall=47504
2022-07-12 21:21:05 | INFO | train_inner | epoch 029:    428 / 1122 loss=5.009, nll_loss=1.94, mask_ins=0.72, word_ins_ml=3.589, word_reposition=0.7, ppl=32.21, wps=13750.7, ups=0.67, wpb=20502.8, bsz=256, num_updates=31800, lr=0.000198263, gnorm=1.706, clip=0, loss_scale=4096, train_wall=148, wall=47653
2022-07-12 21:23:34 | INFO | train_inner | epoch 029:    528 / 1122 loss=4.971, nll_loss=1.912, mask_ins=0.707, word_ins_ml=3.564, word_reposition=0.7, ppl=31.36, wps=13752.2, ups=0.67, wpb=20505.4, bsz=256, num_updates=31900, lr=0.000197952, gnorm=1.754, clip=0, loss_scale=4096, train_wall=148, wall=47802
2022-07-12 21:24:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-07-12 21:26:04 | INFO | train_inner | epoch 029:    629 / 1122 loss=5.004, nll_loss=1.933, mask_ins=0.716, word_ins_ml=3.582, word_reposition=0.706, ppl=32.09, wps=13688.7, ups=0.67, wpb=20564, bsz=256, num_updates=32000, lr=0.000197642, gnorm=1.742, clip=0, loss_scale=2656, train_wall=149, wall=47952
2022-07-12 21:27:21 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 21:28:35 | INFO | train_inner | epoch 029:    730 / 1122 loss=4.975, nll_loss=1.911, mask_ins=0.71, word_ins_ml=3.562, word_reposition=0.703, ppl=31.46, wps=13609.5, ups=0.66, wpb=20516.2, bsz=256, num_updates=32100, lr=0.000197334, gnorm=1.758, clip=0, loss_scale=1531, train_wall=150, wall=48103
2022-07-12 21:31:04 | INFO | train_inner | epoch 029:    830 / 1122 loss=5.011, nll_loss=1.937, mask_ins=0.719, word_ins_ml=3.586, word_reposition=0.706, ppl=32.23, wps=13774.7, ups=0.67, wpb=20548.1, bsz=256, num_updates=32200, lr=0.000197028, gnorm=1.722, clip=0, loss_scale=1024, train_wall=148, wall=48252
2022-07-12 21:33:34 | INFO | train_inner | epoch 029:    930 / 1122 loss=4.994, nll_loss=1.926, mask_ins=0.717, word_ins_ml=3.576, word_reposition=0.701, ppl=31.86, wps=13810.3, ups=0.67, wpb=20613.2, bsz=256, num_updates=32300, lr=0.000196722, gnorm=1.69, clip=0, loss_scale=1024, train_wall=148, wall=48402
2022-07-12 21:36:03 | INFO | train_inner | epoch 029:   1030 / 1122 loss=5.053, nll_loss=1.975, mask_ins=0.725, word_ins_ml=3.619, word_reposition=0.71, ppl=33.21, wps=13723.6, ups=0.67, wpb=20475.5, bsz=256, num_updates=32400, lr=0.000196419, gnorm=1.714, clip=0, loss_scale=1024, train_wall=148, wall=48551
2022-07-12 21:38:19 | INFO | train | epoch 029 | loss 5.001 | nll_loss 1.933 | mask_ins 0.715 | word_ins_ml 3.582 | word_reposition 0.703 | ppl 32.01 | wps 13472.5 | ups 0.66 | wpb 20519.8 | bsz 255.8 | num_updates 32492 | lr 0.00019614 | gnorm 1.725 | clip 0 | loss_scale 2379 | train_wall 1665 | wall 48687
2022-07-12 21:38:46 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 9.787 | nll_loss 5.534 | mask_ins 1.56 | word_ins_ml 6.894 | word_reposition 1.332 | ppl 883.2 | wps 37197.2 | wpb 2367.6 | bsz 32 | num_updates 32492 | best_loss 9.641
2022-07-12 21:38:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 29 @ 32492 updates, score 9.787) (writing took 4.478246195241809 seconds)
2022-07-12 21:39:02 | INFO | train_inner | epoch 030:      8 / 1122 loss=5.008, nll_loss=1.941, mask_ins=0.718, word_ins_ml=3.589, word_reposition=0.7, ppl=32.17, wps=11339, ups=0.56, wpb=20343.4, bsz=253.8, num_updates=32500, lr=0.000196116, gnorm=1.768, clip=0, loss_scale=1024, train_wall=147, wall=48730
2022-07-12 21:41:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 21:41:33 | INFO | train_inner | epoch 030:    109 / 1122 loss=4.988, nll_loss=1.916, mask_ins=0.717, word_ins_ml=3.568, word_reposition=0.703, ppl=31.73, wps=13581.3, ups=0.66, wpb=20508.1, bsz=256, num_updates=32600, lr=0.000195815, gnorm=1.695, clip=0, loss_scale=1277, train_wall=150, wall=48881
2022-07-12 21:43:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 512.0
2022-07-12 21:44:04 | INFO | train_inner | epoch 030:    210 / 1122 loss=5.008, nll_loss=1.928, mask_ins=0.723, word_ins_ml=3.578, word_reposition=0.707, ppl=32.18, wps=13564.8, ups=0.66, wpb=20494.9, bsz=256, num_updates=32700, lr=0.000195515, gnorm=2.027, clip=0, loss_scale=857, train_wall=150, wall=49032
2022-07-12 21:46:33 | INFO | train_inner | epoch 030:    310 / 1122 loss=4.973, nll_loss=1.904, mask_ins=0.709, word_ins_ml=3.557, word_reposition=0.707, ppl=31.4, wps=13759.6, ups=0.67, wpb=20520.3, bsz=256, num_updates=32800, lr=0.000195217, gnorm=1.733, clip=0, loss_scale=512, train_wall=148, wall=49181
2022-07-12 21:49:02 | INFO | train_inner | epoch 030:    410 / 1122 loss=4.971, nll_loss=1.916, mask_ins=0.709, word_ins_ml=3.567, word_reposition=0.695, ppl=31.36, wps=13721, ups=0.67, wpb=20419.8, bsz=256, num_updates=32900, lr=0.00019492, gnorm=1.788, clip=0, loss_scale=512, train_wall=148, wall=49330
2022-07-12 21:51:32 | INFO | train_inner | epoch 030:    510 / 1122 loss=4.975, nll_loss=1.926, mask_ins=0.703, word_ins_ml=3.576, word_reposition=0.697, ppl=31.46, wps=13848.7, ups=0.67, wpb=20691.3, bsz=256, num_updates=33000, lr=0.000194625, gnorm=1.728, clip=0, loss_scale=512, train_wall=149, wall=49480
2022-07-12 21:54:00 | INFO | train_inner | epoch 030:    610 / 1122 loss=4.973, nll_loss=1.904, mask_ins=0.714, word_ins_ml=3.556, word_reposition=0.702, ppl=31.4, wps=13762, ups=0.67, wpb=20463.4, bsz=256, num_updates=33100, lr=0.000194331, gnorm=1.691, clip=0, loss_scale=512, train_wall=148, wall=49628
2022-07-12 21:56:29 | INFO | train_inner | epoch 030:    710 / 1122 loss=4.948, nll_loss=1.889, mask_ins=0.709, word_ins_ml=3.543, word_reposition=0.696, ppl=30.86, wps=13722, ups=0.67, wpb=20419, bsz=256, num_updates=33200, lr=0.000194038, gnorm=1.752, clip=0, loss_scale=620, train_wall=148, wall=49777
2022-07-12 21:58:59 | INFO | train_inner | epoch 030:    810 / 1122 loss=4.984, nll_loss=1.918, mask_ins=0.71, word_ins_ml=3.569, word_reposition=0.705, ppl=31.64, wps=13781.2, ups=0.67, wpb=20586.5, bsz=256, num_updates=33300, lr=0.000193746, gnorm=1.677, clip=0, loss_scale=1024, train_wall=149, wall=49927
2022-07-12 22:01:28 | INFO | train_inner | epoch 030:    910 / 1122 loss=4.939, nll_loss=1.879, mask_ins=0.714, word_ins_ml=3.533, word_reposition=0.691, ppl=30.67, wps=13830.2, ups=0.67, wpb=20596.2, bsz=256, num_updates=33400, lr=0.000193456, gnorm=1.695, clip=0, loss_scale=1024, train_wall=148, wall=50076
2022-07-12 22:03:57 | INFO | train_inner | epoch 030:   1010 / 1122 loss=4.986, nll_loss=1.917, mask_ins=0.717, word_ins_ml=3.567, word_reposition=0.702, ppl=31.69, wps=13828.9, ups=0.67, wpb=20619.7, bsz=256, num_updates=33500, lr=0.000193167, gnorm=1.767, clip=0, loss_scale=1024, train_wall=148, wall=50225
2022-07-12 22:06:26 | INFO | train_inner | epoch 030:   1110 / 1122 loss=4.97, nll_loss=1.91, mask_ins=0.707, word_ins_ml=3.561, word_reposition=0.701, ppl=31.33, wps=13789.3, ups=0.67, wpb=20567.5, bsz=256, num_updates=33600, lr=0.000192879, gnorm=1.72, clip=0, loss_scale=1024, train_wall=148, wall=50374
2022-07-12 22:06:43 | INFO | train | epoch 030 | loss 4.974 | nll_loss 1.91 | mask_ins 0.713 | word_ins_ml 3.561 | word_reposition 0.701 | ppl 31.43 | wps 13485.5 | ups 0.66 | wpb 20519 | bsz 255.8 | num_updates 33612 | lr 0.000192845 | gnorm 1.756 | clip 0 | loss_scale 813 | train_wall 1664 | wall 50391
2022-07-12 22:07:10 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 9.726 | nll_loss 5.545 | mask_ins 1.529 | word_ins_ml 6.909 | word_reposition 1.288 | ppl 846.69 | wps 37056.1 | wpb 2367.6 | bsz 32 | num_updates 33612 | best_loss 9.641
2022-07-12 22:07:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 30 @ 33612 updates, score 9.726) (writing took 4.684181758202612 seconds)
2022-07-12 22:09:27 | INFO | train_inner | epoch 031:     88 / 1122 loss=4.944, nll_loss=1.884, mask_ins=0.7, word_ins_ml=3.538, word_reposition=0.705, ppl=30.78, wps=11289.1, ups=0.55, wpb=20501.3, bsz=253.8, num_updates=33700, lr=0.000192593, gnorm=1.809, clip=0, loss_scale=1116, train_wall=149, wall=50555
2022-07-12 22:10:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 22:11:58 | INFO | train_inner | epoch 031:    189 / 1122 loss=4.968, nll_loss=1.898, mask_ins=0.715, word_ins_ml=3.55, word_reposition=0.703, ppl=31.29, wps=13691.2, ups=0.66, wpb=20620.9, bsz=256, num_updates=33800, lr=0.000192308, gnorm=1.771, clip=0, loss_scale=1460, train_wall=150, wall=50706
2022-07-12 22:14:27 | INFO | train_inner | epoch 031:    289 / 1122 loss=4.968, nll_loss=1.892, mask_ins=0.719, word_ins_ml=3.545, word_reposition=0.704, ppl=31.29, wps=13667.4, ups=0.67, wpb=20391.4, bsz=256, num_updates=33900, lr=0.000192024, gnorm=1.751, clip=0, loss_scale=1024, train_wall=148, wall=50855
2022-07-12 22:16:56 | INFO | train_inner | epoch 031:    389 / 1122 loss=4.968, nll_loss=1.906, mask_ins=0.713, word_ins_ml=3.557, word_reposition=0.699, ppl=31.31, wps=13801.1, ups=0.67, wpb=20594.2, bsz=256, num_updates=34000, lr=0.000191741, gnorm=1.705, clip=0, loss_scale=1024, train_wall=148, wall=51004
2022-07-12 22:19:25 | INFO | train_inner | epoch 031:    489 / 1122 loss=4.988, nll_loss=1.929, mask_ins=0.716, word_ins_ml=3.578, word_reposition=0.694, ppl=31.74, wps=13725, ups=0.67, wpb=20444.8, bsz=256, num_updates=34100, lr=0.00019146, gnorm=1.806, clip=0, loss_scale=1024, train_wall=148, wall=51153
2022-07-12 22:21:54 | INFO | train_inner | epoch 031:    589 / 1122 loss=4.928, nll_loss=1.872, mask_ins=0.71, word_ins_ml=3.527, word_reposition=0.691, ppl=30.45, wps=13845, ups=0.67, wpb=20616.5, bsz=256, num_updates=34200, lr=0.00019118, gnorm=1.732, clip=0, loss_scale=1024, train_wall=148, wall=51302
2022-07-12 22:24:24 | INFO | train_inner | epoch 031:    689 / 1122 loss=4.961, nll_loss=1.904, mask_ins=0.706, word_ins_ml=3.555, word_reposition=0.7, ppl=31.15, wps=13731.2, ups=0.67, wpb=20557.7, bsz=256, num_updates=34300, lr=0.000190901, gnorm=1.766, clip=0, loss_scale=1495, train_wall=149, wall=51452
2022-07-12 22:26:53 | INFO | train_inner | epoch 031:    789 / 1122 loss=4.973, nll_loss=1.919, mask_ins=0.705, word_ins_ml=3.569, word_reposition=0.699, ppl=31.42, wps=13769.5, ups=0.67, wpb=20555.8, bsz=256, num_updates=34400, lr=0.000190623, gnorm=1.699, clip=0, loss_scale=2048, train_wall=148, wall=51601
2022-07-12 22:29:22 | INFO | train_inner | epoch 031:    889 / 1122 loss=4.898, nll_loss=1.846, mask_ins=0.7, word_ins_ml=3.503, word_reposition=0.694, ppl=29.81, wps=13797.4, ups=0.67, wpb=20495.4, bsz=256, num_updates=34500, lr=0.000190347, gnorm=1.692, clip=0, loss_scale=2048, train_wall=148, wall=51750
2022-07-12 22:31:51 | INFO | train_inner | epoch 031:    989 / 1122 loss=4.975, nll_loss=1.914, mask_ins=0.711, word_ins_ml=3.564, word_reposition=0.7, ppl=31.45, wps=13657.6, ups=0.67, wpb=20402.1, bsz=256, num_updates=34600, lr=0.000190071, gnorm=1.763, clip=0, loss_scale=2048, train_wall=149, wall=51899
2022-07-12 22:34:20 | INFO | train_inner | epoch 031:   1089 / 1122 loss=4.942, nll_loss=1.893, mask_ins=0.7, word_ins_ml=3.545, word_reposition=0.696, ppl=30.74, wps=13777.9, ups=0.67, wpb=20539.9, bsz=256, num_updates=34700, lr=0.000189797, gnorm=1.684, clip=0, loss_scale=2048, train_wall=148, wall=52048
2022-07-12 22:35:09 | INFO | train | epoch 031 | loss 4.956 | nll_loss 1.897 | mask_ins 0.709 | word_ins_ml 3.549 | word_reposition 0.699 | ppl 31.05 | wps 13486.3 | ups 0.66 | wpb 20520.9 | bsz 255.8 | num_updates 34733 | lr 0.000189707 | gnorm 1.741 | clip 0 | loss_scale 1509 | train_wall 1665 | wall 52097
2022-07-12 22:35:36 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 9.645 | nll_loss 5.539 | mask_ins 1.503 | word_ins_ml 6.906 | word_reposition 1.237 | ppl 800.82 | wps 37288.8 | wpb 2367.6 | bsz 32 | num_updates 34733 | best_loss 9.641
2022-07-12 22:35:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 31 @ 34733 updates, score 9.645) (writing took 4.731791005469859 seconds)
2022-07-12 22:36:40 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-07-12 22:37:22 | INFO | train_inner | epoch 032:     68 / 1122 loss=4.981, nll_loss=1.913, mask_ins=0.711, word_ins_ml=3.564, word_reposition=0.706, ppl=31.57, wps=11192.6, ups=0.55, wpb=20330.5, bsz=253.8, num_updates=34800, lr=0.000189525, gnorm=1.815, clip=0, loss_scale=2170, train_wall=150, wall=52230
2022-07-12 22:39:51 | INFO | train_inner | epoch 032:    168 / 1122 loss=4.941, nll_loss=1.895, mask_ins=0.702, word_ins_ml=3.547, word_reposition=0.692, ppl=30.72, wps=13753.7, ups=0.67, wpb=20469.9, bsz=256, num_updates=34900, lr=0.000189253, gnorm=1.72, clip=0, loss_scale=2048, train_wall=148, wall=52379
2022-07-12 22:42:20 | INFO | train_inner | epoch 032:    268 / 1122 loss=4.925, nll_loss=1.872, mask_ins=0.701, word_ins_ml=3.527, word_reposition=0.697, ppl=30.39, wps=13777.1, ups=0.67, wpb=20522.5, bsz=256, num_updates=35000, lr=0.000188982, gnorm=1.75, clip=0, loss_scale=2048, train_wall=148, wall=52528
2022-07-12 22:44:49 | INFO | train_inner | epoch 032:    368 / 1122 loss=4.966, nll_loss=1.899, mask_ins=0.715, word_ins_ml=3.551, word_reposition=0.701, ppl=31.25, wps=13846.1, ups=0.67, wpb=20675.9, bsz=256, num_updates=35100, lr=0.000188713, gnorm=1.749, clip=0, loss_scale=2048, train_wall=149, wall=52677
2022-07-12 22:47:18 | INFO | train_inner | epoch 032:    468 / 1122 loss=4.889, nll_loss=1.825, mask_ins=0.71, word_ins_ml=3.485, word_reposition=0.694, ppl=29.63, wps=13935.1, ups=0.67, wpb=20742.9, bsz=256, num_updates=35200, lr=0.000188445, gnorm=1.647, clip=0, loss_scale=2048, train_wall=148, wall=52826
2022-07-12 22:49:47 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2048.0
2022-07-12 22:49:49 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 22:49:50 | INFO | train_inner | epoch 032:    570 / 1122 loss=4.946, nll_loss=1.891, mask_ins=0.707, word_ins_ml=3.544, word_reposition=0.696, ppl=30.83, wps=13496.2, ups=0.66, wpb=20527.3, bsz=256, num_updates=35300, lr=0.000188177, gnorm=1.731, clip=0, loss_scale=2349, train_wall=151, wall=52978
2022-07-12 22:52:20 | INFO | train_inner | epoch 032:    670 / 1122 loss=4.922, nll_loss=1.869, mask_ins=0.704, word_ins_ml=3.524, word_reposition=0.694, ppl=30.31, wps=13662.7, ups=0.67, wpb=20432.4, bsz=256, num_updates=35400, lr=0.000187912, gnorm=1.752, clip=0, loss_scale=1024, train_wall=149, wall=53128
2022-07-12 22:54:49 | INFO | train_inner | epoch 032:    770 / 1122 loss=4.935, nll_loss=1.884, mask_ins=0.703, word_ins_ml=3.537, word_reposition=0.694, ppl=30.59, wps=13662.9, ups=0.67, wpb=20348.1, bsz=256, num_updates=35500, lr=0.000187647, gnorm=1.871, clip=0, loss_scale=1024, train_wall=148, wall=53277
2022-07-12 22:57:18 | INFO | train_inner | epoch 032:    870 / 1122 loss=4.941, nll_loss=1.885, mask_ins=0.708, word_ins_ml=3.538, word_reposition=0.695, ppl=30.71, wps=13679.6, ups=0.67, wpb=20434.9, bsz=256, num_updates=35600, lr=0.000187383, gnorm=1.721, clip=0, loss_scale=1024, train_wall=149, wall=53426
2022-07-12 22:59:47 | INFO | train_inner | epoch 032:    970 / 1122 loss=4.977, nll_loss=1.926, mask_ins=0.703, word_ins_ml=3.574, word_reposition=0.7, ppl=31.5, wps=13814.3, ups=0.67, wpb=20626.7, bsz=256, num_updates=35700, lr=0.00018712, gnorm=1.789, clip=0, loss_scale=1024, train_wall=148, wall=53575
2022-07-12 23:02:17 | INFO | train_inner | epoch 032:   1070 / 1122 loss=4.932, nll_loss=1.865, mask_ins=0.714, word_ins_ml=3.52, word_reposition=0.698, ppl=30.52, wps=13760.5, ups=0.67, wpb=20567.6, bsz=256, num_updates=35800, lr=0.000186859, gnorm=1.74, clip=0, loss_scale=1024, train_wall=149, wall=53725
2022-07-12 23:03:35 | INFO | train | epoch 032 | loss 4.94 | nll_loss 1.884 | mask_ins 0.706 | word_ins_ml 3.537 | word_reposition 0.696 | ppl 30.7 | wps 13461.9 | ups 0.66 | wpb 20519.1 | bsz 255.8 | num_updates 35852 | lr 0.000186723 | gnorm 1.75 | clip 0 | loss_scale 1621 | train_wall 1665 | wall 53803
2022-07-12 23:04:01 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 9.625 | nll_loss 5.463 | mask_ins 1.53 | word_ins_ml 6.83 | word_reposition 1.266 | ppl 789.78 | wps 36945.4 | wpb 2367.6 | bsz 32 | num_updates 35852 | best_loss 9.625
2022-07-12 23:04:10 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_best.pt (epoch 32 @ 35852 updates, score 9.625) (writing took 8.333844721317291 seconds)
2022-07-12 23:05:22 | INFO | train_inner | epoch 033:     48 / 1122 loss=4.963, nll_loss=1.915, mask_ins=0.705, word_ins_ml=3.564, word_reposition=0.694, ppl=31.19, wps=11020.6, ups=0.54, wpb=20416.7, bsz=253.8, num_updates=35900, lr=0.000186598, gnorm=1.752, clip=0, loss_scale=1946, train_wall=149, wall=53910
2022-07-12 23:07:52 | INFO | train_inner | epoch 033:    148 / 1122 loss=4.932, nll_loss=1.883, mask_ins=0.703, word_ins_ml=3.536, word_reposition=0.694, ppl=30.53, wps=13827.6, ups=0.67, wpb=20686.9, bsz=256, num_updates=36000, lr=0.000186339, gnorm=1.682, clip=0, loss_scale=2048, train_wall=149, wall=54060
2022-07-12 23:10:21 | INFO | train_inner | epoch 033:    248 / 1122 loss=4.922, nll_loss=1.869, mask_ins=0.704, word_ins_ml=3.524, word_reposition=0.694, ppl=30.31, wps=13759.7, ups=0.67, wpb=20530.6, bsz=256, num_updates=36100, lr=0.000186081, gnorm=1.758, clip=0, loss_scale=2048, train_wall=148, wall=54209
2022-07-12 23:12:50 | INFO | train_inner | epoch 033:    348 / 1122 loss=4.896, nll_loss=1.845, mask_ins=0.7, word_ins_ml=3.502, word_reposition=0.693, ppl=29.77, wps=13820.3, ups=0.67, wpb=20582.5, bsz=256, num_updates=36200, lr=0.000185824, gnorm=1.68, clip=0, loss_scale=2048, train_wall=148, wall=54358
2022-07-12 23:15:19 | INFO | train_inner | epoch 033:    448 / 1122 loss=4.927, nll_loss=1.884, mask_ins=0.7, word_ins_ml=3.537, word_reposition=0.69, ppl=30.41, wps=13738.7, ups=0.67, wpb=20461.1, bsz=256, num_updates=36300, lr=0.000185567, gnorm=1.68, clip=0, loss_scale=2048, train_wall=148, wall=54507
2022-07-12 23:15:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 23:17:49 | INFO | train_inner | epoch 033:    549 / 1122 loss=4.938, nll_loss=1.899, mask_ins=0.7, word_ins_ml=3.55, word_reposition=0.688, ppl=30.66, wps=13638.7, ups=0.66, wpb=20513, bsz=256, num_updates=36400, lr=0.000185312, gnorm=1.737, clip=0, loss_scale=1054, train_wall=150, wall=54657
2022-07-12 23:20:18 | INFO | train_inner | epoch 033:    649 / 1122 loss=4.927, nll_loss=1.868, mask_ins=0.707, word_ins_ml=3.523, word_reposition=0.698, ppl=30.43, wps=13752.2, ups=0.67, wpb=20476.5, bsz=256, num_updates=36500, lr=0.000185058, gnorm=1.736, clip=0, loss_scale=1024, train_wall=148, wall=54806
2022-07-12 23:22:47 | INFO | train_inner | epoch 033:    749 / 1122 loss=4.924, nll_loss=1.859, mask_ins=0.712, word_ins_ml=3.514, word_reposition=0.697, ppl=30.35, wps=13749, ups=0.67, wpb=20518.4, bsz=256, num_updates=36600, lr=0.000184805, gnorm=1.709, clip=0, loss_scale=1024, train_wall=148, wall=54955
2022-07-12 23:25:16 | INFO | train_inner | epoch 033:    849 / 1122 loss=4.904, nll_loss=1.858, mask_ins=0.7, word_ins_ml=3.514, word_reposition=0.691, ppl=29.95, wps=13736.7, ups=0.67, wpb=20490, bsz=256, num_updates=36700, lr=0.000184553, gnorm=1.764, clip=0, loss_scale=1024, train_wall=148, wall=55104
2022-07-12 23:27:45 | INFO | train_inner | epoch 033:    949 / 1122 loss=4.916, nll_loss=1.868, mask_ins=0.7, word_ins_ml=3.522, word_reposition=0.695, ppl=30.19, wps=13741.5, ups=0.67, wpb=20493.8, bsz=256, num_updates=36800, lr=0.000184302, gnorm=1.729, clip=0, loss_scale=1024, train_wall=148, wall=55253
2022-07-12 23:30:15 | INFO | train_inner | epoch 033:   1049 / 1122 loss=4.958, nll_loss=1.898, mask_ins=0.708, word_ins_ml=3.549, word_reposition=0.702, ppl=31.09, wps=13820.9, ups=0.67, wpb=20628.8, bsz=256, num_updates=36900, lr=0.000184053, gnorm=1.711, clip=0, loss_scale=1905, train_wall=148, wall=55403
2022-07-12 23:32:03 | INFO | train | epoch 033 | loss 4.928 | nll_loss 1.877 | mask_ins 0.703 | word_ins_ml 3.531 | word_reposition 0.694 | ppl 30.45 | wps 13466.7 | ups 0.66 | wpb 20521.3 | bsz 255.8 | num_updates 36973 | lr 0.000183871 | gnorm 1.725 | clip 0 | loss_scale 1581 | train_wall 1663 | wall 55511
2022-07-12 23:32:29 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 9.73 | nll_loss 5.478 | mask_ins 1.514 | word_ins_ml 6.842 | word_reposition 1.374 | ppl 849.38 | wps 37592.5 | wpb 2367.6 | bsz 32 | num_updates 36973 | best_loss 9.625
2022-07-12 23:32:34 | INFO | fairseq.checkpoint_utils | saved checkpoint ../checkpoints_bert_transformer_cased/checkpoint_last.pt (epoch 33 @ 36973 updates, score 9.73) (writing took 4.403481618501246 seconds)
2022-07-12 23:33:14 | INFO | train_inner | epoch 034:     27 / 1122 loss=4.942, nll_loss=1.894, mask_ins=0.701, word_ins_ml=3.546, word_reposition=0.695, ppl=30.74, wps=11328, ups=0.56, wpb=20326, bsz=253.8, num_updates=37000, lr=0.000183804, gnorm=1.768, clip=0, loss_scale=2048, train_wall=148, wall=55582
2022-07-12 23:35:43 | INFO | train_inner | epoch 034:    127 / 1122 loss=4.901, nll_loss=1.842, mask_ins=0.705, word_ins_ml=3.499, word_reposition=0.696, ppl=29.87, wps=13771.7, ups=0.67, wpb=20470.5, bsz=256, num_updates=37100, lr=0.000183556, gnorm=1.671, clip=0, loss_scale=2048, train_wall=148, wall=55731
2022-07-12 23:38:12 | INFO | train_inner | epoch 034:    227 / 1122 loss=4.91, nll_loss=1.876, mask_ins=0.694, word_ins_ml=3.53, word_reposition=0.686, ppl=30.06, wps=13726.4, ups=0.67, wpb=20452.5, bsz=256, num_updates=37200, lr=0.000183309, gnorm=1.752, clip=0, loss_scale=2048, train_wall=148, wall=55880
2022-07-12 23:40:27 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 1024.0
2022-07-12 23:40:42 | INFO | train_inner | epoch 034:    328 / 1122 loss=4.885, nll_loss=1.849, mask_ins=0.698, word_ins_ml=3.505, word_reposition=0.682, ppl=29.54, wps=13607, ups=0.66, wpb=20499.6, bsz=256, num_updates=37300, lr=0.000183063, gnorm=1.818, clip=0, loss_scale=1936, train_wall=150, wall=56030
Traceback (most recent call last):
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/data/yukangliang/实验/BertKpeEditorWithAdaptor/fairseq_cli/train.py", line 369, in cli_main
    torch.multiprocessing.spawn(
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/data/yukangliang/anaconda3/envs/BertKpeEditorWithAdaptor/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 130, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGTERM
train.sh: line 39: keep-best-checkpoints: command not found
